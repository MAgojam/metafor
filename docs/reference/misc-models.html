<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><!-- Inform modern browsers that this page supports both dark and light color schemes,
  and the page author prefers light. --><meta name="color-scheme" content="dark light"><script>
  // If `prefers-color-scheme` is not supported, fall back to light mode.
  // i.e. In this case, inject the `light` CSS before the others, with
  // no media filter so that it will be downloaded with highest priority.
  if (window.matchMedia("(prefers-color-scheme: dark)").media === "not all") {
    document.documentElement.style.display = "none";
    document.head.insertAdjacentHTML(
      "beforeend",
      "<link id=\"css\" rel=\"stylesheet\" href=\"https://bootswatch.com/3/flatly/bootstrap.css\" onload=\"document.documentElement.style.display = ''\">"
    );
  }
</script><title>Fixed-Effects and Random-Effects Models in Meta-Analysis  — misc-models • metafor</title><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- Flatly Theme - Light  --><link id="css-light" rel="stylesheet" href="https://bootswatch.com/3/flatly/bootstrap.css" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><!-- Darkly Theme - Dark --><link id="css-dark" rel="stylesheet" href="https://bootswatch.com/3/darkly/bootstrap.css" media="(prefers-color-scheme: dark)"><!-- preferably CSS --><link rel="stylesheet" href="../preferably.css"><link id="css-code-light" rel="stylesheet" href="../code-color-scheme-light.css" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><link id="css-code-dark" rel="stylesheet" href="../code-color-scheme-dark.css" media="(prefers-color-scheme: dark)"><script src="../darkswitch.js"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="Fixed-Effects and Random-Effects Models in Meta-Analysis  — misc-models"><meta property="og:description" content="Books and articles about meta-analysis often describe and discuss the difference between the so-called &amp;#8216;fixed-effects model&amp;#8217; and the &amp;#8216;random-effects model&amp;#8217; (e.g., Hedges &amp;amp; Olkin, 1985; Cooper et al., 2009). The former term is (mostly) avoided throughout the documentation of the metafor package. The term &amp;#8216;equal-effects model&amp;#8217; is used instead, since it more concretely describes the main assumption underlying this model (i.e., that the underlying true effects/outcomes are homogeneous, or in other words, that they are all equal to each other). The term &amp;#8216;common-effects model&amp;#8217; has also sometimes been used in the literature to describe this model and is equally descriptive.
Moreover, the term &amp;#8216;fixed-effects model&amp;#8217; creates a bit of a conundrum. When authors use this term, they are really typically referring to the equal-effects model. There is however another type of model, the &amp;#8216;real&amp;#8217; fixed-effects model, that is different from the equal-effects model, but now we would need to invent (unnecessarily) a different term to refer to this model. Some have done so or tried to make a distinction between the &amp;#8216;fixed-effect model&amp;#8217; (without the s!) and the &amp;#8216;fixed-effects model&amp;#8217;, but this subtle difference in terminology is easily overlooked/missed. Using the term &amp;#8216;equal-effects model&amp;#8217; avoids this confusion and is more informative.
However, the question then remains what the real fixed-effects model is all about. The purpose of this page is to describe this model and to contrast it with the well-known random-effects model.
Assume we have a set of \(i = 1, \ldots, k\) independent studies and let \(y_i\) denote the observed value of the effect size or outcome measure in the \(i\textrm{th}\) study. Let \(\theta_i\) denote the corresponding (unknown) true effect/outcome, such that \[y_i | \theta_i \sim N(\theta_i, v_i).\] In other words, the observed effect sizes or outcomes are assumed to be unbiased and normally distributed estimates of the corresponding true effects/outcomes with sampling variances equal to \(v_i\). The \(v_i\) values are assumed to be known.
The fixed-effects model is simply given by \[y_i = \theta_i + \epsilon_i,\] where the \(\theta_i\) values are the (fixed) true effects/outcomes of the \(k\) studies. Therefore, the model &amp;#8216;conditions&amp;#8217; on the true effects/outcomes and provides a conditional inference about the \(k\) studies included in the meta-analysis.
When using weighted estimation (the default in rma.uni when method=&quot;FE&quot;), this implies that the fitted model provides an estimate of \[\bar{\theta}_w = \frac{\sum_{i=1}^k w_i \theta_i}{\sum_{i=1}^k w_i},\] that is, the weighted average of the true effects/outcomes in the \(k\) studies, with weights equal to \(w_i = 1/v_i\).
As an example, consider the meta-analysis by Bangert-Drowns et al. (2004) on the effectiveness of writing-to-learn interventions on academic achievement. The dataset (dat.bangertdrowns2004) includes the observed standardized mean differences (variable yi) and the corresponding sampling variances (variable vi) of the 48 studies. We can fit a fixed-effects model to these data with:
# copy data into 'dat'
dat &amp;lt;- dat.bangertdrowns2004

# fit a fixed-effects model
res &amp;lt;- rma(yi, vi, data=dat, method=&quot;FE&quot;)
res

# Fixed-Effects Model (k = 48)
#
# I^2 (total heterogeneity / total variability):   56.12%
# H^2 (total variability / sampling variability):  2.28
#
# Test for Heterogeneity:
# Q(df = 47) = 107.1061, p-val &amp;lt; .0001
#
# Model Results:
#
# estimate      se    zval    pval   ci.lb   ci.ub
#   0.1656  0.0269  6.1499  &amp;lt;.0001  0.1128  0.2184

The Q-test suggests that the underlying true standardized mean differences are heterogeneous \((Q(\textrm{df}=47) = 107.11, p estimate is an estimate of the inverse-variance weighted average of the true standardized mean differences of these 48 studies (i.e., \(\hat{\bar{\theta}}_w = 0.17\)).
One can also employ an unweighted estimation method (by setting weighted=FALSE in rma.uni), which provides an estimate of the unweighted average of the true effects/outcomes in the \(k\) studies, that is, an estimate of \[\bar{\theta}_u = \frac{\sum_{i=1}^k \theta_i}{k}.\]
Returning to the example, we then find:
# fit a fixed-effects model using unweighted estimation
res &amp;lt;- rma(yi, vi, data=dat, method=&quot;FE&quot;, weighted=FALSE)
res

# Fixed-Effects Model (k = 48)
#
# I^2 (total heterogeneity / total variability):   56.12%
# H^2 (total variability / sampling variability):  2.28
#
# Test for Heterogeneity:
# Q(df = 47) = 107.1061, p-val &amp;lt; .0001
#
# Model Results:
#
# estimate      se    zval    pval   ci.lb   ci.ub
#   0.2598  0.0380  6.8366  &amp;lt;.0001  0.1853  0.3343

Therefore, the estimate value is now an estimate of the average of the true standardized mean differences of these 48 studies (i.e., \(\hat{\bar{\theta}}_u = 0.26\)).
For weighted estimation, one could also choose to estimate \(\bar{\theta}_w\), where the \(w_i\) values are user-defined weights (via argument weights in rma.uni). Hence, using inverse-variance weights or unit weights (as in unweighted estimation) are just special cases. It is up to the user to decide to what extent \(\bar{\theta}_w\) is a meaningful parameter to estimate (regardless of the weights used).
For example, we could use the sample sizes as weights:
# fit a fixed-effects model using the sample sizes as weights
res &amp;lt;- rma(yi, vi, data=dat, method=&quot;FE&quot;, weights=ni)
res

# Fixed-Effects Model (k = 48)
#
# I^2 (total heterogeneity / total variability):   56.12%
# H^2 (total variability / sampling variability):  2.28
#
# Test for Heterogeneity:
# Q(df = 47) = 107.1061, p-val &amp;lt; .0001
#
# Model Results:
#
# estimate      se    zval    pval   ci.lb   ci.ub
#   0.1719  0.0269  6.3802  &amp;lt;.0001  0.1191  0.2248

We therefore obtain an estimate of the sample-size weighted average of the true standardized mean differences of these 48 studies (i.e., \(\hat{\bar{\theta}}_w = 0.17\)). Since the sample sizes and the inverse sampling variances are highly correlated (cor(dat$ni, 1/dat$vi) yields 0.999), the results are almost identical to the ones we obtained earlier using inverse-variance weighting.
The random-effects model does not condition on the true effects/outcomes. Instead, the \(k\) studies included in the meta-analysis are assumed to be a random sample from a larger population of studies. In rare cases, the studies included in a meta-analysis are actually sampled from a larger collection of studies. More typically, the collection of studies is a hypothetical population of an essentially infinite set of studies comprising all of the studies that have been conducted, that could have been conducted, or that may be conducted in the future. We assume that \(\theta_i \sim N(\mu, \tau^2)\), that is, the true effects/outcomes in the population of studies are normally distributed with \(\mu\) denoting the average true effect/outcome and \(\tau^2\) the variance of the true effects/outcomes in the population (\(\tau^2\) is therefore often referred to as the amount of &amp;#8216;heterogeneity&amp;#8217; in the true effects/outcomes). The random-effects model can also be written as \[y_i = \mu + u_i + \epsilon_i,\] where \(u_i \sim N(0, \tau^2)\) and \(\epsilon_i \sim N(0, v_i)\). The fitted model provides estimates of \(\mu\) and \(\tau^2\). Consequently, the random-effects model provides an unconditional inference about the average true effect/outcome in the population of studies (from which the \(k\) studies included in the meta-analysis are assumed to be a random sample).
Fitting a random-effects model to the example data yields:
# fit a random-effects model (note: method=&quot;REML&quot; is the default)
res &amp;lt;- rma(yi, vi, data=dat)
res

# Random-Effects Model (k = 48; tau^2 estimator: REML)
#
# tau^2 (estimated amount of total heterogeneity): 0.0499 (SE = 0.0197)
# tau (square root of estimated tau^2 value):      0.2235
# I^2 (total heterogeneity / total variability):   58.37%
# H^2 (total variability / sampling variability):  2.40
#
# Test for Heterogeneity:
# Q(df = 47) = 107.1061, p-val &amp;lt; .0001
#
# Model Results:
#
# estimate      se    zval    pval   ci.lb   ci.ub
#   0.2219  0.0460  4.8209  &amp;lt;.0001  0.1317  0.3122

The value shown under estimate is now an estimate of the average true standardized mean difference of studies in the population of studies from which the 48 studies included in this dataset have come (i.e., \(\hat{\mu}_w = 0.22\)).
When using weighted estimation in the context of a random-effects model, the model is fitted with weights equal to \(w_i = 1/(\tau^2 + v_i)\), with \(\tau^2\) replaced by its estimate (the default in rma.uni when method is set to one of the possible choices for estimating \(\tau^2\)). One can also choose unweighted estimation in the context of the random-effects model (weighted=FALSE) or specify user-defined weights (via weights), although the parameter that is estimated (i.e., \(\mu\)) remains the same regardless of the estimation method and weights used (as opposed to the fixed-effect model, where the parameter estimated is different for weighted versus unweighted estimation or when using different weights than the standard inverse-variance weights). Since weighted estimation with inverse-variance weights is most efficient, it is usually to be preferred for random-effects models (while in the fixed-effect model case, we must carefully consider whether \(\bar{\theta}_w\) or \(\bar{\theta}_u\) is the more meaningful parameter to estimate).
Contrary to what is often stated in the literature, it is important to realize that the fixed-effects model does not assume that the true effects/outcomes are homogeneous (i.e., that \(\theta_i\) is equal to some common value \(\theta\) in all \(k\) studies). In other words, the fixed-effects model provides perfectly valid inferences under heterogeneity, as long as one is restricting these inferences to the set of studies included in the meta-analysis and one realizes that the model does not provide an estimate of \(\theta\) or \(\mu\), but of \(\bar{\theta}_w\) or \(\bar{\theta}_u\) (depending on the estimation method).
In the special case that the true effects/outcomes are actually homogeneous (the equal-effects case), the distinction between the fixed- and random-effects models disappears, since homogeneity implies that \(\mu = \bar{\theta}_w = \bar{\theta}_u \equiv \theta\). However, since there is no infallible method to test whether the true effects/outcomes are really homogeneous or not, a researcher should decide on the type of inference desired before examining the data and choose the model accordingly. In fact, there is nothing wrong with fitting both the fixed- and random-effects models to the same data, since these models address different questions (i.e., what was the average effect in the studies that have been conducted and included in this meta-analysis versus what is the average effect in the larger population of studies?).
Note that fitting an equal-effects model (with method=&quot;EE&quot;) would yield the exact same results as fitting a fixed-effects model, since the equations used to fit these two models are identical. However, the interpretation of the results is different. If we fit an equal-effects model, we make the assumption that the true effects are homogeneous and, if we believe this assumption to be justified, can interpret the estimate as an estimate of the true effect. On the other hand, if we reject the homogeneity assumption, then we should reject the model altogether. In contrast, if we fit a fixed-effects model, we do not assume homogeneity and instead interpret the estimate as an estimate of the (weighted) average true effect of the included studies.
For further discussions of the distinction between the equal-, fixed-, and random-effects models, see Laird and Mosteller (1990) and Hedges and Vevea (1998)."><meta name="twitter:card" content="summary_large_image"><meta name="twitter:creator" content="@wviechtb"><meta name="twitter:site" content="@wviechtb"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body data-spy="scroll" data-target="#toc">
    

    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">metafor</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">3.1-31</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/metafor-package.html">Introduction</a>
</li>
<li>
  <a href="../reference/index.html">Functions</a>
</li>
<li>
  <a href="../articles/pkgdown/diagram.html">Diagram</a>
</li>
<li>
  <a href="https://www.jstatsoft.org/article/view/v036i03" class="external-link">JSS Article</a>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
          <a href="#" id="css-toggle-btn">
            <span class="fas fa-adjust fa-lg"></span>
          </a>
        </li>
        
        <li>
  <a href="https://twitter.com/wviechtb" class="external-link">
    <span class="fa fa-twitter"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/wviechtb/metafor" class="external-link">
    <span class="fa fa-github"></span>
     
  </a>
</li>
        
        


      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Fixed-Effects and Random-Effects Models in Meta-Analysis <script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script></h1>
    
    <div class="hidden name"><code>misc-models.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Books and articles about meta-analysis often describe and discuss the difference between the so-called ‘fixed-effects model’ and the ‘random-effects model’ (e.g., Hedges &amp; Olkin, 1985; Cooper et al., 2009). The former term is (mostly) avoided throughout the documentation of the <span class="pkg">metafor</span> package. The term ‘equal-effects model’ is used instead, since it more concretely describes the main assumption underlying this model (i.e., that the underlying true effects/outcomes are homogeneous, or in other words, that they are all equal to each other). The term ‘common-effects model’ has also sometimes been used in the literature to describe this model and is equally descriptive.</p>
<p>Moreover, the term ‘fixed-effects model’ creates a bit of a conundrum. When authors use this term, they are really typically referring to the equal-effects model. There is however another type of model, the ‘real’ fixed-effects model, that is different from the equal-effects model, but now we would need to invent (unnecessarily) a different term to refer to this model. Some have done so or tried to make a distinction between the ‘fixed-effect model’ (without the s!) and the ‘fixed-effects model’, but this subtle difference in terminology is easily overlooked/missed. Using the term ‘equal-effects model’ avoids this confusion and is more informative.</p>
<p>However, the question then remains what the real fixed-effects model is all about. The purpose of this page is to describe this model and to contrast it with the well-known random-effects model.</p>
<p>Assume we have a set of \(i = 1, \ldots, k\) independent studies and let \(y_i\) denote the observed value of the effect size or outcome measure in the \(i\textrm{th}\) study. Let \(\theta_i\) denote the corresponding (unknown) true effect/outcome, such that \[y_i | \theta_i \sim N(\theta_i, v_i).\] In other words, the observed effect sizes or outcomes are assumed to be unbiased and normally distributed estimates of the corresponding true effects/outcomes with sampling variances equal to \(v_i\). The \(v_i\) values are assumed to be known.</p>
<p>The <b>fixed-effects model</b> is simply given by \[y_i = \theta_i + \epsilon_i,\] where the \(\theta_i\) values are the (fixed) true effects/outcomes of the \(k\) studies. Therefore, the model ‘conditions’ on the true effects/outcomes and provides a <em>conditional inference</em> about the \(k\) studies included in the meta-analysis.</p>
<p>When using weighted estimation (the default in <code><a href="rma.uni.html">rma.uni</a></code> when <code>method="FE"</code>), this implies that the fitted model provides an estimate of \[\bar{\theta}_w = \frac{\sum_{i=1}^k w_i \theta_i}{\sum_{i=1}^k w_i},\] that is, the <em>weighted average</em> of the true effects/outcomes in the \(k\) studies, with weights equal to \(w_i = 1/v_i\).</p>
<p>As an example, consider the meta-analysis by Bangert-Drowns et al. (2004) on the effectiveness of writing-to-learn interventions on academic achievement. The dataset (<code>dat.bangertdrowns2004</code>) includes the observed standardized mean differences (variable <code>yi</code>) and the corresponding sampling variances (variable <code>vi</code>) of the 48 studies. We can fit a fixed-effects model to these data with:</p>
<pre><code># copy data into 'dat'
dat &lt;- dat.bangertdrowns2004

# fit a fixed-effects model
res &lt;- rma(yi, vi, data=dat, method="FE")
res

# Fixed-Effects Model (k = 48)
#
# I^2 (total heterogeneity / total variability):   56.12%
# H^2 (total variability / sampling variability):  2.28
#
# Test for Heterogeneity:
# Q(df = 47) = 107.1061, p-val &lt; .0001
#
# Model Results:
#
# estimate      se    zval    pval   ci.lb   ci.ub
#   0.1656  0.0269  6.1499  &lt;.0001  0.1128  0.2184</code></pre>

<p>The Q-test suggests that the underlying true standardized mean differences are heterogeneous \((Q(\textrm{df}=47) = 107.11, p &lt; .0001).\) Therefore, if we believe this to be true, then the value shown under <code>estimate</code> is an estimate of the inverse-variance weighted average of the true standardized mean differences of these 48 studies (i.e., \(\hat{\bar{\theta}}_w = 0.17\)).</p>
<p>One can also employ an unweighted estimation method (by setting <code>weighted=FALSE</code> in <code><a href="rma.uni.html">rma.uni</a></code>), which provides an estimate of the <em>unweighted average</em> of the true effects/outcomes in the \(k\) studies, that is, an estimate of \[\bar{\theta}_u = \frac{\sum_{i=1}^k \theta_i}{k}.\]</p>
<p>Returning to the example, we then find:</p>
<pre><code># fit a fixed-effects model using unweighted estimation
res &lt;- rma(yi, vi, data=dat, method="FE", weighted=FALSE)
res

# Fixed-Effects Model (k = 48)
#
# I^2 (total heterogeneity / total variability):   56.12%
# H^2 (total variability / sampling variability):  2.28
#
# Test for Heterogeneity:
# Q(df = 47) = 107.1061, p-val &lt; .0001
#
# Model Results:
#
# estimate      se    zval    pval   ci.lb   ci.ub
#   0.2598  0.0380  6.8366  &lt;.0001  0.1853  0.3343</code></pre>

<p>Therefore, the <code>estimate</code> value is now an estimate of the average of the true standardized mean differences of these 48 studies (i.e., \(\hat{\bar{\theta}}_u = 0.26\)).</p>
<p>For weighted estimation, one could also choose to estimate \(\bar{\theta}_w\), where the \(w_i\) values are user-defined weights (via argument <code>weights</code> in <code><a href="rma.uni.html">rma.uni</a></code>). Hence, using inverse-variance weights or unit weights (as in unweighted estimation) are just special cases. It is up to the user to decide to what extent \(\bar{\theta}_w\) is a meaningful parameter to estimate (regardless of the weights used).</p>
<p>For example, we could use the sample sizes as weights:</p>
<pre><code># fit a fixed-effects model using the sample sizes as weights
res &lt;- rma(yi, vi, data=dat, method="FE", weights=ni)
res

# Fixed-Effects Model (k = 48)
#
# I^2 (total heterogeneity / total variability):   56.12%
# H^2 (total variability / sampling variability):  2.28
#
# Test for Heterogeneity:
# Q(df = 47) = 107.1061, p-val &lt; .0001
#
# Model Results:
#
# estimate      se    zval    pval   ci.lb   ci.ub
#   0.1719  0.0269  6.3802  &lt;.0001  0.1191  0.2248</code></pre>

<p>We therefore obtain an estimate of the sample-size weighted average of the true standardized mean differences of these 48 studies (i.e., \(\hat{\bar{\theta}}_w = 0.17\)). Since the sample sizes and the inverse sampling variances are highly correlated (<code>cor(dat$ni, 1/dat$vi)</code> yields <code>0.999</code>), the results are almost identical to the ones we obtained earlier using inverse-variance weighting.</p>
<p>The <b>random-effects model</b> does not condition on the true effects/outcomes. Instead, the \(k\) studies included in the meta-analysis are assumed to be a random sample from a larger population of studies. In rare cases, the studies included in a meta-analysis are actually sampled from a larger collection of studies. More typically, the collection of studies is a hypothetical population of an essentially infinite set of studies comprising all of the studies that have been conducted, that could have been conducted, or that may be conducted in the future. We assume that \(\theta_i \sim N(\mu, \tau^2)\), that is, the true effects/outcomes in the population of studies are normally distributed with \(\mu\) denoting the average true effect/outcome and \(\tau^2\) the variance of the true effects/outcomes in the population (\(\tau^2\) is therefore often referred to as the amount of ‘heterogeneity’ in the true effects/outcomes). The random-effects model can also be written as \[y_i = \mu + u_i + \epsilon_i,\] where \(u_i \sim N(0, \tau^2)\) and \(\epsilon_i \sim N(0, v_i)\). The fitted model provides estimates of \(\mu\) and \(\tau^2\). Consequently, the random-effects model provides an <em>unconditional inference</em> about the average true effect/outcome in the population of studies (from which the \(k\) studies included in the meta-analysis are assumed to be a random sample).</p>
<p>Fitting a random-effects model to the example data yields:</p>
<pre><code># fit a random-effects model (note: method="REML" is the default)
res &lt;- rma(yi, vi, data=dat)
res

# Random-Effects Model (k = 48; tau^2 estimator: REML)
#
# tau^2 (estimated amount of total heterogeneity): 0.0499 (SE = 0.0197)
# tau (square root of estimated tau^2 value):      0.2235
# I^2 (total heterogeneity / total variability):   58.37%
# H^2 (total variability / sampling variability):  2.40
#
# Test for Heterogeneity:
# Q(df = 47) = 107.1061, p-val &lt; .0001
#
# Model Results:
#
# estimate      se    zval    pval   ci.lb   ci.ub
#   0.2219  0.0460  4.8209  &lt;.0001  0.1317  0.3122</code></pre>

<p>The value shown under <code>estimate</code> is now an estimate of the average true standardized mean difference of studies in the population of studies from which the 48 studies included in this dataset have come (i.e., \(\hat{\mu}_w = 0.22\)).</p>
<p>When using weighted estimation in the context of a random-effects model, the model is fitted with weights equal to \(w_i = 1/(\tau^2 + v_i)\), with \(\tau^2\) replaced by its estimate (the default in <code><a href="rma.uni.html">rma.uni</a></code> when <code>method</code> is set to one of the possible choices for estimating \(\tau^2\)). One can also choose unweighted estimation in the context of the random-effects model (<code>weighted=FALSE</code>) or specify user-defined weights (via <code>weights</code>), although the parameter that is estimated (i.e., \(\mu\)) remains the same regardless of the estimation method and weights used (as opposed to the fixed-effect model, where the parameter estimated is different for weighted versus unweighted estimation or when using different weights than the standard inverse-variance weights). Since weighted estimation with inverse-variance weights is most efficient, it is usually to be preferred for random-effects models (while in the fixed-effect model case, we must carefully consider whether \(\bar{\theta}_w\) or \(\bar{\theta}_u\) is the more meaningful parameter to estimate).</p>
<p>Contrary to what is often stated in the literature, it is important to realize that the fixed-effects model does <em>not</em> assume that the true effects/outcomes are homogeneous (i.e., that \(\theta_i\) is equal to some common value \(\theta\) in all \(k\) studies). In other words, the fixed-effects model provides perfectly valid inferences under heterogeneity, as long as one is restricting these inferences to the set of studies included in the meta-analysis and one realizes that the model does not provide an estimate of \(\theta\) or \(\mu\), but of \(\bar{\theta}_w\) or \(\bar{\theta}_u\) (depending on the estimation method).</p>
<p>In the special case that the true effects/outcomes are actually homogeneous (the equal-effects case), the distinction between the fixed- and random-effects models disappears, since homogeneity implies that \(\mu = \bar{\theta}_w = \bar{\theta}_u \equiv \theta\). However, since there is no infallible method to test whether the true effects/outcomes are really homogeneous or not, a researcher should decide on the type of inference desired before examining the data and choose the model accordingly. In fact, there is nothing wrong with fitting both the fixed- and random-effects models to the same data, since these models address different questions (i.e., what was the average effect in the studies that have been conducted and included in this meta-analysis versus what is the average effect in the larger population of studies?).</p>
<p>Note that fitting an equal-effects model (with <code>method="EE"</code>) would yield the exact same results as fitting a fixed-effects model, since the equations used to fit these two models are identical. However, the interpretation of the results is different. If we fit an equal-effects model, we make the assumption that the true effects are homogeneous and, if we believe this assumption to be justified, can interpret the estimate as an estimate of <em>the</em> true effect. On the other hand, if we reject the homogeneity assumption, then we should reject the model altogether. In contrast, if we fit a fixed-effects model, we do not assume homogeneity and instead interpret the estimate as an estimate of the (weighted) average true effect of the included studies.</p>
<p>For further discussions of the distinction between the equal-, fixed-, and random-effects models, see Laird and Mosteller (1990) and Hedges and Vevea (1998).</p>
    </div>


    <div id="ref-sections">
    <div id="author">
    <h2>Author</h2>
    <p>Wolfgang Viechtbauer <a href="mailto:wvb@metafor-project.org">wvb@metafor-project.org</a> <a href="https://www.metafor-project.org" class="external-link">https://www.metafor-project.org</a></p>
    </div>
    <div id="references">
    <h2>References</h2>
    <p>Cooper, H., Hedges, L. V., &amp; Valentine, J. C. (Eds.) (2009). <em>The handbook of research synthesis and meta-analysis</em> (2nd ed.). New York: Russell Sage Foundation.</p>
<p>Hedges, L. V., &amp; Olkin, I. (1985). <em>Statistical methods for meta-analysis</em>. San Diego, CA: Academic Press.</p>
<p>Hedges, L. V., &amp; Vevea, J. L. (1998). Fixed- and random-effects models in meta-analysis. <em>Psychological Methods</em>, <b>3</b>(4), 486--504. <a href="https://doi.org/10.1037/1082-989X.3.4.486" class="external-link">https://doi.org/10.1037/1082-989X.3.4.486</a></p>
<p>Laird, N. M., &amp; Mosteller, F. (1990). Some statistical methods for combining experimental results. <em>International Journal of Technology Assessment in Health Care</em>, <b>6</b>(1), 5--30. <a href="https://doi.org/10.1017/S0266462300008916" class="external-link">https://doi.org/10.1017/S0266462300008916</a></p>
<p>Viechtbauer, W. (2010). Conducting meta-analyses in R with the metafor package. <em>Journal of Statistical Software</em>, <b>36</b>(3), 1--48. <a href="https://doi.org/10.18637/jss.v036.i03" class="external-link">https://doi.org/10.18637/jss.v036.i03</a></p>
    </div>
    </div>

  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p>Developed by .</p>
</div>

<div class="pkgdown">
  <p>Made with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> , using <a href="https://preferably.amirmasoudabdol.name/?source=footer" class="external-link">preferably</a> template.</p>
</div>

      </footer></div>

  


  

  </body></html>

