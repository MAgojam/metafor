[{"path":"/ISSUE_TEMPLATE.html","id":"classification","dir":"","previous_headings":"","what":"Classification:","title":"NA","text":"(Pick one : Bug Report, Feature Request, Enhancement Suggestion) General questions use metafor package asked , r-sig-meta-analysis mailing list (https://stat.ethz.ch/mailman/listinfo/r-sig-meta-analysis). Anything posted really related development package (including potential bug reports).","code":""},{"path":"/ISSUE_TEMPLATE.html","id":"summary","dir":"","previous_headings":"","what":"Summary","title":"NA","text":"Summary problem.","code":""},{"path":"/ISSUE_TEMPLATE.html","id":"reproducible-example-if-applicable","dir":"","previous_headings":"","what":"Reproducible Example (if applicable)","title":"NA","text":"applicable, please provide minimal fully reproducible example. Remove superfluous code pertinent issue hand provide small dataset together code can actually run (dput() function extremely useful ; use one datasets comes metafor package). See also: http://adv-r..co.nz/Reproducibility.html https://stackoverflow.com/questions/5963269/--make--great-r-reproducible-example https://cran.r-project.org/web/packages/reprex/vignettes/reprex-dos--donts.html","code":"# use this for posting code (if applicable) # use this for posting output (if applicable)"},{"path":"/ISSUE_TEMPLATE.html","id":"notes","dir":"","previous_headings":"","what":"Notes","title":"NA","text":"Describe debugging steps ’ve taken . ’ve found workaround, please provide .","code":""},{"path":"/ISSUE_TEMPLATE.html","id":"sessioninfo","dir":"","previous_headings":"","what":"sessionInfo()","title":"NA","text":"Post output sessionInfo() :","code":"# put output here"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Wolfgang Viechtbauer. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1-48. https://doi.org/10.18637/jss.v036.i03","code":"@Article{,   title = {Conducting meta-analyses in {R} with the {metafor} package},   author = {Wolfgang Viechtbauer},   journal = {Journal of Statistical Software},   year = {2010},   volume = {36},   number = {3},   pages = {1--48},   url = {https://doi.org/10.18637/jss.v036.i03}, }"},{"path":[]},{"path":"/index.html","id":"description","dir":"","previous_headings":"","what":"Description","title":"Meta-Analysis Package for R","text":"metafor package comprehensive collection functions conducting meta-analyses R. package includes functions calculate various effect sizes outcome measures, fit equal-, fixed-, random-, mixed-effects models data, carry moderator meta-regression analyses, create various types meta-analytical plots (e.g., forest, funnel, radial, L’Abbé, Baujat, bubble, GOSH plots). meta-analyses binomial person-time data, package also provides functions implement specialized methods, including Mantel-Haenszel method, Peto’s method, variety suitable generalized linear (mixed-effects) models (.e., mixed-effects logistic Poisson regression models). Finally, package provides functionality fitting meta-analytic multivariate/multilevel models account non-independent sampling errors /true effects (e.g., due inclusion multiple treatment studies, multiple endpoints, forms clustering). Network meta-analyses meta-analyses accounting known correlation structures (e.g., due phylogenetic relatedness) can also conducted.","code":""},{"path":"/index.html","id":"package-website","dir":"","previous_headings":"","what":"Package Website","title":"Meta-Analysis Package for R","text":"metafor package website can found https://www.metafor-project.org. website, can find: news concerning package /development, detailed description package features, log package updates made years, -list description planned features implemented future, information download install package, information obtain documentation help using package, analysis examples illustrate various models, methods, techniques, little showcase plots figures can created package, tips notes may useful working package, list people shape form contributed development package, frequently asked questions section, links websites related software meta-analysis.","code":""},{"path":"/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Meta-Analysis Package for R","text":"good starting place interested using metafor package following paper: Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1-48. https://doi.org/10.18637/jss.v036.i03 addition reading paper, carefully read package intro help pages escalc rma.uni functions (rma.mh, rma.peto, rma.glmm, rma.mv functions intend use methods). help pages functions provide links many additional functions, can used fitting model. can also read entire documentation online https://wviechtb.github.io/metafor/ (nicely formatted, equations shown correctly, output examples provided).","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Meta-Analysis Package for R","text":"current official (.e., CRAN) release can installed within R : development version package can installed : builds package source based current version GitHub.","code":"install.packages(\"metafor\") install.packages(\"remotes\") remotes::install_github(\"wviechtb/metafor\")"},{"path":"/index.html","id":"meta","dir":"","previous_headings":"","what":"Meta","title":"Meta-Analysis Package for R","text":"metafor package written Wolfgang Viechtbauer. licensed GNU General Public License. citation info, type citation(package='metafor') R. report issues bugs suggest enhancements package, please go .","code":""},{"path":"/reference/addpoly.default.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Polygons to Forest Plots (Default Method) — addpoly.default","title":"Add Polygons to Forest Plots (Default Method) — addpoly.default","text":"Function add one polygons forest plot.","code":""},{"path":"/reference/addpoly.default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Polygons to Forest Plots (Default Method) — addpoly.default","text":"","code":"# S3 method for default addpoly(x, vi, sei, ci.lb, ci.ub, pi.lb, pi.ub,         rows=-1, level=95, annotate=TRUE, digits=2, width, mlab,         transf, atransf, targs, efac=1, col, border, lty, fonts, cex, ...)"},{"path":"/reference/addpoly.default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Polygons to Forest Plots (Default Method) — addpoly.default","text":"x vector values polygons drawn. vi vector corresponding variances. sei vector corresponding standard errors (note: one two, vi sei, needs specified). ci.lb vector corresponding lower confidence interval bounds. needed vi sei specified. See ‘Details’. ci.ub vector corresponding upper confidence interval bounds. needed vi sei specified. See ‘Details’. pi.lb optional vector corresponding lower prediction interval bounds. pi.ub optional vector corresponding upper prediction interval bounds. rows vector specify rows (generally, horizontal positions) plotting polygons (defaults -1). Can also single value specify row (horizontal position) first polygon (remaining polygons plotted starting row). level numeric value 0 100 specify confidence interval level (default 95). annotate logical specify whether annotations added plot polygons drawn (default TRUE). digits integer specify number decimal places annotations rounded (default 2). width optional integer manually adjust width columns annotations. mlab optional character vector length x giving labels polygons drawn. transf optional argument specify function used transform x values confidence interval bounds (e.g., transf=exp; see also transf). unspecified, transformation used. atransf optional argument specify function used transform annotations (e.g., atransf=exp; see also transf). unspecified, transformation used. targs optional arguments needed function specified via transf atransf. efac vertical expansion factor polygons. default value 1 usually work okay. col optional character string specify name color use polygons. unspecified, function sets default color. border optional character string specify name color use border polygons. unspecified, function sets default color. lty optional character string specify line type prediction interval. unspecified, function sets \"dotted\" default. fonts optional character string specify font use labels annotations. unspecified, default font used. cex optional symbol expansion factor. unspecified, function tries set sensible value. ... arguments.","code":""},{"path":"/reference/addpoly.default.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add Polygons to Forest Plots (Default Method) — addpoly.default","text":"function can used add one polygons existing forest plot created forest function. example, summary estimates based model involving moderators can added plot way (see ‘Examples’). use function, one specify values polygons drawn (via x argument) together corresponding variances (via vi argument) corresponding standard errors (via sei argument). Alternatively, one can specify values polygons drawn together corresponding confidence interval bounds (via ci.lb ci.ub arguments). Optionally, one can also specify bounds corresponding prediction interval bounds via pi.lb pi.ub arguments. arguments transf, atransf, efac, cex always set equal values used create forest plot.","code":""},{"path":"/reference/addpoly.default.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Add Polygons to Forest Plots (Default Method) — addpoly.default","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/addpoly.default.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Add Polygons to Forest Plots (Default Method) — addpoly.default","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/addpoly.default.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Polygons to Forest Plots (Default Method) — addpoly.default","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit mixed-effects model with absolute latitude as a moderator res <- rma(yi, vi, mods = ~ ablat, slab=paste(author, year, sep=\", \"), data=dat)  ### forest plot of the observed risk ratios forest(res, addfit=FALSE, atransf=exp, xlim=c(-8,5), ylim=c(-4.5,16), cex=.8,        order=dat$ablat, ilab=dat$ablat, ilab.xpos=-4,        header=\"Author(s) and Year\")  ### predicted average log risk ratios for 10, 30, and 50 degrees absolute latitude x <- predict(res, newmods=c(10, 30, 50))  ### add predicted average risk ratios to forest plot addpoly(x$pred, sei=x$se, atransf=exp, rows=-2,         mlab=c(\"- at 10 Degrees\", \"- at 30 Degrees\", \"- at 50 Degrees\"), cex=.8) abline(h=0) text(-8, -1, \"Model-Based Estimates:\", pos=4, cex=.8) text(-4, 15, \"Latitude\", cex=.8, font=2)"},{"path":"/reference/addpoly.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Polygons to Forest Plots — addpoly","title":"Add Polygons to Forest Plots — addpoly","text":"addpoly function can used add polygons, sometimes called ‘diamonds’, forest plot, example indicate summary estimates subgroups studies indicate fitted/predicted values based models involving moderators.","code":""},{"path":"/reference/addpoly.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Polygons to Forest Plots — addpoly","text":"","code":"addpoly(x, ...)"},{"path":"/reference/addpoly.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Polygons to Forest Plots — addpoly","text":"x either object class \"rma\" values polygons drawn. See ‘Details’. ... arguments.","code":""},{"path":"/reference/addpoly.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add Polygons to Forest Plots — addpoly","text":"Currently, methods exist two types situations. first case, object x fitted model coming rma.uni, rma.mh, rma.peto, rma.glmm functions. model must either equal- random-effects model, , model contain moderators. corresponding method called addpoly.rma. can used add polygon existing forest plot (usually bottom), showing summary estimate (confidence interval) based fitted model. Alternatively, object x can vector values one polygons drawn. corresponding method addpoly.default.","code":""},{"path":"/reference/addpoly.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Add Polygons to Forest Plots — addpoly","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/addpoly.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Add Polygons to Forest Plots — addpoly","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/addpoly.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Polygons to Forest Plots (Method for 'rma' Objects) — addpoly.rma","title":"Add Polygons to Forest Plots (Method for 'rma' Objects) — addpoly.rma","text":"Function add polygon forest plot showing summary estimate corresponding confidence interval based object class \"rma\".","code":""},{"path":"/reference/addpoly.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Polygons to Forest Plots (Method for 'rma' Objects) — addpoly.rma","text":"","code":"# S3 method for rma addpoly(x, row=-2, level=x$level, annotate=TRUE,         addpred=FALSE, digits=2, width, mlab, transf, atransf, targs,         efac=1, col, border, lty, fonts, cex, ...)"},{"path":"/reference/addpoly.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Polygons to Forest Plots (Method for 'rma' Objects) — addpoly.rma","text":"x object class \"rma\". row numeric value specify row (generally, horizontal position) plotting polygon (default -2). level numeric value 0 100 specify confidence interval level (default take value object). annotate logical specify whether annotations summary estimate added plot (default TRUE). addpred logical specify whether bounds prediction interval added plot (default FALSE). digits integer specify number decimal places annotations rounded (default 2). width optional integer manually adjust width columns annotations. mlab optional character string giving label summary estimate polygon. unspecified, function sets default label. transf optional argument specify function used transform summary estimate confidence interval bound (e.g., transf=exp; see also transf). unspecified, transformation used. atransf optional argument specify function used transform annotations (e.g., atransf=exp; see also transf). unspecified, transformation used. targs optional arguments needed function specified via transf atransf. efac vertical expansion factor polygon. default value 1 usually work okay. col optional character string specify name color use polygon. unspecified, function sets default color. border optional character string specify name color use border polygon. unspecified, function sets default color. lty optional character string specify line type prediction interval. unspecified, function sets \"dotted\" default. fonts optional character string specify font use label annotations. unspecified, default font used. cex optional symbol expansion factor. unspecified, function tries set sensible value. ... arguments.","code":""},{"path":"/reference/addpoly.rma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add Polygons to Forest Plots (Method for 'rma' Objects) — addpoly.rma","text":"function can used add four-sided polygon, sometimes called summary ‘diamond’, existing forest plot created forest function. polygon shows summary estimate (confidence interval bounds) based equal- random-effects model. Using function, summary estimates based different types models can shown plot. Also, summary estimates based subgrouping studies can added plot way. See ‘Examples’. arguments transf, atransf, efac, cex always set equal values used create forest plot.","code":""},{"path":"/reference/addpoly.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Add Polygons to Forest Plots (Method for 'rma' Objects) — addpoly.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/addpoly.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Add Polygons to Forest Plots (Method for 'rma' Objects) — addpoly.rma","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/addpoly.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Polygons to Forest Plots (Method for 'rma' Objects) — addpoly.rma","text":"","code":"### meta-analysis of the log risk ratios using the Mantel-Haenszel method res <- rma.mh(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg,               slab=paste(author, year, sep=\", \"))  ### forest plot of the observed risk ratios with summary estimate forest(res, atransf=exp, xlim=c(-8,6), ylim=c(-2.5,16), header=TRUE)  ### meta-analysis of the log risk ratios using a random-effects model res <- rma(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### add summary estimate from the random-effects model to the forest plot addpoly(res, atransf=exp)   ### forest plot with subgrouping of studies and summaries per subgroup res <- rma(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg,            slab=paste(author, year, sep=\", \")) forest(res, xlim=c(-16, 4.6), at=log(c(.05, .25, 1, 4)), atransf=exp,        ilab=cbind(dat.bcg$tpos, dat.bcg$tneg, dat.bcg$cpos, dat.bcg$cneg),        ilab.xpos=c(-9.5,-8,-6,-4.5), cex=.75, ylim=c(-1, 27),        order=dat.bcg$alloc, rows=c(3:4,9:15,20:23),        mlab=\"RE Model for All Studies\", header=\"Author(s) and Year\") op <- par(cex=.75, font=2) text(c(-9.5,-8,-6,-4.5), 26, c(\"TB+\", \"TB-\", \"TB+\", \"TB-\")) text(c(-8.75,-5.25),     27, c(\"Vaccinated\", \"Control\")) par(font=4) text(-16, c(24,16,5), c(\"Systematic Allocation\", \"Random Allocation\",                         \"Alternate Allocation\"), pos=4) par(op) res <- rma(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg,            subset=(alloc==\"systematic\")) addpoly(res, row=18.5, cex=.75, atransf=exp, mlab=\"RE Model for Subgroup\") res <- rma(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg,            subset=(alloc==\"random\")) addpoly(res, row=7.5, cex=.75, atransf=exp, mlab=\"RE Model for Subgroup\") res <- rma(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg,            subset=(alloc==\"alternate\")) addpoly(res, row=1.5, cex=.75, atransf=exp, mlab=\"RE Model for Subgroup\")"},{"path":"/reference/aggregate.escalc.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate Multiple Effect Sizes or Outcomes Within Studies — aggregate.escalc","title":"Aggregate Multiple Effect Sizes or Outcomes Within Studies — aggregate.escalc","text":"function can used aggregate multiple effect sizes outcomes belonging study (level clustering variable) single combined effect size outcome.","code":""},{"path":"/reference/aggregate.escalc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate Multiple Effect Sizes or Outcomes Within Studies — aggregate.escalc","text":"","code":"# S3 method for escalc aggregate(x, cluster, time, obs, V, struct=\"CS\", rho, phi,           weighted=TRUE, checkpd=TRUE, fun, na.rm=TRUE, subset, select, digits, ...)"},{"path":"/reference/aggregate.escalc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate Multiple Effect Sizes or Outcomes Within Studies — aggregate.escalc","text":"x object class \"escalc\". cluster vector specify clustering variable (e.g., study). time optional vector specify time points (relevant struct=\"CAR\", \"CS+CAR\", \"CS*CAR\"). obs optional vector distinguish different observed effect sizes outcomes measured time point (relevant struct=\"CS*CAR\"). V optional argument specify variance-covariance matrix sampling errors. specified, argument struct used specify variance-covariance structure. struct character string specify variance-covariance structure sampling errors within cluster (either \"ID\", \"CS\", \"CAR\", \"CS+CAR\", \"CS*CAR\"). See ‘Details’. rho value correlation sampling errors within clusters (struct=\"CS\", \"CS+CAR\", \"CS*CAR\"). Can also vector value correlation cluster. phi value autocorrelation sampling errors within clusters (struct=\"CAR\", \"CS+CAR\", \"CS*CAR\"). Can also vector value autocorrelation cluster. weighted logical specify whether estimates within clusters aggregated using inverse-variance weighting (default TRUE). set FALSE, unweighted averages computed. checkpd logical specify whether check variance-covariance matrices sampling errors within clusters positive definite (default TRUE). fun optional list three functions aggregating variables besides effect sizes outcomes within clusters (numeric/integer variables, logicals, types, respectively). na.rm logical specify whether NA values removed aggregating values within clusters. Can also vector two logicals (first pertaining effect sizes outcomes, second variables). subset optional (logical numeric) vector specify subset rows include aggregating effect sizes outcomes. select optional vector specify names variables include aggregated dataset. digits optional integer specify number decimal places printed results rounded (default take value object). ... arguments.","code":""},{"path":"/reference/aggregate.escalc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Aggregate Multiple Effect Sizes or Outcomes Within Studies — aggregate.escalc","text":"many meta-analyses, multiple effect sizes outcomes can extracted study. Ideally, structures analyzed using appropriate multilevel/multivariate model can fitted rma.mv function. However, may occasionally reasons aggregating multiple effect sizes outcomes belonging study (level clustering variable) single combined effect size outcome. present function can used purpose. input must object class \"escalc\". error ‘Error match.fun(FUN): argument \"FUN\" missing, default’ indicates regular data frame passed function, work. One can turn regular data frame (containing effect sizes outcomes corresponding sampling variances) \"escalc\" object escalc function. See ‘Examples’ illustration . cluster variable used specify estimates/outcomes belong study/cluster. simplest case, estimates/outcomes within clusters (, precise, sampling errors) assumed independent. usually safe assumption long study participant (whatever study units ) contributes data single estimate/outcome. example, study provides effect size estimates male female subjects separately, sampling errors can usually assumed independent. case, one can set struct=\"ID\" multiple estimates/outcomes within cluster combined using standard inverse-variance weighting (.e., using weighted least squares) assumption independence. cases, estimates/outcomes within clusters assumed independent. example, multiple effect size estimates computed group subjects (e.g., based different scales measure construct interest), estimates likely correlated. actual correlation estimates unknown, one can often still make educated guess set argument rho value, assumed pairs estimates within clusters struct=\"CS\" (compound symmetric structure). Multiple estimates/outcomes within cluster combined using inverse-variance weighting taking correlation consideration (.e., using generalized least squares). One can also specify different value rho cluster passing vector (length number clusters) argument. multiple effect size estimates computed group subjects different time points, may sensible assume correlation estimates decreases function distance time points. , one can specify struct=\"CAR\" (continuous-time autoregressive structure), set phi autocorrelation (two estimates one time-unit apart), use argument time specify actual time points corresponding estimates. correlation two estimates, \\(y_{}\\) \\(y_{'}\\), \\(\\textrm{th}\\) cluster, time points \\(\\textrm{time}_{}\\) \\(\\textrm{time}_{'}\\), given \\(\\phi^{|\\textrm{time}_{} - \\textrm{time}_{'}|}\\). One can also specify different value phi cluster passing vector (length number clusters) argument. One can also combine compound symmetric autoregressive structures multiple time points multiple observed effect sizes outcomes time points. One option struct=\"CS+CAR\". case, one must specify time argument rho phi. correlation two estimates, \\(y_{}\\) \\(y_{'}\\), \\(\\textrm{th}\\) cluster, time points \\(\\textrm{time}_{}\\) \\(\\textrm{time}_{'}\\), given \\(\\rho + (1 - \\rho) \\phi^{|\\textrm{time}_{} - \\textrm{time}_{'}|}\\). Alternatively, one can specify struct=\"CS*CAR\". case, one must specify time obs arguments rho phi. correlation two estimates, \\(y_{ijt}\\) \\(y_{ijt'}\\), value obs different values time, given \\(\\phi^{|\\textrm{time}_{ijt} - \\textrm{time}_{ijt'}|}\\), correlation two estimates, \\(y_{ijt}\\) \\(y_{ij't}\\), different values obs value time, given \\(\\rho\\), correlation two estimates, \\(y_{ijt}\\) \\(y_{ij't'}\\), different values obs different values time, given \\(\\rho \\times \\phi^{|\\textrm{time}_{ijt} - \\textrm{time}_{ijt'}|}\\). Finally, one actually knows correlation (hence covariance) pair estimates (approximation thereof), one can also specify entire variance-covariance matrix estimates (precisely, sampling errors) via V argument (case, arguments struct, time, obs, rho, phi ignored). Note vcalc function can used construct V matrix provides even flexibility specifying various types dependencies. See ‘Examples’ illustration . Instead using inverse-variance weighting (.e., weighted/generalized least squares) combine estimates within clusters, one can set weighted=FALSE case estimates averaged within clusters without weighting (although correlations estimates specified still taken consideration). variables (besides estimates) also aggregated cluster level. default, numeric/integer type variables averaged, logicals also averaged (yielding proportion TRUE values), types variables (e.g., character variables factors) frequent category/level returned. One can also specify list three functions via fun argument aggregating variables belonging three types. Argument na.rm controls missing values handled. default, missing estimates first removed aggregating non-missing values within cluster. applies aggregating variables. One can also specify vector two logicals na.rm argument control missing values handled aggregating estimates aggregating variables.","code":""},{"path":"/reference/aggregate.escalc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregate Multiple Effect Sizes or Outcomes Within Studies — aggregate.escalc","text":"object class c(\"escalc\",\"data.frame\") contains (selected) variables aggregated cluster level.    object formatted printed print function.","code":""},{"path":"/reference/aggregate.escalc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Aggregate Multiple Effect Sizes or Outcomes Within Studies — aggregate.escalc","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/aggregate.escalc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Aggregate Multiple Effect Sizes or Outcomes Within Studies — aggregate.escalc","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/aggregate.escalc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Aggregate Multiple Effect Sizes or Outcomes Within Studies — aggregate.escalc","text":"","code":"### copy data into 'dat' and examine data dat <- dat.konstantopoulos2011 head(dat, 11) #>  #>    district school study year     yi    vi  #> 1        11      1     1 1976 -0.180 0.118  #> 2        11      2     2 1976 -0.220 0.118  #> 3        11      3     3 1976  0.230 0.144  #> 4        11      4     4 1976 -0.300 0.144  #> 5        12      1     5 1989  0.130 0.014  #> 6        12      2     6 1989 -0.260 0.014  #> 7        12      3     7 1989  0.190 0.015  #> 8        12      4     8 1989  0.320 0.024  #> 9        18      1     9 1994  0.450 0.023  #> 10       18      2    10 1994  0.380 0.043  #> 11       18      3    11 1994  0.290 0.012  #>   ### aggregate estimates to the district level, assuming independent sampling ### errors for multiples studies/schools within the same district agg <- aggregate(dat, cluster=district, struct=\"ID\") agg #>  #>    district school study   year     yi    vi  #> 1        11    2.5   2.5 1976.0 -0.126 0.032  #> 2        12    2.5   6.5 1989.0  0.067 0.004  #> 3        18    2.0  10.0 1994.0  0.350 0.007  #> 4        27    2.5  13.5 1976.0  0.500 0.001  #> 5        56    2.5  17.5 1997.0  0.051 0.002  #> 6        58    6.0  25.0 1976.0 -0.042 0.001  #> 7        71    2.0  32.0 1997.0  0.886 0.004  #> 8        86    4.5  37.5 1997.0 -0.029 0.000  #> 9        91    3.5  44.5 2000.0  0.250 0.002  #> 10      108    3.0  50.0 2000.0  0.015 0.006  #> 11      644    2.5  54.5 1994.5  0.162 0.019  #>   ### copy data into 'dat' and examine data dat <- dat.assink2016 head(dat, 19) #>    study esid id      yi     vi pubstatus year deltype #> 1      1    1  1  0.9066 0.0740         1  4.5 general #> 2      1    2  2  0.4295 0.0398         1  4.5 general #> 3      1    3  3  0.2679 0.0481         1  4.5 general #> 4      1    4  4  0.2078 0.0239         1  4.5 general #> 5      1    5  5  0.0526 0.0331         1  4.5 general #> 6      1    6  6 -0.0507 0.0886         1  4.5 general #> 7      2    1  7  0.5117 0.0115         1  1.5 general #> 8      2    2  8  0.4738 0.0076         1  1.5 general #> 9      2    3  9  0.3544 0.0065         1  1.5 general #> 10     3    1 10  2.2844 0.3325         1 -8.5 general #> 11     3    2 11  2.1771 0.3073         1 -8.5 general #> 12     3    3 12  1.7777 0.2697         1 -8.5 general #> 13     3    4 13  1.5480 0.4533         1 -8.5 general #> 14     3    5 14  1.4855 0.1167         1 -6.5 general #> 15     3    6 15  1.4836 0.1706         1 -6.5 general #> 16     3    7 16  1.2777 0.1538         1 -8.5 general #> 17     3    8 17  1.0311 0.3132         1 -8.5 general #> 18     3    9 18  0.9409 0.1487         1 -6.5 general #> 19     3   10 19  0.6263 0.2139         1 -6.5 general  ### note: 'dat' is a regular data frame class(dat) #> [1] \"data.frame\"  ### turn data frame into an 'escalc' object dat <- escalc(yi=yi, vi=vi, data=dat) class(dat) #> [1] \"escalc\"     \"data.frame\"  ### aggregate the estimates to the study level, assuming a CS structure for ### the sampling errors within studies with a correlation of 0.6 agg <- aggregate(dat, cluster=study, rho=0.6) agg #>  #>    study esid   id      yi     vi pubstatus  year deltype  #> 1      1  3.5  3.5  0.1629 0.0197         1   4.5 general  #> 2      2  2.0  8.0  0.4060 0.0056         1   1.5 general  #> 3      3  5.5 14.5  1.0790 0.0832         1  -7.7 general  #> 4      4  1.0 20.0 -0.0447 0.0331         1  -7.5 general  #> 5      5  1.0 21.0  1.5490 0.1384         1 -11.5 general  #> 6      6  3.0 24.0 -0.0550 0.0214         1   5.5 general  #> 7      7  3.5 29.5  1.0072 0.0545         1   3.5 general  #> 8      8  1.0 33.0  0.3695 0.0199         1   1.5 general  #> 9      9  1.5 34.5  0.1379 0.0271         1   5.5 general  #> 10    10  3.0 38.0  0.1167 0.0107         1   4.5 general  #> 11    11 11.5 51.5  0.5258 0.0114         0  -6.5 general  #> 12    12  3.0 65.0  0.2805 0.0028         0   4.5   overt  #> 13    13  1.5 68.5  0.3018 0.0110         1  -3.5 general  #> 14    14  3.5 72.5  0.0356 0.0014         1  -1.5 general  #> 15    15  2.0 77.0  0.0908 0.1269         1 -13.5 general  #> 16    16  8.5 86.5  0.0181 0.0169         1   2.5  covert  #> 17    17  3.5 97.5 -0.0552 0.0072         1   5.5 general  #>   ### use vcalc() and then the V argument V <- vcalc(vi, cluster=study, obs=esid, data=dat, rho=0.6) agg <- aggregate(dat, cluster=study, V=V) agg #>  #>    study esid   id      yi     vi pubstatus  year deltype  #> 1      1  3.5  3.5  0.1629 0.0197         1   4.5 general  #> 2      2  2.0  8.0  0.4060 0.0056         1   1.5 general  #> 3      3  5.5 14.5  1.0790 0.0832         1  -7.7 general  #> 4      4  1.0 20.0 -0.0447 0.0331         1  -7.5 general  #> 5      5  1.0 21.0  1.5490 0.1384         1 -11.5 general  #> 6      6  3.0 24.0 -0.0550 0.0214         1   5.5 general  #> 7      7  3.5 29.5  1.0072 0.0545         1   3.5 general  #> 8      8  1.0 33.0  0.3695 0.0199         1   1.5 general  #> 9      9  1.5 34.5  0.1379 0.0271         1   5.5 general  #> 10    10  3.0 38.0  0.1167 0.0107         1   4.5 general  #> 11    11 11.5 51.5  0.5258 0.0114         0  -6.5 general  #> 12    12  3.0 65.0  0.2805 0.0028         0   4.5   overt  #> 13    13  1.5 68.5  0.3018 0.0110         1  -3.5 general  #> 14    14  3.5 72.5  0.0356 0.0014         1  -1.5 general  #> 15    15  2.0 77.0  0.0908 0.1269         1 -13.5 general  #> 16    16  8.5 86.5  0.0181 0.0169         1   2.5  covert  #> 17    17  3.5 97.5 -0.0552 0.0072         1   5.5 general  #>   ### use a correlation of 0.7 for effect sizes corresponding to the same type of ### delinquent behavior and a correlation of 0.5 for effect sizes corresponding ### to different types of delinquent behavior V <- vcalc(vi, cluster=study, type=deltype, obs=esid, data=dat, rho=c(0.7, 0.5)) agg <- aggregate(dat, cluster=study, V=V) agg #>  #>    study esid   id      yi     vi pubstatus  year deltype  #> 1      1  3.5  3.5  0.1275 0.0190         1   4.5 general  #> 2      2  2.0  8.0  0.3922 0.0059         1   1.5 general  #> 3      3  5.5 14.5  0.9909 0.0783         1  -7.7 general  #> 4      4  1.0 20.0 -0.0447 0.0331         1  -7.5 general  #> 5      5  1.0 21.0  1.5490 0.1384         1 -11.5 general  #> 6      6  3.0 24.0 -0.0838 0.0193         1   5.5 general  #> 7      7  3.5 29.5  1.0821 0.0573         1   3.5 general  #> 8      8  1.0 33.0  0.3695 0.0199         1   1.5 general  #> 9      9  1.5 34.5  0.1372 0.0287         1   5.5 general  #> 10    10  3.0 38.0  0.1025 0.0102         1   4.5 general  #> 11    11 11.5 51.5  0.4522 0.0093         0  -6.5 general  #> 12    12  3.0 65.0  0.2840 0.0028         0   4.5   overt  #> 13    13  1.5 68.5  0.3016 0.0117         1  -3.5 general  #> 14    14  3.5 72.5  0.0334 0.0012         1  -1.5 general  #> 15    15  2.0 77.0  0.0827 0.1359         1 -13.5 general  #> 16    16  8.5 86.5 -0.2268 0.0176         1   2.5  covert  #> 17    17  3.5 97.5 -0.0914 0.0071         1   5.5 general  #>   ### reshape 'dat.ishak2007' into long format dat <- dat.ishak2007 dat <- reshape(dat.ishak2007, direction=\"long\", idvar=\"study\", v.names=c(\"yi\",\"vi\"),                     varying=list(c(2,4,6,8), c(3,5,7,9))) dat <- dat[order(dat$study, dat$time),] dat <- dat[!is.na(dat$yi),] rownames(dat) <- NULL head(dat, 8) #>  #>               study mdur mbase time    yi    vi  #> 1    Alegret (2001) 16.1  53.6    1 -33.4  14.3  #> 2 Barichella (2003) 13.5  45.3    1 -20.0   7.3  #> 3 Barichella (2003) 13.5  45.3    3 -30.0   5.7  #> 4     Berney (2002) 13.6  45.6    1 -21.1   7.3  #> 5   Burchiel (1999) 13.6  48.0    1 -20.0   8.0  #> 6   Burchiel (1999) 13.6  48.0    2 -20.0   8.0  #> 7   Burchiel (1999) 13.6  48.0    3 -18.0   5.0  #> 8       Chen (2003) 12.1  65.7    2 -32.9 125.0  #>   ### aggregate the estimates to the study level, assuming a CAR structure for ### the sampling errors within studies with an autocorrelation of 0.9 agg <- aggregate(dat, cluster=study, struct=\"CAR\", time=time, phi=0.9) head(agg, 5) #>  #>               study mdur mbase time    yi    vi  #> 1    Alegret (2001) 16.1  53.6    1 -33.4  14.3  #> 2 Barichella (2003) 13.5  45.3    2 -28.1   5.6  #> 3     Berney (2002) 13.6  45.6    1 -21.1   7.3  #> 4   Burchiel (1999) 13.6  48.0    2 -17.2   4.6  #> 5       Chen (2003) 12.1  65.7    2 -32.9 125.0  #>"},{"path":"/reference/anova.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Likelihood Ratio and Wald-Type Tests for 'rma' Objects — anova.rma","title":"Likelihood Ratio and Wald-Type Tests for 'rma' Objects — anova.rma","text":"two (nested) models class \"rma.uni\" \"rma.mv\", function provides full versus reduced model comparison terms model fit statistics likelihood ratio test. single model specified, Wald-type test one model coefficients linear combinations thereof carried .","code":""},{"path":"/reference/anova.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Likelihood Ratio and Wald-Type Tests for 'rma' Objects — anova.rma","text":"","code":"# S3 method for rma anova(object, object2, btt, X, att, Z, digits, ...)"},{"path":"/reference/anova.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Likelihood Ratio and Wald-Type Tests for 'rma' Objects — anova.rma","text":"object object class \"rma.uni\" \"rma.mv\". object2 (optional) object class \"rma.uni\" \"rma.mv\". See ‘Details’. btt optional vector indices specify coefficients included Wald-type test. Can also string grep . See ‘Details’. X optional numeric vector matrix specify one linear combinations coefficients model tested. See ‘Details’. att optional vector indices specify scale coefficients included Wald-type test. Can also string grep . See ‘Details’. relevant location-scale models (see rma.uni). Z optional numeric vector matrix specify one linear combinations scale coefficients model tested. See ‘Details’. relevant location-scale models (see rma.uni). digits optional integer specify number decimal places printed results rounded. unspecified, default take value object. ... arguments.","code":""},{"path":"/reference/anova.rma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Likelihood Ratio and Wald-Type Tests for 'rma' Objects — anova.rma","text":"single model specified, function provides Wald-type tests one model coefficients linear combinations thereof. particular, equal- random-effects models (.e., models without moderators), just test single coefficient model. models including moderators, omnibus test model coefficients conducted excludes intercept (first coefficient) included model. intercept included model, omnibus test includes coefficients model including first. Alternatively, one can manually specify indices coefficients test via btt argument. example, btt=c(3,4), third fourth coefficient model included test (intercept included model, corresponds first coefficient model). Instead specifying coefficient numbers, one can specify string btt. case, grep used search coefficient names match string. Using btt argument, one can example select coefficients corresponding particular factor test factor whole significant. See ‘Examples’. Instead, one can use X argument specify linear combination coefficients model tested (.e., whether linear combination significantly different zero). matrix linear combinations specified, row defines particular linear combination tested. matrix full rank, omnibus Wald-type test linear combinations also provided. Linear combinations can also obtained predict function, provide corresponding confidence intervals. specifying two models comparison, function provides likelihood ratio test (LRT) comparing two models. two models must based set data, must class, nested LRT make sense. Note LRTs meaningful using REML estimation two models differ terms fixed effects. Also, theory underlying LRTs really applicable comparing models fitted ML/REML estimation. location-scale models fitted rma.uni function, one can use att specify indices scale coefficients test. Similarly, one can use Z argument specify one multiple linear combinations scale coefficients model tested.","code":""},{"path":"/reference/anova.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Likelihood Ratio and Wald-Type Tests for 'rma' Objects — anova.rma","text":"object class \"anova.rma\". single model specified (without arguments together btt att argument), object list containing following components: QM test statistic Wald-type test model coefficients. QMdf corresponding degrees freedom. QMp corresponding p-value. btt indices coefficients tested Wald-type test. k number outcomes included analysis. p number coefficients model (including intercept). m number coefficients included Wald-type test. ... additional elements/values. argument X used, object list containing following components: QM test statistic omnibus Wald-type test linear combinations. QMdf corresponding degrees freedom. QMp corresponding p-value. hyp description linear combinations tested. Xb values linear combinations. se standard errors linear combinations. zval test statistics linear combinations. pval corresponding p-values. two models specified, object list containing following components: fit.stats.f log-likelihood, deviance, AIC, BIC, AICc full model. fit.stats.r log-likelihood, deviance, AIC, BIC, AICc reduced model. parms.f number parameters full model. parms.r number parameters reduced model. LRT likelihood ratio test statistic. pval corresponding p-value. QE.f test statistic test (residual) heterogeneity full model. QE.r test statistic test (residual) heterogeneity reduced model. tau2.f estimated \\(\\tau^2\\) value full model. NA \"rma.mv\" objects. tau2.r estimated \\(\\tau^2\\) value reduced model. NA \"rma.mv\" objects. R2 amount (percent) heterogeneity reduced model accounted full model (NA \"rma.mv\" objects). can regarded pseudo \\(R^2\\) statistic (Raudenbush, 2009). Note value may accurate unless \\(k\\) large (Lopez-Lopez et al., 2014). ... additional elements/values. results formatted printed print function.","code":""},{"path":"/reference/anova.rma.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Likelihood Ratio and Wald-Type Tests for 'rma' Objects — anova.rma","text":"function can also used conduct likelihood ratio test (LRT) amount (residual) heterogeneity random- mixed-effects models. full model fitted either method=\"ML\" method=\"REML\" reduced model method=\"EE\". p-value test based chi-square distribution 1 degree freedom, actually needs adjusted fact parameter (.e., \\(\\tau^2\\)) falls boundary parameter space null hypothesis (see Viechtbauer, 2007, details). LRTs variance components complex models (fitted rma.mv function) can also conducted manner (see ‘Examples’).","code":""},{"path":"/reference/anova.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Likelihood Ratio and Wald-Type Tests for 'rma' Objects — anova.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/anova.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Likelihood Ratio and Wald-Type Tests for 'rma' Objects — anova.rma","text":"Hardy, R. J., & Thompson, S. G. (1996). likelihood approach meta-analysis random effects. Statistics Medicine, 15(6), 619--629. https://doi.org/10.1002/(sici)1097-0258(19960330)15:6%3C619::aid-sim188%3E3.0.co;2-Huizenga, H. M., Visser, ., & Dolan, C. V. (2011). Testing overall moderator effects random effects meta-regression. British Journal Mathematical Statistical Psychology, 64(1), 1--19. https://doi.org/10.1348/000711010X522687 López-López, J. ., Marín-Martínez, F., Sánchez-Meca, J., Van den Noortgate, W., & Viechtbauer, W. (2014). Estimation predictive power model mixed-effects meta-regression: simulation study. British Journal Mathematical Statistical Psychology, 67(1), 30--48. https://doi.org/10.1111/bmsp.12002 Raudenbush, S. W. (2009). Analyzing effect sizes: Random effects models. H. Cooper, L. V. Hedges, & J. C. Valentine (Eds.), handbook research synthesis meta-analysis (2nd ed., pp. 295--315). New York: Russell Sage Foundation. Viechtbauer, W. (2007). Hypothesis tests population heterogeneity meta-analysis. British Journal Mathematical Statistical Psychology, 60(1), 29--60. https://doi.org/10.1348/000711005X64042 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/anova.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Likelihood Ratio and Wald-Type Tests for 'rma' Objects — anova.rma","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit random-effects model res1 <- rma(yi, vi, data=dat, method=\"ML\")  ### fit mixed-effects model with two moderators (absolute latitude and publication year) res2 <- rma(yi, vi, mods = ~ ablat + year, data=dat, method=\"ML\")  ### Wald-type test of the two moderators anova(res2) #>  #> Test of Moderators (coefficients 2:3): #> QM(df = 2) = 33.9192, p-val < .0001 #>   ### alternative way of specifying the same test anova(res2, X=rbind(c(0,1,0), c(0,0,1))) #>  #> Hypotheses:              #> 1: ablat = 0  #> 2:  year = 0  #>  #> Results: #>    estimate     se    zval   pval  #> 1:  -0.0308 0.0063 -4.9057 <.0001  #> 2:  -0.0032 0.0092 -0.3471 0.7285  #>  #> Omnibus Test of Hypotheses: #> QM(df = 2) = 33.9192, p-val < .0001 #>   ### corresponding likelihood ratio test anova(res1, res2) #>  #>         df     AIC     BIC    AICc   logLik     LRT   pval       QE  tau^2      R^2  #> Full     4 23.2922 25.5520 28.2922  -7.6461                 28.3251 0.0269           #> Reduced  2 29.3302 30.4601 30.5302 -12.6651 10.0379 0.0066 152.2330 0.2800 90.3948%  #>   ### test of a linear combination anova(res2, X=c(1,35,1970)) #>  #> Hypothesis:                                       #> 1: intrcpt + 35*ablat + 1970*year = 0  #>  #> Results: #>    estimate     se    zval   pval  #> 1:  -0.7533 0.0837 -9.0039 <.0001  #>  #> Test of Hypothesis: #> QM(df = 1) = 81.0700, p-val < .0001 #>   ### use predict() to obtain the same linear combination (with its CI) predict(res2, newmods=c(35,1970)) #>  #>     pred     se   ci.lb   ci.ub   pi.lb   pi.ub  #>  -0.7533 0.0837 -0.9173 -0.5893 -1.1142 -0.3925  #>   ### mixed-effects model with three moderators res3 <- rma(yi, vi, mods = ~ ablat + year + alloc, data=dat, method=\"ML\") res3 #>  #> Mixed-Effects Model (k = 13; tau^2 estimator: ML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.0329 (SE = 0.0272) #> tau (square root of estimated tau^2 value):             0.1814 #> I^2 (residual heterogeneity / unaccounted variability): 33.24% #> H^2 (unaccounted variability / sampling variability):   1.50 #> R^2 (amount of heterogeneity accounted for):            88.24% #>  #> Test for Residual Heterogeneity: #> QE(df = 8) = 26.2030, p-val = 0.0010 #>  #> Test of Moderators (coefficients 2:5): #> QM(df = 4) = 31.2609, p-val < .0001 #>  #> Model Results: #>  #>                  estimate       se     zval    pval     ci.lb    ci.ub     ​  #> intrcpt          -10.0824  23.9973  -0.4201  0.6744  -57.1162  36.9514       #> ablat             -0.0277   0.0071  -3.9298  <.0001   -0.0416  -0.0139  ***  #> year               0.0053   0.0122   0.4371  0.6620   -0.0185   0.0292       #> allocrandom       -0.2826   0.2540  -1.1127  0.2658   -0.7804   0.2152       #> allocsystematic   -0.1104   0.2551  -0.4330  0.6650   -0.6104   0.3895       #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### test the 'alloc' factor anova(res3, btt=4:5) #>  #> Test of Moderators (coefficients 4:5): #> QM(df = 2) = 1.4674, p-val = 0.4801 #>   ### instead of specifying the coefficient numbers, grep for \"alloc\" anova(res3, btt=\"alloc\") #>  #> Test of Moderators (coefficients 4:5): #> QM(df = 2) = 1.4674, p-val = 0.4801 #>   ############################################################################  ### an example of doing LRTs of variance components in more complex models dat <- dat.konstantopoulos2011 res <- rma.mv(yi, vi, random = ~ 1 | district/school, data=dat)  ### test the district-level variance component res0 <- rma.mv(yi, vi, random = ~ 1 | district/school, data=dat, sigma2=c(0,NA)) anova(res, res0) #>  #>         df     AIC     BIC    AICc   logLik     LRT   pval       QE tau^2  #> Full     3 21.9174 27.9394 22.3880  -7.9587                578.8640    NA  #> Reduced  2 37.6910 41.7057 37.9218 -16.8455 17.7736 <.0001 578.8640    NA  #>   ### test the school-level variance component res0 <- rma.mv(yi, vi, random = ~ 1 | district/school, data=dat, sigma2=c(NA,0)) anova(res, res0) #>  #>         df     AIC     BIC    AICc   logLik     LRT   pval       QE tau^2  #> Full     3 21.9174 27.9394 22.3880  -7.9587                578.8640    NA  #> Reduced  2 68.4330 72.4476 68.6637 -32.2165 48.5155 <.0001 578.8640    NA  #>   ### test both variance components simultaneously res0 <- rma.mv(yi, vi, data=dat) anova(res, res0) #>  #>         df      AIC      BIC     AICc    logLik      LRT   pval       QE tau^2  #> Full     3  21.9174  27.9394  22.3880   -7.9587                 578.8640    NA  #> Reduced  1 439.7236 441.7310 439.7991 -218.8618 421.8062 <.0001 578.8640    NA  #>"},{"path":"/reference/baujat.html","id":null,"dir":"Reference","previous_headings":"","what":"Baujat Plots for 'rma' Objects — baujat","title":"Baujat Plots for 'rma' Objects — baujat","text":"Function create Baujat plots objects class \"rma\".","code":""},{"path":"/reference/baujat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Baujat Plots for 'rma' Objects — baujat","text":"","code":"baujat(x, ...)  # S3 method for rma baujat(x, xlim, ylim, xlab, ylab, cex, symbol=\"ids\", grid=TRUE, progbar=FALSE, ...)"},{"path":"/reference/baujat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Baujat Plots for 'rma' Objects — baujat","text":"x object class \"rma\". xlim x-axis limits. unspecified, function tries set x-axis limits sensible values. ylim y-axis limits. unspecified, function tries set y-axis limits sensible values. xlab title x-axis. unspecified, function tries set appropriate axis title. ylab title y-axis. unspecified, function tries set appropriate axis title. cex optional character expansion factor. unspecified, function tries set sensible value. symbol either integer specify pch value (.e., plotting symbol), \"slab\" plot study labels, \"ids\" (default) plot study id numbers. grid logical specify whether grid added plot (can also color name). progbar logical specify whether progress bar shown (default FALSE). ... arguments.","code":""},{"path":"/reference/baujat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Baujat Plots for 'rma' Objects — baujat","text":"model specified via x must model fitted either rma.uni, rma.mh, rma.peto functions. Baujat et al. (2002) proposed diagnostic plot detect sources heterogeneity meta-analytic data. plot shows contribution study overall \\(Q\\)-test statistic heterogeneity x-axis versus influence study (defined standardized squared difference overall estimate based equal-effects model without study included model fitting) y-axis. type plot can produced first fitting equal-effects model either rma.uni (using method=\"EE\"), rma.mh, rma.peto functions passing fitted model object baujat function. models fitted rma.uni function (may random-effects mixed-effects meta-regressions models), idea underlying type plot can generalized follows (Viechtbauer, 2021): x-axis corresponds squared Pearson residual study, y-axis corresponds standardized squared difference predicted/fitted value study without study included model fitting. default, points plotted study id numbers, one can also plot study labels setting symbol=\"slab\" (study labels available within model object) one can specify plotting symbol via symbol argument gets passed pch (see points possible options).","code":""},{"path":"/reference/baujat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Baujat Plots for 'rma' Objects — baujat","text":"data frame components: x x-axis coordinates points plotted. y y-axis coordinates points plotted. ids study id numbers. slab study labels. Note data frame returned invisibly.","code":""},{"path":"/reference/baujat.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Baujat Plots for 'rma' Objects — baujat","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/baujat.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Baujat Plots for 'rma' Objects — baujat","text":"Baujat, B., Mahe, C., Pignon, J.-P., & Hill, C. (2002). graphical method exploring heterogeneity meta-analyses: Application meta-analysis 65 trials. Statistics Medicine, 21(18), 2641--2652. https://doi.org/10.1002/sim.1221 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03 Viechtbauer, W. (2021). Model checking meta-analysis. C. H. Schmid, T. Stijnen, & . R. White (Eds.), Handbook meta-analysis (pp. 219--254). Boca Raton, FL: CRC Press. https://doi.org/10.1201/9781315119403","code":""},{"path":[]},{"path":"/reference/baujat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Baujat Plots for 'rma' Objects — baujat","text":"","code":"### copy data from Pignon et al. (2000) into 'dat' dat <- dat.pignon2000  ### calculate estimated log hazard ratios and sampling variances dat$yi <- with(dat, OmE/V) dat$vi <- with(dat, 1/V)  ### meta-analysis based on all 65 trials res <- rma(yi, vi, data=dat, method=\"EE\", slab=trial)  ### create Baujat plot baujat(res)   ### some variations of the plotting symbol baujat(res, symbol=19)  baujat(res, symbol=\"slab\")   ### label only a selection of the more 'extreme' points sav <- baujat(res, symbol=19, xlim=c(0,20)) sav <- sav[sav$x >= 10 | sav$y >= 0.10,] text(sav$x, sav$y, sav$slab, pos=1)"},{"path":"/reference/bldiag.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct Block Diagonal Matrix — bldiag","title":"Construct Block Diagonal Matrix — bldiag","text":"Function construct block diagonal matrix (list ) matrices.","code":""},{"path":"/reference/bldiag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct Block Diagonal Matrix — bldiag","text":"","code":"bldiag(..., order)"},{"path":"/reference/bldiag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct Block Diagonal Matrix — bldiag","text":"... individual matrices list matrices. order optional argument specify variable based square block diagonal matrix ordered.","code":""},{"path":"/reference/bldiag.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Construct Block Diagonal Matrix — bldiag","text":"Posted R-help Berton Gunter (2 Sep 2005) adjustments Wolfgang Viechtbauer","code":""},{"path":[]},{"path":"/reference/bldiag.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct Block Diagonal Matrix — bldiag","text":"","code":"### copy data into 'dat' dat <- dat.berkey1998 dat #>  #>    trial           author year ni outcome      yi     vi    v1i    v2i  #> 1      1 Pihlstrom et al. 1983 14      PD  0.4700 0.0075 0.0075 0.0030  #> 2      1 Pihlstrom et al. 1983 14      AL -0.3200 0.0077 0.0030 0.0077  #> 3      2    Lindhe et al. 1982 15      PD  0.2000 0.0057 0.0057 0.0009  #> 4      2    Lindhe et al. 1982 15      AL -0.6000 0.0008 0.0009 0.0008  #> 5      3   Knowles et al. 1979 78      PD  0.4000 0.0021 0.0021 0.0007  #> 6      3   Knowles et al. 1979 78      AL -0.1200 0.0014 0.0007 0.0014  #> 7      4  Ramfjord et al. 1987 89      PD  0.2600 0.0029 0.0029 0.0009  #> 8      4  Ramfjord et al. 1987 89      AL -0.3100 0.0015 0.0009 0.0015  #> 9      5    Becker et al. 1988 16      PD  0.5600 0.0148 0.0148 0.0072  #> 10     5    Becker et al. 1988 16      AL -0.3900 0.0304 0.0072 0.0304  #>   ### construct list with the variance-covariance matrices of the observed outcomes for the studies V <- lapply(split(dat[c(\"v1i\", \"v2i\")], dat$trial), as.matrix) V #> $`1` #>      v1i    v2i #> 1 0.0075 0.0030 #> 2 0.0030 0.0077 #>  #> $`2` #>      v1i   v2i #> 3 0.0057 9e-04 #> 4 0.0009 8e-04 #>  #> $`3` #>      v1i    v2i #> 5 0.0021 0.0007 #> 6 0.0007 0.0014 #>  #> $`4` #>      v1i    v2i #> 7 0.0029 0.0009 #> 8 0.0009 0.0015 #>  #> $`5` #>       v1i    v2i #> 9  0.0148 0.0072 #> 10 0.0072 0.0304 #>   ### construct block diagonal matrix V <- bldiag(V) V #>         [,1]   [,2]   [,3]  [,4]   [,5]   [,6]   [,7]   [,8]   [,9]  [,10] #>  [1,] 0.0075 0.0030 0.0000 0e+00 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [2,] 0.0030 0.0077 0.0000 0e+00 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [3,] 0.0000 0.0000 0.0057 9e-04 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [4,] 0.0000 0.0000 0.0009 8e-04 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [5,] 0.0000 0.0000 0.0000 0e+00 0.0021 0.0007 0.0000 0.0000 0.0000 0.0000 #>  [6,] 0.0000 0.0000 0.0000 0e+00 0.0007 0.0014 0.0000 0.0000 0.0000 0.0000 #>  [7,] 0.0000 0.0000 0.0000 0e+00 0.0000 0.0000 0.0029 0.0009 0.0000 0.0000 #>  [8,] 0.0000 0.0000 0.0000 0e+00 0.0000 0.0000 0.0009 0.0015 0.0000 0.0000 #>  [9,] 0.0000 0.0000 0.0000 0e+00 0.0000 0.0000 0.0000 0.0000 0.0148 0.0072 #> [10,] 0.0000 0.0000 0.0000 0e+00 0.0000 0.0000 0.0000 0.0000 0.0072 0.0304  ### if we split based on 'author', the list elements in V are in a different order than tha data V <- lapply(split(dat[c(\"v1i\", \"v2i\")], dat$author), as.matrix) V #> $`Becker et al.` #>       v1i    v2i #> 9  0.0148 0.0072 #> 10 0.0072 0.0304 #>  #> $`Knowles et al.` #>      v1i    v2i #> 5 0.0021 0.0007 #> 6 0.0007 0.0014 #>  #> $`Lindhe et al.` #>      v1i   v2i #> 3 0.0057 9e-04 #> 4 0.0009 8e-04 #>  #> $`Pihlstrom et al.` #>      v1i    v2i #> 1 0.0075 0.0030 #> 2 0.0030 0.0077 #>  #> $`Ramfjord et al.` #>      v1i    v2i #> 7 0.0029 0.0009 #> 8 0.0009 0.0015 #>   ### can use 'order' argument to reorder the block-diagonal matrix into the correct order V <- bldiag(V, order=dat$author) V #>         [,1]   [,2]   [,3]  [,4]   [,5]   [,6]   [,7]   [,8]   [,9]  [,10] #>  [1,] 0.0075 0.0030 0.0000 0e+00 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [2,] 0.0030 0.0077 0.0000 0e+00 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [3,] 0.0000 0.0000 0.0057 9e-04 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [4,] 0.0000 0.0000 0.0009 8e-04 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [5,] 0.0000 0.0000 0.0000 0e+00 0.0021 0.0007 0.0000 0.0000 0.0000 0.0000 #>  [6,] 0.0000 0.0000 0.0000 0e+00 0.0007 0.0014 0.0000 0.0000 0.0000 0.0000 #>  [7,] 0.0000 0.0000 0.0000 0e+00 0.0000 0.0000 0.0029 0.0009 0.0000 0.0000 #>  [8,] 0.0000 0.0000 0.0000 0e+00 0.0000 0.0000 0.0009 0.0015 0.0000 0.0000 #>  [9,] 0.0000 0.0000 0.0000 0e+00 0.0000 0.0000 0.0000 0.0000 0.0148 0.0072 #> [10,] 0.0000 0.0000 0.0000 0e+00 0.0000 0.0000 0.0000 0.0000 0.0072 0.0304"},{"path":"/reference/blsplit.html","id":null,"dir":"Reference","previous_headings":"","what":"Split Block Diagonal Matrix — blsplit","title":"Split Block Diagonal Matrix — blsplit","text":"Split block diagonal matrix list matrices.","code":""},{"path":"/reference/blsplit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split Block Diagonal Matrix — blsplit","text":"","code":"blsplit(x, cluster, sort=FALSE)"},{"path":"/reference/blsplit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split Block Diagonal Matrix — blsplit","text":"x block diagonal matrix. cluster vector specify clustering variable use splitting. sort logical indicate whether sort list unique cluster values (default FALSE).","code":""},{"path":"/reference/blsplit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split Block Diagonal Matrix — blsplit","text":"list one matrices.","code":""},{"path":"/reference/blsplit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Split Block Diagonal Matrix — blsplit","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":[]},{"path":"/reference/blsplit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Split Block Diagonal Matrix — blsplit","text":"","code":"### copy data into 'dat' dat <- dat.assink2016  ### assume that the effect sizes within studies are correlated with rho=0.6 V <- vcalc(vi, cluster=study, obs=esid, data=dat, rho=0.6)  ### split V matrix into list of matrices Vs <- blsplit(V, cluster=dat$study) Vs[1:2] #> $`1` #>            [,1]       [,2]       [,3]       [,4]       [,5]       [,6] #> [1,] 0.07400000 0.03256182 0.03579642 0.02523284 0.02969485 0.04858296 #> [2,] 0.03256182 0.03980000 0.02625218 0.01850511 0.02177744 0.03562949 #> [3,] 0.03579642 0.02625218 0.04810000 0.02034336 0.02394075 0.03916883 #> [4,] 0.02523284 0.01850511 0.02034336 0.02390000 0.01687579 0.02761004 #> [5,] 0.02969485 0.02177744 0.02394075 0.01687579 0.03310000 0.03249242 #> [6,] 0.04858296 0.03562949 0.03916883 0.02761004 0.03249242 0.08860000 #>  #> $`2` #>             [,1]        [,2]        [,3] #> [1,] 0.011500000 0.005609278 0.005187485 #> [2,] 0.005609278 0.007600000 0.004217108 #> [3,] 0.005187485 0.004217108 0.006500000 #>  lapply(Vs[1:2], cov2cor) #> $`1` #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,]  1.0  0.6  0.6  0.6  0.6  0.6 #> [2,]  0.6  1.0  0.6  0.6  0.6  0.6 #> [3,]  0.6  0.6  1.0  0.6  0.6  0.6 #> [4,]  0.6  0.6  0.6  1.0  0.6  0.6 #> [5,]  0.6  0.6  0.6  0.6  1.0  0.6 #> [6,]  0.6  0.6  0.6  0.6  0.6  1.0 #>  #> $`2` #>      [,1] [,2] [,3] #> [1,]  1.0  0.6  0.6 #> [2,]  0.6  1.0  0.6 #> [3,]  0.6  0.6  1.0 #>"},{"path":"/reference/blup.html","id":null,"dir":"Reference","previous_headings":"","what":"Best Linear Unbiased Predictions for 'rma.uni' Objects — blup","title":"Best Linear Unbiased Predictions for 'rma.uni' Objects — blup","text":"function calculates best linear unbiased predictions (BLUPs) study-specific true effect sizes outcomes combining fitted values based fixed effects estimated contributions random effects objects class \"rma.uni\". Corresponding standard errors prediction interval bounds also provided.","code":""},{"path":"/reference/blup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Best Linear Unbiased Predictions for 'rma.uni' Objects — blup","text":"","code":"blup(x, ...)  # S3 method for rma.uni blup(x, level, digits, transf, targs, ...)"},{"path":"/reference/blup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Best Linear Unbiased Predictions for 'rma.uni' Objects — blup","text":"x object class \"rma.uni\". level numeric value 0 100 specify prediction interval level. unspecified, default take value object. digits optional integer specify number decimal places printed results rounded. unspecified, default take value object. transf optional argument specify function used transform predicted values interval bounds (e.g., transf=exp; see also transf). unspecified, transformation used. targs optional arguments needed function specified transf. ... arguments.","code":""},{"path":"/reference/blup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Best Linear Unbiased Predictions for 'rma.uni' Objects — blup","text":"object class \"list.rma\". object list containing following components: pred predicted values. se corresponding standard errors. pi.lb lower bound prediction intervals. pi.ub upper bound prediction intervals. ... additional elements/values. object formatted printed print function.","code":""},{"path":"/reference/blup.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Best Linear Unbiased Predictions for 'rma.uni' Objects — blup","text":"best linear unbiased predictions random effects, see ranef. predicted/fitted values based fixed effects model, see fitted predict. conditional residuals (deviations observed effect sizes outcomes BLUPs), see rstandard.rma.uni type=\"conditional\". Equal-effects models contain random study effects. BLUPs models therefore equal fitted values, , obtained fitted predict. using transf argument, transformation applied predicted values corresponding interval bounds. standard errors set equal NA omitted printed output. default, standard normal distribution used calculate prediction intervals. model fitted test=\"t\" test=\"knha\", t-distribution \\(k-p\\) degrees freedom used. precise, noted function actually calculates empirical BLUPs (eBLUPs), since predicted values function estimated value \\(\\tau^2\\).","code":""},{"path":"/reference/blup.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Best Linear Unbiased Predictions for 'rma.uni' Objects — blup","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/blup.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Best Linear Unbiased Predictions for 'rma.uni' Objects — blup","text":"Kackar, R. N., & Harville, D. . (1981). Unbiasedness two-stage estimation prediction procedures mixed linear models. Communications Statistics, Theory Methods, 10(13), 1249--1261. https://doi.org/10.1080/03610928108828108 Raudenbush, S. W., & Bryk, . S. (1985). Empirical Bayes meta-analysis. Journal Educational Statistics, 10(2), 75--98. https://doi.org/10.3102/10769986010002075 Robinson, G. K. (1991). BLUP good thing: estimation random effects. Statistical Science, 6(1), 15--32. https://doi.org/10.1214/ss/1177011926 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/blup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Best Linear Unbiased Predictions for 'rma.uni' Objects — blup","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### meta-analysis of the log risk ratios using a random-effects model res <- rma(yi, vi, data=dat)  ### BLUPs of the true risk ratios for each study blup(res, transf=exp) #>  #>      pred  pi.lb  pi.ub  #> 1  0.4492 0.2012 1.0032  #> 2  0.2860 0.1431 0.5716  #> 3  0.3727 0.1590 0.8740  #> 4  0.2471 0.1887 0.3236  #> 5  0.7502 0.4958 1.1352  #> 6  0.4563 0.3883 0.5362  #> 7  0.2882 0.1400 0.5936  #> 8  1.0029 0.8871 1.1338  #> 9  0.6024 0.3911 0.9279  #> 10 0.2873 0.1775 0.4651  #> 11 0.7021 0.5665 0.8702  #> 12 0.7522 0.3064 1.8469  #> 13 0.8635 0.5359 1.3915  #>   ### illustrate shrinkage of BLUPs towards the (estimated) population average res <- rma(yi, vi, data=dat) blups <- blup(res)$pred plot(NA, NA, xlim=c(.8,2.4), ylim=c(-2,0.5), pch=19,      xaxt=\"n\", bty=\"n\", xlab=\"\", ylab=\"Log Risk Ratio\") segments(rep(1,13), dat$yi, rep(2,13), blups, col=\"darkgray\") points(rep(1,13), dat$yi, pch=19) points(rep(2,13), blups, pch=19) axis(side=1, at=c(1,2), labels=c(\"Observed\\nValues\", \"BLUPs\"), lwd=0) segments(0, res$beta, 2.15, res$beta, lty=\"dotted\") text(2.3, res$beta, substitute(hat(mu)==muhat, list(muhat=round(res$beta[[1]], 2))), cex=1)"},{"path":"/reference/coef.permutest.rma.uni.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the Model Coefficient Table from 'permutest.rma.uni' Objects — coef.permutest.rma.uni","title":"Extract the Model Coefficient Table from 'permutest.rma.uni' Objects — coef.permutest.rma.uni","text":"function extracts estimated model coefficients, corresponding standard errors, test statistics, p-values (based permutation tests), confidence interval bounds objects class \"permutest.rma.uni\".","code":""},{"path":"/reference/coef.permutest.rma.uni.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the Model Coefficient Table from 'permutest.rma.uni' Objects — coef.permutest.rma.uni","text":"","code":"# S3 method for permutest.rma.uni coef(object, ...)"},{"path":"/reference/coef.permutest.rma.uni.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract the Model Coefficient Table from 'permutest.rma.uni' Objects — coef.permutest.rma.uni","text":"object object class \"permutest.rma.uni\". ... arguments.","code":""},{"path":"/reference/coef.permutest.rma.uni.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract the Model Coefficient Table from 'permutest.rma.uni' Objects — coef.permutest.rma.uni","text":"data frame following elements: estimate estimated model coefficient(s). se corresponding standard error(s). zval corresponding test statistic(s). pval p-value(s) based permutation test(s). ci.lb lower bound (permutation-based) confidence interval(s). ci.ub upper bound (permutation-based) confidence interval(s). model fitted test=\"t\" test=\"knha\", zval called tval data frame returned function.","code":""},{"path":"/reference/coef.permutest.rma.uni.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract the Model Coefficient Table from 'permutest.rma.uni' Objects — coef.permutest.rma.uni","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/coef.permutest.rma.uni.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract the Model Coefficient Table from 'permutest.rma.uni' Objects — coef.permutest.rma.uni","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/coef.permutest.rma.uni.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract the Model Coefficient Table from 'permutest.rma.uni' Objects — coef.permutest.rma.uni","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit mixed-effects model with absolute latitude and publication year as moderators res <- rma(yi, vi, mods = ~ ablat + year, data=dat)  ### carry out permutation test # \\dontrun{ set.seed(1234) # for reproducibility sav <- permutest(res) #> Running 1000 iterations for approximate permutation test. coef(sav)# } #>             estimate          se       zval  pval        ci.lb        ci.ub #> intrcpt -3.545505079 29.09587983 -0.1218559 0.907 -60.57238164 53.481371479 #> ablat   -0.028011275  0.01023404 -2.7370689 0.016  -0.04806963 -0.007952924 #> year     0.001907557  0.01468382  0.1299088 0.901  -0.02687219  0.030687307"},{"path":"/reference/coef.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the Model Coefficients and Coefficient Table from 'rma' and 'summary.rma' Objects — coef.rma","title":"Extract the Model Coefficients and Coefficient Table from 'rma' and 'summary.rma' Objects — coef.rma","text":"coef function extracts estimated model coefficients objects class \"rma\". objects class \"summary.rma\", model coefficients, corresponding standard errors, test statistics, p-values, confidence interval bounds extracted.","code":""},{"path":"/reference/coef.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the Model Coefficients and Coefficient Table from 'rma' and 'summary.rma' Objects — coef.rma","text":"","code":"# S3 method for rma coef(object, ...) # S3 method for summary.rma coef(object, ...)"},{"path":"/reference/coef.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract the Model Coefficients and Coefficient Table from 'rma' and 'summary.rma' Objects — coef.rma","text":"object object class \"rma\" \"summary.rma\". ... arguments.","code":""},{"path":"/reference/coef.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract the Model Coefficients and Coefficient Table from 'rma' and 'summary.rma' Objects — coef.rma","text":"Either vector estimated model coefficient(s) data frame following elements: estimate estimated model coefficient(s). se corresponding standard error(s). zval corresponding test statistic(s). pval corresponding p-value(s). ci.lb corresponding lower bound confidence interval(s). ci.ub corresponding upper bound confidence interval(s). model fitted test=\"t\" test=\"knha\", zval called tval data frame returned function.","code":""},{"path":"/reference/coef.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract the Model Coefficients and Coefficient Table from 'rma' and 'summary.rma' Objects — coef.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/coef.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract the Model Coefficients and Coefficient Table from 'rma' and 'summary.rma' Objects — coef.rma","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/coef.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract the Model Coefficients and Coefficient Table from 'rma' and 'summary.rma' Objects — coef.rma","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit mixed-effects model with absolute latitude and publication year as moderators res <- rma(yi, vi, mods = ~ ablat + year, data=dat)  ### extract model coefficients coef(res) #>      intrcpt        ablat         year  #> -3.545505079 -0.028011275  0.001907557   ### extract model coefficient table coef(summary(res)) #>             estimate          se       zval        pval        ci.lb        ci.ub #> intrcpt -3.545505079 29.09587983 -0.1218559 0.903013130 -60.57238164 53.481371479 #> ablat   -0.028011275  0.01023404 -2.7370689 0.006198931  -0.04806963 -0.007952924 #> year     0.001907557  0.01468382  0.1299088 0.896638598  -0.02687219  0.030687307"},{"path":"/reference/confint.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Confidence Intervals for 'rma' Objects — confint.rma","title":"Confidence Intervals for 'rma' Objects — confint.rma","text":"function calculates confidence intervals model coefficients /parameters model.","code":""},{"path":"/reference/confint.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confidence Intervals for 'rma' Objects — confint.rma","text":"","code":"# S3 method for rma.uni confint(object, parm, level, fixed=FALSE, random=TRUE, type,         digits, transf, targs, verbose=FALSE, control, ...)  # S3 method for rma.mh confint(object, parm, level, digits, transf, targs, ...)  # S3 method for rma.peto confint(object, parm, level, digits, transf, targs, ...)  # S3 method for rma.glmm confint(object, parm, level, digits, transf, targs, ...)  # S3 method for rma.mv confint(object, parm, level, fixed=FALSE, sigma2, tau2, rho, gamma2, phi,         digits, transf, targs, verbose=FALSE, control, ...)  # S3 method for rma.uni.selmodel confint(object, parm, level, fixed=FALSE, tau2, delta,         digits, transf, targs, verbose=FALSE, control, ...)  # S3 method for rma.ls confint(object, parm, level, fixed=FALSE, alpha,         digits, transf, targs, verbose=FALSE, control, ...)"},{"path":"/reference/confint.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confidence Intervals for 'rma' Objects — confint.rma","text":"object object class \"rma.uni\", \"rma.mh\", \"rma.peto\", \"rma.mv\", \"rma.uni.selmodel\", \"rma.ls\". method yet implemented objects class \"rma.glmm\". parm argument compatibility generic function confint, (currently) ignored. fixed logical specify whether confidence intervals model coefficients returned. random logical specify whether confidence interval amount (residual) heterogeneity returned. type optional character string specify method use computing confidence interval amount (residual) heterogeneity (either \"QP\", \"GENQ\", \"PL\"). sigma2 integer specify \\(\\sigma^2\\) parameter confidence interval obtained. tau2 integer specify \\(\\tau^2\\) parameter confidence interval obtained. rho integer specify \\(\\rho\\) parameter confidence interval obtained. gamma2 integer specify \\(\\gamma^2\\) parameter confidence interval obtained. phi integer specify \\(\\phi\\) parameter confidence interval obtained. delta integer specify \\(\\delta\\) parameter confidence interval obtained. alpha integer specify \\(\\alpha\\) parameter confidence interval obtained. level numeric value 0 100 specify confidence interval level. unspecified, default take value object. digits optional integer specify number decimal places results rounded. unspecified, default take value object. transf optional argument specify function used transform model coefficients interval bounds (e.g., transf=exp; see also transf). unspecified, transformation used. targs optional arguments needed function specified transf. verbose logical specify whether output generated progress iterative algorithms used obtain confidence intervals (default FALSE). See ‘Details’. control list control values iterative algorithms. unspecified, default values defined inside function. See ‘Note’. ... arguments.","code":""},{"path":"/reference/confint.rma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Confidence Intervals for 'rma' Objects — confint.rma","text":"Confidence intervals model coefficients can obtained setting fixed=TRUE simply usual Wald-type intervals (also shown printing fitted object). parameter(s) confidence intervals can obtained depend model object:  objects class \"rma.uni\" obtained rma.uni function, confidence interval amount (residual) heterogeneity (.e., \\(\\tau^2\\)) can obtained setting random=TRUE (default). interval obtained iteratively either via Q-profile method via generalized Q-statistic method (Hartung Knapp, 2005; Viechtbauer, 2007; Jackson, 2013; Jackson et al., 2014). latter automatically used model fitted method=\"GENQ\" method=\"GENQM\", former used cases. Either method provides exact confidence interval \\(\\tau^2\\) random- mixed-effects models. square root interval bounds also returned easier interpretation. Confidence intervals \\(^2\\) \\(H^2\\) also provided (Higgins & Thompson, 2002). Since \\(^2\\) \\(H^2\\) just monotonic transformations \\(\\tau^2\\) (details, see print), confidence intervals \\(^2\\) \\(H^2\\) also exact. One can also set type=\"PL\" obtain profile likelihood confidence interval \\(\\tau^2\\) (corresponding CIs \\(^2\\) \\(H^2\\)), consistent use ML/REML estimation, exact (see ‘Note’). objects class \"rma.mv\" obtained rma.mv function, confidence intervals obtained default (non-fixed) variance correlation components model. Alternatively, one can use sigma2, tau2, rho, gamma2, phi arguments specify variance/correlation parameter confidence interval obtained. one arguments can used time. single integer used specify number parameter. function provides profile likelihood confidence intervals parameters. good idea examine corresponding profile likelihood plots (via profile function) make sure bounds obtained sensible. selection model objects class \"rma.uni.selmodel\" obtained selmodel function, confidence intervals obtained default \\(\\tau^2\\) (models estimated parameter) (non-fixed) selection model parameters. Alternatively, one can choose obtain confidence interval \\(\\tau^2\\) setting tau2=TRUE one selection model parameters specifying number via delta argument. function provides profile likelihood confidence intervals parameters. good idea examine corresponding profile likelihood plots (via profile function) make sure bounds obtained sensible. location-scale model objects class \"rma.ls\" obtained rma.uni function, confidence intervals obtained default (non-fixed) scale parameters. Alternatively, one can choose obtain confidence interval one scale parameters specifying number via alpha argument. function provides profile likelihood confidence intervals parameters. good idea examine corresponding profile likelihood plots (via profile function) make sure bounds obtained sensible. methods used find confidence intervals parameters iterative require use uniroot function. default, desired accuracy (tol) set equal .Machine$double.eps^0.25 maximum number iterations (maxiter) 1000. values can adjusted control=list(tol=value, maxiter=value), defaults adequate purposes. verbose=TRUE, output generated progress iterative algorithms. especially useful model fitting slow, case finding confidence interval bounds can also take considerable amounts time. using uniroot function, one must also set appropriate end points interval searched confidence interval bounds. function tries set sensible defaults end points, may happen function able determine bound /certain limit (indicated output accordingly < > signs). can also happen model fitted converge especially extremes interval searched. result missing (NA) bounds corresponding warnings. may necessary adjust end points manually (see ‘Note’). Finally, also possible lower upper confidence interval bounds variance component fall zero. Since bounds fall outside parameter space, confidence interval consists null/empty set. Alternatively, one interpret confidence interval bounds \\([0,0]\\) indicating ‘highly/overly homogeneous’ data.","code":""},{"path":"/reference/confint.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Confidence Intervals for 'rma' Objects — confint.rma","text":"object class \"confint.rma\". object list either one two elements (named fixed random) following elements: estimate estimate model coefficient, variance/correlation component, selection model parameter. ci.lb lower bound confidence interval. ci.ub upper bound confidence interval. obtaining confidence intervals multiple components, object list class \"list.confint.rma\", element \"confint.rma\" object described .    results formatted printed print function.","code":""},{"path":"/reference/confint.rma.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Confidence Intervals for 'rma' Objects — confint.rma","text":"computing CI \\(\\tau^2\\) objects class \"rma.uni\", estimate \\(\\tau^2\\) usually fall within CI bounds provided Q-profile method. However, guaranteed. Depending method used estimate \\(\\tau^2\\) width CI, can happen CI actually contain estimate. Using empirical Bayes Paule-Mandel estimator \\(\\tau^2\\) fitting model (.e., using method=\"EB\" method=\"PM\") usually ensures estimate \\(\\tau^2\\) falls within CI (method=\"PMM\", guaranteed). method=\"GENQ\" used fit model, corresponding CI obtained via generalized Q-statistic method also usually contains estimate \\(\\tau^2\\) (method=\"GENQM\", guaranteed). using ML/REML estimation, profile likelihood CI (obtained setting type=\"PL\") guaranteed contain estimate \\(\\tau^2\\). computing CI \\(\\tau^2\\) objects class \"rma.uni\", end points interval searched CI bounds \\([0,100]\\) (, upper bound, ten times estimate \\(\\tau^2\\), whichever greater). upper bound large enough cases, can adjusted control=list(tau2.max=value). One can also adjust lower end point control=list(tau2.min=value). play around value know . objects class \"rma.mv\", function provides profile likelihood CIs variance/correlation parameters model. variance components, lower end point interval searched set 0 upper end point larger 10 100 times value component. correlations, function tries set lower end point sensible default depending type variance structure chosen, upper end point set 1. One can adjust lower /upper end points control=list(vc.min=value, vc.max=value). Also, function tries adjust lower/upper end points model converge extremes (end points moved closer estimated value component). total number tries setting/adjusting end points manner determined via control=list(eptries=value), default 10 tries. objects class \"rma.uni.selmodel\" \"rma.ls\", function also sets sensible defaults end points interval searched CI bounds (\\(\\tau^2\\), \\(\\delta\\), \\(\\alpha\\) parameter(s)). One can adjust end points number retries (described ) control=list(vc.min=value, vc.max=value, eptries=value). Q-profile generalized Q-statistic methods exact assumptions random- mixed-effects models (.e., normally distributed observed true effect sizes outcomes known sampling variances). practice, assumptions usually approximately true, turning CIs \\(\\tau^2\\) also approximations. Profile likelihood CIs exact construction rely asymptotic behavior likelihood ratio statistic, may inaccurate small samples, inherently consistent use ML/REML estimation.","code":""},{"path":"/reference/confint.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Confidence Intervals for 'rma' Objects — confint.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/confint.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Confidence Intervals for 'rma' Objects — confint.rma","text":"Hardy, R. J., & Thompson, S. G. (1996). likelihood approach meta-analysis random effects. Statistics Medicine, 15(6), 619--629. https://doi.org/10.1002/(sici)1097-0258(19960330)15:6%3C619::aid-sim188%3E3.0.co;2-Hartung, J., & Knapp, G. (2005). confidence intervals among-group variance one-way random effects model unequal error variances. Journal Statistical Planning Inference, 127(1-2), 157--177. https://doi.org/10.1016/j.jspi.2003.09.032 Higgins, J. P. T., & Thompson, S. G. (2002). Quantifying heterogeneity meta-analysis. Statistics Medicine, 21(11), 1539--1558. https://doi.org/10.1002/sim.1186 Jackson, D. (2013). Confidence intervals -study variance random effects meta-analysis using generalised Cochran heterogeneity statistics. Research Synthesis Methods, 4(3), 220--229. https://doi.org/10.1186/s12874-016-0219-y Jackson, D., Turner, R., Rhodes, K., & Viechtbauer, W. (2014). Methods calculating confidence credible intervals residual -study variance random effects meta-regression models. BMC Medical Research Methodology, 14, 103. https://doi.org/10.1186/1471-2288-14-103 Viechtbauer, W. (2007). Confidence intervals amount heterogeneity meta-analysis. Statistics Medicine, 26(1), 37--52. https://doi.org/10.1002/sim.2514 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/confint.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Confidence Intervals for 'rma' Objects — confint.rma","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### meta-analysis of the log risk ratios using a random-effects model res <- rma(yi, vi, data=dat, method=\"REML\")  ### confidence interval for the total amount of heterogeneity confint(res) #>  #>        estimate   ci.lb   ci.ub  #> tau^2    0.3132  0.1197  1.1115  #> tau      0.5597  0.3460  1.0543  #> I^2(%)  92.2214 81.9177 97.6781  #> H^2     12.8558  5.5303 43.0680  #>   ### mixed-effects model with absolute latitude in the model res <- rma(yi, vi, mods = ~ ablat, data=dat)  ### confidence interval for the residual amount of heterogeneity confint(res) #>  #>        estimate   ci.lb   ci.ub  #> tau^2    0.0764  0.0167  0.7849  #> tau      0.2763  0.1292  0.8859  #> I^2(%)  68.3931 32.1080 95.6976  #> H^2      3.1639  1.4729 23.2428  #>   ### multilevel random-effects model res <- rma.mv(yi, vi, random = ~ 1 | district/school, data=dat.konstantopoulos2011)  ### profile plots and confidence intervals for the variance components # \\dontrun{ par(mfrow=c(2,1)) profile(res, sigma2=1, steps=40, cline=TRUE) sav <- confint(res, sigma2=1) sav #>  #>           estimate  ci.lb  ci.ub  #> sigma^2.1   0.0651 0.0222 0.2072  #> sigma.1     0.2551 0.1491 0.4552  #>  abline(v=sav$random[1,2:3], lty=\"dotted\") profile(res, sigma2=2, steps=40, cline=TRUE) sav <- confint(res, sigma2=2) sav #>  #>           estimate  ci.lb  ci.ub  #> sigma^2.2   0.0327 0.0163 0.0628  #> sigma.2     0.1809 0.1276 0.2507  #>  abline(v=sav$random[1,2:3], lty=\"dotted\")# }   ### multivariate parameterization of the model res <- rma.mv(yi, vi, random = ~ school | district, data=dat.konstantopoulos2011)  ### profile plots and confidence intervals for the variance component and correlation # \\dontrun{ par(mfrow=c(2,1)) profile(res, tau2=1, steps=40, cline=TRUE) sav <- confint(res, tau2=1) sav #>  #>       estimate  ci.lb  ci.ub  #> tau^2   0.0978 0.0528 0.2398  #> tau     0.3127 0.2298 0.4897  #>  abline(v=sav$random[1,2:3], lty=\"dotted\") profile(res, rho=1, steps=40, cline=TRUE) sav <- confint(res, rho=1) sav #>  #>     estimate  ci.lb  ci.ub  #> rho   0.6653 0.3282 0.8855  #>  abline(v=sav$random[1,2:3], lty=\"dotted\")# }"},{"path":"/reference/contrmat.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct Contrast Matrix for Two-Group Comparisons — contrmat","title":"Construct Contrast Matrix for Two-Group Comparisons — contrmat","text":"function constructs matrix indicates two groups contrasted row dataset.","code":""},{"path":"/reference/contrmat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct Contrast Matrix for Two-Group Comparisons — contrmat","text":"","code":"contrmat(data, grp1, grp2, last, shorten=FALSE, minlen=2, check=TRUE, append=TRUE)"},{"path":"/reference/contrmat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct Contrast Matrix for Two-Group Comparisons — contrmat","text":"data data frame wide format. grp1 either name (given character string) position (given single number) first group variable data frame. grp2 either name (given character string) position (given single number) second group variable data frame. last optional character string specify group placed last column matrix (must one groups group variables). given, frequently occurring second group placed last. shorten logical specify whether variable names corresponding group names shortened (default FALSE). minlen integer specify minimum length shortened variable names (default 2). check logical specify whether variables names checked ensure syntactically valid variable names , adjusted (make.names) (default TRUE). append logical specify whether contrast matrix appended data frame specified via data argument (default TRUE). append=FALSE, contrast matrix returned.","code":""},{"path":"/reference/contrmat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Construct Contrast Matrix for Two-Group Comparisons — contrmat","text":"function can used construct matrix indicates two groups contrasted row data frame (1 first group, -1 second group, 0 otherwise). grp1 grp2 arguments used specify group variables dataset (either character strings numbers indicating column positions variables dataset). Optional argument last used specify group placed last column matrix. shorten=TRUE, variable names corresponding group names shortened (least minlen; actual length might longer ensure uniqueness variable names). examples illustrate use function.","code":""},{"path":"/reference/contrmat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct Contrast Matrix for Two-Group Comparisons — contrmat","text":"matrix many variables groups.","code":""},{"path":"/reference/contrmat.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Construct Contrast Matrix for Two-Group Comparisons — contrmat","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/contrmat.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Construct Contrast Matrix for Two-Group Comparisons — contrmat","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/contrmat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct Contrast Matrix for Two-Group Comparisons — contrmat","text":"","code":"### restructure to wide format dat <- dat.senn2013 dat <- dat[c(1,4,3,2,5,6)] dat <- to.wide(dat, study=\"study\", grp=\"treatment\", ref=\"placebo\", grpvars=4:6) dat #>                    study comment   treatment.1 ni.1  mi.1 sdi.1   treatment.2 ni.2  mi.2 sdi.2 id #> 1            Alex (1998)  change     metformin  291  0.13 1.428  sulfonylurea  300  0.50 1.450  1 #> 2           Baksi (2004)  change rosiglitazone  218 -1.20 1.112       placebo  233  0.10 1.036  2 #> 3           Costa (1997)  change      acarbose   36 -1.10 0.360       placebo   29 -0.30 0.700  3 #> 4        Davidson (2007)  change rosiglitazone  117 -1.20 1.097       placebo  116  0.14 1.093  4 #> 5       De Fronzo (1995)  change     metformin  213 -1.70 1.459       placebo  209  0.20 1.446  5 #> 6          Derosa (2004)     raw  pioglitazone   45  6.80 0.800 rosiglitazone   42  6.70 0.900  6 #> 7          Garber (2008)  change  vildagliptin  132 -0.63 1.034       placebo  144  0.07 1.080  7 #> 8  Gonzalez-Ortiz (2004)  change     metformin   34 -1.30 1.861       placebo   37 -0.90 1.803  8 #> 9        Hanefeld (2004)     raw     metformin  320  7.45 1.073  pioglitazone  319  7.61 1.072  9 #> 10      Hermansen (2007)  change   sitagliptin  106 -0.30 0.940       placebo  106  0.27 0.940 10 #> 11       Johnston (1994)  change      miglitol   68 -0.41 1.072       placebo   63  0.33 1.032 11 #> 12      Johnston (1998a)  change      miglitol   91 -0.43 0.954       placebo   43  0.98 1.311 12 #> 13      Johnston (1998b)  change      miglitol   49 -0.12 1.400       placebo   34  0.56 1.166 13 #> 14        Kerenyi (2004)  change rosiglitazone  160 -0.91 0.990       placebo  154 -0.14 0.920 14 #> 15            Kim (2007)  change     metformin   56 -1.10 1.139 rosiglitazone   57 -1.10 1.341 15 #> 16         Kipnes (2001)  change  pioglitazone  182 -1.20 1.369       placebo  181  0.10 1.024 16 #> 17          Lewin (2007)  change     metformin  431 -0.74 1.106       placebo  144  0.08 1.004 17 #> 18         Moulin (2006)  change    benfluorex  161 -0.82 1.028       placebo  156  0.19 1.374 18 #> 19          Oyama (2008)  change      acarbose   41 -0.70 0.800  sulfonylurea   43 -0.30 0.600 19 #> 20     Rosenstock (2008)  change rosiglitazone   59 -1.17 1.229       placebo   57 -0.08 1.208 20 #> 21         Stucci (1996)     raw    benfluorex   28  8.03 1.290       placebo   30  8.26 1.350 21 #> 22 Vongthavaravat (2002)  change rosiglitazone  164 -1.10 1.559  sulfonylurea  170  0.10 0.992 22 #> 23         Willms (1999)  change      acarbose   31 -2.30 1.782       placebo   29 -1.30 1.831 23 #> 24         Willms (1999)  change     metformin   29 -2.50 0.862       placebo   29 -1.30 1.831 24 #> 25  Wolffenbuttel (1999)  change rosiglitazone  183 -0.90 1.100       placebo  192  0.20 1.110 25 #> 26           Yang (2003)  change     metformin   96 -0.95 1.500 rosiglitazone  102 -1.09 1.650 26 #> 27            Zhu (2003)  change rosiglitazone  210 -1.90 1.470       placebo  105 -0.40 1.300 27 #>     comp   design #> 1  me-su    me-su #> 2  ro-pl    ro-pl #> 3  ac-pl    ac-pl #> 4  ro-pl    ro-pl #> 5  me-pl    me-pl #> 6  pi-ro    pi-ro #> 7  vi-pl    vi-pl #> 8  me-pl    me-pl #> 9  me-pi    me-pi #> 10 si-pl    si-pl #> 11 mi-pl    mi-pl #> 12 mi-pl    mi-pl #> 13 mi-pl    mi-pl #> 14 ro-pl    ro-pl #> 15 me-ro    me-ro #> 16 pi-pl    pi-pl #> 17 me-pl    me-pl #> 18 be-pl    be-pl #> 19 ac-su    ac-su #> 20 ro-pl    ro-pl #> 21 be-pl    be-pl #> 22 ro-su    ro-su #> 23 ac-pl ac-me-pl #> 24 me-pl ac-me-pl #> 25 ro-pl    ro-pl #> 26 me-ro    me-ro #> 27 ro-pl    ro-pl  ### add contrast matrix dat <- contrmat(dat, grp1=\"treatment.1\", grp2=\"treatment.2\") dat #>                    study comment   treatment.1 ni.1  mi.1 sdi.1   treatment.2 ni.2  mi.2 sdi.2 id #> 1            Alex (1998)  change     metformin  291  0.13 1.428  sulfonylurea  300  0.50 1.450  1 #> 2           Baksi (2004)  change rosiglitazone  218 -1.20 1.112       placebo  233  0.10 1.036  2 #> 3           Costa (1997)  change      acarbose   36 -1.10 0.360       placebo   29 -0.30 0.700  3 #> 4        Davidson (2007)  change rosiglitazone  117 -1.20 1.097       placebo  116  0.14 1.093  4 #> 5       De Fronzo (1995)  change     metformin  213 -1.70 1.459       placebo  209  0.20 1.446  5 #> 6          Derosa (2004)     raw  pioglitazone   45  6.80 0.800 rosiglitazone   42  6.70 0.900  6 #> 7          Garber (2008)  change  vildagliptin  132 -0.63 1.034       placebo  144  0.07 1.080  7 #> 8  Gonzalez-Ortiz (2004)  change     metformin   34 -1.30 1.861       placebo   37 -0.90 1.803  8 #> 9        Hanefeld (2004)     raw     metformin  320  7.45 1.073  pioglitazone  319  7.61 1.072  9 #> 10      Hermansen (2007)  change   sitagliptin  106 -0.30 0.940       placebo  106  0.27 0.940 10 #> 11       Johnston (1994)  change      miglitol   68 -0.41 1.072       placebo   63  0.33 1.032 11 #> 12      Johnston (1998a)  change      miglitol   91 -0.43 0.954       placebo   43  0.98 1.311 12 #> 13      Johnston (1998b)  change      miglitol   49 -0.12 1.400       placebo   34  0.56 1.166 13 #> 14        Kerenyi (2004)  change rosiglitazone  160 -0.91 0.990       placebo  154 -0.14 0.920 14 #> 15            Kim (2007)  change     metformin   56 -1.10 1.139 rosiglitazone   57 -1.10 1.341 15 #> 16         Kipnes (2001)  change  pioglitazone  182 -1.20 1.369       placebo  181  0.10 1.024 16 #> 17          Lewin (2007)  change     metformin  431 -0.74 1.106       placebo  144  0.08 1.004 17 #> 18         Moulin (2006)  change    benfluorex  161 -0.82 1.028       placebo  156  0.19 1.374 18 #> 19          Oyama (2008)  change      acarbose   41 -0.70 0.800  sulfonylurea   43 -0.30 0.600 19 #> 20     Rosenstock (2008)  change rosiglitazone   59 -1.17 1.229       placebo   57 -0.08 1.208 20 #> 21         Stucci (1996)     raw    benfluorex   28  8.03 1.290       placebo   30  8.26 1.350 21 #> 22 Vongthavaravat (2002)  change rosiglitazone  164 -1.10 1.559  sulfonylurea  170  0.10 0.992 22 #> 23         Willms (1999)  change      acarbose   31 -2.30 1.782       placebo   29 -1.30 1.831 23 #> 24         Willms (1999)  change     metformin   29 -2.50 0.862       placebo   29 -1.30 1.831 24 #> 25  Wolffenbuttel (1999)  change rosiglitazone  183 -0.90 1.100       placebo  192  0.20 1.110 25 #> 26           Yang (2003)  change     metformin   96 -0.95 1.500 rosiglitazone  102 -1.09 1.650 26 #> 27            Zhu (2003)  change rosiglitazone  210 -1.90 1.470       placebo  105 -0.40 1.300 27 #>     comp   design acarbose benfluorex metformin miglitol pioglitazone rosiglitazone sitagliptin #> 1  me-su    me-su        0          0         1        0            0             0           0 #> 2  ro-pl    ro-pl        0          0         0        0            0             1           0 #> 3  ac-pl    ac-pl        1          0         0        0            0             0           0 #> 4  ro-pl    ro-pl        0          0         0        0            0             1           0 #> 5  me-pl    me-pl        0          0         1        0            0             0           0 #> 6  pi-ro    pi-ro        0          0         0        0            1            -1           0 #> 7  vi-pl    vi-pl        0          0         0        0            0             0           0 #> 8  me-pl    me-pl        0          0         1        0            0             0           0 #> 9  me-pi    me-pi        0          0         1        0           -1             0           0 #> 10 si-pl    si-pl        0          0         0        0            0             0           1 #> 11 mi-pl    mi-pl        0          0         0        1            0             0           0 #> 12 mi-pl    mi-pl        0          0         0        1            0             0           0 #> 13 mi-pl    mi-pl        0          0         0        1            0             0           0 #> 14 ro-pl    ro-pl        0          0         0        0            0             1           0 #> 15 me-ro    me-ro        0          0         1        0            0            -1           0 #> 16 pi-pl    pi-pl        0          0         0        0            1             0           0 #> 17 me-pl    me-pl        0          0         1        0            0             0           0 #> 18 be-pl    be-pl        0          1         0        0            0             0           0 #> 19 ac-su    ac-su        1          0         0        0            0             0           0 #> 20 ro-pl    ro-pl        0          0         0        0            0             1           0 #> 21 be-pl    be-pl        0          1         0        0            0             0           0 #> 22 ro-su    ro-su        0          0         0        0            0             1           0 #> 23 ac-pl ac-me-pl        1          0         0        0            0             0           0 #> 24 me-pl ac-me-pl        0          0         1        0            0             0           0 #> 25 ro-pl    ro-pl        0          0         0        0            0             1           0 #> 26 me-ro    me-ro        0          0         1        0            0            -1           0 #> 27 ro-pl    ro-pl        0          0         0        0            0             1           0 #>    sulfonylurea vildagliptin placebo #> 1            -1            0       0 #> 2             0            0      -1 #> 3             0            0      -1 #> 4             0            0      -1 #> 5             0            0      -1 #> 6             0            0       0 #> 7             0            1      -1 #> 8             0            0      -1 #> 9             0            0       0 #> 10            0            0      -1 #> 11            0            0      -1 #> 12            0            0      -1 #> 13            0            0      -1 #> 14            0            0      -1 #> 15            0            0       0 #> 16            0            0      -1 #> 17            0            0      -1 #> 18            0            0      -1 #> 19           -1            0       0 #> 20            0            0      -1 #> 21            0            0      -1 #> 22           -1            0       0 #> 23            0            0      -1 #> 24            0            0      -1 #> 25            0            0      -1 #> 26            0            0       0 #> 27            0            0      -1  ### data in long format dat <- dat.hasselblad1998 dat #>    id study            authors year            trt  xi   ni #> 1   1     1        Reid et al. 1974     no_contact  75  731 #> 2   2     1        Reid et al. 1974 ind_counseling 363  714 #> 3   3     2    Cottraux et al. 1983     no_contact   9  140 #> 4   4     2    Cottraux et al. 1983 ind_counseling  23  140 #> 5   5     2    Cottraux et al. 1983 grp_counseling  10  138 #> 6   6     3       Slama et al. 1990     no_contact   2  106 #> 7   7     3       Slama et al. 1990 ind_counseling   9  205 #> 8   8     4    Jamrozik et al. 1984     no_contact  58  549 #> 9   9     4    Jamrozik et al. 1984 ind_counseling 237 1561 #> 10 10     5      Rabkin et al. 1984     no_contact   0   33 #> 11 11     5      Rabkin et al. 1984 ind_counseling   9   48 #> 12 12     6   Decker and Evans 1989      self_help  20   49 #> 13 13     6   Decker and Evans 1989 ind_counseling  16   43 #> 14 14     7    Richmond et al. 1986     no_contact   3  100 #> 15 15     7    Richmond et al. 1986 ind_counseling  31   98 #> 16 16     8              Leung 1991     no_contact   1   31 #> 17 17     8              Leung 1991 ind_counseling  26   95 #> 18 18     9  Mothersill et al. 1988      self_help  11   78 #> 19 19     9  Mothersill et al. 1988 ind_counseling  12   85 #> 20 20     9  Mothersill et al. 1988 grp_counseling  29  170 #> 21 21    10    Langford et al. 1983     no_contact   6   39 #> 22 22    10    Langford et al. 1983 ind_counseling  17   77 #> 23 23    11       Gritz et al. 1992     no_contact  79  702 #> 24 24    11       Gritz et al. 1992      self_help  77  694 #> 25 25    12    Campbell et al. 1986     no_contact  18  671 #> 26 26    12    Campbell et al. 1986      self_help  21  535 #> 27 27    13     Sanders et al. 1989     no_contact  64  642 #> 28 28    13     Sanders et al. 1989 ind_counseling 107  761 #> 29 29    14    Hilleman et al. 1993 ind_counseling  12   76 #> 30 30    14    Hilleman et al. 1993 grp_counseling  20   74 #> 31 31    15     Gillams et al. 1984 ind_counseling   9   55 #> 32 32    15     Gillams et al. 1984 grp_counseling   3   26 #> 33 33    16 Mogielnicki et al. 1986      self_help   7   66 #> 34 34    16 Mogielnicki et al. 1986 grp_counseling  32  127 #> 35 35    17        Page et al. 1986     no_contact   5   62 #> 36 36    17        Page et al. 1986 ind_counseling   8   90 #> 37 37    18    Vetter and Ford 1990     no_contact  20  234 #> 38 38    18    Vetter and Ford 1990 ind_counseling  34  237 #> 39 39    19  Williams and Hall 1988     no_contact   0   20 #> 40 40    19  Williams and Hall 1988 grp_counseling   9   20 #> 41 41    20    Pallonen et al. 1994     no_contact   8  116 #> 42 42    20    Pallonen et al. 1994      self_help  19  149 #> 43 43    21     Russell et al. 1983     no_contact  95 1107 #> 44 44    21     Russell et al. 1983 ind_counseling 143 1031 #> 45 45    22 Stewart and Rosser 1982     no_contact  15  187 #> 46 46    22 Stewart and Rosser 1982 ind_counseling  36  504 #> 47 47    23     Russell et al. 1979     no_contact  78  584 #> 48 48    23     Russell et al. 1979 ind_counseling  73  675 #> 49 49    24    Kendrick et al. 1995     no_contact  69 1177 #> 50 50    24    Kendrick et al. 1995 ind_counseling  54  888  ### restructure to wide format dat <- to.wide(dat, study=\"study\", grp=\"trt\", ref=\"no_contact\", grpvars=6:7) dat #>    id study            authors year          trt.1 xi.1 ni.1          trt.2 xi.2 ni.2  comp   design #> 1   1     1        Reid et al. 1974 ind_counseling  363  714     no_contact   75  731 in-no    in-no #> 2   2     2    Cottraux et al. 1983 grp_counseling   10  138     no_contact    9  140 gr-no gr-in-no #> 3   3     2    Cottraux et al. 1983 ind_counseling   23  140     no_contact    9  140 in-no gr-in-no #> 4   4     3       Slama et al. 1990 ind_counseling    9  205     no_contact    2  106 in-no    in-no #> 5   5     4    Jamrozik et al. 1984 ind_counseling  237 1561     no_contact   58  549 in-no    in-no #> 6   6     5      Rabkin et al. 1984 ind_counseling    9   48     no_contact    0   33 in-no    in-no #> 7   7     6   Decker and Evans 1989 ind_counseling   16   43      self_help   20   49 in-se    in-se #> 8   8     7    Richmond et al. 1986 ind_counseling   31   98     no_contact    3  100 in-no    in-no #> 9   9     8              Leung 1991 ind_counseling   26   95     no_contact    1   31 in-no    in-no #> 10 10     9  Mothersill et al. 1988 grp_counseling   29  170      self_help   11   78 gr-se gr-in-se #> 11 11     9  Mothersill et al. 1988 ind_counseling   12   85      self_help   11   78 in-se gr-in-se #> 12 12    10    Langford et al. 1983 ind_counseling   17   77     no_contact    6   39 in-no    in-no #> 13 13    11       Gritz et al. 1992      self_help   77  694     no_contact   79  702 se-no    se-no #> 14 14    12    Campbell et al. 1986      self_help   21  535     no_contact   18  671 se-no    se-no #> 15 15    13     Sanders et al. 1989 ind_counseling  107  761     no_contact   64  642 in-no    in-no #> 16 16    14    Hilleman et al. 1993 grp_counseling   20   74 ind_counseling   12   76 gr-in    gr-in #> 17 17    15     Gillams et al. 1984 grp_counseling    3   26 ind_counseling    9   55 gr-in    gr-in #> 18 18    16 Mogielnicki et al. 1986 grp_counseling   32  127      self_help    7   66 gr-se    gr-se #> 19 19    17        Page et al. 1986 ind_counseling    8   90     no_contact    5   62 in-no    in-no #> 20 20    18    Vetter and Ford 1990 ind_counseling   34  237     no_contact   20  234 in-no    in-no #> 21 21    19  Williams and Hall 1988 grp_counseling    9   20     no_contact    0   20 gr-no    gr-no #> 22 22    20    Pallonen et al. 1994      self_help   19  149     no_contact    8  116 se-no    se-no #> 23 23    21     Russell et al. 1983 ind_counseling  143 1031     no_contact   95 1107 in-no    in-no #> 24 24    22 Stewart and Rosser 1982 ind_counseling   36  504     no_contact   15  187 in-no    in-no #> 25 25    23     Russell et al. 1979 ind_counseling   73  675     no_contact   78  584 in-no    in-no #> 26 26    24    Kendrick et al. 1995 ind_counseling   54  888     no_contact   69 1177 in-no    in-no  ### add contrast matrix dat <- contrmat(dat, grp1=\"trt.1\", grp2=\"trt.2\", shorten=TRUE, minlen=3) dat #>    id study            authors year          trt.1 xi.1 ni.1          trt.2 xi.2 ni.2  comp   design #> 1   1     1        Reid et al. 1974 ind_counseling  363  714     no_contact   75  731 in-no    in-no #> 2   2     2    Cottraux et al. 1983 grp_counseling   10  138     no_contact    9  140 gr-no gr-in-no #> 3   3     2    Cottraux et al. 1983 ind_counseling   23  140     no_contact    9  140 in-no gr-in-no #> 4   4     3       Slama et al. 1990 ind_counseling    9  205     no_contact    2  106 in-no    in-no #> 5   5     4    Jamrozik et al. 1984 ind_counseling  237 1561     no_contact   58  549 in-no    in-no #> 6   6     5      Rabkin et al. 1984 ind_counseling    9   48     no_contact    0   33 in-no    in-no #> 7   7     6   Decker and Evans 1989 ind_counseling   16   43      self_help   20   49 in-se    in-se #> 8   8     7    Richmond et al. 1986 ind_counseling   31   98     no_contact    3  100 in-no    in-no #> 9   9     8              Leung 1991 ind_counseling   26   95     no_contact    1   31 in-no    in-no #> 10 10     9  Mothersill et al. 1988 grp_counseling   29  170      self_help   11   78 gr-se gr-in-se #> 11 11     9  Mothersill et al. 1988 ind_counseling   12   85      self_help   11   78 in-se gr-in-se #> 12 12    10    Langford et al. 1983 ind_counseling   17   77     no_contact    6   39 in-no    in-no #> 13 13    11       Gritz et al. 1992      self_help   77  694     no_contact   79  702 se-no    se-no #> 14 14    12    Campbell et al. 1986      self_help   21  535     no_contact   18  671 se-no    se-no #> 15 15    13     Sanders et al. 1989 ind_counseling  107  761     no_contact   64  642 in-no    in-no #> 16 16    14    Hilleman et al. 1993 grp_counseling   20   74 ind_counseling   12   76 gr-in    gr-in #> 17 17    15     Gillams et al. 1984 grp_counseling    3   26 ind_counseling    9   55 gr-in    gr-in #> 18 18    16 Mogielnicki et al. 1986 grp_counseling   32  127      self_help    7   66 gr-se    gr-se #> 19 19    17        Page et al. 1986 ind_counseling    8   90     no_contact    5   62 in-no    in-no #> 20 20    18    Vetter and Ford 1990 ind_counseling   34  237     no_contact   20  234 in-no    in-no #> 21 21    19  Williams and Hall 1988 grp_counseling    9   20     no_contact    0   20 gr-no    gr-no #> 22 22    20    Pallonen et al. 1994      self_help   19  149     no_contact    8  116 se-no    se-no #> 23 23    21     Russell et al. 1983 ind_counseling  143 1031     no_contact   95 1107 in-no    in-no #> 24 24    22 Stewart and Rosser 1982 ind_counseling   36  504     no_contact   15  187 in-no    in-no #> 25 25    23     Russell et al. 1979 ind_counseling   73  675     no_contact   78  584 in-no    in-no #> 26 26    24    Kendrick et al. 1995 ind_counseling   54  888     no_contact   69 1177 in-no    in-no #>    grp ind sel no_ #> 1    0   1   0  -1 #> 2    1   0   0  -1 #> 3    0   1   0  -1 #> 4    0   1   0  -1 #> 5    0   1   0  -1 #> 6    0   1   0  -1 #> 7    0   1  -1   0 #> 8    0   1   0  -1 #> 9    0   1   0  -1 #> 10   1   0  -1   0 #> 11   0   1  -1   0 #> 12   0   1   0  -1 #> 13   0   0   1  -1 #> 14   0   0   1  -1 #> 15   0   1   0  -1 #> 16   1  -1   0   0 #> 17   1  -1   0   0 #> 18   1   0  -1   0 #> 19   0   1   0  -1 #> 20   0   1   0  -1 #> 21   1   0   0  -1 #> 22   0   0   1  -1 #> 23   0   1   0  -1 #> 24   0   1   0  -1 #> 25   0   1   0  -1 #> 26   0   1   0  -1"},{"path":"/reference/cumul.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative Meta-Analysis for 'rma' Objects — cumul","title":"Cumulative Meta-Analysis for 'rma' Objects — cumul","text":"functions repeatedly fit specified model, adding one study time model.","code":""},{"path":"/reference/cumul.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative Meta-Analysis for 'rma' Objects — cumul","text":"","code":"cumul(x, ...)  # S3 method for rma.uni cumul(x, order, digits, transf, targs, progbar=FALSE, ...) # S3 method for rma.mh cumul(x, order, digits, transf, targs, progbar=FALSE, ...) # S3 method for rma.peto cumul(x, order, digits, transf, targs, progbar=FALSE, ...)"},{"path":"/reference/cumul.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative Meta-Analysis for 'rma' Objects — cumul","text":"x object class \"rma.mh\", \"rma.peto\", \"rma.uni\". order optional argument specify variable based studies ordered cumulative meta-analysis. digits optional integer specify number decimal places printed results rounded. unspecified, default take value object. transf optional argument specify function used transform model coefficients interval bounds (e.g., transf=exp; see also transf). unspecified, transformation used. targs optional arguments needed function specified transf. progbar logical specify whether progress bar shown (default FALSE). ... arguments.","code":""},{"path":"/reference/cumul.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cumulative Meta-Analysis for 'rma' Objects — cumul","text":"\"rma.uni\" objects, model specified via x must model without moderators (.e., either equal- random-effects model). argument order specified, studies added according order original dataset. variable specified order, variable assumed length original dataset used model fitting. subsetting removal studies missing values applied model fitting also automatically applied variable specified via order argument. See ‘Examples’.","code":""},{"path":"/reference/cumul.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cumulative Meta-Analysis for 'rma' Objects — cumul","text":"object class c(\"list.rma\",\"cumul.rma\"). object list containing following components: estimate estimated (average) outcomes. se corresponding standard errors. zval corresponding test statistics. pval corresponding p-values. ci.lb lower bounds confidence intervals. ci.ub upper bounds confidence intervals. Q test statistics test heterogeneity. Qp corresponding p-values. tau2 estimated amount heterogeneity (random-effects models). I2 values \\(^2\\). H2 values \\(H^2\\). ... arguments. model fitted test=\"t\" test=\"knha\", zval called tval object returned function.    object formatted printed print function. forest plot showing results cumulative meta-analysis can obtained forest. Alternatively, plot can also used visualize results.","code":""},{"path":"/reference/cumul.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Cumulative Meta-Analysis for 'rma' Objects — cumul","text":"using transf option, transformation applied estimated coefficients corresponding interval bounds. standard errors set equal NA omitted printed output.","code":""},{"path":"/reference/cumul.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cumulative Meta-Analysis for 'rma' Objects — cumul","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/cumul.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cumulative Meta-Analysis for 'rma' Objects — cumul","text":"Chalmers, T. C., & Lau, J. (1993). Meta-analytic stimulus changes clinical trials. Statistical Methods Medical Research, 2(2), 161--172. https://doi.org/10.1177/096228029300200204 Lau, J., Schmid, C. H., & Chalmers, T. C. (1995). Cumulative meta-analysis clinical trials builds evidence exemplary medical care. Journal Clinical Epidemiology, 48(1), 45--57. https://doi.org/10.1016/0895-4356(94)00106-z Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/cumul.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumulative Meta-Analysis for 'rma' Objects — cumul","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit random-effects model res <- rma(yi, vi, data=dat)  ### cumulative meta-analysis (in the order of publication year) cumul(res, transf=exp, order=dat$year) #>  #>    estimate    zval  pvals  ci.lb  ci.ub        Q     Qp   tau2      I2      H2  #> 1    0.4109 -1.5586 0.1191 0.1343 1.2574   0.0000 1.0000 0.0000  0.0000  1.0000  #> 2    0.2658 -3.7967 0.0001 0.1341 0.5268   0.9315 0.3345 0.0000  0.0000  1.0000  #> 6    0.3783 -3.9602 0.0001 0.2338 0.6120   3.1879 0.2031 0.0872 40.7090  1.6866  #> 3    0.3675 -4.5037 0.0000 0.2377 0.5681   3.8614 0.2768 0.0763 33.9750  1.5146  #> 10   0.3324 -5.5164 0.0000 0.2248 0.4916   7.6415 0.1056 0.0858 48.4120  1.9384  #> 9    0.3778 -5.1875 0.0000 0.2615 0.5457  10.1854 0.0702 0.1046 60.0008  2.5000  #> 12   0.4061 -4.7250 0.0000 0.2794 0.5901  13.2116 0.0398 0.1205 59.9982  2.4999  #> 5    0.4545 -4.0039 0.0001 0.3089 0.6686  19.5749 0.0066 0.1780 72.3904  3.6219  #> 7    0.4208 -4.4107 0.0000 0.2864 0.6182  22.8208 0.0036 0.2023 73.5065  3.7745  #> 11   0.4560 -4.3588 0.0000 0.3204 0.6491  34.1203 0.0001 0.2005 81.4029  5.3772  #> 13   0.4925 -3.9701 0.0001 0.3472 0.6987  39.6122 0.0000 0.2281 83.0110  5.8862  #> 4    0.4517 -4.4184 0.0000 0.3175 0.6426  67.9858 0.0000 0.2732 87.0314  7.7109  #> 8    0.4894 -3.9744 0.0001 0.3441 0.6962 152.2330 0.0000 0.3132 92.2214 12.8558  #>   ### meta-analysis of the (log) risk ratios using the Mantel-Haenszel method res <- rma.mh(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### cumulative meta-analysis cumul(res, order=dat.bcg$year) #>  #>    estimate     se     zval   pval   ci.lb   ci.ub        Q     Qp      I2      H2  #> 1   -0.8893 0.5706  -1.5586 0.1191 -2.0077  0.2290   0.0000 1.0000  0.0000  1.0000  #> 2   -1.3517 0.3455  -3.9124 0.0001 -2.0289 -0.6746   0.9373 0.3330  0.0000  0.9373  #> 6   -0.8273 0.0808 -10.2371 0.0000 -0.9857 -0.6689   3.2109 0.2008 37.7127  1.6055  #> 3   -0.8379 0.0802 -10.4490 0.0000 -0.9951 -0.6807   3.8945 0.2731 22.9687  1.2982  #> 10  -0.8940 0.0769 -11.6254 0.0000 -1.0447 -0.7433   7.7589 0.1008 48.4460  1.9397  #> 9   -0.8507 0.0730 -11.6480 0.0000 -0.9938 -0.7075  10.2660 0.0680 51.2956  2.0532  #> 12  -0.8358 0.0725 -11.5275 0.0000 -0.9779 -0.6937  13.2768 0.0388 54.8084  2.2128  #> 5   -0.7744 0.0688 -11.2623 0.0000 -0.9092 -0.6397  19.6127 0.0065 64.3088  2.8018  #> 7   -0.7896 0.0680 -11.6188 0.0000 -0.9228 -0.6564  22.8443 0.0036 64.9803  2.8555  #> 11  -0.6660 0.0577 -11.5373 0.0000 -0.7792 -0.5529  34.1377 0.0001 73.6362  3.7931  #> 13  -0.6351 0.0563 -11.2811 0.0000 -0.7454 -0.5247  39.6232 0.0000 74.7622  3.9623  #> 4   -0.7758 0.0520 -14.9267 0.0000 -0.8777 -0.6739  68.3763 0.0000 83.9126  6.2160  #> 8   -0.4537 0.0393 -11.5338 0.0000 -0.5308 -0.3766 152.5676 0.0000 92.1346 12.7140  #>  cumul(res, order=dat.bcg$year, transf=TRUE) #>  #>    estimate     zval   pval  ci.lb  ci.ub        Q     Qp      I2      H2  #> 1    0.4109  -1.5586 0.1191 0.1343 1.2574   0.0000 1.0000  0.0000  1.0000  #> 2    0.2588  -3.9124 0.0001 0.1315 0.5094   0.9373 0.3330  0.0000  0.9373  #> 6    0.4372 -10.2371 0.0000 0.3732 0.5123   3.2109 0.2008 37.7127  1.6055  #> 3    0.4326 -10.4490 0.0000 0.3697 0.5062   3.8945 0.2731 22.9687  1.2982  #> 10   0.4090 -11.6254 0.0000 0.3518 0.4756   7.7589 0.1008 48.4460  1.9397  #> 9    0.4271 -11.6480 0.0000 0.3702 0.4929  10.2660 0.0680 51.2956  2.0532  #> 12   0.4335 -11.5275 0.0000 0.3761 0.4997  13.2768 0.0388 54.8084  2.2128  #> 5    0.4610 -11.2623 0.0000 0.4028 0.5275  19.6127 0.0065 64.3088  2.8018  #> 7    0.4540 -11.6188 0.0000 0.3974 0.5187  22.8443 0.0036 64.9803  2.8555  #> 11   0.5138 -11.5373 0.0000 0.4588 0.5753  34.1377 0.0001 73.6362  3.7931  #> 13   0.5299 -11.2811 0.0000 0.4745 0.5917  39.6232 0.0000 74.7622  3.9623  #> 4    0.4603 -14.9267 0.0000 0.4158 0.5097  68.3763 0.0000 83.9126  6.2160  #> 8    0.6353 -11.5338 0.0000 0.5881 0.6862 152.5676 0.0000 92.1346 12.7140  #>   ### meta-analysis of the (log) odds ratios using Peto's method res <- rma.mh(ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### cumulative meta-analysis cumul(res, order=dat.bcg$year) #>  #>    estimate     se     zval   pval   ci.lb   ci.ub        Q     Qp      I2      H2  #> 1   -0.9387 0.5976  -1.5708 0.1162 -2.1100  0.2326   0.0000 1.0000  0.0000  1.0000  #> 2   -1.4215 0.3595  -3.9539 0.0001 -2.1261 -0.7169   0.9404 0.3322  0.0000  0.9404  #> 6   -0.9968 0.0957 -10.4137 0.0000 -1.1844 -0.8092   2.3134 0.3145 13.5455  1.1567  #> 3   -1.0061 0.0947 -10.6259 0.0000 -1.1917 -0.8205   2.6721 0.4450  0.0000  0.8907  #> 10  -1.0542 0.0893 -11.8020 0.0000 -1.2293 -0.8792   4.6200 0.3286 13.4195  1.1550  #> 9   -0.9846 0.0835 -11.7978 0.0000 -1.1482 -0.8211   9.5987 0.0874 47.9095  1.9197  #> 12  -0.9652 0.0827 -11.6734 0.0000 -1.1273 -0.8032  13.3029 0.0385 54.8972  2.2172  #> 5   -0.8805 0.0775 -11.3644 0.0000 -1.0323 -0.7286  22.4178 0.0022 68.7748  3.2025  #> 7   -0.8957 0.0766 -11.6965 0.0000 -1.0457 -0.7456  24.9324 0.0016 67.9132  3.1165  #> 11  -0.7286 0.0624 -11.6815 0.0000 -0.8508 -0.6063  41.0143 0.0000 78.0565  4.5571  #> 13  -0.6914 0.0607 -11.3982 0.0000 -0.8103 -0.5725  47.3437 0.0000 78.8779  4.7344  #> 4   -0.8333 0.0552 -15.0934 0.0000 -0.9415 -0.7251  73.1329 0.0000 84.9589  6.6484  #> 8   -0.4734 0.0410 -11.5444 0.0000 -0.5538 -0.3930 163.9426 0.0000 92.6804 13.6619  #>  cumul(res, order=dat.bcg$year, transf=TRUE) #>  #>    estimate     zval   pval  ci.lb  ci.ub        Q     Qp      I2      H2  #> 1    0.3911  -1.5708 0.1162 0.1212 1.2619   0.0000 1.0000  0.0000  1.0000  #> 2    0.2414  -3.9539 0.0001 0.1193 0.4883   0.9404 0.3322  0.0000  0.9404  #> 6    0.3691 -10.4137 0.0000 0.3059 0.4452   2.3134 0.3145 13.5455  1.1567  #> 3    0.3656 -10.6259 0.0000 0.3037 0.4402   2.6721 0.4450  0.0000  0.8907  #> 10   0.3485 -11.8020 0.0000 0.2925 0.4151   4.6200 0.3286 13.4195  1.1550  #> 9    0.3736 -11.7978 0.0000 0.3172 0.4400   9.5987 0.0874 47.9095  1.9197  #> 12   0.3809 -11.6734 0.0000 0.3239 0.4479  13.3029 0.0385 54.8972  2.2172  #> 5    0.4146 -11.3644 0.0000 0.3562 0.4826  22.4178 0.0022 68.7748  3.2025  #> 7    0.4083 -11.6965 0.0000 0.3514 0.4745  24.9324 0.0016 67.9132  3.1165  #> 11   0.4826 -11.6815 0.0000 0.4271 0.5454  41.0143 0.0000 78.0565  4.5571  #> 13   0.5009 -11.3982 0.0000 0.4447 0.5641  47.3437 0.0000 78.8779  4.7344  #> 4    0.4346 -15.0934 0.0000 0.3901 0.4843  73.1329 0.0000 84.9589  6.6484  #> 8    0.6229 -11.5444 0.0000 0.5748 0.6750 163.9426 0.0000 92.6804 13.6619  #>   ### make first log risk ratio missing and fit model without study 2; then the ### variable specified via 'order' should still be of the same length as the ### original dataset; subsetting and removal of studies with missing values is ### automatically done by the cumul() function dat$yi[1] <- NA res <- rma(yi, vi, data=dat, subset=-2) #> Warning: Studies with NAs omitted from model fitting. cumul(res, transf=exp, order=dat$year) #>  #>    estimate    zval  pvals  ci.lb  ci.ub        Q     Qp   tau2      I2      H2  #> 6    0.4556 -9.4599 0.0000 0.3871 0.5362   0.0000 1.0000 0.0000  0.0000  1.0000  #> 3    0.4514 -9.6497 0.0000 0.3841 0.5306   0.7478 0.3872 0.0000  0.0000  1.0000  #> 10   0.3504 -4.3207 0.0000 0.2178 0.5639   4.9051 0.0861 0.1008 59.6906  2.4808  #> 9    0.4100 -4.2685 0.0000 0.2722 0.6174   7.1487 0.0673 0.1034 66.8114  3.0131  #> 12   0.4480 -3.6703 0.0002 0.2918 0.6878  10.0666 0.0393 0.1304 66.7246  3.0052  #> 5    0.5075 -3.1669 0.0015 0.3335 0.7722  15.9241 0.0071 0.1704 75.5631  4.0922  #> 7    0.4584 -3.5536 0.0004 0.2981 0.7048  19.3442 0.0036 0.2132 77.6086  4.4660  #> 11   0.4970 -3.6803 0.0002 0.3425 0.7212  29.4342 0.0001 0.1880 83.2856  5.9829  #> 13   0.5390 -3.3443 0.0008 0.3752 0.7743  34.5952 0.0000 0.2077 84.0877  6.2845  #> 4    0.4835 -3.7288 0.0002 0.3300 0.7084  64.2052 0.0000 0.2831 89.1076  9.1808  #> 8    0.5262 -3.3578 0.0008 0.3618 0.7655 144.6390 0.0000 0.3139 93.3044 14.9352  #>"},{"path":"/reference/dfround.html","id":null,"dir":"Reference","previous_headings":"","what":"Round Variables in a Data Frame — dfround","title":"Round Variables in a Data Frame — dfround","text":"Function round numeric variables data frame.","code":""},{"path":"/reference/dfround.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Round Variables in a Data Frame — dfround","text":"","code":"dfround(x, digits)"},{"path":"/reference/dfround.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Round Variables in a Data Frame — dfround","text":"x data frame. digits either single integer numeric vector length columns x.","code":""},{"path":"/reference/dfround.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Round Variables in a Data Frame — dfround","text":"simple convenience function round numeric variables data frame, possibly different numbers digits. Hence, digits can either single integer (used round numeric variables specified number digits) numeric vector (length columns x) specify number digits variable rounded. Non-numeric variables skipped. digits vector, arbitrary value (NA) can specified variables.","code":""},{"path":"/reference/dfround.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Round Variables in a Data Frame — dfround","text":"Returns data frame variables rounded specified.","code":""},{"path":"/reference/dfround.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Round Variables in a Data Frame — dfround","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/dfround.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Round Variables in a Data Frame — dfround","text":"","code":"dat <- dat.bcg dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat) res <- rma(yi, vi, mods = ~ ablat + year, data=dat) coef(summary(res)) #>             estimate          se       zval        pval        ci.lb        ci.ub #> intrcpt -3.545505079 29.09587983 -0.1218559 0.903013130 -60.57238164 53.481371479 #> ablat   -0.028011275  0.01023404 -2.7370689 0.006198931  -0.04806963 -0.007952924 #> year     0.001907557  0.01468382  0.1299088 0.896638598  -0.02687219  0.030687307 dfround(coef(summary(res)), digits=c(2,3,2,3,2,2)) #>         estimate     se  zval  pval  ci.lb ci.ub #> intrcpt    -3.55 29.096 -0.12 0.903 -60.57 53.48 #> ablat      -0.03  0.010 -2.74 0.006  -0.05 -0.01 #> year        0.00  0.015  0.13 0.897  -0.03  0.03"},{"path":"/reference/escalc.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Effect Sizes and Outcome Measures — escalc","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"function can used calculate various effect sizes outcome measures (corresponding sampling variances) commonly used meta-analyses.","code":""},{"path":"/reference/escalc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"","code":"escalc(measure, ai, bi, ci, di, n1i, n2i, x1i, x2i, t1i, t2i,        m1i, m2i, sd1i, sd2i, xi, mi, ri, ti, sdi, r2i, ni, yi, vi, sei,        data, slab, subset, include,        add=1/2, to=\"only0\", drop00=FALSE, vtype=\"LS\",        var.names=c(\"yi\",\"vi\"), add.measure=FALSE,        append=TRUE, replace=TRUE, digits, ...)"},{"path":"/reference/escalc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"measure character string specify effect size outcome measure calculated. See ‘Details’ possible options data needed compute selected effect size outcome measure specified. ai vector specify \\(2 \\times 2\\) table frequencies (upper left cell). bi vector specify \\(2 \\times 2\\) table frequencies (upper right cell). ci vector specify \\(2 \\times 2\\) table frequencies (lower left cell). di vector specify \\(2 \\times 2\\) table frequencies (lower right cell). n1i vector specify group sizes row totals (first group/row). n2i vector specify group sizes row totals (second group/row). x1i vector specify number events (first group). x2i vector specify number events (second group). t1i vector specify total person-times (first group). t2i vector specify total person-times (second group). m1i vector specify means (first group time point). m2i vector specify means (second group time point). sd1i vector specify standard deviations (first group time point). sd2i vector specify standard deviations (second group time point). xi vector specify frequencies event interest. mi vector specify frequencies complement event interest group means. ri vector specify raw correlation coefficients. ti vector specify total person-times. sdi vector specify standard deviations. r2i vector specify \\(R^2\\) values. ni vector specify sample/group sizes. yi vector specify observed effect sizes outcomes. vi vector specify corresponding sampling variances. sei vector specify corresponding standard errors. data optional data frame containing variables given arguments . slab optional vector labels studies. subset optional (logical numeric) vector specify subset studies included data frame returned function. include optional (logical numeric) vector specify subset studies measure calculated. See ‘Value’ section details. add non-negative number specify amount add zero cells, counts, frequencies. See ‘Details’. character string specify values add added (either \"\", \"only0\", \"if0all\", \"none\"). See ‘Details’. drop00 logical specify whether studies cases/events (cases) groups dropped calculating observed effect sizes outcomes. See ‘Details’. vtype character string specify type sampling variances calculate. See ‘Details’. var.names character string two elements specify name variable observed effect sizes outcomes name variable corresponding sampling variances (defaults \"yi\" \"vi\"). add.measure logical specify whether variable added data frame (default name \"measure\") indicates type outcome measure computed. using option, var.names can third element change variable name. append logical specify whether data frame provided via data argument returned together observed effect sizes outcomes corresponding sampling variances (default TRUE). replace logical specify whether existing values yi vi data frame replaced . relevant append=TRUE data frame already contains yi vi variables. replace=TRUE (default), existing values overwritten. replace=FALSE, NA values replaced. See ‘Value’ section details. digits optional integer specify number decimal places printed results rounded. unspecified, default 4. Note values stored without rounding returned object. See also details control number digits output. ... arguments.","code":""},{"path":"/reference/escalc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"meta-analysis can conducted, relevant results study must quantified way resulting values can aggregated compared. Depending () goals meta-analysis, (b) design types studies included, (c) information provided therein, one various effect size outcome measures described may appropriate meta-analysis can computed escalc function. measure argument character string specify outcome measure calculated (see various options), arguments ai ni used specify information needed calculate various measures (depending chosen outcome measure, different arguments need specified), data can used specify data frame containing variables given previous arguments. add, , drop00 arguments may needed dealing frequency count data may need special handling frequencies counts equal zero (see details). Finally, vtype argument used specify sampling variances estimated (, see details). provide structure various effect size outcome measures can calculated escalc function, can distinguish measures used : contrast two independent (either experimentally created naturally occurring) groups, describe direction strength association two variables, summarize characteristic attribute individual groups, quantify change within single group difference two matched pairs samples. Furthermore, appropriate, can distinguish measures applicable characteristic, response, dependent variable assessed individual studies : dichotomous (binary) variable (e.g., remission versus remission), count events per time unit (e.g., number migraines per year), quantitative variable (e.g., amount depression assessed rating scale).","code":""},{"path":"/reference/escalc.html","id":"outcome-measures-for-two-group-comparisons","dir":"Reference","previous_headings":"","what":"Outcome Measures for Two-Group Comparisons","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"many meta-analyses, goal synthesize results studies compare contrast two groups. groups may experimentally defined (e.g., treatment control group created via random assignment) may occur naturally (e.g., men women, employees working high- versus low-stress conditions, people exposed environmental risk factor versus exposed).","code":""},{"path":"/reference/escalc.html","id":"measures-for-dichotomous-variables","dir":"Reference","previous_headings":"","what":"Measures for Dichotomous Variables","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"various fields (health medical sciences), response variable measured often dichotomous (binary), data study comparing two different groups can expressed terms \\(2 \\times 2\\) table, : ai, bi, ci, di denote cell frequencies (.e., number people falling particular category) n1i n2i row totals (.e., group sizes). example, set randomized clinical trials, group 1 group 2 may refer treatment placebo/control group, respectively, outcome 1 denoting event interest (e.g., death, complications, failure improve treatment) outcome 2 complement. Similarly, set cohort studies, group 1 group 2 may denote engage engage potentially harmful behavior (e.g., smoking), outcome 1 denoting development particular disease (e.g., lung cancer) follow-period. Finally, set case-control studies, group 1 group 2 may refer disease (.e., cases) free disease (.e., controls), outcome 1 denoting, example, exposure environmental risk factor past outcome 2 non-exposure. Note examples, stratified sampling scheme fixes row totals (.e., group sizes) design. meta-analysis studies reporting results terms \\(2 \\times 2\\) tables can based one several different outcome measures, including risk ratio (also called relative risk), odds ratio, risk difference, arcsine square root transformed risk difference (e.g., Fleiss & Berlin, 2009, Rücker et al., 2009). outcome measures, one needs specify cell frequencies via ai, bi, ci, di arguments (alternatively, one can use ai, ci, n1i, n2i arguments). options measure argument : \"RR\" log risk ratio, \"\" log odds ratio, \"RD\" risk difference, \"\" arcsine square root transformed risk difference (Rücker et al., 2009), \"PETO\" log odds ratio estimated Peto's method (Yusuf et al., 1985). Note log taken risk ratio odds ratio, makes outcome measures symmetric around 0 yields corresponding sampling distributions closer normality. Also, multiplied 2, arcsine square root transformed risk difference actually identical Cohen's h (Cohen, 1988). \\(2 \\times 2\\) table available (reconstructed) study, measures odds ratio corresponding confidence interval bounds reported, one one can easily transform values corresponding log odds ratio sampling variance directly. See illustration/discussion . Cell entries zero count can problematic, especially risk ratio odds ratio. Adding small constant cells \\(2 \\times 2\\) tables common solution problem. =\"only0\" (default), value add (default 1/2; see ‘Note’) added cell \\(2 \\times 2\\) tables least one cell equal 0. =\"\", value add added cell \\(2 \\times 2\\) tables. =\"if0all\", value add added cell \\(2 \\times 2\\) tables, least one \\(2 \\times 2\\) table zero cell. Setting =\"none\" add=0 effect: adjustment observed table frequencies made. Depending outcome measure data, may lead division zero (occurs, resulting value recoded NA). Also, studies ai=ci=0 bi=di=0 may considered uninformative size effect dropping studies sometimes recommended (Higgins et al., 2019). can done setting drop00=TRUE. values studies set NA. Datasets corresponding data type provided dat.bcg, dat.collins1985a, dat.collins1985b, dat.egger2001, dat.hine1989, dat.laopaiboon2015, dat.lee2004, dat.li2007, dat.linde2005, dat.nielweise2007, dat.yusuf1985. Assuming dichotomous outcome actually dichotomized version responses underlying quantitative scale, also possible estimate standardized mean difference based \\(2 \\times 2\\) table data, using either probit transformed risk difference transformation odds ratio (e.g., Cox & Snell, 1989; Chinn, 2000; Hasselblad & Hedges, 1995; Sánchez-Meca et al., 2003). options measure argument : \"PBIT\" probit transformed risk difference estimate standardized mean difference, \"OR2DN\" transformed odds ratio estimate standardized mean difference (assuming normal distributions), \"OR2DL\" transformed odds ratio estimate standardized mean difference (assuming logistic distributions). probit transformation assumes responses underlying quantitative scale normally distributed. two versions odds ratio transformation, first also assuming normal distributions within two groups, second assumes responses within groups follow logistic distributions. dataset corresponding data type provided dat.gibson2002.","code":""},{"path":"/reference/escalc.html","id":"measures-for-event-counts","dir":"Reference","previous_headings":"","what":"Measures for Event Counts","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"medical epidemiological studies comparing two different groups (e.g., treated versus untreated patients, exposed versus unexposed individuals), results sometimes reported terms event counts (.e., number events, strokes myocardial infarctions) certain period time. Data type also referred ‘person-time data’. Assume studies report data form: x1i x2i denote number events first second group, respectively, t1i t2i corresponding total person-times risk. Often, person-time measured years, t1i t2i denote total number follow-years two groups. form data fundamentally different described previous section, since total follow-time may differ even groups size individuals studied may experience event interest multiple times. Hence, different outcome measures ones described previous section need considered data reported format. include incidence rate ratio, incidence rate difference, square root transformed incidence rate difference (Bagos & Nikolopoulos, 2009; Rothman et al., 2008). outcome measures, one needs specify total number events via x1i x2i arguments corresponding total person-time values via t1i t2i arguments. options measure argument : \"IRR\" log incidence rate ratio, \"IRD\" incidence rate difference, \"IRSD\" square root transformed incidence rate difference. Note log taken incidence rate ratio, makes outcome measure symmetric around 0 yields corresponding sampling distribution closer normality. Studies zero events one groups can problematic, especially incidence rate ratio. Adding small constant number events common solution problem. =\"only0\" (default), value add (default 1/2; see ‘Note’) added x1i x2i studies zero events one groups. =\"\", value add added x1i x2i studies. =\"if0all\", value add added x1i x2i studies, least one study zero events one groups. Setting =\"none\" add=0 effect: adjustment observed number events made. Depending outcome measure data, may lead division zero (occurs, resulting value recoded NA). Like \\(2 \\times 2\\) table data, studies x1i=x2i=0 may considered uninformative size effect dropping studies sometimes recommended. can done setting drop00=TRUE. values studies set NA. Datasets corresponding data type provided dat.hart1999 dat.nielweise2008.","code":""},{"path":"/reference/escalc.html","id":"measures-for-quantitative-variables","dir":"Reference","previous_headings":"","what":"Measures for Quantitative Variables","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"response dependent variable assessed individual studies measured quantitative scale, customary report certain summary statistics, mean standard deviation observations. data layout study comparing two groups respect variable form: m1i m2i observed means two groups, sd1i sd2i observed standard deviations, n1i n2i denote number individuals group. , two groups may experimentally created (e.g., treatment control group based random assignment) naturally occurring (e.g., men women). either case, raw mean difference, standardized mean difference, (log transformed) ratio means (also called log response ratio) useful outcome measures meta-analyzing studies type. options measure argument : \"MD\" raw mean difference (e.g., Borenstein, 2009), \"SMD\" standardized mean difference (Hedges, 1981), \"SMDH\" standardized mean difference heteroscedastic population variances two groups (Bonett, 2008, 2009), \"ROM\" log transformed ratio means (Hedges et al., 1999; Lajeunesse, 2011). measure=\"ROM\", log taken ratio means, makes outcome measure symmetric around 0 yields corresponding sampling distribution closer normality. Hence, measure computed m1i m2i opposite signs (.e., meant used ratio scale measurements, means positive anyway). measure=\"SMD\", positive bias standardized mean difference (.e., Cohen's d value) automatically corrected within function, yielding Hedges' g (Hedges, 1981). Similarly, bias correction applied measure=\"SMDH\" (Bonett, 2009). measure=\"SMD\", means standard deviations unknown study, t-statistic independent samples t-test reported (corresponding p-value, can transformed t-statistic), one can easily transform t-statistic d-value directly. See illustration/discussion . measure=\"MD\", one can choose vtype=\"LS\" (default) vtype=\"HO\". former computes sampling variances without assuming homoscedasticity (.e., true variances measurements group 1 group 2 within study), latter assumes homoscedasticity (equations 12.5 12.3 Borenstein, 2009, respectively). measure=\"SMD\", one can choose vtype=\"LS\" (default) usual large-sample approximation compute sampling variances (equation 8 Hedges, 1982), vtype=\"UB\" compute unbiased estimates sampling variances (equation 9 Hedges, 1983), vtype=\"LS2\" compute sampling variances described Borenstein (2009) (.e., equation 12.17), vtype=\"AV\" compute sampling variances usual large-sample approximation plugging sample-size weighted average Hedges' g values equation. measure=\"ROM\", one can choose vtype=\"LS\" (default) usual large-sample approximation compute sampling variances (equation 1 Hedges et al., 1999), vtype=\"HO\" compute sampling variances assuming homoscedasticity (unnumbered equation equation 1 Hedges et al., 1999), vtype=\"AV\" compute sampling variances assuming homoscedasticity coefficient variation within group across studies, vtype=\"AVHO\" compute sampling variances assuming homoscedasticity coefficient variation groups across studies. Datasets corresponding data type provided dat.normand1999 dat.curtis1998. also possible transform standardized mean differences log odds ratios (e.g., Cox & Snell, 1989; Chinn, 2000; Hasselblad & Hedges, 1995; Sánchez-Meca et al., 2003). options measure argument : \"D2ORN\" transformed standardized mean difference estimate log odds ratio (assuming normal distributions), \"D2ORL\" transformed standardized mean difference estimate log odds ratio (assuming logistic distributions). transformations provide estimate log odds ratio, first assuming responses within two groups normally distributed, second assumes responses follow logistic distributions. dataset illustrating combined analysis standardized mean differences probit transformed risk differences provided dat.gibson2002. Finally, interest may also focused differences two groups respect variability. , (log transformed) ratio coefficient variation two groups (also called coefficient variation ratio) can useful measure (Nakagawa et al., 2015). focus solely variability measurements within two groups, (log transformed) ratio standard deviations (also called variability ratio) can used (Nakagawa et al., 2015). latter, one needs specify sd1i, sd2i, n1i, n2i. options measure argument : \"CVR\" log transformed coefficient variation ratio, \"VR\" log transformed variability ratio. Note slight bias correction applied measures (Nakagawa et al., 2015). Also, sampling variance measure=\"CVR\" computed given equation 12 Nakagawa et al. (2015), without ‘\\(-2 \\rho \\ldots\\)’ terms, since normally distributed data (assume ) mean variance (transformations thereof) independent.","code":""},{"path":"/reference/escalc.html","id":"outcome-measures-for-variable-association","dir":"Reference","previous_headings":"","what":"Outcome Measures for Variable Association","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"Meta-analyses often used synthesize studies examine direction strength association two variables measured concurrently /without manipulation experimenters. section, variety outcome measures discussed may suitable meta-analyses purpose. can distinguish measures applicable variables measured quantitative scales, variables measured dichotomous, two variables mixed types.","code":""},{"path":"/reference/escalc.html","id":"measures-for-two-quantitative-variables","dir":"Reference","previous_headings":"","what":"Measures for Two Quantitative Variables","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"(Pearson product-moment) correlation coefficient quantifies direction strength (linear) relationship two quantitative variables therefore frequently used outcome measure meta-analyses. Two alternative measures bias-corrected version correlation coefficient Fisher's r--z transformed correlation coefficient. measures, one needs specify ri, vector raw correlation coefficients, ni, corresponding sample sizes. options measure argument : \"COR\" raw correlation coefficient, \"UCOR\" raw correlation coefficient corrected slight negative bias (based equation 2.3 Olkin & Pratt, 1958), \"ZCOR\" Fisher's r--z transformed correlation coefficient (Fisher, 1921). measure=\"COR\" measure=\"UCOR\", one can choose vtype=\"LS\" (default) usual large-sample approximation compute sampling variances (.e., plugging (biased-corrected) correlation coefficients equation 12.27 Borenstein, 2009), vtype=\"UB\" compute unbiased estimates sampling variances (see Hedges, 1989, using exact equation instead approximation), vtype=\"AV\" compute sampling variances usual large-sample approximation plugging sample-size weighted average (bias-corrected) correlation coefficients equation. Datasets corresponding data type provided dat.mcdaniel1994 dat.molloy2014. meta-analyses involving multiple correlations extracted sample, see also rcalc function.","code":""},{"path":"/reference/escalc.html","id":"measures-for-two-dichotomous-variables","dir":"Reference","previous_headings":"","what":"Measures for Two Dichotomous Variables","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"goal meta-analysis examine relationship two dichotomous variables, data study can presented form \\(2 \\times 2\\) table, except may clear distinction grouping variable outcome variable. Moreover, table may result cross-sectional (.e., multinomial) sampling, none table margins (except total sample size) fixed study design. phi coefficient odds ratio commonly used measures association \\(2 \\times 2\\) table data (e.g., Fleiss & Berlin, 2009). latter particularly advantageous, directly comparable values obtained stratified sampling (described earlier). Yule's Q Yule's Y (Yule, 1912) additional measures association \\(2 \\times 2\\) table data (although typically used meta-analyses). Finally, assuming two dichotomous variables actually dichotomized versions responses two underlying quantitative scales (assuming two variables follow bivariate normal distribution), also possible estimate correlation two variables using tetrachoric correlation coefficient (Pearson, 1900; Kirk, 1973). outcome measures, one needs specify cell frequencies via ai, bi, ci, di arguments (alternatively, one can use ai, ci, n1i, n2i arguments). options measure argument : \"\" log odds ratio, \"PHI\" phi coefficient, \"YUQ\" Yule's Q (Yule, 1912), \"YUY\" Yule's Y (Yule, 1912), \"RTET\" tetrachoric correlation coefficient. Tables one zero counts handled described earlier. measure=\"PHI\", one must indicate via vtype=\"ST\" vtype=\"CS\" whether data studies obtained using stratified cross-sectional (.e., multinomial) sampling, respectively (also possible specify entire vector vtype argument case sampling scheme differed various studies). dataset corresponding data type provided dat.bourassa1996.","code":""},{"path":"/reference/escalc.html","id":"measures-for-mixed-variable-types","dir":"Reference","previous_headings":"","what":"Measures for Mixed Variable Types","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"Finally, can consider outcome measures can used describe relationship two variables, one variable dichotomous variable measures quantitative characteristic. case, likely study authors report summary statistics, mean standard deviation measurements within two groups (defined dichotomous variable). Based information, one can compute point-biserial correlation coefficient (Tate, 1954) measure association two variables. dichotomous variable actually dichotomized version responses underlying quantitative scale (assuming two variables follow bivariate normal distribution), also possible estimate correlation two variables using biserial correlation coefficient (Pearson, 1909; Soper, 1914; Jacobs & Viechtbauer, 2017). , one needs specify m1i m2i observed means two groups, sd1i sd2i observed standard deviations, n1i n2i number individuals group. options measure argument : \"RPB\" point-biserial correlation coefficient, \"RBIS\" biserial correlation coefficient. measure=\"RPB\", one must indicate via vtype=\"ST\" vtype=\"CS\" whether data studies obtained using stratified cross-sectional (.e., multinomial) sampling, respectively (also possible specify entire vector vtype argument case sampling scheme differed various studies).","code":""},{"path":"/reference/escalc.html","id":"outcome-measures-for-individual-groups","dir":"Reference","previous_headings":"","what":"Outcome Measures for Individual Groups","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"section, outcome measures described may useful goal meta-analysis synthesize studies characterize property individual groups. distinguish measures applicable characteristic interest dichotomous variable, characteristic represents event count, characteristic assessed quantitative variable.","code":""},{"path":"/reference/escalc.html","id":"measures-for-dichotomous-variables-1","dir":"Reference","previous_headings":"","what":"Measures for Dichotomous Variables","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"meta-analysis may conducted aggregate studies provide data individual groups respect dichotomous dependent variable. , one needs specify xi ni, denoting number individuals experiencing event interest total number individuals within study, respectively. Instead specifying ni, one can use mi specify number individuals experience event interest. options measure argument : \"PR\" raw proportion, \"PLN\" log transformed proportion, \"PLO\" logit transformed proportion (.e., log odds), \"PAS\" arcsine square root transformed proportion (.e., angular transformation), \"PFT\" Freeman-Tukey double arcsine transformed proportion (Freeman & Tukey, 1950). Zero cell entries can problematic certain outcome measures. =\"only0\" (default), value add (default 1/2; see ‘Note’) added xi mi studies xi mi equal 0. =\"\", value add added xi mi studies. =\"if0all\", value add added studies, least one study zero value xi mi. Setting =\"none\" add=0 effect: adjustment observed values made. Depending outcome measure data, may lead division zero (occurs, resulting value recoded NA). Datasets corresponding data type provided dat.pritz1997 dat.debruin2009.","code":""},{"path":"/reference/escalc.html","id":"measures-for-event-counts-1","dir":"Reference","previous_headings":"","what":"Measures for Event Counts","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"Various measures can used characterize individual groups dependent variable assessed event count. , one needs specify xi ti, denoting number events occurred total person-times risk, respectively. options measure argument : \"IR\" raw incidence rate, \"IRLN\" log transformed incidence rate, \"IRS\" square root transformed incidence rate, \"IRFT\" Freeman-Tukey transformed incidence rate (Freeman & Tukey, 1950). Measures \"IR\" \"IRLN\" can also used meta-analyzing standardized incidence ratios (SIRs), observed number events divided expected number events. case, arguments xi ti used specify observed expected number events studies. Since SIRs symmetric around 1, usually appropriate meta-analyze log transformed SIRs (.e., using measure \"IRLN\"), symmetric around 0. Studies zero events can problematic, especially log transformed incidence rate. Adding small constant number events common solution problem. =\"only0\" (default), value add (default 1/2; see ‘Note’) added xi studies zero events. =\"\", value add added xi studies. =\"if0all\", value add added xi studies, least one study zero events. Setting =\"none\" add=0 effect: adjustment observed number events made. Depending outcome measure data, may lead division zero (occurs, resulting value recoded NA).","code":""},{"path":"/reference/escalc.html","id":"measures-for-quantitative-variables-1","dir":"Reference","previous_headings":"","what":"Measures for Quantitative Variables","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"goal meta-analysis may also characterize individual groups, response, characteristic, dependent variable assessed individual studies measured quantitative scale. simplest case, raw mean quantitative variable reported group, becomes observed outcome meta-analysis. , one needs specify mi, sdi, ni observed means, observed standard deviations, sample sizes, respectively. ratio scale measurements, log transformed mean log transformed coefficient variation (bias correction) may also interest (Nakagawa et al., 2015). focus solely variability measurements, log transformed standard deviation (bias correction) useful measure (Nakagawa et al., 2015; Raudenbush & Bryk, 1987). , one needs specify sdi ni. options measure argument : \"MN\" raw mean, \"MNLN\" log transformed mean, \"CVLN\" log transformed coefficient variation, \"SDLN\" log transformed standard deviation. Note sdi used specify standard deviations observed values response, characteristic, dependent variable standard errors means. Also, sampling variance measure=\"CVLN\" computed given equation 27 Nakagawa et al. (2015), without ‘\\(-2 \\rho \\ldots\\)’ term, since normally distributed data (assume ) mean variance (transformations thereof) independent.","code":""},{"path":"/reference/escalc.html","id":"outcome-measures-for-change-or-matched-pairs","dir":"Reference","previous_headings":"","what":"Outcome Measures for Change or Matched Pairs","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"complicated situation arises purpose meta-analysis assess amount change within individual groups (e.g., treatment two different treatments) dealing matched pairs designs.","code":""},{"path":"/reference/escalc.html","id":"measures-for-dichotomous-variables-2","dir":"Reference","previous_headings":"","what":"Measures for Dichotomous Variables","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"dichotomous variables, data study type gives rise paired \\(2 \\times 2\\) table, form: ai, bi, ci, di denote cell frequencies. Note ‘trt1’ ‘trt2’ may applied single group subjects matched pairs subjects. Also, ‘trt1’ ‘trt2’ might refer two different time points (e.g., treatment). case, data study can rearranged marginal table form: form \\(2 \\times 2\\) table arise study comparing/contrasting two independent groups. options measure argument compute outcome measures based marginal table : \"MPRR\" matched pairs marginal log risk ratio, \"MPOR\" matched pairs marginal log odds ratio, \"MPRD\" matched pairs marginal risk difference. See Becker Balagtas (1993), Curtin et al. (2002), Elbourne et al. (2002), Fagerland et al. (2014), May Johnson (1997), Newcombe (1998), Stedman et al. (2011), Zou (2007) discussions measures. options measure argument compute outcome measures based paired table : \"MPORC\" conditional log odds ratio, \"MPPETO\" conditional log odds ratio estimated Peto's method. See Curtin et al. (2002) Zou (2007) discussions measures. marginal tables available, another possibility compute marginal log odds ratios based table directly. However, correct computation sampling variances, correlations (phi coefficients) paired tables must known (‘guestimated’). use approach, set measure=\"MPORM\" use argument ri specify correlation coefficients.","code":""},{"path":"/reference/escalc.html","id":"measures-for-quantitative-variables-2","dir":"Reference","previous_headings":"","what":"Measures for Quantitative Variables","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"response dependent variable assessed individual studies measured quantitative scale, raw mean change, standardized versions thereof, (log transformed) ratio means (log response ratio) can used outcome measures (Becker, 1988; Gibbons et al., 1993; Lajeunesse, 2011; Morris, 2000). , one needs specify m1i m2i, observed means two measurement occasions, sd1i sd2i corresponding observed standard deviations, ri correlation measurements two measurement occasions, ni sample size. options measure argument : \"MC\" raw mean change, \"SMCC\" standardized mean change using change score standardization (Gibbons et al., 1993), \"SMCR\" standardized mean change using raw score standardization (Becker, 1988), \"SMCRH\" standardized mean change using raw score standardization heteroscedastic population variances two measurement occasions (Bonett, 2008), \"ROMC\" log transformed ratio means (Lajeunesse, 2011). See also Morris DeShon (2002) thorough discussion difference change score measures. notes change score measures. practice, one often mix information available individual studies compute measures. particular, m1i m2i unknown, raw mean change directly reported particular study, one can set m1i value m2i 0 (making sure raw mean change computed m1i-m2i within study way around). Also, raw mean change (\"MC\") standardized mean change using change score standardization (\"SMCC\"), sd1i, sd2i, ri unknown, standard deviation change scores directly reported, one can set sd1i value sd2i ri 0. Finally, standardized mean change using raw score standardization (\"SMCR\"), argument sd2i actually needed, standardization based sd1i (Becker, 1988; Morris, 2000), usually pre-test standard deviation (post-test standard deviation used, set sd1i ). Note measures also applicable matched-pairs designs (subscripts 1 2 simply denote first second group formed matching). Finally, interest may also focused differences variability measurements two measurement occasions (two matched groups). , (log transformed) ratio coefficient variation (also called coefficient variation ratio) can useful measure (Nakagawa et al., 2015). focus solely variability measurements, (log transformed) ratio standard deviations (also called variability ratio) can used (Nakagawa et al., 2015). latter, one needs specify sd1i, sd2i, ni, ri. options measure argument : \"CVRC\" log transformed coefficient variation ratio, \"VRC\" log transformed variability ratio. definitions measures given Nakagawa et al. (2015) computed two sets dependent measurements. Hence, computation sampling variances adjusted take correlation measurements consideration.","code":""},{"path":"/reference/escalc.html","id":"other-outcome-measures-for-meta-analyses","dir":"Reference","previous_headings":"","what":"Other Outcome Measures for Meta-Analyses","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"outcome measures sometimes used meta-analyses directly fall categories . described section.","code":""},{"path":"/reference/escalc.html","id":"cronbach-s-alpha-and-transformations-thereof","dir":"Reference","previous_headings":"","what":"Cronbach's alpha and Transformations Thereof","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"Meta-analytic methods can also used aggregate Cronbach's alpha values multiple studies. usually referred ‘reliability generalization meta-analysis’ (Vacha-Haase, 1998). , one needs specify ai, mi, ni observed alpha values, number items/replications/parts measurement instrument, sample sizes, respectively. One can either directly analyze raw Cronbach's alpha values transformations thereof (Bonett, 2002, 2010; Hakstian & Whalen, 1976). options measure argument : \"ARAW\" raw alpha values, \"AHW\" transformed alpha values (Hakstian & Whalen, 1976), \"ABT\" transformed alpha values (Bonett, 2002). Note transformations implemented slightly different ones described Hakstian Whalen (1976) Bonett (2002). particular, \"AHW\", transformation \\(1-(1-\\alpha)^{1/3}\\) used, \"ABT\", transformation \\(-\\ln(1-\\alpha)\\) used. ensures transformed values monotonically increasing functions \\(\\alpha\\). dataset corresponding data type provided dat.bonett2010.","code":""},{"path":"/reference/escalc.html","id":"partial-and-semi-partial-correlations","dir":"Reference","previous_headings":"","what":"Partial and Semi-Partial Correlations","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"Aloe Becker (2012), Aloe Thompson (2013), Aloe (2014) describe use partial semi-partial correlation coefficients method meta-analyzing results regression models (focus common regression coefficient interest across studies). compute measures, one needs specify ti test statistics (.e., t-tests) regression coefficient interest, ni sample sizes studies, mi number predictors regression models, r2i \\(R^2\\) value regression models (latter needed measure=\"SPCOR\"). options measure argument : \"PCOR\" partial correlation coefficient, \"ZPCOR\" Fisher's r--z transformed partial correlation coefficient, \"SPCOR\" semi-partial correlation coefficient. Note sign (semi-)partial correlation coefficients determined based signs values specified via ti argument. Also, Fisher transformation can applied partial correlation coefficient, semi-partial coefficients. dataset corresponding data type provided dat.aloe2013.","code":""},{"path":"/reference/escalc.html","id":"converting-a-data-frame-to-an-escalc-object","dir":"Reference","previous_headings":"","what":"Converting a Data Frame to an 'escalc' Object","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"function can also used convert regular data frame ‘escalc’ object. One simply sets measure argument one options described (measure=\"GEN\" generic outcome measure specified) passes observed effect sizes outcomes via yi argument corresponding sampling variances via vi argument (standard errors via sei argument).","code":""},{"path":"/reference/escalc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"object class c(\"escalc\",\"data.frame\"). object data frame containing following components: yi observed effect sizes outcomes. vi corresponding sampling variances. append=TRUE data frame specified via data argument, yi vi appended data frame. Note var.names argument actually specifies names two variables (yi vi defaults).    data frame already contains two variables names specified var.names argument, values two variables overwritten replace=TRUE (default). setting replace=FALSE, values NA replaced.    subset argument can used select studies included data frame returned function. hand, include argument simply selects studies measure computed (computed ).    object formatted printed print function. summary function can used obtain confidence intervals individual outcomes. See methods.escalc additional method functions \"escalc\" objects.    aggregate function, one can aggregate multiple effect sizes outcomes belonging study (clustering variable) single combined effect size outcome.","code":""},{"path":"/reference/escalc.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"variable names specified var.names syntactically valid variable names. necessary, adjusted . Although default value add 1/2, certain measures use bias correction makes little sense measures, function internally sets add=0. applies following measures: \"\", \"PHI\", \"RTET\", \"IRSD\", \"PAS\", \"PFT\", \"IRS\", \"IRFT\". One can still force use bias correction explicitly setting add argument non-zero value.","code":""},{"path":"/reference/escalc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/escalc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"Aloe, . M. (2014). empirical investigation partial effect sizes meta-analysis correlational data. Journal General Psychology, 141(1), 47--64. https://doi.org/10.1080/00221309.2013.853021 Aloe, . M., & Becker, B. J. (2012). effect size regression predictors meta-analysis. Journal Educational Behavioral Statistics, 37(2), 278--297. https://doi.org/10.3102/1076998610396901 Aloe, . M., & Thompson, C. G. (2013). synthesis partial effect sizes. Journal Society Social Work Research, 4(4), 390--405. https://doi.org/10.5243/jsswr.2013.24 Bagos, P. G., & Nikolopoulos, G. K. (2009). Mixed-effects Poisson regression models meta-analysis follow-studies constant varying durations. International Journal Biostatistics, 5(1). https://doi.org/10.2202/1557-4679.1168 Becker, B. J. (1988). Synthesizing standardized mean-change measures. British Journal Mathematical Statistical Psychology, 41(2), 257--278.  https://doi.org/10.1111/j.2044-8317.1988.tb00901.x Becker, M. P., & Balagtas, C. C. (1993). Marginal modeling binary cross-data. Biometrics, 49(4), 997--1009. https://doi.org/10.2307/2532242 Bonett, D. G. (2002). Sample size requirements testing estimating coefficient alpha. Journal Educational Behavioral Statistics, 27(4), 335--340. https://doi.org/10.3102/10769986027004335 Bonett, D. G. (2008). Confidence intervals standardized linear contrasts means. Psychological Methods, 13(2), 99--109. https://doi.org/10.1037/1082-989X.13.2.99 Bonett, D. G. (2009). Meta-analytic interval estimation standardized unstandardized mean differences. Psychological Methods, 14(3), 225--238. https://doi.org/10.1037/a0016619 Bonett, D. G. (2010). Varying coefficient meta-analytic methods alpha reliability. Psychological Methods, 15(4), 368--385. https://doi.org/10.1037/a0020142 Borenstein, M. (2009). Effect sizes continuous data. H. Cooper, L. V. Hedges, & J. C. Valentine (Eds.), handbook research synthesis meta-analysis (2nd ed., pp. 221--235). New York: Russell Sage Foundation. Chinn, S. (2000). simple method converting odds ratio effect size use meta-analysis. Statistics Medicine, 19(22), 3127--3131. https://doi.org/10.1002/1097-0258(20001130)19:22<3127::aid-sim784>3.0.co;2-m Cohen, J. (1988). Statistical power analysis behavioral sciences (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum Associates. Cox, D. R., & Snell, E. J. (1989). Analysis binary data (2nd ed.). London: Chapman & Hall. Curtin, F., Elbourne, D., & Altman, D. G. (2002). Meta-analysis combining parallel cross-clinical trials. II: Binary outcomes. Statistics Medicine, 21(15), 2145--2159. https://doi.org/10.1002/sim.1206 Elbourne, D. R., Altman, D. G., Higgins, J. P. T., Curtin, F., Worthington, H. V., & Vail, . (2002). Meta-analyses involving cross-trials: Methodological issues. International Journal Epidemiology, 31(1), 140--149. https://doi.org/10.1093/ije/31.1.140 Fagerland, M. W., Lydersen, S., & Laake, P. (2014). Recommended tests confidence intervals paired binomial proportions. Statistics Medicine, 33(16), 2850--2875. https://doi.org/10.1002/sim.6148 Fisher, R. . (1921). “probable error” coefficient correlation deduced small sample. Metron, 1, 1--32. http://hdl.handle.net/2440/15169 Fleiss, J. L., & Berlin, J. (2009). Effect sizes dichotomous data. H. Cooper, L. V. Hedges, & J. C. Valentine (Eds.), handbook research synthesis meta-analysis (2nd ed., pp. 237--253). New York: Russell Sage Foundation. Freeman, M. F., & Tukey, J. W. (1950). Transformations related angular square root. Annals Mathematical Statistics, 21(4), 607--611. https://doi.org/10.1214/aoms/1177729756 Gibbons, R. D., Hedeker, D. R., & Davis, J. M. (1993). Estimation effect size series experiments involving paired comparisons. Journal Educational Statistics, 18(3), 271--279. https://doi.org/10.3102/10769986018003271 Hakstian, . R., & Whalen, T. E. (1976). k-sample significance test independent alpha coefficients. Psychometrika, 41(2), 219--231. https://doi.org/10.1007/BF02291840 Hasselblad, V., & Hedges, L. V. (1995). Meta-analysis screening diagnostic tests. Psychological Bulletin, 117(1), 167-178. https://doi.org/10.1037/0033-2909.117.1.167 Hedges, L. V. (1981). Distribution theory Glass's estimator effect size related estimators. Journal Educational Statistics, 6(2), 107--128. https://doi.org/10.3102/10769986006002107 Hedges, L. V. (1982). Estimation effect size series independent experiments. Psychological Bulletin, 92(2), 490--499. https://doi.org/10.1037/0033-2909.92.2.490 Hedges, L. V. (1983). random effects model effect sizes. Psychological Bulletin, 93(2), 388--395. https://doi.org/10.1037/0033-2909.93.2.388 Hedges, L. V. (1989). unbiased correction sampling error validity generalization studies. Journal Applied Psychology, 74(3), 469--477. https://doi.org/10.1037/0021-9010.74.3.469 Hedges, L. V., Gurevitch, J., & Curtis, P. S. (1999). meta-analysis response ratios experimental ecology. Ecology, 80(4), 1150--1156. https://doi.org/10.1890/0012-9658(1999)080[1150:TMAORR]2.0.CO;2 Higgins, J. P. T., Thomas, J., Chandler, J., Cumpston, M., Li, T., Page, M. J., & Welch, V. . (Eds.) (2019). Cochrane handbook systematic reviews interventions (2nd ed.). Chichester, UK: Wiley. https://training.cochrane.org/handbook Jacobs, P., & Viechtbauer, W. (2017). Estimation biserial correlation sampling variance use meta-analysis. Research Synthesis Methods, 8(2), 161--180. https://doi.org/10.1002/jrsm.1218 Kirk, D. B. (1973). numerical approximation bivariate normal (tetrachoric) correlation coefficient. Psychometrika, 38(2), 259--268. https://doi.org/10.1007/BF02291118 Lajeunesse, M. J. (2011). meta-analysis response ratios studies correlated multi-group designs. Ecology, 92(11), 2049--2055. https://doi.org/10.1890/11-0423.1 May, W. L., & Johnson, W. D. (1997). Confidence intervals differences correlated binary proportions. Statistics Medicine, 16(18), 2127--2136. https://doi.org/10.1002/(SICI)1097-0258(19970930)16:18<2127::AID-SIM633>3.0.CO;2-W Morris, S. B. (2000). Distribution standardized mean change effect size meta-analysis repeated measures. British Journal Mathematical Statistical Psychology, 53(1), 17--29. https://doi.org/10.1348/000711000159150 Morris, S. B., & DeShon, R. P. (2002). Combining effect size estimates meta-analysis repeated measures independent-groups designs. Psychological Methods, 7(1), 105--125. https://doi.org/10.1037/1082-989x.7.1.105 Nakagawa, S., Poulin, R., Mengersen, K., Reinhold, K., Engqvist, L., Lagisz, M., & Senior, . M. (2015). Meta-analysis variation: Ecological evolutionary applications beyond. Methods Ecology Evolution, 6(2), 143--152. https://doi.org/10.1111/2041-210x.12309 Newcombe, R. G. (1998). Improved confidence intervals difference binomial proportions based paired data. Statistics Medicine, 17(22), 2635--2650. https://doi.org/10.1002/(SICI)1097-0258(19981130)17:22<2635::AID-SIM954>3.0.CO;2-C Olkin, ., & Pratt, J. W. (1958). Unbiased estimation certain correlation coefficients. Annals Mathematical Statistics, 29(1), 201--211. https://doi.org/10.1214/aoms/1177706717 Pearson, K. (1900). Mathematical contributions theory evolution. VII. correlation characters quantitatively measurable. Philosophical Transactions Royal Society London, Series , 195, 1--47. https://doi.org/10.1098/rsta.1900.0022 Pearson, K. (1909). new method determining correlation measured character , character B, percentage cases wherein B exceeds (falls short ) given intensity recorded grade . Biometrika, 7(1/2), 96--105. https://doi.org/10.1093/biomet/7.1-2.96 Raudenbush, S. W., & Bryk, . S. (1987). Examining correlates diversity. Journal Educational Statistics, 12(3), 241--269. https://doi.org/10.3102/10769986012003241 Rothman, K. J., Greenland, S., & Lash, T. L. (2008). Modern epidemiology (3rd ed.). Philadelphia: Lippincott Williams & Wilkins. Rücker, G., Schwarzer, G., Carpenter, J., & Olkin, . (2009). add anything nothing? arcsine difference measure treatment effect meta-analysis zero cells. Statistics Medicine, 28(5), 721--738. https://doi.org/10.1002/sim.3511 Sánchez-Meca, J., Marín-Martínez, F., & Chacón-Moscoso, S. (2003). Effect-size indices dichotomized outcomes meta-analysis. Psychological Methods, 8(4), 448--467. https://doi.org/10.1037/1082-989X.8.4.448 Soper, H. E. (1914). probable error bi-serial expression correlation coefficient. Biometrika, 10(2/3), 384--390. https://doi.org/10.1093/biomet/10.2-3.384 Stedman, M. R., Curtin, F., Elbourne, D. R., Kesselheim, . S., & Brookhart, M. . (2011). Meta-analyses involving cross-trials: Methodological issues. International Journal Epidemiology, 40(6), 1732--1734. https://doi.org/10.1093/ije/dyp345 Tate, R. F. (1954). Correlation discrete continuous variable: Point-biserial correlation. Annals Mathematical Statistics, 25(3), 603--607. https://doi.org/10.1214/aoms/1177728730 Vacha-Haase, T. (1998). Reliability generalization: Exploring variance measurement error affecting score reliability across studies. Educational Psychological Measurement, 58(1), 6--20. https://doi.org/10.1177/0013164498058001002 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03 Yule, G. U. (1912). methods measuring association two attributes. Journal Royal Statistical Society, 75(6), 579--652. https://doi.org/10.2307/2340126 Yusuf, S., Peto, R., Lewis, J., Collins, R., & Sleight, P. (1985). Beta blockade myocardial infarction: overview randomized trials. Progress Cardiovascular Disease, 27(5), 335--371. https://doi.org/10.1016/s0033-0620(85)80003-7 Zou, G. Y. (2007). One relative risk versus two odds ratios: Implications meta-analyses involving paired unpaired binary data. Clinical Trials, 4(1), 25--31. https://doi.org/10.1177/1740774506075667","code":""},{"path":[]},{"path":"/reference/escalc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Effect Sizes and Outcome Measures — escalc","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg) dat #>  #>    trial               author year tpos  tneg cpos  cneg ablat      alloc      yi     vi  #> 1      1              Aronson 1948    4   119   11   128    44     random -0.8893 0.3256  #> 2      2     Ferguson & Simes 1949    6   300   29   274    55     random -1.5854 0.1946  #> 3      3      Rosenthal et al 1960    3   228   11   209    42     random -1.3481 0.4154  #> 4      4    Hart & Sutherland 1977   62 13536  248 12619    52     random -1.4416 0.0200  #> 5      5 Frimodt-Moller et al 1973   33  5036   47  5761    13  alternate -0.2175 0.0512  #> 6      6      Stein & Aronson 1953  180  1361  372  1079    44  alternate -0.7861 0.0069  #> 7      7     Vandiviere et al 1973    8  2537   10   619    19     random -1.6209 0.2230  #> 8      8           TPT Madras 1980  505 87886  499 87892    13     random  0.0120 0.0040  #> 9      9     Coetzee & Berjak 1968   29  7470   45  7232    27     random -0.4694 0.0564  #> 10    10      Rosenthal et al 1961   17  1699   65  1600    42 systematic -1.3713 0.0730  #> 11    11       Comstock et al 1974  186 50448  141 27197    18 systematic -0.3394 0.0124  #> 12    12   Comstock & Webster 1969    5  2493    3  2338    33 systematic  0.4459 0.5325  #> 13    13       Comstock et al 1976   27 16886   29 17825    33 systematic -0.0173 0.0714  #>   ### suppose that for a particular study, yi and vi are known (i.e., have ### already been calculated) but the 2x2 table counts are not known; with ### replace=FALSE, the yi and vi values for that study are not replaced dat[1:12,10:11] <- NA dat[13,4:7] <- NA dat #>  #>    trial               author year tpos  tneg cpos  cneg ablat      alloc      yi     vi  #> 1      1              Aronson 1948    4   119   11   128    44     random      NA     NA  #> 2      2     Ferguson & Simes 1949    6   300   29   274    55     random      NA     NA  #> 3      3      Rosenthal et al 1960    3   228   11   209    42     random      NA     NA  #> 4      4    Hart & Sutherland 1977   62 13536  248 12619    52     random      NA     NA  #> 5      5 Frimodt-Moller et al 1973   33  5036   47  5761    13  alternate      NA     NA  #> 6      6      Stein & Aronson 1953  180  1361  372  1079    44  alternate      NA     NA  #> 7      7     Vandiviere et al 1973    8  2537   10   619    19     random      NA     NA  #> 8      8           TPT Madras 1980  505 87886  499 87892    13     random      NA     NA  #> 9      9     Coetzee & Berjak 1968   29  7470   45  7232    27     random      NA     NA  #> 10    10      Rosenthal et al 1961   17  1699   65  1600    42 systematic      NA     NA  #> 11    11       Comstock et al 1974  186 50448  141 27197    18 systematic      NA     NA  #> 12    12   Comstock & Webster 1969    5  2493    3  2338    33 systematic      NA     NA  #> 13    13       Comstock et al 1976   NA    NA   NA    NA    33 systematic -0.0173 0.0714  #>  dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat, replace=FALSE) dat #>  #>    trial               author year tpos  tneg cpos  cneg ablat      alloc      yi     vi  #> 1      1              Aronson 1948    4   119   11   128    44     random -0.8893 0.3256  #> 2      2     Ferguson & Simes 1949    6   300   29   274    55     random -1.5854 0.1946  #> 3      3      Rosenthal et al 1960    3   228   11   209    42     random -1.3481 0.4154  #> 4      4    Hart & Sutherland 1977   62 13536  248 12619    52     random -1.4416 0.0200  #> 5      5 Frimodt-Moller et al 1973   33  5036   47  5761    13  alternate -0.2175 0.0512  #> 6      6      Stein & Aronson 1953  180  1361  372  1079    44  alternate -0.7861 0.0069  #> 7      7     Vandiviere et al 1973    8  2537   10   619    19     random -1.6209 0.2230  #> 8      8           TPT Madras 1980  505 87886  499 87892    13     random  0.0120 0.0040  #> 9      9     Coetzee & Berjak 1968   29  7470   45  7232    27     random -0.4694 0.0564  #> 10    10      Rosenthal et al 1961   17  1699   65  1600    42 systematic -1.3713 0.0730  #> 11    11       Comstock et al 1974  186 50448  141 27197    18 systematic -0.3394 0.0124  #> 12    12   Comstock & Webster 1969    5  2493    3  2338    33 systematic  0.4459 0.5325  #> 13    13       Comstock et al 1976   NA    NA   NA    NA    33 systematic -0.0173 0.0714  #>   ### illustrate difference between 'subset' and 'include' arguments escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg, subset=1:6) #>  #>   trial               author year tpos  tneg cpos  cneg ablat     alloc      yi     vi  #> 1     1              Aronson 1948    4   119   11   128    44    random -0.8893 0.3256  #> 2     2     Ferguson & Simes 1949    6   300   29   274    55    random -1.5854 0.1946  #> 3     3      Rosenthal et al 1960    3   228   11   209    42    random -1.3481 0.4154  #> 4     4    Hart & Sutherland 1977   62 13536  248 12619    52    random -1.4416 0.0200  #> 5     5 Frimodt-Moller et al 1973   33  5036   47  5761    13 alternate -0.2175 0.0512  #> 6     6      Stein & Aronson 1953  180  1361  372  1079    44 alternate -0.7861 0.0069  #>  escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg, include=1:6) #>  #>    trial               author year tpos  tneg cpos  cneg ablat      alloc      yi     vi  #> 1      1              Aronson 1948    4   119   11   128    44     random -0.8893 0.3256  #> 2      2     Ferguson & Simes 1949    6   300   29   274    55     random -1.5854 0.1946  #> 3      3      Rosenthal et al 1960    3   228   11   209    42     random -1.3481 0.4154  #> 4      4    Hart & Sutherland 1977   62 13536  248 12619    52     random -1.4416 0.0200  #> 5      5 Frimodt-Moller et al 1973   33  5036   47  5761    13  alternate -0.2175 0.0512  #> 6      6      Stein & Aronson 1953  180  1361  372  1079    44  alternate -0.7861 0.0069  #> 7      7     Vandiviere et al 1973    8  2537   10   619    19     random      NA     NA  #> 8      8           TPT Madras 1980  505 87886  499 87892    13     random      NA     NA  #> 9      9     Coetzee & Berjak 1968   29  7470   45  7232    27     random      NA     NA  #> 10    10      Rosenthal et al 1961   17  1699   65  1600    42 systematic      NA     NA  #> 11    11       Comstock et al 1974  186 50448  141 27197    18 systematic      NA     NA  #> 12    12   Comstock & Webster 1969    5  2493    3  2338    33 systematic      NA     NA  #> 13    13       Comstock et al 1976   27 16886   29 17825    33 systematic      NA     NA  #>   ### convert a regular data frame to an 'escalc' object ### dataset from Lipsey & Wilson (2001), Table 7.1, page 130 dat <- data.frame(id = c(100, 308, 1596, 2479, 9021, 9028, 161, 172, 537, 7049),                   yi = c(-0.33, 0.32, 0.39, 0.31, 0.17, 0.64, -0.33, 0.15, -0.02, 0.00),                   vi = c(0.084, 0.035, 0.017, 0.034, 0.072, 0.117, 0.102, 0.093, 0.012, 0.067),                   random = c(0, 0, 0, 0, 0, 0, 1, 1, 1, 1),                   intensity = c(7, 3, 7, 5, 7, 7, 4, 4, 5, 6)) dat <- escalc(measure=\"SMD\", yi=yi, vi=vi, data=dat, slab=paste(\"Study ID:\", id), digits=3) dat #>  #>      id     yi    vi random intensity  #> 1   100 -0.330 0.084      0         7  #> 2   308  0.320 0.035      0         3  #> 3  1596  0.390 0.017      0         7  #> 4  2479  0.310 0.034      0         5  #> 5  9021  0.170 0.072      0         7  #> 6  9028  0.640 0.117      0         7  #> 7   161 -0.330 0.102      1         4  #> 8   172  0.150 0.093      1         4  #> 9   537 -0.020 0.012      1         5  #> 10 7049  0.000 0.067      1         6  #>"},{"path":"/reference/fitstats.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Statistics and Information Criteria for 'rma' Objects — fitstats","title":"Fit Statistics and Information Criteria for 'rma' Objects — fitstats","text":"Functions extract log-likelihood, deviance, AIC, BIC, AICc values objects class \"rma\".","code":""},{"path":"/reference/fitstats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Statistics and Information Criteria for 'rma' Objects — fitstats","text":"","code":"fitstats(object, ...)  # S3 method for rma fitstats(object, ..., REML)  # S3 method for rma logLik(object, REML, ...) # S3 method for rma deviance(object, REML, ...)  # S3 method for rma AIC(object, ..., k=2, correct=FALSE) # S3 method for rma BIC(object, ...)"},{"path":"/reference/fitstats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Statistics and Information Criteria for 'rma' Objects — fitstats","text":"object object class \"rma\". ... optionally fitted model objects. REML logical specify whether regular restricted likelihood function used obtain fit statistics information criteria. Defaults method estimation used, TRUE object fitted method=\"REML\" FALSE otherwise. k numeric value specify penalty per parameter use. default (k=2) classical AIC. See AIC details. correct logical specify whether regular (default) corrected (.e., AICc) extracted.","code":""},{"path":"/reference/fitstats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Statistics and Information Criteria for 'rma' Objects — fitstats","text":"fitstats, data frame (restricted) log-likelihood, deviance, AIC, BIC, AICc values model passed function.    logLik, object class \"logLik\", providing (restricted) log-likelihood model evaluated estimated coefficient(s).    deviance, numeric value corresponding deviance.    AIC BIC, either numeric value corresponding AIC, AICc, BIC data frame rows corresponding models columns representing number parameters model (df) AIC, AICc, BIC.","code":""},{"path":"/reference/fitstats.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Fit Statistics and Information Criteria for 'rma' Objects — fitstats","text":"Variance components model (e.g., \\(\\tau^2\\) random/mixed-effects models fitted rma.uni) counted additional parameters calculation AIC, BIC, AICc. Also, fixed effects counted parameters calculation AIC, BIC, AICc even using REML estimation.","code":""},{"path":"/reference/fitstats.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fit Statistics and Information Criteria for 'rma' Objects — fitstats","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/fitstats.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit Statistics and Information Criteria for 'rma' Objects — fitstats","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/fitstats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Statistics and Information Criteria for 'rma' Objects — fitstats","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### random-effects model res1 <- rma(yi, vi, data=dat, method=\"ML\")  ### mixed-effects model with absolute latitude and publication year as moderators res2 <- rma(yi, vi, mods = ~ ablat + year, data=dat, method=\"ML\")  ### compare fit statistics fitstats(res1, res2) #>                res1      res2 #> logLik:   -12.66508 -7.646115 #> deviance:  37.11602 27.078099 #> AIC:       29.33015 23.292231 #> BIC:       30.46005 25.552028 #> AICc:      30.53015 28.292231  ### log-likelihoods logLik(res1) #> 'log Lik.' -12.66508 (df=2) logLik(res2) #> 'log Lik.' -7.646115 (df=4)  ### deviances deviance(res1) #> [1] 37.11602 deviance(res2) #> [1] 27.0781  ### AIC, AICc, and BIC values AIC(res1, res2) #>      df      AIC #> res1  2 29.33015 #> res2  4 23.29223 AIC(res1, res2, correct=TRUE) #>      df     AICc #> res1  2 30.53015 #> res2  4 28.29223 BIC(res1, res2) #>      df      BIC #> res1  2 30.46005 #> res2  4 25.55203"},{"path":"/reference/fitted.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitted Values for 'rma' Objects — fitted.rma","title":"Fitted Values for 'rma' Objects — fitted.rma","text":"function computes fitted values objects class \"rma\".","code":""},{"path":"/reference/fitted.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitted Values for 'rma' Objects — fitted.rma","text":"","code":"# S3 method for rma fitted(object, ...)"},{"path":"/reference/fitted.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitted Values for 'rma' Objects — fitted.rma","text":"object object class \"rma\". ... arguments.","code":""},{"path":"/reference/fitted.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitted Values for 'rma' Objects — fitted.rma","text":"vector fitted values.","code":""},{"path":"/reference/fitted.rma.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Fitted Values for 'rma' Objects — fitted.rma","text":"predict function also provides standard errors confidence intervals fitted values. Best linear unbiased predictions (BLUPs) combine fitted values based fixed effects estimated contributions random effects can obtained blup (objects class \"rma.uni\"). objects involving moderators, fitted values identical estimated value model intercept.","code":""},{"path":"/reference/fitted.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitted Values for 'rma' Objects — fitted.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/fitted.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitted Values for 'rma' Objects — fitted.rma","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/fitted.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitted Values for 'rma' Objects — fitted.rma","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit mixed-effects model with absolute latitude and publication year as moderators res <- rma(yi, vi, mods = ~ ablat + year, data=dat)  ### compute the fitted values fitted(res) #>          1          2          3          4          5          6          7          8          9  #> -1.0620809 -1.3682974 -0.9831677 -1.2308520 -0.1460425 -1.0525432 -0.3141101 -0.1326896 -0.5477381  #>         10         11         12         13  #> -0.9812602 -0.2841913 -0.7138982 -0.7005453"},{"path":"/reference/forest.cumul.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Forest Plots (Method for 'cumul.rma' Objects) — forest.cumul.rma","title":"Forest Plots (Method for 'cumul.rma' Objects) — forest.cumul.rma","text":"Function create forest plots objects class \"cumul.rma\".","code":""},{"path":"/reference/forest.cumul.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forest Plots (Method for 'cumul.rma' Objects) — forest.cumul.rma","text":"","code":"# S3 method for cumul.rma forest(x, annotate=TRUE, header=FALSE,        xlim, alim, olim, ylim, top=3, at, steps=5,        level=x$level, refline=0, digits=2L, width,        xlab, ilab, ilab.xpos, ilab.pos,        transf, atransf, targs, rows,        efac=1, pch=15, psize=1, col,        lty, fonts, cex, cex.lab, cex.axis, annosym, ...)"},{"path":"/reference/forest.cumul.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forest Plots (Method for 'cumul.rma' Objects) — forest.cumul.rma","text":"x object class \"cumul.rma\" obtained cumul. annotate logical specify whether annotations added plot (default TRUE). header logical specify whether column headings added plot (default FALSE). Can also character vector specify left right headings (left one). xlim horizontal limits plot region. unspecified, function tries set horizontal plot limits sensible values. alim x-axis limits. unspecified, function tries set x-axis limits sensible values. olim optional argument specify observation/outcome limits. unspecified, limits used. ylim y-axis limits plot. unspecified, function tries set y-axis limits sensible values. top amount space leave empty top plot (e.g., adding headers) (default 3 rows). position x-axis tick marks corresponding labels. unspecified, function tries set tick mark positions/labels sensible values. steps number tick marks x-axis (default 5). Ignored positions specified via argument. level numeric value 0 100 specify confidence interval level (default take value object). refline numeric value specify location vertical ‘reference’ line (default 0). line can suppressed setting argument NA. digits integer specify number decimal places tick mark labels x-axis annotations rounded (default 2L). Can also vector two integers, first specify number decimal places annotations, second x-axis labels. specifying integer (e.g., 2L), trailing zeros decimal mark dropped x-axis labels. specifying numeric value (e.g., 2), trailing zeros retained. width optional integer manually adjust width columns annotations. xlab title x-axis. unspecified, function tries set appropriate axis title. ilab optional vector, matrix, data frame providing additional information studies added plot. ilab.xpos numeric vector specify x-axis position(s) variable(s) given via ilab (must specified ilab specified). ilab.pos integer(s) (either 1, 2, 3, 4) specify alignment vector(s) given via ilab (2 means right, 4 mean left aligned). unspecified, default center labels. transf optional argument specify name function used transform estimates confidence interval bounds (e.g., transf=exp; see also transf). unspecified, transformation used. atransf optional argument specify name function used transform x-axis labels annotations (e.g., atransf=exp; see also transf). unspecified, transformation used. targs optional arguments needed function specified via transf atransf. rows optional vector specify rows (generally, horizontal positions) plotting outcomes. Can also single value specify row (horizontal position) first outcome (remaining outcomes plotted starting row). unspecified, function sets value automatically. efac vertical expansion factor confidence interval limits arrows. default value 1 usually work okay. Can also vector two numbers, first CI limits, second arrows. pch plotting symbol use estimates. default, filled square used. See points options. Can also vector values. psize numeric value specify point sizes estimates (default 1). Can also vector values. col optional character string specify name color use plotting (\"black\" used default specified). Can also vector color names. lty optional character string specify line type confidence intervals. unspecified, function sets \"solid\" default. fonts optional character string specify font use study labels, annotations, extra information (specified via ilab). unspecified, default font used. cex optional character symbol expansion factor. unspecified, function tries set sensible value. cex.lab optional expansion factor x-axis title. unspecified, function tries set sensible value. cex.axis optional expansion factor x-axis labels. unspecified, function tries set sensible value. annosym optional vector length 3 change left bracket, separation, right bracket symbols annotations. ... arguments.","code":""},{"path":"/reference/forest.cumul.rma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Forest Plots (Method for 'cumul.rma' Objects) — forest.cumul.rma","text":"plot shows estimated (average) outcome corresponding confidence interval one study time added analysis.","code":""},{"path":"/reference/forest.cumul.rma.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Forest Plots (Method for 'cumul.rma' Objects) — forest.cumul.rma","text":"function tries set sensible values optional arguments, may necessary adjust certain circumstances. function actually returns information chosen defaults invisibly. Printing information useful starting point make adjustments plot. number studies quite large, labels, annotations, symbols may become quite small impossible read. Stretching plot window vertically may provide readable figure (one call function adjusting window size, label/symbol sizes can properly adjusted). Also, cex, cex.lab, cex.axis arguments useful adjust symbol text sizes. horizontal plot /x-axis limits set manually, horizontal plot limits (xlim) must least wide x-axis limits (alim). restriction enforced inside function. outcome measure used creating plot bounded (e.g., correlations bounded -1 +1, proportions bounded 0 1), one can use olim argument enforce limits (observed outcomes confidence intervals exceed bounds ). lty argument can also vector two elements, first specifying line type individual CIs (\"solid\" default), second line type horizontal line automatically added plot (\"solid\" default; set \"blank\" remove ).","code":""},{"path":"/reference/forest.cumul.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Forest Plots (Method for 'cumul.rma' Objects) — forest.cumul.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/forest.cumul.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Forest Plots (Method for 'cumul.rma' Objects) — forest.cumul.rma","text":"Chalmers, T. C., & Lau, J. (1993). Meta-analytic stimulus changes clinical trials. Statistical Methods Medical Research, 2(2), 161--172. https://doi.org/10.1177/096228029300200204 Lau, J., Schmid, C. H., & Chalmers, T. C. (1995). Cumulative meta-analysis clinical trials builds evidence exemplary medical care. Journal Clinical Epidemiology, 48(1), 45--57. https://doi.org/10.1016/0895-4356(94)00106-z Lewis, S., & Clarke, M. (2001). Forest plots: Trying see wood trees. British Medical Journal, 322(7300), 1479--1480. https://doi.org/10.1136/bmj.322.7300.1479 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/forest.cumul.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forest Plots (Method for 'cumul.rma' Objects) — forest.cumul.rma","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit random-effects model res <- rma(yi, vi, data=dat, slab=paste(author, year, sep=\", \"))  ### draw cumulative forest plots x <- cumul(res, order=dat$year) forest(x, cex=.8, header=TRUE)  forest(x, alim=c(-2,1), cex=.8, header=TRUE)   ### meta-analysis of the (log) risk ratios using the Mantel-Haenszel method res <- rma.mh(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg,               slab=paste(author, year, sep=\", \"))  ### draw cumulative forest plot x <- cumul(res, order=dat$year) forest(x, alim=c(-2,1), cex=.8, header=TRUE)"},{"path":"/reference/forest.default.html","id":null,"dir":"Reference","previous_headings":"","what":"Forest Plots (Default Method) — forest.default","title":"Forest Plots (Default Method) — forest.default","text":"Function create forest plots given set data.","code":""},{"path":"/reference/forest.default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forest Plots (Default Method) — forest.default","text":"","code":"# S3 method for default forest(x, vi, sei, ci.lb, ci.ub,        annotate=TRUE, showweights=FALSE, header=FALSE,        xlim, alim, olim, ylim, top=3, at, steps=5,        level=95, refline=0, digits=2L, width,        xlab, slab, ilab, ilab.xpos, ilab.pos,        order, subset, transf, atransf, targs, rows,        efac=1, pch=15, psize, plim=c(0.5,1.5), col,        lty, fonts, cex, cex.lab, cex.axis, annosym, ...)"},{"path":"/reference/forest.default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forest Plots (Default Method) — forest.default","text":"x vector length \\(k\\) observed effect sizes outcomes. vi vector length \\(k\\) corresponding sampling variances. sei vector length \\(k\\) corresponding standard errors (note: one two, vi sei, needs specified). ci.lb vector length \\(k\\) corresponding lower confidence interval bounds. needed vi sei specified. See ‘Details’. ci.ub vector length \\(k\\) corresponding upper confidence interval bounds. needed vi sei specified. See ‘Details’. annotate logical specify whether annotations added plot (default TRUE). showweights logical specify whether annotations also include inverse variance weights (default FALSE). header logical specify whether column headings added plot (default FALSE). Can also character vector specify left right headings  (left one). xlim horizontal limits plot region. unspecified, function tries set horizontal plot limits sensible values. alim x-axis limits. unspecified, function tries set x-axis limits sensible values. olim optional argument specify observation/outcome limits. unspecified, limits used. ylim y-axis limits plot. unspecified, function tries set y-axis limits sensible values. top amount space leave empty top plot (e.g., adding headers) (default 3 rows). position x-axis tick marks corresponding labels. unspecified, function tries set tick mark positions/labels sensible values. steps number tick marks x-axis (default 5). Ignored positions specified via argument. level numeric value 0 100 specify confidence interval level (default 95). refline numeric value specify location vertical ‘reference’ line (default 0). line can suppressed setting argument NA. digits integer specify number decimal places tick mark labels x-axis annotations rounded (default 2L). Can also vector two integers, first specify number decimal places annotations, second x-axis labels. specifying integer (e.g., 2L), trailing zeros decimal mark dropped x-axis labels. specifying numeric value (e.g., 2), trailing zeros retained. width optional integer manually adjust width columns annotations. xlab title x-axis. unspecified, function tries set appropriate axis title. slab optional vector labels \\(k\\) studies. unspecified, simple labels created within function. suppress labels, set argument NA. ilab optional vector, matrix, data frame providing additional information studies added plot. ilab.xpos numeric vector specify x-axis position(s) variable(s) given via ilab (must specified ilab specified). ilab.pos integer(s) (either 1, 2, 3, 4) specify alignment vector(s) given via ilab (2 means right, 4 mean left aligned). unspecified, default center labels. order optional character string specify studies ordered. Can also variable based studies ordered. See ‘Details’. subset optional (logical numeric) vector specify subset studies included plot. transf optional argument specify function used transform observed outcomes corresponding confidence interval bounds (e.g., transf=exp; see also transf). unspecified, transformation used. atransf optional argument specify function used transform x-axis labels annotations (e.g., atransf=exp; see also transf). unspecified, transformation used. targs optional arguments needed function specified via transf atransf. rows optional vector specify rows (generally, horizontal positions) plotting outcomes. Can also single value specify row (horizontal position) first outcome (remaining outcomes plotted starting row). unspecified, function sets value automatically. efac vertical expansion factor confidence interval limits arrows. default value 1 usually work okay. Can also vector two numbers, first CI limits, second arrows. pch plotting symbol use observed outcomes. default, filled square used. See points options. Can also vector values. psize optional numeric value specify point sizes observed outcomes. unspecified, point sizes function precision estimates. Can also vector values. plim numeric vector length 2 scale point sizes (ignored psize specified). See ‘Details’. col optional character string specify name color use plotting observed outcomes (\"black\" used default specified). Can also vector color names. lty optional character string specify line type confidence intervals. unspecified, function sets \"solid\" default. fonts optional character string specify font use study labels, annotations, extra information (specified via ilab). unspecified, default font used. cex optional character symbol expansion factor. unspecified, function tries set sensible value. cex.lab optional expansion factor x-axis title. unspecified, function tries set sensible value. cex.axis optional expansion factor x-axis labels. unspecified, function tries set sensible value. annosym optional vector length 3 change left bracket, separation, right bracket symbols annotations. ... arguments.","code":""},{"path":"/reference/forest.default.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Forest Plots (Default Method) — forest.default","text":"plot shows observed effect sizes outcomes corresponding confidence intervals. use function, one specify observed outcomes (via x argument) together corresponding sampling variances (via vi argument) corresponding standard errors (via sei argument). Alternatively, one can specify observed outcomes together corresponding confidence interval bounds (via ci.lb ci.ub arguments). transf argument, observed outcomes corresponding confidence interval bounds can transformed suitable function. example, plotting log odds ratios, one use transf=exp obtain forest plot showing odds ratios. Alternatively, one can use atransf argument transform x-axis labels annotations (e.g., atransf=exp). See also transf useful transformation functions context meta-analysis. examples illustrate use arguments. default, studies ordered top bottom (.e., first study dataset placed row \\(k\\), second study row \\(k-1\\), , last study, placed first row). studies can reordered order argument: order=\"obs\": studies ordered observed outcomes, order=\"prec\": studies ordered sampling variances. Alternatively, also possible set order equal variable based studies ordered (see ‘Examples’). Additional columns information studies can added plot via ilab argument. can either single variable entire matrix / data frame (many rows studies forest plot). ilab.xpos argument must also specified indicate x-axis position variables specified via ilab. Summary estimates can added plot addpoly function. See documentation function examples. default (.e., psize specified), point sizes function precision (.e., inverse standard errors) outcomes. way, precise estimates visually prominent plot. making point sizes function inverse standard errors estimates, areas proportional inverse sampling variances, corresponds weights receive equal-effects model. However, point sizes rescaled smallest point size plim[1] largest point size plim[2]. result, relative sizes (.e., areas) longer exactly correspond relative weights model. exactly relative point sizes desired, one can set plim[2] NA, case points rescaled smallest point size corresponds plim[1] points scaled accordingly. result, largest point may large. Alternatively, one can set plim[1] NA, case points rescaled largest point size corresponds plim[2] points scaled accordingly. result, smallest point may small essentially indistinguishable confidence interval line. avoid latter, one can also set plim[3], enforces minimal point size.","code":""},{"path":"/reference/forest.default.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Forest Plots (Default Method) — forest.default","text":"function tries set sensible values optional arguments, may necessary adjust certain circumstances. function actually returns information chosen defaults invisibly. Printing information useful starting point make adjustments plot. number studies quite large, labels, annotations, symbols may become quite small impossible read. Stretching plot window vertically may provide readable figure (one call function adjusting window size, label/symbol sizes can properly adjusted). Also, cex, cex.lab, cex.axis arguments useful adjust symbol text sizes. horizontal plot /x-axis limits set manually, horizontal plot limits (xlim) must least wide x-axis limits (alim). restriction enforced inside function. outcome measure used creating plot bounded (e.g., correlations bounded -1 +1, proportions bounded 0 1), one can use olim argument enforce limits (observed outcomes confidence intervals exceed bounds ). lty argument can also vector two elements, first specifying line type individual CIs (\"solid\" default), second line type horizontal line automatically added plot (\"solid\" default; set \"blank\" remove ).","code":""},{"path":"/reference/forest.default.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Forest Plots (Default Method) — forest.default","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/forest.default.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Forest Plots (Default Method) — forest.default","text":"Lewis, S., & Clarke, M. (2001). Forest plots: Trying see wood trees. British Medical Journal, 322(7300), 1479--1480. https://doi.org/10.1136/bmj.322.7300.1479 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/forest.default.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forest Plots (Default Method) — forest.default","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### default forest plot of the observed log risk ratios forest(dat$yi, dat$vi)   ### forest plot of the observed risk ratios (transform outcomes) forest(dat$yi, dat$vi, slab=paste(dat$author, dat$year, sep=\", \"), transf=exp,        alim=c(0,2), steps=5, xlim=c(-2.5,4), refline=1, cex=.9, header=TRUE)   ### forest plot of the observed risk ratios (transformed x-axis) forest(dat$yi, dat$vi, slab=paste(dat$author, dat$year, sep=\", \"), atransf=exp,        at=log(c(.05,.25,1,4,20)), xlim=c(-10,8), cex=.9, header=TRUE)   ### forest plot of the observed risk ratios with studies ordered by the RRs forest(dat$yi, dat$vi, slab=paste(dat$author, dat$year, sep=\", \"), atransf=exp,        at=log(c(.05,.25,1,4,20)), xlim=c(-10,8), cex=.9, header=TRUE, order=\"obs\")   ### forest plot of the observed risk ratios with studies ordered by absolute latitude forest(dat$yi, dat$vi, slab=paste(dat$author, dat$year, sep=\", \"), atransf=exp,        at=log(c(.05,.25,1,4,20)), xlim=c(-10,8), cex=.9, header=TRUE, order=dat$ablat)   ### see also examples for the forest.rma function"},{"path":"/reference/forest.html","id":null,"dir":"Reference","previous_headings":"","what":"Forest Plots — forest","title":"Forest Plots — forest","text":"forest function can used create forest plots.","code":""},{"path":"/reference/forest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forest Plots — forest","text":"","code":"forest(x, ...)"},{"path":"/reference/forest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forest Plots — forest","text":"x either object class \"rma\", vector observed effect sizes outcomes, object class \"cumul.rma\". See ‘Details’. ... arguments.","code":""},{"path":"/reference/forest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Forest Plots — forest","text":"Currently, methods exist three types situations. first case, object x fitted model object coming rma.uni, rma.mh, rma.peto functions. corresponding method forest.rma. Alternatively, object x can vector observed effect sizes outcomes. corresponding method forest.default. Finally, object x can object coming cumul.rma.uni, cumul.rma.mh, cumul.rma.peto functions. corresponding method forest.cumul.rma.","code":""},{"path":"/reference/forest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Forest Plots — forest","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/forest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Forest Plots — forest","text":"Lewis, S., & Clarke, M. (2001). Forest plots: Trying see wood trees. British Medical Journal, 322(7300), 1479--1480. https://doi.org/10.1136/bmj.322.7300.1479 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/forest.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Forest Plots (Method for 'rma' Objects) — forest.rma","title":"Forest Plots (Method for 'rma' Objects) — forest.rma","text":"Function create forest plots objects class \"rma\".","code":""},{"path":"/reference/forest.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forest Plots (Method for 'rma' Objects) — forest.rma","text":"","code":"# S3 method for rma forest(x, annotate=TRUE, addfit=TRUE, addpred=FALSE,        showweights=FALSE, header=FALSE,        xlim, alim, olim, ylim, top=3, at, steps=5,        level=x$level, refline=0, digits=2L, width,        xlab, slab, mlab, ilab, ilab.xpos, ilab.pos,        order, transf, atransf, targs, rows,        efac=1, pch=15, psize, plim=c(0.5,1.5), colout,        col, border, lty, fonts, cex, cex.lab, cex.axis, annosym, ...)"},{"path":"/reference/forest.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forest Plots (Method for 'rma' Objects) — forest.rma","text":"x object class \"rma\". annotate logical specify whether annotations added plot (default TRUE). addfit logical specify whether summary estimate (models without moderators) fitted values (models moderators) added plot (default TRUE). See ‘Details’. addpred logical specify whether bounds prediction interval added plot (default FALSE). See ‘Details’. showweights logical specify whether annotations also include weights given observed outcomes model fitting (default FALSE). See ‘Details’. header logical specify whether column headings added plot (default FALSE). Can also character vector specify left right headings  (left one). xlim horizontal limits plot region. unspecified, function tries set horizontal plot limits sensible values. alim x-axis limits. unspecified, function tries set x-axis limits sensible values. olim optional argument specify observation/outcome limits. unspecified, limits used. ylim y-axis limits plot. unspecified, function tries set y-axis limits sensible values. top amount space leave empty top plot (e.g., adding headers) (default 3 rows). position x-axis tick marks corresponding labels. unspecified, function tries set tick mark positions/labels sensible values. steps number tick marks x-axis (default 5). Ignored positions specified via argument. level numeric value 0 100 specify confidence interval level (default take value object). refline numeric value specify location vertical ‘reference’ line (default 0). line can suppressed setting argument NA. digits integer specify number decimal places tick mark labels x-axis annotations rounded (default 2L). Can also vector two integers, first specify number decimal places annotations, second x-axis labels. specifying integer (e.g., 2L), trailing zeros decimal mark dropped x-axis labels. specifying numeric value (e.g., 2), trailing zeros retained. width optional integer manually adjust width columns annotations. xlab title x-axis. unspecified, function tries set appropriate axis title. slab optional vector labels \\(k\\) studies. unspecified, labels either taken object (study labels specified) simple labels created within function. suppress labels, set argument NA. mlab optional character string giving label summary estimate equal- random-effects model. unspecified, label created within function. ilab optional vector, matrix, data frame providing additional information studies added plot. ilab.xpos numeric vector specify x-axis position(s) variable(s) given via ilab (must specified ilab specified). ilab.pos integer(s) (either 1, 2, 3, 4) specify alignment vector(s) given via ilab (2 means right, 4 mean left aligned). unspecified, default center labels. order optional character string specify studies ordered. Can also variable based studies ordered. See ‘Details’. transf optional argument specify function used transform observed outcomes, summary estimates, fitted values, confidence interval bounds (e.g., transf=exp; see also transf). unspecified, transformation used. atransf optional argument specify function used transform x-axis labels annotations (e.g., atransf=exp; see also transf). unspecified, transformation used. targs optional arguments needed function specified via transf atransf. rows optional vector specify rows (generally, horizontal positions) plotting outcomes. Can also single value specify row (horizontal position) first outcome (remaining outcomes plotted starting row). unspecified, function sets value automatically. efac vertical expansion factor confidence interval limits, arrows, symbol used denote summary estimates. default value 1 usually work okay. Can also vector two numbers, first CI limits arrows, second summary estimates. Can also vector three numbers, first CI limits, second arrows, third summary estimates. pch plotting symbol use observed outcomes. default, filled square used. See points options. Can also vector values. psize optional numeric value specify point sizes observed outcomes. unspecified, point sizes function model weights. Can also vector values. plim numeric vector length 2 scale point sizes (ignored psize specified). See ‘Details’. colout optional character string specify name color use plotting observed outcomes (\"black\" used default specified). Can also vector color names. col optional character string specify name color use summary polygon fitted values. unspecified, function sets default color. border optional character string specify name color use border summary polygon fitted values. unspecified, function sets default color. lty optional character string specify line type confidence intervals. unspecified, function sets \"solid\" default. fonts optional character string specify font use study labels, annotations, extra information (specified via ilab). unspecified, default font used. cex optional character symbol expansion factor. unspecified, function tries set sensible value. cex.lab optional expansion factor x-axis title. unspecified, function tries set sensible value. cex.axis optional expansion factor x-axis labels. unspecified, function tries set sensible value. annosym optional vector length 3 change left bracket, separation, right bracket symbols annotations. ... arguments.","code":""},{"path":"/reference/forest.rma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Forest Plots (Method for 'rma' Objects) — forest.rma","text":"plot shows observed effect sizes outcomes corresponding confidence intervals. equal- random-effects model (.e., models without moderators), four-sided polygon, sometimes called summary ‘diamond’, added bottom forest plot, showing summary estimate based model (center polygon corresponding estimate left/right edges indicating confidence interval limits). col border arguments can used adjust (border) color polygon. Drawing polgyon can suppressed setting addfit=FALSE. random-effects models addpred=TRUE, dotted line added summary polygon indicates (approximate) bounds prediction interval (interval indicates level % true outcomes expected fall) (Riley et al., 2011). random-effects models class \"rma.mv\" (see rma.mv) multiple \\(\\tau^2\\) values, addpred argument can used specify level inner factor prediction interval provided (since intervals differ depending \\(\\tau^2\\) value). model also contain multiple \\(\\gamma^2\\) values, addpred argument length 2 specify levels inner factors. See also predict.rma, used compute interval bounds. meta-regression models (.e., models involving moderators), fitted value study added polygon plot. default, width polygons corresponds confidence interval limits fitted values. setting addpred=TRUE, width reflects prediction interval limits. , col border arguments can used adjust (border) color polygons. polygons can suppressed setting addfit=FALSE. transf argument, observed outcomes, summary estimate, fitted values, confidence interval bounds, prediction interval bounds can transformed suitable function. example, plotting log odds ratios, one use transf=exp obtain forest plot showing odds ratios. Alternatively, one can use atransf argument transform x-axis labels annotations (e.g., atransf=exp). See also transf useful transformation functions context meta-analysis. examples illustrate use arguments. default, studies ordered top bottom (.e., first study dataset placed row \\(k\\), second study row \\(k-1\\), , last study, placed first row). studies can reordered order argument: order=\"obs\": studies ordered observed outcomes, order=\"fit\": studies ordered fitted values, order=\"prec\": studies ordered sampling variances, order=\"resid\": studies ordered size residuals, order=\"rstandard\": studies ordered size standardized residuals, order=\"abs.resid\": studies ordered size absolute residuals, order=\"abs.rstandard\": studies ordered size absolute standardized residuals. Alternatively, also possible set order equal variable based studies ordered (see ‘Examples’). Additional columns information studies can added plot via ilab argument. can either single variable entire matrix / data frame (many rows studies forest plot). ilab.xpos argument must also specified indicate x-axis position variables specified via ilab. figure illustrates elements forest plot can arranged meaning arguments xlim, alim , ilab, ilab.xpos.  figure corresponds following code:  Additional summary estimates can added plot addpoly function. See documentation function examples. showweights=TRUE, annotations include information weights given observed outcomes model fitting. simple models (fitted rma.uni function), weights correspond ‘inverse-variance weights’ (given percent). models fitted rma.mv function, weights based diagonal weight matrix. Note weighting structure typically complex models (.e., weight matrix usually just diagonal matrix) weights shown therefore reflect complexity. See weights.rma details. default (.e., psize specified), point sizes function square root model weights. way, areas proportional weights. However, point sizes rescaled smallest point size plim[1] largest point size plim[2]. result, relative sizes (.e., areas) longer exactly correspond relative weights. exactly relative point sizes desired, one can set plim[2] NA, case points rescaled smallest point size corresponds plim[1] points scaled accordingly. result, largest point may large. Alternatively, one can set plim[1] NA, case points rescaled largest point size corresponds plim[2] points scaled accordingly. result, smallest point may small essentially indistinguishable confidence interval line. avoid latter, one can also set plim[3], enforces minimal point size.","code":"dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg) res <- rma(yi, vi, data=dat, slab=paste(author, year, sep=\", \")) forest(res, addpred=TRUE, xlim=c(-16,7), at=seq(-3,2,by=1),        ilab=cbind(dat$tpos, dat$tneg, dat$cpos, dat$cneg),        ilab.xpos=c(-9.5,-8,-6,-4.5), cex=.75, header=\"Author(s) and Year\") text(c(-9.5,-8,-6,-4.5), 15, c(\"TB+\", \"TB-\", \"TB+\", \"TB-\"), cex=.75, font=2) text(c(-8.75,-5.25),     16, c(\"Vaccinated\", \"Control\"),    cex=.75, font=2)"},{"path":"/reference/forest.rma.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Forest Plots (Method for 'rma' Objects) — forest.rma","text":"function tries set sensible values optional arguments, may necessary adjust certain circumstances. function actually returns information chosen defaults invisibly. Printing information useful starting point make adjustments plot (see ‘Examples’). number studies quite large, labels, annotations, symbols may become quite small impossible read. Stretching plot window vertically may provide readable figure (one call function adjusting window size, label/symbol sizes can properly adjusted). Also, cex, cex.lab, cex.axis arguments useful adjust symbol text sizes. horizontal plot /x-axis limits set manually, horizontal plot limits (xlim) must least wide x-axis limits (alim). restriction enforced inside function. outcome measure used creating plot bounded (e.g., correlations bounded -1 +1, proportions bounded 0 1), one can use olim argument enforce limits (observed outcomes confidence/prediction intervals exceed bounds ). models without moderators, col argument can also vector two elements, first specifying color summary polygon, second specifying color line prediction interval. lty argument can also vector three elements, first specifying line type individual CIs (\"solid\" default), second line type prediction interval (\"dotted\" default), third line type horizontal lines automatically added plot (\"solid\" default; set \"blank\" remove ).","code":""},{"path":"/reference/forest.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Forest Plots (Method for 'rma' Objects) — forest.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/forest.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Forest Plots (Method for 'rma' Objects) — forest.rma","text":"Lewis, S., & Clarke, M. (2001). Forest plots: Trying see wood trees. British Medical Journal, 322(7300), 1479--1480. https://doi.org/10.1136/bmj.322.7300.1479 Riley, R. D., Higgins, J. P. T., & Deeks, J. J. (2011). Interpretation random effects meta-analyses. British Medical Journal, 342, d549. https://doi.org/10.1136/bmj.d549 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/forest.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forest Plots (Method for 'rma' Objects) — forest.rma","text":"","code":"### meta-analysis of the log risk ratios using a random-effects model res <- rma(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg,            slab=paste(author, year, sep=\", \"))  ### default forest plot of the log risk ratios and summary estimate forest(res, header=TRUE)  ### summary estimate in row -1; studies in rows k=13 through 1; horizontal ### lines in rows 0 and k+1; two extra lines of space at the top for headings, ### and other annotations; headings (if requested) in line k+2 op <- par(xpd=TRUE) text(x=-8.4, y=-1:16, -1:16, pos=4, cex=.6)  par(op)  ### can also inspect defaults chosen defaults <- forest(res)  defaults #> $xlim #> [1] -8.00  7.26 #>  #> $alim #> [1] -3  2 #>  #> $at #> [1] -3 -2 -1  0  1  2 #>  #> $ylim #> [1] -1.5 16.0 #>  #> $rows #>  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 #>  #> $cex #> [1] 1 #>  #> $cex.lab #> [1] 1 #>  #> $cex.axis #> [1] 1 #>   ### several forest plots illustrating the use of various arguments forest(res, cex=.8)  forest(res, cex=.8, addpred=TRUE)  forest(res, cex=.8, alim=c(-3,3))  forest(res, cex=.8, order=\"prec\", alim=c(-3,3))  forest(res, cex=.8, order=dat.bcg$ablat, addpred=TRUE)   ### adjust xlim values to see how that changes the plot forest(res)  par(\"usr\")[1:2] ### this shows what xlim values were chosen by default #> [1] -8.00  7.26 forest(res, xlim=c(-16,14))  forest(res, xlim=c(-18,10))  forest(res, xlim=c(-10,10))   ### illustrate transf argument forest(res, transf=exp, at=0:7, xlim=c(-8,12), cex=.8, refline=1, header=TRUE)   ### illustrate atransf argument forest(res, atransf=exp, at=log(c(.05,.25,1,4,20)), xlim=c(-8,7), cex=.8, header=TRUE)   ### showweights argument forest(res, atransf=exp, at=log(c(.05,.25,1,4,20)), xlim=c(-8,8),        order=\"prec\", showweights=TRUE, cex=.8)   ### forest plot with extra annotations ### note: may need to widen plotting device to avoid overlapping text forest(res, atransf=exp, at=log(c(.05, .25, 1, 4)), xlim=c(-16,6),        ilab=cbind(dat.bcg$tpos, dat.bcg$tneg, dat.bcg$cpos, dat.bcg$cneg),        ilab.xpos=c(-9.5,-8,-6,-4.5), cex=.75, header=\"Author(s) and Year\") op <- par(cex=.75, font=2) text(c(-9.5,-8,-6,-4.5), 15, c(\"TB+\", \"TB-\", \"TB+\", \"TB-\")) text(c(-8.75,-5.25),     16, c(\"Vaccinated\", \"Control\"))  par(op)  ### mixed-effects model with absolute latitude in the model res <- rma(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, mods = ~ ablat,            data=dat.bcg, slab=paste(author, year, sep=\", \"))  ### forest plot with observed and fitted values forest(res, xlim=c(-9,5), order=\"fit\", cex=.8, ilab=dat.bcg$ablat,        ilab.xpos=-4, atransf=exp, at=log(c(.05,.25,1,4)),        header=\"Author(s) and Year\") text(-4, 15, \"Latitude\", cex=.8, font=2)   ### meta-analysis of the log risk ratios using a random-effects model res <- rma(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg,            slab=paste(author, year, sep=\", \"))  ### for more complicated plots, the ylim and rows arguments may be useful forest(res) forest(res, ylim=c(-1.5, 16)) ### the default  forest(res, ylim=c(-1.5, 20)) ### extra space in plot  forest(res, ylim=c(-1.5, 20), rows=c(17:15, 12:6, 3:1)) ### set positions   ### forest plot with subgrouping of studies ### note: may need to widen plotting device to avoid overlapping text forest(res, xlim=c(-16, 4.6), at=log(c(.05, .25, 1, 4)), atransf=exp,        ilab=cbind(dat.bcg$tpos, dat.bcg$tneg, dat.bcg$cpos, dat.bcg$cneg),        ilab.xpos=c(-9.5,-8,-6,-4.5), cex=.75, ylim=c(0.5, 21),        order=dat.bcg$alloc, rows=c(1:2,5:11,14:17),        header=\"Author(s) and Year\") op <- par(cex=0.75, font=2) text(c(-9.5,-8,-6,-4.5), 20, c(\"TB+\", \"TB-\", \"TB+\", \"TB-\")) text(c(-8.75,-5.25),     21, c(\"Vaccinated\", \"Control\")) op <- par(font=4) text(-16, c(18,12,3), c(\"Systematic Allocation\", \"Random Allocation\",                         \"Alternate Allocation\"), pos=4)  par(op)  ### see also the addpoly.rma function for an example where summaries ### for the three subgroups are added to such a forest plot  ### illustrate use of olim argument with a meta-analysis of raw correlation ### coefficients (data from Pritz, 1997); without olim=c(0,1), some of the ### CIs would have upper bounds larger than 1 dat <- escalc(measure=\"PR\", xi=xi, ni=ni, data=dat.pritz1997) res <- rma(yi, vi, data=dat, slab=paste0(study, \") \", authors)) forest(res, xlim=c(-0.8,1.6), alim=c(0,1), psize=1, refline=coef(res), olim=c(0,1), header=TRUE)   ### an example of a forest plot where the data have a multilevel structure and ### we want to reflect this by grouping together estimates from the same cluster dat <- dat.konstantopoulos2011 res <- rma.mv(yi, vi, random = ~ 1 | district/school, data=dat,               slab=paste0(\"District \", district, \", School: \", school)) dd <- c(0,diff(dat$district)) dd[dd > 0] <- 1 rows <- (1:res$k) + cumsum(dd) par(tck=-.01, mgp = c(1.6,.2,0)) forest(res, cex=0.5, header=TRUE, rows=rows, ylim=c(0.5,max(rows)+3)) abline(h = rows[c(1,diff(rows)) == 2] - 1, lty=\"dotted\")"},{"path":"/reference/formula.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Model Formulae for 'rma' Objects — formula.rma","title":"Model Formulae for 'rma' Objects — formula.rma","text":"function extracts model formulae objects class \"rma\".","code":""},{"path":"/reference/formula.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model Formulae for 'rma' Objects — formula.rma","text":"","code":"# S3 method for rma formula(x, type=\"mods\", ...)"},{"path":"/reference/formula.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model Formulae for 'rma' Objects — formula.rma","text":"x object class \"rma\". type formula returned; either \"mods\" (default), \"yi\" (case argument yi used specify formula), \"scale\" (location-scale models). ... arguments.","code":""},{"path":"/reference/formula.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model Formulae for 'rma' Objects — formula.rma","text":"requested formula.","code":""},{"path":"/reference/formula.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Model Formulae for 'rma' Objects — formula.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/formula.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Model Formulae for 'rma' Objects — formula.rma","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/formula.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model Formulae for 'rma' Objects — formula.rma","text":"","code":"### copy BCG vaccine data into 'dat' dat <- dat.bcg  ### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat,               slab=paste(author, \", \", year, sep=\"\"))  ### mixed-effects meta-regression model res <- rma(yi, vi, mods = ~ ablat + alloc, data=dat) formula(res, type=\"mods\") #> ~ablat + alloc #> <environment: 0x55f5b942c678>  ### specify moderators via 'yi' argument res <- rma(yi ~ ablat + alloc, vi, data=dat) formula(res, type=\"yi\") #> yi ~ ablat + alloc #> <environment: 0x55f5bd0d81f8>"},{"path":"/reference/fsn.html","id":null,"dir":"Reference","previous_headings":"","what":"Fail-Safe N Analysis (File Drawer Analysis) — fsn","title":"Fail-Safe N Analysis (File Drawer Analysis) — fsn","text":"Function compute fail-safe N (also called file drawer analysis).","code":""},{"path":"/reference/fsn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fail-Safe N Analysis (File Drawer Analysis) — fsn","text":"","code":"fsn(yi, vi, sei, data, type=\"Rosenthal\", alpha=.05,     target, weighted=FALSE, subset, digits, ...)"},{"path":"/reference/fsn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fail-Safe N Analysis (File Drawer Analysis) — fsn","text":"yi vector observed effect sizes outcomes. vi vector corresponding sampling variances. sei vector corresponding standard errors (note: one two, vi sei, needs specified). data optional data frame containing variables given arguments . type character string specify method use calculation fail-safe N. Possible options \"Rosenthal\" (default), \"Orwin\", \"Rosenberg\". See ‘Details’. alpha target alpha level use Rosenthal Rosenberg methods (default .05). target target average effect size outcome use Orwin method. undefined, target average effect size outcome equal observed average effect size outcome divided 2. weighted logical specify whether Orwin's method based unweighted (default) weighted averages (default FALSE). subset optional (logical numeric) vector specify subset studies used calculations. digits optional integer specify number decimal places printed results rounded. ... arguments.","code":""},{"path":"/reference/fsn.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fail-Safe N Analysis (File Drawer Analysis) — fsn","text":"function can used combination usual effect sizes / outcome measures used meta-analyses (e.g., log risk ratios, log odds ratios, risk differences, mean differences, standardized mean differences, raw correlation coefficients, correlation coefficients transformed Fisher's r--z transformation), , generally, set estimates (corresponding sampling variances) one like analyze. Simply specify observed outcomes via yi argument corresponding sampling variances via vi argument (instead specifying vi, one can specify standard errors via sei argument). escalc function can used compute wide variety effect sizes / outcome measures (corresponding sampling variances) based summary statistics. Rosenthal method (sometimes called ‘file drawer analysis’) calculates number studies averaging null results added given set observed outcomes reduce combined significance level (p-value) particular alpha level (e.g., .05). calculation based Stouffer's method combine p-values described Rosenthal (1979). Orwin method calculates number studies averaging null results added given set observed outcomes reduce (unweighted weighted) average outcome target value (specified via target argument). method described Orwin (1983). weighted=FALSE (default), method require (makes use) vi (sei), arguments relevant method. target argument specified, target average outcome equal observed average outcome divided 2 (quite arbitrary). One really set target value reflects outcome one consider practically irrelevant. Note target opposite sign actually observed average outcome, sign automatically flipped. Rosenberg method calculates number studies averaging null results added given set observed outcomes reduce significance level (.e., p-value) weighted average outcome (based equal-effects model) particular alpha level (e.g., .05). method described Rosenberg (2005). combined/observed significance level specified alpha level (type = \"Rosenthal\" type = \"Rosenberg\") observed average outcome target average outcome (type = \"Orwin\"), fail-sage N value 0.","code":""},{"path":"/reference/fsn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fail-Safe N Analysis (File Drawer Analysis) — fsn","text":"object class \"fsn\". object list containing following components: type method used. fsnum calculated fail-safe N. alpha specified alpha level. pval p-value observed results. NA Orwin method. meanes average outcome observed results. NA Rosenthal method. target target value. NA Rosenthal Rosenberg methods. results formatted printed print function.","code":""},{"path":"/reference/fsn.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Fail-Safe N Analysis (File Drawer Analysis) — fsn","text":"Rosenberg method, p-value calculated based standard normal distribution (instead t-distribution, suggested Rosenberg, 2005).","code":""},{"path":"/reference/fsn.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fail-Safe N Analysis (File Drawer Analysis) — fsn","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/fsn.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fail-Safe N Analysis (File Drawer Analysis) — fsn","text":"Rosenthal, R. (1979). \"file drawer problem\" tolerance null results. Psychological Bulletin, 86(3), 638--641. https://doi.org/10.1037/0033-2909.86.3.638 Orwin, R. G. (1983). fail-safe N effect size meta-analysis. Journal Educational Statistics, 8(2), 157--159. https://doi.org/10.3102/10769986008002157 Rosenberg, M. S. (2005). file-drawer problem revisited: general weighted method calculating fail-safe numbers meta-analysis. Evolution, 59(2), 464--468. https://doi.org/10.1111/j.0014-3820.2005.tb01004.x Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/fsn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fail-Safe N Analysis (File Drawer Analysis) — fsn","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit equal-effects model rma(yi, vi, data=dat, method=\"EE\") #>  #> Equal-Effects Model (k = 13) #>  #> I^2 (total heterogeneity / total variability):   92.12% #> H^2 (total variability / sampling variability):  12.69 #>  #> Test for Heterogeneity: #> Q(df = 12) = 152.2330, p-val < .0001 #>  #> Model Results: #>  #> estimate      se      zval    pval    ci.lb    ci.ub     ​  #>  -0.4303  0.0405  -10.6247  <.0001  -0.5097  -0.3509  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### fail-safe N computations fsn(yi, vi, data=dat) #>  #> Fail-safe N Calculation Using the Rosenthal Approach #>  #> Observed Significance Level: <.0001 #> Target Significance Level:   0.05 #>  #> Fail-safe N: 598 #>  fsn(yi, data=dat, type=\"Orwin\", target=log(0.95)) # target corresponds to a 5% risk reduction #>  #> Fail-safe N Calculation Using the Orwin Approach #>  #> Average Effect Size: -0.7407 #> Target Effect Size:  -0.0513 #>  #> Fail-safe N: 175 #>  fsn(yi, vi, data=dat, type=\"Orwin\", weighted=TRUE, target=log(0.95)) #>  #> Fail-safe N Calculation Using the Orwin Approach #>  #> Average Effect Size: -0.4303 #> Target Effect Size:  -0.0513 #>  #> Fail-safe N: 97 #>  fsn(yi, vi, data=dat, type=\"Rosenberg\") #>  #> Fail-safe N Calculation Using the Rosenberg Approach #>  #> Average Effect Size:         -0.4303 #> Observed Significance Level: <.0001 #> Target Significance Level:   0.05 #>  #> Fail-safe N: 370 #>"},{"path":"/reference/funnel.html","id":null,"dir":"Reference","previous_headings":"","what":"Funnel Plots — funnel","title":"Funnel Plots — funnel","text":"Function create funnel plots.","code":""},{"path":"/reference/funnel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Funnel Plots — funnel","text":"","code":"funnel(x, ...)  # S3 method for rma funnel(x, yaxis=\"sei\",        xlim, ylim, xlab, ylab,        steps=5, at, atransf, targs, digits, level=x$level,        addtau2=FALSE, type=\"rstandard\",        back=\"lightgray\", shade=\"white\", hlines=\"white\",        refline, lty=3, pch=19, pch.fill=21, col, bg,        label=FALSE, offset=0.4, legend=FALSE, ci.res=1000, ...)  # S3 method for default funnel(x, vi, sei, ni, subset, yaxis=\"sei\",        xlim, ylim, xlab, ylab,        steps=5, at, atransf, targs, digits, level=95,        back=\"lightgray\", shade=\"white\", hlines=\"white\",        refline=0, lty=3, pch=19, col, bg,        label=FALSE, offset=0.4, legend=FALSE, ci.res=1000, ...)"},{"path":"/reference/funnel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Funnel Plots — funnel","text":"x object class \"rma\" vector observed effect sizes outcomes. vi vector corresponding sampling variances (needed x vector observed effect sizes outcomes). sei vector corresponding standard errors (note: one two, vi sei, needs specified). ni vector corresponding sample sizes. relevant passing vector via x. subset optional (logical numeric) vector specify subset studies included plot. relevant passing vector via x. yaxis either \"sei\", \"vi\", \"seinv\", \"vinv\", \"ni\", \"ninv\", \"sqrtni\", \"sqrtninv\", \"lni\", \"wi\" indicate values placed y-axis. See ‘Details’. xlim x-axis limits. unspecified, function tries set x-axis limits sensible values. ylim y-axis limits. unspecified, function tries set y-axis limits sensible values. xlab title x-axis. unspecified, function tries set appropriate axis title. ylab title y-axis. unspecified, function tries set appropriate axis title. steps number tick marks y-axis (default 5). position x-axis tick marks corresponding labels. unspecified, function tries set tick mark positions/labels sensible values. atransf optional argument specify function used transform x-axis labels (e.g., atransf=exp; see also transf). unspecified, transformation used. targs optional arguments needed function specified via atransf. digits optional integer specify number decimal places tick mark labels x- y-axis rounded. Can also vector two integers, first specify number decimal places x-axis, second y-axis labels (e.g., digits=c(2,3)). unspecified, function tries set argument sensible values. level numeric value 0 100 specify level pseudo confidence interval region (\"rma\" objects, default take value object). May also vector values obtain multiple regions. See ‘Examples’. addtau2 logical indicate whether amount heterogeneity accounted drawing pseudo confidence interval region (default FALSE). Ignored x meta-regression model residuals plotted. See ‘Details’. type either \"rstandard\" (default) \"rstudent\" specify whether usual deleted residuals used creating funnel plot x meta-regression model. See ‘Details’. back color use background plotting region (default \"lightgray\"). shade color use shading pseudo confidence interval region (default \"white\"). level vector values, different shading colors can specified region. hlines color horizontal reference lines (default \"white\"). refline numeric value specify location vertical ‘reference’ line pseudo confidence interval centered. unspecified, reference line drawn equal- random-effects model estimate zero meta-regression models (case residuals plotted) directly plotting observed outcomes. lty line type pseudo confidence interval region reference line. default draw dotted lines (see par options). Can also vector specify two line types separately. pch plotting symbol use observed outcomes. default, filled circle used. Can also vector values. See points options. pch.fill plotting symbol use outcomes filled trim fill method. default, circle used. relevant plotting object created trimfill function. col optional character string specify name color use points (\"black\" used default specified). Can also vector color names. bg optional character string specify name background color open plot symbols (\"white\" used default specified). Can also vector color names. label argument control labeling points (default FALSE). See ‘Details’. offset argument control distance points corresponding labels. legend logical indicate whether legend added plot (default FALSE). Can also keyword indicate position legend (see legend). ci.res integer specify number y-axis values calculate bounds pseudo confidence interval. default 1000, usually provides sufficient resolution plotting. ... arguments.","code":""},{"path":"/reference/funnel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Funnel Plots — funnel","text":"equal- random-effects models (.e., models involving moderators), plot shows observed effect sizes outcomes x-axis corresponding standard errors (.e., square root sampling variances) y-axis. vertical line indicates estimate based model. pseudo confidence interval region drawn around value bounds equal \\(\\pm 1.96 \\mbox{SE}\\), \\(\\mbox{SE}\\) standard error value y-axis (assuming level=95). addtau2=TRUE (models class \"rma.uni\"), bounds pseudo confidence interval region equal \\(\\pm 1.96 \\sqrt{\\mbox{SE}^2 + \\hat{\\tau}^2}\\), \\(\\hat{\\tau}^2\\) amount heterogeneity estimated model. (mixed-effects) meta-regression models (.e., models involving moderators), plot shows residuals x-axis corresponding standard errors. Either usual deleted residuals can used purpose (set via type argument). See residuals details different types residuals. atransf argument, labels x-axis can transformed suitable function. example, plotting log odds ratios, one use transf=exp obtain funnel plot values x-axis corresponding odds ratios. See also transf useful transformation functions context meta-analysis. Instead placing standard errors y-axis, several options available setting yaxis argument : yaxis=\"vi\" sampling variances, yaxis=\"seinv\" inverse standard errors, yaxis=\"vinv\" inverse sampling variances, yaxis=\"ni\" sample sizes, yaxis=\"ninv\" inverse sample sizes, yaxis=\"sqrtni\" square root sample sizes, yaxis=\"sqrtninv\" inverse square root sample sizes, yaxis=\"lni\" log sample sizes, yaxis=\"wi\" weights. However, yaxis=\"sei\" (default) pseudo confidence region expected (upside-) funnel shape straight lines. Also, placing (function ) sample sizes y-axis weights, pseudo confidence region drawn. See Sterne Egger (2001) details choice y-axis. object passed function comes trimfill function, outcomes filled trim fill method also added funnel plot. symbol use plotting filled values can specified via pch.fill argument. One can also directly pass vector observed effect sizes outcomes (via x) corresponding sampling variances (via vi), standard errors (via sei), /sample sizes (via ni) function. default, vertical reference line drawn zero. arguments back, shade, hlines can set NULL suppress shading horizontal reference line. label argument, one can control whether points plot labeled. label=\"\" (label=TRUE), points plot labeled. label=\"\", points falling outside pseudo confidence region labeled. Finally, one can also set argument numeric value (1 \\(k\\)) specify many extreme points labeled (e.g., label=1 extreme point labeled, label=3, extreme, second third extreme points labeled). offset argument, one can adjust distance labels corresponding points.","code":""},{"path":"/reference/funnel.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Funnel Plots — funnel","text":"Placing (function ) sample sizes y-axis (.e., using yaxis=\"ni\", yaxis=\"ninv\", yaxis=\"sqrtni\", yaxis=\"sqrtninv\", yaxis=\"lni\") possible information sample sizes actually stored within object passed funnel function. automatically case observed effect sizes outcomes computed escalc function observed effect sizes outcomes computed within model fitting function. hand, case rma.uni used together yi vi arguments yi vi values computed escalc. case, still possible pass information sample sizes rma.uni function (e.g., use rma.uni(yi, vi, ni=ni, data=dat), data frame dat includes variable called ni sample sizes). using unweighted estimation, using yaxis=\"wi\" place points horizontal line. directly passing vector observed effect sizes outcomes function, yaxis=\"wi\" equivalent yaxis=\"vinv\", except weights expressed percent. specifying vectors pch, col, /bg, variables specified assumed length data passed funnel function model fitting function (using funnel model object). subsetting removal studies missing values automatically applied variables specified via arguments.","code":""},{"path":"/reference/funnel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Funnel Plots — funnel","text":"data frame components: x x-axis coordinates points plotted. y y-axis coordinates points plotted. slab study labels. Note data frame returned invisibly.","code":""},{"path":"/reference/funnel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Funnel Plots — funnel","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/funnel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Funnel Plots — funnel","text":"Light, R. J., & Pillemer, D. B. (1984). Summing : science reviewing research. Cambridge, MA: Harvard University Press. Peters, J. L., Sutton, . J., Jones, D. R., Abrams, K. R., & Rushton, L. (2008). Contour-enhanced meta-analysis funnel plots help distinguish publication bias causes asymmetry. Journal Clinical Epidemiology, 61(10), 991--996. https://doi.org/10.1016/j.jclinepi.2007.11.010 Sterne, J. . C., & Egger, M. (2001). Funnel plots detecting bias meta-analysis: Guidelines choice axis. Journal Clinical Epidemiology, 54(10), 1046--1055. https://doi.org/10.1016/s0895-4356(01)00377-8 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/funnel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Funnel Plots — funnel","text":"","code":"### copy BCG vaccine data into 'dat' dat <- dat.bcg  ### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat)  ### fit random-effects model res <- rma(yi, vi, data=dat, slab=paste(dat$author, dat$year, sep=\", \"))  ### draw a standard funnel plot funnel(res)   ### show risk ratio values on x-axis (log scale) funnel(res, atransf=exp)  ### label points outside of the pseudo confidence interval region funnel(res, atransf=exp, label=\"out\")   ### passing log risk ratios and sampling variances directly to the function ### note: same plot, except that reference line is centered at zero funnel(dat$yi, dat$vi)  ### can accomplish the same thing by setting refline=0 funnel(res, refline=0)   ### adjust the position of the x-axis labels, number of digits, and y-axis limits funnel(res, atransf=exp, at=log(c(.125, .25, .5, 1, 2)), digits=3L, ylim=c(0,.8))   ### contour-enhanced funnel plot centered at 0 (see Peters et al., 2008) funnel(res, level=c(90, 95, 99), shade=c(\"white\", \"gray55\", \"gray75\"), refline=0, legend=TRUE)   ### same, but show risk ratio values on the x-axis and some further adjustments funnel(res, level=c(90, 95, 99), shade=c(\"white\", \"gray55\", \"gray75\"), digits=3L, ylim=c(0,.8),        refline=0, legend=TRUE, atransf=exp, at=log(c(.125, .25, .5, 1, 2, 4, 8)))   ### illustrate the use of vectors for 'pch' and 'col' res <- rma(yi, vi, data=dat, subset=2:10) funnel(res, pch=ifelse(dat$yi > -1, 19, 21), col=ifelse(sqrt(dat$vi) > .3, \"red\", \"blue\"))   ### can add a second funnel via (undocumented) argument refline2 funnel(res, atransf=exp, at=log(c(.125, .25, .5, 1, 2, 4)), digits=3L, ylim=c(0,.8), refline2=0)   ### mixed-effects model with absolute latitude in the model res <- rma(yi, vi, mods = ~ ablat, data=dat)  ### funnel plot of the residuals funnel(res)   ### simulate a large meta-analytic dataset (correlations with rho = 0.2) ### with no heterogeneity or publication bias; then try out different ### versions of the funnel plot  gencor <- function(rhoi, ni) {    x1 <- rnorm(ni, mean=0, sd=1)    x2 <- rnorm(ni, mean=0, sd=1)    x3 <- rhoi*x1 + sqrt(1-rhoi^2)*x2    cor(x1, x3) }  set.seed(1234) k  <- 200                               ### number of studies to simulate ni <- round(rchisq(k, df=2) * 20 + 20)  ### simulate sample sizes (skewed distribution) ri <- mapply(gencor, rep(0.2,k), ni)    ### simulate correlations  res <- rma(measure=\"ZCOR\", ri=ri, ni=ni, method=\"EE\") ### use r-to-z transformed correlations  funnel(res, yaxis=\"sei\")  funnel(res, yaxis=\"vi\")  funnel(res, yaxis=\"seinv\")  funnel(res, yaxis=\"vinv\")  funnel(res, yaxis=\"ni\")  funnel(res, yaxis=\"ninv\")  funnel(res, yaxis=\"sqrtni\")  funnel(res, yaxis=\"sqrtninv\")  funnel(res, yaxis=\"lni\")  funnel(res, yaxis=\"wi\")"},{"path":"/reference/gosh.html","id":null,"dir":"Reference","previous_headings":"","what":"GOSH Plots for 'rma' Objects — gosh","title":"GOSH Plots for 'rma' Objects — gosh","text":"Function create GOSH plots objects class \"rma\".","code":""},{"path":"/reference/gosh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GOSH Plots for 'rma' Objects — gosh","text":"","code":"gosh(x, ...)  # S3 method for rma gosh(x, subsets, progbar=TRUE, parallel=\"no\", ncpus=1, cl, ...)"},{"path":"/reference/gosh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"GOSH Plots for 'rma' Objects — gosh","text":"x object class \"rma\". subsets optional integer specify number subsets. progbar logical specify whether progress bar shown (default TRUE). parallel character string specify whether parallel processing used (default \"\"). parallel processing, set either \"snow\" \"multicore\". See ‘Details’. ncpus integer specify number processes use parallel processing. cl optional cluster use parallel=\"snow\". unspecified, cluster local machine created duration call. ... arguments.","code":""},{"path":"/reference/gosh.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"GOSH Plots for 'rma' Objects — gosh","text":"model specified via x must model fitted either rma.uni, rma.mh, rma.peto function. Olkin et al. (2012) proposed GOSH (graphical display study heterogeneity) plot, based examining results equal-effects model possible subsets size \\(1, \\ldots, k\\) \\(k\\) studies included meta-analysis. homogeneous set studies, model estimates obtained way form roughly symmetric, contiguous, unimodal distribution. hand, distribution multimodal, suggests presence heterogeneity, possibly due outliers /distinct subgroupings studies. Plotting estimates measure heterogeneity (e.g., \\(^2\\), \\(H^2\\), \\(Q\\)-statistic) can also help reveal subclusters, indicative heterogeneity. type plot can produced first fitting equal-effects model either rma.uni (using method=\"EE\"), rma.mh, rma.peto functions passing fitted model object gosh function plotting results. models fitted rma.uni function (may random-effects mixed-effects meta-regressions models), idea underlying type plot can generalized (Viechtbauer, 2021) examining distribution model coefficients, plotting , measure (residual) heterogeneity (including estimate \\(\\tau^2\\)). Note models without moderators, application method requires fitting total \\(2^k - 1\\) models, excessively large number \\(k\\) large. example, \\(k=10\\), 1023 possible subsets, \\(k=20\\), number already grows 1048575. even larger \\(k\\), may become computationally infeasible consider possible subsets. Instead, can examine (sufficiently large number ) random subsets. default, number possible subsets \\(\\le 10^6\\), function consider possible subsets otherwise \\(10^6\\) random subsets. One can use subsets argument specify different number subsets consider. subsets specified actually larger number possible subsets, function automatically considers possible subsets use random subsets. machines multiple cores, one can try speed things delegating model fitting separate worker processes, , setting parallel=\"snow\" parallel=\"multicore\" ncpus value larger 1. Parallel processing makes use parallel package, using makePSOCKcluster parLapply functions parallel=\"snow\" using mclapply parallel=\"multicore\" (latter works Unix/Linux-alikes). parallel::detectCores(), one can check number available cores local machine.","code":""},{"path":"/reference/gosh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"GOSH Plots for 'rma' Objects — gosh","text":"object class \"gosh.rma\". object list containing following components: res data frame results subset (various heterogeneity statistics model coefficient(s)). incl matrix indicating studies included subset. ... additional elements/values. results can printed print function plotted plot function.","code":""},{"path":"/reference/gosh.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"GOSH Plots for 'rma' Objects — gosh","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/gosh.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"GOSH Plots for 'rma' Objects — gosh","text":"Olkin, ., Dahabreh, . J., & Trikalinos, T. . (2012). GOSH - graphical display study heterogeneity. Research Synthesis Methods, 3(3), 214--223. https://doi.org/10.1002/jrsm.1053 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03 Viechtbauer, W. (2021). Model checking meta-analysis. C. H. Schmid, T. Stijnen, & . R. White (Eds.), Handbook meta-analysis (pp. 219--254). Boca Raton, FL: CRC Press. https://doi.org/10.1201/9781315119403","code":""},{"path":[]},{"path":"/reference/gosh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"GOSH Plots for 'rma' Objects — gosh","text":"","code":"### calculate log odds ratios and corresponding sampling variances dat <- escalc(measure=\"OR\", ai=ai, n1i=n1i, ci=ci, n2i=n2i, data=dat.egger2001)  ### meta-analysis of all trials including ISIS-4 using an equal-effects model res <- rma(yi, vi, data=dat, method=\"EE\")  ### fit FE model to all possible subsets (65535 models) # \\dontrun{ sav <- gosh(res, progbar=FALSE) sav #>  #> Model fits attempted: 65535 #> Model fits succeeded: 65535 #>  #>             mean     min      q1  median      q3     max  #> k         8.0001  1.0000  7.0000  8.0000  9.0000 16.0000  #> Q        16.2141  0.0000  8.6068 14.1750 23.9552 47.0593  #> I2       45.1552  0.0000 24.8066 52.5244 68.6902 87.5350  #> H2        2.2396  0.0000  1.3299  2.1063  3.1939  8.0225  #> estimate -0.3424 -2.4075 -0.5535  0.0148  0.0354  0.2231  #>   ### create GOSH plot ### red points for subsets that include and blue points ### for subsets that exclude study 16 (the ISIS-4 trial) plot(sav, out=16, breaks=100)# }"},{"path":"/reference/hc.html","id":null,"dir":"Reference","previous_headings":"","what":"Meta-Analysis based on the Method by Henmi and Copas (2010) — hc","title":"Meta-Analysis based on the Method by Henmi and Copas (2010) — hc","text":"function can used obtain estimate average true outcome corresponding confidence interval random-effects model using method described Henmi Copas (2010).","code":""},{"path":"/reference/hc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Meta-Analysis based on the Method by Henmi and Copas (2010) — hc","text":"","code":"hc(object, ...)  # S3 method for rma.uni hc(object, digits, transf, targs, control, ...)"},{"path":"/reference/hc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Meta-Analysis based on the Method by Henmi and Copas (2010) — hc","text":"object object class \"rma.uni\". digits optional integer specify number decimal places printed results rounded. unspecified, default take value object. transf optional argument specify function used transform estimate corresponding interval bounds (e.g., transf=exp; see also transf). unspecified, transformation used. targs optional arguments needed function specified transf. control list control values iterative algorithm. unspecified, default values defined inside function. See ‘Note’. ... arguments.","code":""},{"path":"/reference/hc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Meta-Analysis based on the Method by Henmi and Copas (2010) — hc","text":"model specified via object must model without moderators (.e., either equal- random-effects model). using usual method fitting random-effects model (.e., weighted estimation inverse-variance weights), weights assigned smaller larger studies become uniform amount heterogeneity increases. consequence, estimated average outcome become increasingly biased certain forms publication bias (smaller studies one side funnel plot missing). method Henmi Copas (2010) tries counteract problem providing estimate average true outcome based inverse-variance weights used equal-effects model (take amount heterogeneity consideration). amount heterogeneity still estimated (DerSimonian-Laird estimator) incorporated standard error estimated average outcome corresponding confidence interval. Currently, method handling objects class \"rma.uni\" hc function. therefore provides method conducting sensitivity analysis model fitted rma.uni function.","code":""},{"path":"/reference/hc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Meta-Analysis based on the Method by Henmi and Copas (2010) — hc","text":"object class \"hc.rma.uni\". object list containing following components: beta estimated average true outcome. se corresponding standard error. ci.lb lower bound confidence intervals average true outcome. ci.ub upper bound confidence intervals average true outcome. ... additional elements/values. results formatted printed print function.","code":""},{"path":"/reference/hc.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Meta-Analysis based on the Method by Henmi and Copas (2010) — hc","text":"method makes use uniroot function. default, desired accuracy set equal .Machine$double.eps^0.25 maximum number iterations 1000. desired accuracy (tol) maximum number iterations (maxiter) can adjusted control argument (.e., control=list(tol=value, maxiter=value)).","code":""},{"path":"/reference/hc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Meta-Analysis based on the Method by Henmi and Copas (2010) — hc","text":"Original code Henmi Copas (2010). Corrected typos Michael Dewey (lists@dewey.myzen.co.uk). Incorporated package small adjustments consistency functions package Wolfgang Viechtbauer (wvb@metafor-project.org).","code":""},{"path":"/reference/hc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Meta-Analysis based on the Method by Henmi and Copas (2010) — hc","text":"Henmi, M., & Copas, J. B. (2010). Confidence intervals random effects meta-analysis robustness publication bias. Statistics Medicine, 29(29), 2969--2983. https://doi.org/10.1002/sim.4029 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/hc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Meta-Analysis based on the Method by Henmi and Copas (2010) — hc","text":"","code":"### calculate log odds ratios and corresponding sampling variances dat <- escalc(measure=\"OR\", ai=ai, n1i=n1i, ci=ci, n2i=n2i, data=dat.lee2004) dat #>  #>    id        study year ai n1i ci n2i      yi     vi  #> 1   1      Agarwal 2000 18 100 20 100 -0.1301 0.1303  #> 2   2      Agarwal 2002  5  50 18  50 -1.6219 0.3090  #> 3   3     Alkaissi 1999  9  20  7  20  0.4184 0.4218  #> 4   4     Alkaissi 2002 32 135 31 139  0.0792 0.0825  #> 5   5        Allen 1994  9  23 10  23 -0.1795 0.3595  #> 6   6 Andrzejowski 1996 11  18 12  18 -0.2412 0.4838  #> 7   7       Duggal 1998 69 122 80 122 -0.3805 0.0697  #> 8   8       Dundee 1986  3  25 12  25 -1.9124 0.5390  #> 9   9 Ferrera-Love 1996  1  30  1  30  0.0000 2.0690  #> 10 10       Gieron 1993 11  30 19  30 -1.0931 0.2871  #> 11 11       Harmon 1999  7  44 16  39 -1.3021 0.2759  #> 12 12       Harmon 2000  4  47  6  47 -0.4531 0.4643  #> 13 13           Ho 1996  1  30 13  30 -3.0990 1.1702  #> 14 14         Rusy 2002 24  40 71  80 -1.6600 0.2294  #> 15 15         Wang 2002 16  50 53  88 -1.1687 0.1394  #> 16 16       Zarate 2001 28 110 25 111  0.1610 0.0995  #>   ### meta-analysis based on log odds ratios res <- rma(yi, vi, data=dat) res #>  #> Random-Effects Model (k = 16; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.3526 (SE = 0.2254) #> tau (square root of estimated tau^2 value):      0.5938 #> I^2 (total heterogeneity / total variability):   62.35% #> H^2 (total variability / sampling variability):  2.66 #>  #> Test for Heterogeneity: #> Q(df = 15) = 38.4231, p-val = 0.0008 #>  #> Model Results: #>  #> estimate      se     zval    pval    ci.lb    ci.ub     ​  #>  -0.6820  0.2013  -3.3877  0.0007  -1.0766  -0.2874  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### funnel plot as in Henmi and Copas (2010) funnel(res, yaxis=\"seinv\", refline=0, xlim=c(-3,3), ylim=c(.5,3.5), steps=7, digits=1, back=\"white\")   ### use method by Henmi and Copas (2010) as a sensitivity analysis hc(res) #>  #>     method   tau2 estimate     se   ci.lb   ci.ub  #> rma   REML 0.3526  -0.6820 0.2013 -1.0766 -0.2874  #> hc      DL 0.3325  -0.5145 0.2178 -0.9994 -0.0295  #>   ### back-transform results to odds ratio scale hc(res, transf=exp) #>  #>     method   tau2 estimate  ci.lb  ci.ub  #> rma   REML 0.3526   0.5056 0.3408 0.7502  #> hc      DL 0.3325   0.5978 0.3681 0.9709  #>"},{"path":"/reference/influence.rma.mv.html","id":null,"dir":"Reference","previous_headings":"","what":"Outlier and Influential Case Diagnostics for 'rma.mv' Objects — influence.rma.mv","title":"Outlier and Influential Case Diagnostics for 'rma.mv' Objects — influence.rma.mv","text":"functions can used compute various outlier influential case diagnostics (indicate influence deleting one case time model fit fitted/residual values) objects class \"rma.mv\".","code":""},{"path":"/reference/influence.rma.mv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Outlier and Influential Case Diagnostics for 'rma.mv' Objects — influence.rma.mv","text":"","code":"# S3 method for rma.mv cooks.distance(model, progbar=FALSE, cluster,                reestimate=TRUE, parallel=\"no\", ncpus=1, cl, ...)  # S3 method for rma.mv dfbetas(model, progbar=FALSE, cluster,         reestimate=TRUE, parallel=\"no\", ncpus=1, cl, ...)  # S3 method for rma.mv hatvalues(model, type=\"diagonal\", ...)"},{"path":"/reference/influence.rma.mv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Outlier and Influential Case Diagnostics for 'rma.mv' Objects — influence.rma.mv","text":"model object class \"rma.mv\". progbar logical specify whether progress bar shown (default FALSE). cluster optional vector specify clustering variable use computing Cook's distances DFBETAS values. specified, measures computed individual observed effect sizes outcomes. reestimate logical specify whether variance/correlation components re-estimated deletion \\(\\textrm{th}\\) case (default TRUE). parallel character string specify whether parallel processing used (default \"\"). parallel processing, set either \"snow\" \"multicore\". See ‘Details’. ncpus integer specify number processes use parallel processing. cl optional cluster use parallel=\"snow\". unspecified, cluster local machine created duration call. type character string specify whether diagonal hat matrix (\"diagonal\") entire hat matrix (\"matrix\") returned. ... arguments.","code":""},{"path":"/reference/influence.rma.mv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Outlier and Influential Case Diagnostics for 'rma.mv' Objects — influence.rma.mv","text":"term ‘case’ refers particular row dataset used model fitting (argument cluster specified) level variable specified via cluster. Cook's distance \\(\\textrm{th}\\) case can interpreted Mahalanobis distance entire set predicted values \\(\\textrm{th}\\) case included \\(\\textrm{th}\\) case excluded model fitting. DFBETAS value(s) essentially indicate(s) many standard deviations estimated coefficient(s) change(s) excluding \\(\\textrm{th}\\) case model fitting.","code":""},{"path":"/reference/influence.rma.mv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Outlier and Influential Case Diagnostics for 'rma.mv' Objects — influence.rma.mv","text":"cooks.distance function returns vector. dfbetas function returns data frame. hatvalues function returns either vector diagonal elements hat matrix entire hat matrix.","code":""},{"path":"/reference/influence.rma.mv.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Outlier and Influential Case Diagnostics for 'rma.mv' Objects — influence.rma.mv","text":"Right now, leave-one-diagnostics calculated refitting model \\(k\\) times (\\(k\\) number cases). Depending large \\(k\\) , may take moments finish calculations. complex models fitted rma.mv, can become computationally expensive. machines multiple cores, one can usually speed things delegating model fitting separate worker processes, , setting parallel=\"snow\" parallel=\"multicore\" ncpus value larger 1. Parallel processing makes use parallel package, using makePSOCKcluster parLapply functions parallel=\"snow\" using mclapply parallel=\"multicore\" (latter works Unix/Linux-alikes). parallel::detectCores(), one can check number available cores local machine. Alternatively (addition using parallel processing), one can also set reestimate=FALSE, case variance/correlation components model re-estimated deleting \\(\\textrm{th}\\) case dataset. yields approximation Cook's distances DFBETAS values ignores influence \\(\\textrm{th}\\) case variance/correlation components, considerably faster (often yields similar results). may possible fit model deletion \\(\\textrm{th}\\) case dataset. result NA values case.","code":""},{"path":"/reference/influence.rma.mv.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Outlier and Influential Case Diagnostics for 'rma.mv' Objects — influence.rma.mv","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/influence.rma.mv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Outlier and Influential Case Diagnostics for 'rma.mv' Objects — influence.rma.mv","text":"Belsley, D. ., Kuh, E., & Welsch, R. E. (1980). Regression diagnostics. New York: Wiley. Cook, R. D., & Weisberg, S. (1982). Residuals influence regression. London: Chapman Hall. Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03 Viechtbauer, W., & Cheung, M. W.-L. (2010). Outlier influence diagnostics meta-analysis. Research Synthesis Methods, 1(2), 112--125. https://doi.org/10.1002/jrsm.11","code":""},{"path":[]},{"path":"/reference/influence.rma.mv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Outlier and Influential Case Diagnostics for 'rma.mv' Objects — influence.rma.mv","text":"","code":"### copy data from Konstantopoulos (2011) into 'dat' dat <- dat.konstantopoulos2011  ### multilevel random-effects model res <- rma.mv(yi, vi, random = ~ 1 | district/school, data=dat) print(res, digits=3) #>  #> Multivariate Meta-Analysis Model (k = 56; method: REML) #>  #> Variance Components: #>  #>            estim   sqrt  nlvls  fixed           factor  #> sigma^2.1  0.065  0.255     11     no         district  #> sigma^2.2  0.033  0.181     56     no  district/school  #>  #> Test for Heterogeneity: #> Q(df = 55) = 578.864, p-val < .001 #>  #> Model Results: #>  #> estimate     se   zval   pval  ci.lb  ci.ub   ​  #>    0.185  0.085  2.185  0.029  0.019  0.350  *  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### Cook's distances for each observed outcome x <- cooks.distance(res) x #>            1            2            3            4            5            6            7  #> 1.965212e-03 2.989768e-03 2.638140e-03 3.873368e-03 1.954562e-04 2.049672e-02 1.172821e-03  #>            8            9           10           11           12           13           14  #> 3.913806e-03 3.646294e-03 3.850068e-04 4.111673e-04 5.636933e-03 8.697463e-03 6.052503e-04  #>           15           16           17           18           19           20           21  #> 4.759729e-03 1.527261e-05 9.905788e-05 2.095987e-03 2.978160e-03 1.173555e-04 7.600104e-05  #>           22           23           24           25           26           27           28  #> 7.315289e-05 4.966021e-04 2.024080e-05 6.448093e-04 3.866063e-04 1.220054e-04 2.886483e-04  #>           29           30           31           32           33           34           35  #> 7.676490e-08 1.391702e-06 6.193156e-02 2.406239e-02 6.513879e-02 2.075376e-05 8.763819e-07  #>           36           37           38           39           40           41           42  #> 3.485720e-05 1.141739e-04 6.503505e-06 5.671804e-05 8.326350e-05 1.048009e-04 3.320742e-03  #>           43           44           45           46           47           48           49  #> 6.412251e-03 3.831098e-05 3.937144e-03 1.780433e-03 1.374408e-03 2.479767e-02 2.281846e-02  #>           50           51           52           53           54           55           56  #> 2.803636e-04 3.453698e-03 1.101867e-02 1.405349e-04 1.257869e-02 1.606173e-03 4.733739e-03  plot(x, type=\"o\", pch=19, xlab=\"Observed Outcome\", ylab=\"Cook's Distance\")   ### Cook's distances for each district x <- cooks.distance(res, cluster=dat$district) x #>           11           12           18           27           56           58           71  #> 0.0693784140 0.0161880606 0.0419849759 0.1192089452 0.0213566370 0.1014506985 0.5585174853  #>           86           91          108          644  #> 0.0656500671 0.0037438517 0.0548839759 0.0003441647  plot(x, type=\"o\", pch=19, xlab=\"District\", ylab=\"Cook's Distance\", xaxt=\"n\") axis(side=1, at=seq_along(x), labels=as.numeric(names(x)))   ### hat values hatvalues(res) #>           1           2           3           4           5           6           7           8  #> 0.018246414 0.018246414 0.015562154 0.015562154 0.024305990 0.024305990 0.023796820 0.020021978  #>           9          10          11          12          13          14          15          16  #> 0.028628711 0.021068630 0.035668057 0.018288352 0.026253550 0.026253550 0.024271478 0.018700077  #>          17          18          19          20          21          22          23          24  #> 0.024347299 0.025637683 0.026335563 0.008149594 0.008470846 0.008307115 0.007851819 0.008149594  #>          25          26          27          28          29          30          31          32  #> 0.007997936 0.011094988 0.010815774 0.010815774 0.010815774 0.010815774 0.027875751 0.030425177  #>          33          34          35          36          37          38          39          40  #> 0.031137102 0.012900198 0.012900198 0.012900198 0.012900198 0.012900198 0.012900198 0.012900198  #>          41          42          43          44          45          46          47          48  #> 0.012900198 0.016836925 0.016451963 0.016836925 0.017240335 0.015732539 0.015732539 0.018231717  #>          49          50          51          52          53          54          55          56  #> 0.018231717 0.018522325 0.018522325 0.018522325 0.017484652 0.018246600 0.020990821 0.020990821"},{"path":"/reference/influence.rma.uni.html","id":null,"dir":"Reference","previous_headings":"","what":"Outlier and Influential Case Diagnostics for 'rma.uni' Objects — influence.rma.uni","title":"Outlier and Influential Case Diagnostics for 'rma.uni' Objects — influence.rma.uni","text":"functions can used compute various outlier influential case diagnostics (indicate influence deleting one case time model fit fitted/residual values) objects class \"rma.uni\". corresponding documentation \"rma.mv\" objects, see influence.rma.mv.","code":""},{"path":"/reference/influence.rma.uni.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Outlier and Influential Case Diagnostics for 'rma.uni' Objects — influence.rma.uni","text":"","code":"# S3 method for rma.uni influence(model, digits, progbar=FALSE, ...)  # S3 method for infl.rma.uni print(x, digits=x$digits, infonly=FALSE, ...)  # S3 method for rma.uni cooks.distance(model, progbar=FALSE, ...) # S3 method for rma.uni dfbetas(model, progbar=FALSE, ...) # S3 method for rma.uni hatvalues(model, type=\"diagonal\", ...)"},{"path":"/reference/influence.rma.uni.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Outlier and Influential Case Diagnostics for 'rma.uni' Objects — influence.rma.uni","text":"model object class \"rma.uni\". x object class \"infl.rma.uni\" (print). digits optional integer specify number decimal places printed results rounded. unspecified, default take value object. progbar logical specify whether progress bar shown (default FALSE). infonly logical specify whether influential cases printed (default FALSE). type character string specify whether diagonal hat matrix (\"diagonal\") entire hat matrix (\"matrix\") returned. ... arguments.","code":""},{"path":"/reference/influence.rma.uni.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Outlier and Influential Case Diagnostics for 'rma.uni' Objects — influence.rma.uni","text":"term ‘case’ refers particular row dataset used model fitting (typically synonymous study). influence function calculates following leave-one-diagnostics case: externally standardized residual, DFFITS value, Cook's distance, covariance ratio, leave-one-amount (residual) heterogeneity, leave-one-test statistic test (residual) heterogeneity, DFBETAS value(s). diagonal elements hat matrix weights (%) given observed effect sizes outcomes model fitting also provided (except scaling, hat values weights models without moderators, differ moderators included). details externally standardized residuals, see rstudent.rma.uni. DFFITS value essentially indicates many standard deviations predicted (average) effect outcome \\(\\textrm{th}\\) case changes excluding \\(\\textrm{th}\\) case model fitting. Cook's distance can interpreted Mahalanobis distance entire set predicted values \\(\\textrm{th}\\) case included \\(\\textrm{th}\\) case excluded model fitting. covariance ratio defined determinant variance-covariance matrix parameter estimates based dataset \\(\\textrm{th}\\) case removed divided determinant variance-covariance matrix parameter estimates based complete dataset. value 1 therefore indicates removal \\(\\textrm{th}\\) case yields precise estimates model coefficients. leave-one-amount (residual) heterogeneity estimated value \\(\\tau^2\\) based dataset \\(\\textrm{th}\\) case removed. always equal 0 equal-effects models. Similarly, leave-one-test statistic test (residual) heterogeneity value test statistic test (residual) heterogeneity calculated based dataset \\(\\textrm{th}\\) case removed. Finally, DFBETAS value(s) essentially indicate(s) many standard deviations estimated coefficient(s) change(s) excluding \\(\\textrm{th}\\) case model fitting. case may considered ‘influential’ least one following true: absolute DFFITS value larger \\(3 \\times \\sqrt{p/(k-p)}\\), \\(p\\) number model coefficients \\(k\\) number cases. lower tail area chi-square distribution \\(p\\) degrees freedom cut Cook's distance larger 50%. hat value larger \\(3 \\times (p/k)\\). DFBETAS value larger \\(1\\). Cases considered influential respect measures marked asterisk. Note chosen cut-offs (somewhat) arbitrary. Substantively informed judgment always used examining influence case results.","code":""},{"path":"/reference/influence.rma.uni.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Outlier and Influential Case Diagnostics for 'rma.uni' Objects — influence.rma.uni","text":"object class \"infl.rma.uni\", list containing following components: inf element class \"list.rma\" externally standardized residuals, DFFITS values, Cook's distances, covariance ratios, leave-one-\\(\\tau^2\\) estimates, leave-one-(residual) heterogeneity test statistics, hat values, weights, indicator whether case influential . dfbs element class \"list.rma\" DFBETAS values. ... additional elements/values. results printed print.infl.rma.uni plotted plot.infl.rma.uni.","code":""},{"path":"/reference/influence.rma.uni.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Outlier and Influential Case Diagnostics for 'rma.uni' Objects — influence.rma.uni","text":"Right now, leave-one-diagnostics calculated refitting model \\(k\\) times. Depending large \\(k\\) , may take moments finish calculations. shortcuts calculating least values without refitting model time, currently implemented (may exist leave-one-diagnostics calculated function). may possible fit model deletion \\(\\textrm{th}\\) case dataset. result NA values case. Certain relationships leave-one-diagnostics (internally externally) standardized residuals (Belsley, Kuh, & Welsch, 1980; Cook & Weisberg, 1982) longer hold meta-analytic models. Maybe relationships. remain determined.","code":""},{"path":"/reference/influence.rma.uni.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Outlier and Influential Case Diagnostics for 'rma.uni' Objects — influence.rma.uni","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/influence.rma.uni.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Outlier and Influential Case Diagnostics for 'rma.uni' Objects — influence.rma.uni","text":"Belsley, D. ., Kuh, E., & Welsch, R. E. (1980). Regression diagnostics. New York: Wiley. Cook, R. D., & Weisberg, S. (1982). Residuals influence regression. London: Chapman Hall. Hedges, L. V., & Olkin, . (1985). Statistical methods meta-analysis. San Diego, CA: Academic Press. Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03 Viechtbauer, W., & Cheung, M. W.-L. (2010). Outlier influence diagnostics meta-analysis. Research Synthesis Methods, 1(2), 112--125. https://doi.org/10.1002/jrsm.11","code":""},{"path":[]},{"path":"/reference/influence.rma.uni.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Outlier and Influential Case Diagnostics for 'rma.uni' Objects — influence.rma.uni","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit mixed-effects model with absolute latitude and publication year as moderators res <- rma(yi, vi, mods = ~ ablat + year, data=dat)  ### compute the diagnostics inf <- influence(res) inf #> $inf #>  #>    rstudent  dffits cook.d  cov.r tau2.del  QE.del    hat  weight inf  #> 1    0.2978  0.1785 0.0348 1.8003   0.1317 28.3142 0.1725  3.3664      #> 2   -0.4303 -0.2368 0.0620 1.9207   0.1308 27.5744 0.2367  4.8106      #> 3   -0.5100 -0.1094 0.0125 1.2348   0.1191 27.7572 0.0487  2.7920      #> 4   -1.4032 -2.9415 7.3179 3.5225   0.0906 23.1836 0.8082 11.2312   *  #> 5   -0.1490 -0.0263 0.0032 2.6341   0.1497 27.2543 0.2483  9.0681      #> 6    1.0551  0.8926 0.7205 1.3621   0.0994 21.2875 0.4061 12.4817      #> 7   -2.5961 -0.6815 0.4173 0.2379   0.0544 19.1240 0.0766  4.4008      #> 8    0.4793  0.3703 0.1899 2.9984   0.1498 24.1266 0.3627 12.8020      #> 9    0.2027  0.1305 0.0237 2.2071   0.1501 28.2874 0.1030  8.7848      #> 10  -0.9872 -0.3870 0.1470 1.0702   0.1072 24.7567 0.1310  7.9919      #> 11  -0.1197 -0.0030 0.0052 2.8336   0.1583 25.5103 0.2214 11.9238      #> 12   1.4677  0.2171 0.0469 0.9274   0.1059 26.1197 0.0235  2.2836      #> 13   2.1302  0.8150 0.4994 0.2178   0.0498 21.4920 0.1612  8.0630      #>  #> $dfbs #>  #>    intrcpt   ablat    year  #> 1   0.1492 -0.0622 -0.1491  #> 2  -0.0949 -0.1001  0.0963  #> 3  -0.0280 -0.0403  0.0283  #> 4   2.2248 -2.5380 -2.2161  #> 5   0.0350  0.0063 -0.0354  #> 6   0.5935 -0.0008 -0.5954  #> 7  -0.2659  0.5368  0.2591  #> 8  -0.0394 -0.2110  0.0431  #> 9   0.0728 -0.0865 -0.0718  #> 10 -0.1188 -0.0973  0.1194  #> 11  0.0631 -0.0343 -0.0631  #> 12 -0.0413  0.0465  0.0419  #> 13 -0.8276  0.6269  0.8279  #>   ### plot the values plot(inf)   ### compute Cook's distances, DFBETAS values, and hat values cooks.distance(res) #>           1           2           3           4           5           6           7           8  #> 0.034763870 0.061956371 0.012503192 7.317914072 0.003236974 0.720524896 0.417263935 0.189852980  #>           9          10          11          12          13  #> 0.023722929 0.146959603 0.005232795 0.046915399 0.499370065  dfbetas(res) #>  #>    intrcpt   ablat    year  #> 1   0.1492 -0.0622 -0.1491  #> 2  -0.0949 -0.1001  0.0963  #> 3  -0.0280 -0.0403  0.0283  #> 4   2.2248 -2.5380 -2.2161  #> 5   0.0350  0.0063 -0.0354  #> 6   0.5935 -0.0008 -0.5954  #> 7  -0.2659  0.5368  0.2591  #> 8  -0.0394 -0.2110  0.0431  #> 9   0.0728 -0.0865 -0.0718  #> 10 -0.1188 -0.0973  0.1194  #> 11  0.0631 -0.0343 -0.0631  #> 12 -0.0413  0.0465  0.0419  #> 13 -0.8276  0.6269  0.8279  #>  hatvalues(res) #>          1          2          3          4          5          6          7          8          9  #> 0.17250070 0.23668273 0.04870101 0.80821407 0.24826116 0.40606407 0.07657599 0.36274386 0.10304034  #>         10         11         12         13  #> 0.13102564 0.22140605 0.02353859 0.16124580"},{"path":"/reference/labbe.html","id":null,"dir":"Reference","previous_headings":"","what":"L'Abbe Plots for 'rma' Objects — labbe","title":"L'Abbe Plots for 'rma' Objects — labbe","text":"Function create L'Abbé plots objects class \"rma\".","code":""},{"path":"/reference/labbe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"L'Abbe Plots for 'rma' Objects — labbe","text":"","code":"labbe(x, ...)  # S3 method for rma labbe(x, xlim, ylim, xlab, ylab,       add=x$add, to=x$to, transf, targs,       pch=21, psize, plim=c(0.5,3.5),       col, bg, grid=FALSE, lty, ...)"},{"path":"/reference/labbe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"L'Abbe Plots for 'rma' Objects — labbe","text":"x object class \"rma\". See ‘Details’. xlim x-axis limits. unspecified, function tries set x-axis limits sensible values. ylim y-axis limits. unspecified, function tries set y-axis limits sensible values. xlab title x-axis. unspecified, function tries set appropriate axis title. ylab title y-axis. unspecified, function tries set appropriate axis title. add See ‘Details’ documentation escalc function details. See ‘Details’ documentation escalc function details. transf optional argument specify function used transform outcomes (e.g., transf=exp; see also transf). unspecified, transformation used. targs optional arguments needed function specified transf. pch plotting symbol use outcomes. default, filled circle used. Can also vector values. See points options. psize optional numeric vector specify point sizes outcomes. unspecified, point sizes function precision outcomes. Can also vector values. plim numeric vector length 2 scale point sizes (ignored psize specified). See ‘Details’. col optional character string specify name color use points (\"black\" used default specified). Can also vector color names. bg optional character string specify name background color open plot symbols (\"gray\" used default specified). Can also vector color names. Set NA make plotting symbols transparent. grid logical specify whether grid added plot (can also color name). lty optional character vector specify line type diagonal reference line effect line indicates estimated effect based fitted model. unspecified, function sets c(\"solid\",\"dashed\") default (use \"blank\" suppress line). ... arguments.","code":""},{"path":"/reference/labbe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"L'Abbe Plots for 'rma' Objects — labbe","text":"model specified via x must model without moderators (.e., either equal- random-effects model) fitted either rma.uni, rma.mh, rma.peto, rma.glmm functions. Moreover, model must fitted measure set equal \"RD\" (risk differences), \"RR\" (risk ratios), \"\" (odds ratios), \"\" (arcsine square root transformed risk differences), \"IRR\" (incidence rate ratios), \"IRD\" (incidence rate differences), \"IRSD\" (square root transformed incidence rate differences). function calculates arm-level outcomes two groups (e.g., treatment control) plots . particular, function plots raw proportions two groups analyzing risk differences, log proportions analyzing (log) risk ratios, log odds analyzing (log) odds ratios, arcsine square root transformed proportions analyzing arcsine square root transformed risk differences, raw incidence rates analyzing incidence rate differences, log incidence rates analyzing (log) incidence rate ratios, square root transformed incidence rates analyzing square root transformed incidence rate differences. transf argument can used transform values (e.g., transf=exp transform log proportions back raw proportions; see also transf). described documentation escalc function, zero cells can lead problems calculating particular outcomes. Adding small constant cells \\(2 \\times 2\\) tables common solution problem. default, functions adopts method handling zero cells used fitting model. default (.e., psize specified), point sizes function precision (.e., inverse standard errors) outcomes. way, precise estimates visually prominent plot. making point sizes function inverse standard errors estimates, areas proportional inverse sampling variances, corresponds weights receive equal-effects model. However, point sizes rescaled smallest point size plim[1] largest point size plim[2]. result, relative sizes (.e., areas) longer exactly correspond relative weights model. exactly relative point sizes desired, one can set plim[2] NA, case points rescaled smallest point size corresponds plim[1] points scaled accordingly. result, largest point may large. Alternatively, one can set plim[1] NA, case points rescaled largest point size corresponds plim[2] points scaled accordingly. solid line corresponds identical outcomes two groups (.e., absence difference two groups). dashed line indicates estimated effect based fitted model.","code":""},{"path":"/reference/labbe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"L'Abbe Plots for 'rma' Objects — labbe","text":"data frame components: x x-axis coordinates points plotted. y y-axis coordinates points plotted. cex point sizes. pch plotting symbols. col point colors. bg background colors. ids study id numbers. slab study labels. Note data frame returned invisibly.","code":""},{"path":"/reference/labbe.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"L'Abbe Plots for 'rma' Objects — labbe","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/labbe.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"L'Abbe Plots for 'rma' Objects — labbe","text":"L'Abbé, K. ., Detsky, . S., & O'Rourke, K. (1987). Meta-analysis clinical research. Annals Internal Medicine, 107(2), 224--233. https://doi.org/10.7326/0003-4819-107-2-224 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/labbe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"L'Abbe Plots for 'rma' Objects — labbe","text":"","code":"### meta-analysis of the log risk ratios using a random-effects model res <- rma(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### default plot labbe(res)   ### funnel plot with risk values on the x- and y-axis and add grid labbe(res, transf=exp, grid=TRUE)"},{"path":"/reference/leave1out.html","id":null,"dir":"Reference","previous_headings":"","what":"Leave-One-Out Diagnostics for 'rma' Objects — leave1out","title":"Leave-One-Out Diagnostics for 'rma' Objects — leave1out","text":"functions repeatedly fit specified model, leaving one observation/study time.","code":""},{"path":"/reference/leave1out.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Leave-One-Out Diagnostics for 'rma' Objects — leave1out","text":"","code":"leave1out(x, ...)  # S3 method for rma.uni leave1out(x, digits, transf, targs, progbar=FALSE, ...) # S3 method for rma.mh leave1out(x, digits, transf, targs, progbar=FALSE, ...) # S3 method for rma.peto leave1out(x, digits, transf, targs, progbar=FALSE, ...)"},{"path":"/reference/leave1out.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Leave-One-Out Diagnostics for 'rma' Objects — leave1out","text":"x object class \"rma.mh\", \"rma.peto\", \"rma.uni\". digits optional integer specify number decimal places printed results rounded. unspecified, default take value object. transf optional argument specify function used transform model coefficients interval bounds (e.g., transf=exp; see also transf). unspecified, transformation used. targs optional arguments needed function specified transf. progbar logical specify whether progress bar shown (default FALSE). ... arguments.","code":""},{"path":"/reference/leave1out.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Leave-One-Out Diagnostics for 'rma' Objects — leave1out","text":"\"rma.uni\" objects, model specified via x must model without moderators (.e., either equal- random-effects model).","code":""},{"path":"/reference/leave1out.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Leave-One-Out Diagnostics for 'rma' Objects — leave1out","text":"object class \"list.rma\". object list containing following components: estimate estimated (average) outcomes. se corresponding standard errors. zval corresponding test statistics. pval corresponding p-values. ci.lb lower bounds confidence intervals. ci.ub upper bounds confidence intervals. Q test statistics test heterogeneity. Qp corresponding p-values. tau2 estimated amount heterogeneity (random-effects models). I2 values \\(^2\\). H2 values \\(H^2\\). model fitted test=\"t\" test=\"knha\", zval called tval object returned function.    object formatted printed print function.","code":""},{"path":"/reference/leave1out.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Leave-One-Out Diagnostics for 'rma' Objects — leave1out","text":"using transf option, transformation applied estimated coefficients corresponding interval bounds. standard errors set equal NA omitted printed output.","code":""},{"path":"/reference/leave1out.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Leave-One-Out Diagnostics for 'rma' Objects — leave1out","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/leave1out.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Leave-One-Out Diagnostics for 'rma' Objects — leave1out","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03 Viechtbauer, W., & Cheung, M. W.-L. (2010). Outlier influence diagnostics meta-analysis. Research Synthesis Methods, 1(2), 112--125. https://doi.org/10.1002/jrsm.11","code":""},{"path":[]},{"path":"/reference/leave1out.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Leave-One-Out Diagnostics for 'rma' Objects — leave1out","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### random-effects model res <- rma(yi, vi, data=dat)  ### leave-one-out analysis leave1out(res) #>  #>    estimate     se    zval   pval   ci.lb   ci.ub        Q     Qp   tau2      I2      H2  #> 1   -0.7071 0.1900 -3.7223 0.0002 -1.0794 -0.3348 151.5826 0.0000 0.3362 93.2259 14.7622  #> 2   -0.6540 0.1807 -3.6195 0.0003 -1.0082 -0.2999 145.3176 0.0000 0.2926 92.2540 12.9098  #> 3   -0.6856 0.1857 -3.6916 0.0002 -1.0495 -0.3216 150.1970 0.0000 0.3207 92.9354 14.1551  #> 4   -0.6284 0.1766 -3.5580 0.0004 -0.9746 -0.2822  96.5626 0.0000 0.2628 90.4125 10.4302  #> 5   -0.7642 0.1918 -3.9845 0.0001 -1.1401 -0.3883 151.3200 0.0000 0.3278 92.7634 13.8187  #> 6   -0.7109 0.2003 -3.5499 0.0004 -1.1034 -0.3184 128.1867 0.0000 0.3596 90.9118 11.0033  #> 7   -0.6552 0.1805 -3.6307 0.0003 -1.0090 -0.3015 145.8296 0.0000 0.2930 92.2777 12.9495  #> 8   -0.7948 0.1799 -4.4184 0.0000 -1.1473 -0.4422  67.9858 0.0000 0.2732 87.0314  7.7109  #> 9   -0.7412 0.1967 -3.7686 0.0002 -1.1267 -0.3557 152.2051 0.0000 0.3495 93.2133 14.7346  #> 10  -0.6530 0.1843 -3.5439 0.0004 -1.0142 -0.2919 139.8271 0.0000 0.2987 92.2322 12.8737  #> 11  -0.7579 0.1958 -3.8708 0.0001 -1.1416 -0.3741 151.4655 0.0000 0.3405 91.8110 12.2114  #> 12  -0.7598 0.1821 -4.1727 0.0000 -1.1167 -0.4029 150.7868 0.0000 0.3082 92.6782 13.6579  #> 13  -0.7775 0.1855 -4.1908 0.0000 -1.1412 -0.4139 149.7884 0.0000 0.3037 92.3444 13.0623  #>  leave1out(res, transf=exp) #>  #>    estimate    zval   pval  ci.lb  ci.ub        Q     Qp   tau2      I2      H2  #> 1    0.4931 -3.7223 0.0002 0.3398 0.7155 151.5826 0.0000 0.3362 93.2259 14.7622  #> 2    0.5199 -3.6195 0.0003 0.3649 0.7409 145.3176 0.0000 0.2926 92.2540 12.9098  #> 3    0.5038 -3.6916 0.0002 0.3501 0.7250 150.1970 0.0000 0.3207 92.9354 14.1551  #> 4    0.5334 -3.5580 0.0004 0.3774 0.7541  96.5626 0.0000 0.2628 90.4125 10.4302  #> 5    0.4657 -3.9845 0.0001 0.3198 0.6782 151.3200 0.0000 0.3278 92.7634 13.8187  #> 6    0.4912 -3.5499 0.0004 0.3318 0.7273 128.1867 0.0000 0.3596 90.9118 11.0033  #> 7    0.5193 -3.6307 0.0003 0.3646 0.7397 145.8296 0.0000 0.2930 92.2777 12.9495  #> 8    0.4517 -4.4184 0.0000 0.3175 0.6426  67.9858 0.0000 0.2732 87.0314  7.7109  #> 9    0.4765 -3.7686 0.0002 0.3241 0.7007 152.2051 0.0000 0.3495 93.2133 14.7346  #> 10   0.5205 -3.5439 0.0004 0.3627 0.7469 139.8271 0.0000 0.2987 92.2322 12.8737  #> 11   0.4687 -3.8708 0.0001 0.3193 0.6879 151.4655 0.0000 0.3405 91.8110 12.2114  #> 12   0.4678 -4.1727 0.0000 0.3274 0.6684 150.7868 0.0000 0.3082 92.6782 13.6579  #> 13   0.4595 -4.1908 0.0000 0.3194 0.6611 149.7884 0.0000 0.3037 92.3444 13.0623  #>   ### meta-analysis of the (log) risk ratios using the Mantel-Haenszel method res <- rma.mh(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### leave-one-out analysis leave1out(res) #>  #>    estimate     se     zval   pval   ci.lb   ci.ub        Q     Qp      I2      H2  #> 1   -0.4514 0.0394 -11.4462 0.0000 -0.5287 -0.3741 151.9153 0.0000 92.7591 13.8105  #> 2   -0.4410 0.0395 -11.1512 0.0000 -0.5185 -0.3635 145.5727 0.0000 92.4436 13.2339  #> 3   -0.4495 0.0394 -11.4001 0.0000 -0.5267 -0.3722 150.5130 0.0000 92.6917 13.6830  #> 4   -0.3392 0.0414  -8.1874 0.0000 -0.4205 -0.2580  96.5629 0.0000 88.6085  8.7784  #> 5   -0.4614 0.0400 -11.5474 0.0000 -0.5397 -0.3831 151.6611 0.0000 92.7470 13.7874  #> 6   -0.3666 0.0448  -8.1809 0.0000 -0.4544 -0.2788 129.2200 0.0000 91.4874 11.7473  #> 7   -0.4466 0.0395 -11.3046 0.0000 -0.5241 -0.3692 146.2134 0.0000 92.4767 13.2921  #> 8   -0.7758 0.0520 -14.9267 0.0000 -0.8777 -0.6739  68.3763 0.0000 83.9126  6.2160  #> 9   -0.4532 0.0399 -11.3633 0.0000 -0.5314 -0.3751 152.5497 0.0000 92.7892 13.8682  #> 10  -0.4278 0.0399 -10.7338 0.0000 -0.5059 -0.3497 140.0446 0.0000 92.1454 12.7313  #> 11  -0.4698 0.0421 -11.1706 0.0000 -0.5522 -0.3874 151.8140 0.0000 92.7543 13.8013  #> 12  -0.4566 0.0394 -11.5865 0.0000 -0.5338 -0.3794 151.1253 0.0000 92.7213 13.7387  #> 13  -0.4637 0.0398 -11.6542 0.0000 -0.5417 -0.3858 150.1246 0.0000 92.6728 13.6477  #>  leave1out(res, transf=exp) #>  #>    estimate     zval   pval  ci.lb  ci.ub        Q     Qp      I2      H2  #> 1    0.6367 -11.4462 0.0000 0.5894 0.6879 151.9153 0.0000 92.7591 13.8105  #> 2    0.6434 -11.1512 0.0000 0.5954 0.6952 145.5727 0.0000 92.4436 13.2339  #> 3    0.6380 -11.4001 0.0000 0.5905 0.6892 150.5130 0.0000 92.6917 13.6830  #> 4    0.7123  -8.1874 0.0000 0.6568 0.7726  96.5629 0.0000 88.6085  8.7784  #> 5    0.6304 -11.5474 0.0000 0.5829 0.6818 151.6611 0.0000 92.7470 13.7874  #> 6    0.6931  -8.1809 0.0000 0.6348 0.7567 129.2200 0.0000 91.4874 11.7473  #> 7    0.6398 -11.3046 0.0000 0.5921 0.6913 146.2134 0.0000 92.4767 13.2921  #> 8    0.4603 -14.9267 0.0000 0.4158 0.5097  68.3763 0.0000 83.9126  6.2160  #> 9    0.6356 -11.3633 0.0000 0.5878 0.6872 152.5497 0.0000 92.7892 13.8682  #> 10   0.6520 -10.7338 0.0000 0.6030 0.7049 140.0446 0.0000 92.1454 12.7313  #> 11   0.6251 -11.1706 0.0000 0.5757 0.6788 151.8140 0.0000 92.7543 13.8013  #> 12   0.6334 -11.5865 0.0000 0.5864 0.6843 151.1253 0.0000 92.7213 13.7387  #> 13   0.6289 -11.6542 0.0000 0.5817 0.6799 150.1246 0.0000 92.6728 13.6477  #>   ### meta-analysis of the (log) odds ratios using Peto's method res <- rma.peto(ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### leave-one-out analysis leave1out(res) #>  #>    estimate     se     zval   pval   ci.lb   ci.ub        Q     Qp      I2      H2  #> 1   -0.4722 0.0408 -11.5791 0.0000 -0.5521 -0.3923 167.2005 0.0000 93.4211 15.2000  #> 2   -0.4616 0.0409 -11.2751 0.0000 -0.5418 -0.3814 160.5154 0.0000 93.1471 14.5923  #> 3   -0.4702 0.0408 -11.5317 0.0000 -0.5501 -0.3903 165.7913 0.0000 93.3652 15.0719  #> 4   -0.3591 0.0435  -8.2533 0.0000 -0.4443 -0.2738 112.1274 0.0000 90.1897 10.1934  #> 5   -0.4832 0.0413 -11.6873 0.0000 -0.5642 -0.4021 166.3727 0.0000 93.3883 15.1248  #> 6   -0.3710 0.0451  -8.2328 0.0000 -0.4593 -0.2827 139.3918 0.0000 92.1086 12.6720  #> 7   -0.4660 0.0408 -11.4343 0.0000 -0.5459 -0.3861 158.6048 0.0000 93.0645 14.4186  #> 8   -0.8161 0.0531 -15.3842 0.0000 -0.9201 -0.7122  67.1837 0.0000 83.6270  6.1076  #> 9   -0.4747 0.0413 -11.4973 0.0000 -0.5557 -0.3938 167.7284 0.0000 93.4418 15.2480  #> 10  -0.4486 0.0413 -10.8488 0.0000 -0.5296 -0.3675 155.8992 0.0000 92.9442 14.1727  #> 11  -0.4911 0.0434 -11.3135 0.0000 -0.5762 -0.4060 166.5326 0.0000 93.3947 15.1393  #> 12  -0.4775 0.0407 -11.7236 0.0000 -0.5573 -0.3976 166.0703 0.0000 93.3763 15.0973  #> 13  -0.4853 0.0411 -11.7960 0.0000 -0.5659 -0.4046 164.7427 0.0000 93.3229 14.9766  #>  leave1out(res, transf=exp) #>  #>    estimate     zval   pval  ci.lb  ci.ub        Q     Qp      I2      H2  #> 1    0.6236 -11.5791 0.0000 0.5757 0.6755 167.2005 0.0000 93.4211 15.2000  #> 2    0.6303 -11.2751 0.0000 0.5817 0.6829 160.5154 0.0000 93.1471 14.5923  #> 3    0.6249 -11.5317 0.0000 0.5769 0.6769 165.7913 0.0000 93.3652 15.0719  #> 4    0.6983  -8.2533 0.0000 0.6413 0.7605 112.1274 0.0000 90.1897 10.1934  #> 5    0.6168 -11.6873 0.0000 0.5688 0.6689 166.3727 0.0000 93.3883 15.1248  #> 6    0.6900  -8.2328 0.0000 0.6317 0.7538 139.3918 0.0000 92.1086 12.6720  #> 7    0.6275 -11.4343 0.0000 0.5793 0.6797 158.6048 0.0000 93.0645 14.4186  #> 8    0.4421 -15.3842 0.0000 0.3985 0.4906  67.1837 0.0000 83.6270  6.1076  #> 9    0.6220 -11.4973 0.0000 0.5737 0.6745 167.7284 0.0000 93.4418 15.2480  #> 10   0.6385 -10.8488 0.0000 0.5888 0.6924 155.8992 0.0000 92.9442 14.1727  #> 11   0.6120 -11.3135 0.0000 0.5621 0.6663 166.5326 0.0000 93.3947 15.1393  #> 12   0.6204 -11.7236 0.0000 0.5728 0.6719 166.0703 0.0000 93.3763 15.0973  #> 13   0.6155 -11.7960 0.0000 0.5679 0.6672 164.7427 0.0000 93.3229 14.9766  #>"},{"path":"/reference/llplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Likelihood Plot of a Parameter Corresponding to an Effect Size or Outcome Measure — llplot","title":"Likelihood Plot of a Parameter Corresponding to an Effect Size or Outcome Measure — llplot","text":"Function plot likelihood certain parameter corresponding effect size outcome measure given study data.","code":""},{"path":"/reference/llplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Likelihood Plot of a Parameter Corresponding to an Effect Size or Outcome Measure — llplot","text":"","code":"llplot(measure, yi, vi, sei, ai, bi, ci, di, n1i, n2i, data, subset, drop00=TRUE,        xvals=1000, xlim, ylim, xlab, ylab, scale=TRUE,        lty, lwd, col, level=99.99, refline=0, ...)"},{"path":"/reference/llplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Likelihood Plot of a Parameter Corresponding to an Effect Size or Outcome Measure — llplot","text":"measure character string specify effect size outcome measure likelihoods calculated. See ‘Details’ possible options data specified. yi vector observed effect sizes outcomes. vi vector corresponding sampling variances. sei vector specify corresponding standard. ai vector specify \\(2 \\times 2\\) table frequencies (upper left cell). bi vector specify \\(2 \\times 2\\) table frequencies (upper right cell). ci vector specify \\(2 \\times 2\\) table frequencies (lower left cell). di vector specify \\(2 \\times 2\\) table frequencies (lower right cell). n1i vector specify group sizes row totals (first group/row). n2i vector specify group sizes row totals (second group/row). data optional data frame containing variables given arguments . subset optional (logical numeric) vector specify subset studies included plot. drop00 logical specify whether studies cases (cases) groups dropped. See ‘Details’. xvals integer specify many distinct values likelihood evaluated. xlim x-axis limits. unspecified, function tries set x-axis limits sensible values. ylim y-axis limits. unspecified, function tries set y-axis limits sensible values. xlab title x-axis. unspecified, function tries set appropriate axis title. ylab title y-axis. unspecified, function tries set appropriate axis title. scale logical specify whether likelihood values scaled, total area curve (approximately) equal 1. lty line types (either single value vector length \\(k\\)). unspecified, function sets line types according characteristics likelihood function. See ‘Details’. lwd line widths (either single value vector length \\(k\\)). unspecified, function sets widths according sampling variances (line thicker precise studies vice-versa). col line colors (either single value vector length \\(k\\)). unspecified, function uses various shades gray according sampling variances (darker shades used precise studies vice-versa). level numeric value 0 100 specify plotting limits likelihood line terms confidence interval (default 99.99). refline numeric value specify location vertical ‘reference’ line (default 0). line can suppressed setting argument NA. ... arguments.","code":""},{"path":"/reference/llplot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Likelihood Plot of a Parameter Corresponding to an Effect Size or Outcome Measure — llplot","text":"moment, function accepts measure=\"GEN\" measure=\"\". measure=\"GEN\", one must specify arguments yi observed effect sizes outcomes vi corresponding sampling variances (instead specifying vi, one can specify standard errors via sei argument). function plots likelihood true effect size outcome based normal sampling distribution observed outcome given yi variance given vi study. measure=\"\", one must specify arguments ai, bi, ci, di, denote cell frequencies \\(2 \\times 2\\) tables. Alternatively, one can specify ai, ci, n1i, n2i. See escalc function details. function plots likelihood true log odds ratio based non-central hypergeometric distribution \\(2 \\times 2\\) table. Since studies cases (cases) groups flat likelihood informative odds ratio, dropped default (.e., drop00=TRUE) hence drawn (drop00=FALSE, likelihood indicated dotted lines). studies single zero count, MLE odds ratio infinite likelihoods indicated dashed lines.","code":""},{"path":"/reference/llplot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Likelihood Plot of a Parameter Corresponding to an Effect Size or Outcome Measure — llplot","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/llplot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Likelihood Plot of a Parameter Corresponding to an Effect Size or Outcome Measure — llplot","text":"van Houwelingen, H. C., Zwinderman, K. H., & Stijnen, T. (1993). bivariate approach meta-analysis. Statistics Medicine, 12(24), 2273--2284. https://doi.org/10.1002/sim.4780122405 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/llplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Likelihood Plot of a Parameter Corresponding to an Effect Size or Outcome Measure — llplot","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### draw likelihoods llplot(measure=\"GEN\", yi=yi, vi=vi, data=dat, lwd=1, refline=NA, xlim=c(-3,2))   ### create plot (Figure 2 in van Houwelingen, Zwinderman, & Stijnen, 1993) llplot(measure=\"OR\", ai=b.xci, n1i=nci, ci=b.xti, n2i=nti, data=dat.collins1985a,        lwd=1, refline=NA, xlim=c(-4,4), drop00=FALSE) #> Warning: Studies with NAs omitted from plotting."},{"path":"/reference/matreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Regression Models based on Correlation and Covariance Matrices — matreg","title":"Fit Regression Models based on Correlation and Covariance Matrices — matreg","text":"Function fit regression models based correlation covariance matrices.","code":""},{"path":"/reference/matreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Regression Models based on Correlation and Covariance Matrices — matreg","text":"","code":"matreg(y, x, R, n, V, cov=FALSE, means, ztor=FALSE, nearpd=FALSE, level=95, digits, ...)"},{"path":"/reference/matreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Regression Models based on Correlation and Covariance Matrices — matreg","text":"y index outcome variable. x indices predictor variables. R correlation covariance matrix (lower triangular part including diagonal). n sample size based elements correlation/covariance matrix computed. V variance-covariance matrix lower triangular elements correlation/covariance matrix. Either V n specified, . See ‘Details’. cov logical specify whether R covariance matrix (default FALSE). means optional vector specify means variables (relevant cov=TRUE). ztor logical specify whether R matrix r--z transformed correlations back-transformed raw correlations (default FALSE). See ‘Details’. nearpd logical specify whether nearPD function Matrix package used \\(R_{x,x}\\) matrix inverted. See ‘Note’. level numeric value 0 100 specify confidence interval level (default 95). digits optional integer specify number decimal places printed results rounded. ... arguments.","code":""},{"path":"/reference/matreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit Regression Models based on Correlation and Covariance Matrices — matreg","text":"Let \\(R\\) \\(p \\times p\\) correlation covariance matrix. Let \\(y\\) denote row/column outcome variable \\(x\\) row(s)/column(s) predictor variable(s) matrix. Let \\(R_{x,x}\\) \\(R_{x,y}\\) denote corresponding submatrices \\(R\\). \\[b = R_{x,x}^{-1} R_{x,y}\\] yields standardized raw regression coefficients (depending whether \\(R\\) correlation covariance matrix, respectively) regressing outcome variable predictor variable(s). \\(R\\) matrix may computed based single sample \\(n\\) subjects. case, one specify sample size via argument n. variance-covariance matrix standardized regression coefficients given \\(\\mbox{Var}[b] = \\mbox{MSE} \\times R_{x,x}^{-1}\\), \\(\\mbox{MSE} = (1 - b'R_{x,y}) / (n - m)\\) \\(m\\) denotes number predictor variables. standard errors regression coefficients given square root diagonal elements \\(\\mbox{Var}[b]\\). Test statistics (case, t-statistics) corresponding p-values can computed regular regression analysis. \\(R\\) covariance matrix, one set cov=TRUE specify means \\(p\\) variables via argument means obtain raw regression coefficients including intercept corresponding standard errors. Alternatively, \\(R\\) may result meta-analysis correlation coefficients. case, elements \\(R\\) pooled correlation coefficients variance-covariance matrix pooled coefficients specified via argument V. order elements V correspond order elements lower triangular part \\(R\\) column-wise. example, \\(R\\) \\(4 \\times 4\\) matrix form: \\[\\begin{bmatrix} 1 & & & \\\\ r_{21} & 1 & & \\\\ r_{31} & r_{32} & 1 & \\\\ r_{41} & r_{42} & r_{43} & 1 \\end{bmatrix}\\] elements \\(r_{21}\\), \\(r_{31}\\), \\(r_{41}\\), \\(r_{32}\\), \\(r_{42}\\), \\(r_{43}\\) hence V \\(6 \\times 6\\) variance-covariance matrix elements order. variance-covariance matrix standardized regression coefficients (.e., \\(\\mbox{Var}[b]\\)) computed function V described Becker (1992) using multivariate delta method. standard errors standardized regression coefficients given square root diagonal elements \\(\\mbox{Var}[b]\\). Test statistics (case, z-statistics) corresponding p-values can computed usual manner. case \\(R\\) result meta-analysis Fisher r--z transformed correlation coefficients (hence V corresponding variance-covariance matrix pooled transformed coefficients), one set argument ztor=TRUE, appropriate back-transformation applied R (V) within function. Finally, \\(R\\) may covariance matrix based meta-analysis (e.g., estimated variance-covariance matrix random effects multivariate model). case, one set cov=TRUE V variance-covariance matrix elements \\(R\\), now including diagonal. Hence, \\(R\\) \\(4 \\times 4\\) matrix form: \\[\\begin{bmatrix} \\tau_1^2 & & & \\\\ \\tau_{21} & \\tau_2^2 & & \\\\ \\tau_{31} & \\tau_{32} & \\tau_3^2 & \\\\ \\tau_{41} & \\tau_{42} & \\tau_{43} & \\tau_4^2 \\end{bmatrix}\\] elements \\(\\tau^2_1\\), \\(\\tau_{21}\\), \\(\\tau_{31}\\), \\(\\tau_{41}\\), \\(\\tau^2_2\\), \\(\\tau_{32}\\), \\(\\tau_{42}\\), \\(\\tau^2_3\\), \\(\\tau_{43}\\), \\(\\tau^2_4\\), hence V \\(10 \\times 10\\) variance-covariance matrix elements order. Argument means can used specify means variables.","code":""},{"path":"/reference/matreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Regression Models based on Correlation and Covariance Matrices — matreg","text":"object class \"matreg\". object list containing following components: tab data frame estimated model coefficients, standard errors, test statistics, degrees freedom (t-tests), p-values, lower/upper confidence interval bounds. vb variance-covariance matrix estimated model coefficients. ... additional elements/values. results formatted printed print function.","code":""},{"path":"/reference/matreg.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Fit Regression Models based on Correlation and Covariance Matrices — matreg","text":"lower triangular part R (V specified) used computations. \\(R_{x,x}\\) invertible, error issued. case, one can set argument nearpd=TRUE, case nearPD function Matrix package used find nearest positive semi-definite matrix, invertible. results treated caution done. \\(R\\) covariance matrix V means specified, means treated known constants estimating standard error intercept.","code":""},{"path":"/reference/matreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fit Regression Models based on Correlation and Covariance Matrices — matreg","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/matreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit Regression Models based on Correlation and Covariance Matrices — matreg","text":"Becker, B. J. (1992). Using results replicated studies estimate linear models. Journal Educational Statistics, 17(4), 341--362. https://doi.org/10.3102/10769986017004341 Becker, B. J. (1995). Corrections \"Using results replicated studies estimate linear models\". Journal Educational Behavioral Statistics, 20(1), 100--102. https://doi.org/10.3102/10769986020001100","code":""},{"path":[]},{"path":"/reference/matreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Regression Models based on Correlation and Covariance Matrices — matreg","text":"","code":"### copy data into 'dat' dat <- dat.craft2003  ### construct dataset and var-cov matrix of the correlations tmp <- rcalc(ri ~ var1 + var2 | study, ni=ni, data=dat) V <- tmp$V dat <- tmp$dat  ### turn var1.var2 into a factor with the desired order of levels dat$var1.var2 <- factor(dat$var1.var2,    levels=c(\"acog.perf\", \"asom.perf\", \"conf.perf\", \"acog.asom\", \"acog.conf\", \"asom.conf\"))  ### multivariate random-effects model res <- rma.mv(yi, V, mods = ~ var1.var2 - 1, random = ~ var1.var2 | study, struct=\"UN\", data=dat) #> Warning: Rows with NAs omitted from model fitting. res #>  #> Multivariate Meta-Analysis Model (k = 51; method: REML) #>  #> Variance Components: #>  #> outer factor: study     (nlvls = 9) #> inner factor: var1.var2 (nlvls = 6) #>  #>             estim    sqrt  k.lvl  fixed      level  #> tau^2.1    0.1611  0.4014      9     no  acog.perf  #> tau^2.2    0.0604  0.2459      9     no  asom.perf  #> tau^2.3    0.0468  0.2163      8     no  conf.perf  #> tau^2.4    0.0047  0.0683      9     no  acog.asom  #> tau^2.5    0.0125  0.1119      8     no  acog.conf  #> tau^2.6    0.0111  0.1052      8     no  asom.conf  #>  #>            rho.acg.p  rho.asm.p  rho.cnf.  rho.acg.s  rho.acg.c  rho.asm.c    acg.p  asm.p  cnf.  #> acog.perf          1                                                              -      9     8  #> asom.perf     0.9497          1                                                  no      -     8  #> conf.perf    -0.6178    -0.5969         1                                        no     no     -  #> acog.asom     0.5491     0.4604   -0.9345          1                             no     no    no  #> acog.conf     0.0432    -0.0495    0.7023    -0.6961          1                  no     no    no  #> asom.conf     0.3532     0.2688   -0.1311    -0.0891     0.4193          1       no     no    no  #>            acg.s  acg.c  asm.c  #> acog.perf      9      8      8  #> asom.perf      9      8      8  #> conf.perf      8      8      8  #> acog.asom      -      8      8  #> acog.conf     no      -      8  #> asom.conf     no     no      -  #>  #> Test for Residual Heterogeneity: #> QE(df = 45) = 334.8358, p-val < .0001 #>  #> Test of Moderators (coefficients 1:6): #> QM(df = 6) = 596.7711, p-val < .0001 #>  #> Model Results: #>  #>                     estimate      se     zval    pval    ci.lb    ci.ub     ​  #> var1.var2acog.perf   -0.0600  0.1408  -0.4264  0.6698  -0.3359   0.2159       #> var1.var2asom.perf   -0.1423  0.0917  -1.5527  0.1205  -0.3220   0.0373       #> var1.var2conf.perf    0.3167  0.0847   3.7393  0.0002   0.1507   0.4827  ***  #> var1.var2acog.asom    0.5671  0.0367  15.4640  <.0001   0.4953   0.6390  ***  #> var1.var2acog.conf   -0.4888  0.0509  -9.6048  <.0001  -0.5886  -0.3891  ***  #> var1.var2asom.conf   -0.4750  0.0506  -9.3901  <.0001  -0.5741  -0.3758  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### restructure estimated mean correlations into a 4x4 matrix R <- vec2mat(coef(res)) rownames(R) <- colnames(R) <- c(\"perf\", \"acog\", \"asom\", \"conf\") round(R, digits=3) #>        perf   acog   asom   conf #> perf  1.000 -0.060 -0.142  0.317 #> acog -0.060  1.000  0.567 -0.489 #> asom -0.142  0.567  1.000 -0.475 #> conf  0.317 -0.489 -0.475  1.000  ### check that order in vcov(res) corresponds to order in R round(vcov(res), digits=4) #>                    var1.var2acog.perf var1.var2asom.perf var1.var2conf.perf var1.var2acog.asom #> var1.var2acog.perf             0.0198             0.0115            -0.0069             0.0017 #> var1.var2asom.perf             0.0115             0.0084            -0.0043             0.0009 #> var1.var2conf.perf            -0.0069            -0.0043             0.0072            -0.0017 #> var1.var2acog.asom             0.0017             0.0009            -0.0017             0.0013 #> var1.var2acog.conf             0.0004            -0.0002             0.0023            -0.0009 #> var1.var2asom.conf             0.0018             0.0010            -0.0004            -0.0004 #>                    var1.var2acog.conf var1.var2asom.conf #> var1.var2acog.perf             0.0004             0.0018 #> var1.var2asom.perf            -0.0002             0.0010 #> var1.var2conf.perf             0.0023            -0.0004 #> var1.var2acog.asom            -0.0009            -0.0004 #> var1.var2acog.conf             0.0026             0.0011 #> var1.var2asom.conf             0.0011             0.0026  ### fit regression model with 'perf' as outcome and 'acog', 'asom', and 'conf' as predictors fit <- matreg(1, 2:4, R=R, V=vcov(res)) fit #>  #>       estimate      se     zval    pval    ci.lb   ci.ub     ​  #> acog    0.1482  0.1566   0.9465  0.3439  -0.1587  0.4550       #> asom   -0.0536  0.0768  -0.6979  0.4852  -0.2043  0.0970       #> conf    0.3637  0.0910   3.9985  <.0001   0.1854  0.5419  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   # \\dontrun{ ### repeat the above but with r-to-z transformed correlations dat <- dat.craft2003 tmp <- rcalc(ri ~ var1 + var2 | study, ni=ni, data=dat, rtoz=TRUE) V <- tmp$V dat <- tmp$dat dat$var1.var2 <- factor(dat$var1.var2,    levels=c(\"acog.perf\", \"asom.perf\", \"conf.perf\", \"acog.asom\", \"acog.conf\", \"asom.conf\")) res <- rma.mv(yi, V, mods = ~ var1.var2 - 1, random = ~ var1.var2 | study, struct=\"UN\", data=dat) #> Warning: Rows with NAs omitted from model fitting. R <- vec2mat(coef(res)) rownames(R) <- colnames(R) <- c(\"perf\", \"acog\", \"asom\", \"conf\") fit <- matreg(1, 2:4, R=R, V=vcov(res), ztor=TRUE) fit# } #>  #>       estimate      se     zval    pval    ci.lb   ci.ub     ​  #> acog    0.1362  0.1697   0.8023  0.4224  -0.1965  0.4688       #> asom   -0.0678  0.0761  -0.8900  0.3735  -0.2170  0.0814       #> conf    0.3666  0.0934   3.9248  <.0001   0.1835  0.5496  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### a different example based on van Houwelingen et al. (2002)  ### create dataset in long format dat.long <- to.long(measure=\"OR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.colditz1994) dat.long <- escalc(measure=\"PLO\", xi=out1, mi=out2, data=dat.long) dat.long$tpos <- dat.long$tneg <- dat.long$cpos <- dat.long$cneg <- NULL levels(dat.long$group) <- c(\"CON\", \"EXP\")  ### fit bivariate model res <- rma.mv(yi, vi, mods = ~ group - 1, random = ~ group | trial, struct=\"UN\",               data=dat.long, method=\"ML\") res #>  #> Multivariate Meta-Analysis Model (k = 26; method: ML) #>  #> Variance Components: #>  #> outer factor: trial (nlvls = 13) #> inner factor: group (nlvls = 2) #>  #>             estim    sqrt  k.lvl  fixed  level  #> tau^2.1    2.4073  1.5516     13     no    CON  #> tau^2.2    1.4314  1.1964     13     no    EXP  #>  #>      rho.CON  rho.EXP    CON  EXP  #> CON        1               -   13  #> EXP   0.9467        1     no    -  #>  #> Test for Residual Heterogeneity: #> QE(df = 24) = 5270.3863, p-val < .0001 #>  #> Test of Moderators (coefficients 1:2): #> QM(df = 2) = 292.4633, p-val < .0001 #>  #> Model Results: #>  #>           estimate      se      zval    pval    ci.lb    ci.ub     ​  #> groupCON   -4.0960  0.4347   -9.4226  <.0001  -4.9480  -3.2440  ***  #> groupEXP   -4.8337  0.3396  -14.2329  <.0001  -5.4994  -4.1681  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### regression of log(odds)_EXP on log(odds)_CON reg <- matreg(y=2, x=1, R=res$G, cov=TRUE, means=coef(res), n=res$g.levels.comb.k) reg #>  #>          estimate      se     tval  df    pval    ci.lb    ci.ub     ​  #> intrcpt   -1.8437  0.3265  -5.6477  11  0.0001  -2.5623  -1.1252  ***  #> CON        0.7300  0.0749   9.7467  11  <.0001   0.5651   0.8948  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### but the SE of the CON coefficient is not computed correctly, since above we treat res$G as if ### it was a var-cov matrix computed from raw data based on res$g.levels.comb.k (= 13) data points  ### fit bivariate model and get the var-cov matrix of the estimates in res$G res <- rma.mv(yi, vi, mods = ~ group - 1, random = ~ group | trial, struct=\"UN\",               data=dat.long, method=\"ML\", cvvc=\"varcov\", control=list(nearpd=TRUE))  ### now use res$vvc as the var-cov matrix of the estimates in res$G matreg(y=2, x=1, R=res$G, cov=TRUE, means=coef(res), V=res$vvc) #>  #>          estimate      se     zval    pval    ci.lb    ci.ub     ​  #> intrcpt   -1.8437  0.3548  -5.1967  <.0001  -2.5391  -1.1484  ***  #> CON        0.7300  0.0866   8.4276  <.0001   0.5602   0.8998  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>"},{"path":"/reference/metafor-package.html","id":null,"dir":"Reference","previous_headings":"","what":"metafor: A Meta-Analysis Package for R  — metafor-package","title":"metafor: A Meta-Analysis Package for R  — metafor-package","text":"metafor package provides comprehensive collection functions conducting meta-analyses R. package can used calculate various effect size outcome measures allows user fit equal-, fixed-, random-effects models data. including study-level variables (‘moderators’) predictors models, (mixed-effects) meta-regression models can also fitted. meta-analyses \\(2 \\times 2\\) tables, proportions, incidence rates, incidence rate ratios, package also provides functions implement specialized methods, including Mantel-Haenszel method, Peto's method, variety suitable generalized linear mixed-effects models (.e., mixed-effects logistic Poisson regression models). non-independent effects/outcomes (e.g., due correlated sampling errors, correlated true effects outcomes, forms clustering), package also provides function fitting multilevel multivariate models meta-analytic data. Various methods available assess model fit, identify outliers /influential studies, conducting sensitivity analyses (e.g., standardized residuals, Cook's distances, leave-one-analyses). Advanced techniques hypothesis testing obtaining confidence intervals (e.g., average effect outcome model coefficients meta-regression model) also implemented (e.g., Knapp Hartung method, permutation tests, cluster robust inference methods / robust variance estimation). package also provides functions creating forest, funnel, radial (Galbraith), normal quantile-quantile, L'Abbé, Baujat, bubble, GOSH plots. presence publication bias (precisely, funnel plot asymmetry ‘small-study effects’) potential impact results can examined via rank correlation Egger's regression test, trim fill method, test excess significance, applying variety selection models.","code":""},{"path":[]},{"path":"/reference/metafor-package.html","id":"the-escalc-function","dir":"Reference","previous_headings":"","what":"The escalc Function","title":"metafor: A Meta-Analysis Package for R  — metafor-package","text":"[escalc] meta-analysis can conducted, relevant results study must quantified way resulting values can aggregated compared. escalc function can used compute wide variety effect size outcome measures (corresponding sampling variances) often used meta-analyses (e.g., risk ratios, odds ratios, risk differences, mean differences, standardized mean differences, response ratios / ratios means, raw r--z transformed correlation coefficients). Measures quantifying characteristic individual groups (e.g., terms means, proportions, incidence rates transformations thereof), measures change (e.g., raw standardized mean changes), measures variability (e.g., variability ratios coefficient variation ratios) also available.","code":""},{"path":"/reference/metafor-package.html","id":"the-rma-uni-function","dir":"Reference","previous_headings":"","what":"The rma.uni Function","title":"metafor: A Meta-Analysis Package for R  — metafor-package","text":"[rma.uni] various meta-analytic models typically used practice special cases general linear (mixed-effects) model. rma.uni function (alias rma) provides general framework fitting models. function can used combination effect size outcome measures computed escalc function , generally, set estimates (corresponding sampling variances standard errors) one like analyze. notation models underlying rma.uni function explained . set \\(= 1, \\ldots, k\\) independent studies, let \\(y_i\\) denote observed value effect size outcome measure \\(\\textrm{th}\\) study. Let \\(\\theta_i\\) denote corresponding (unknown) true effect/outcome, \\[y_i | \\theta_i \\sim N(\\theta_i, v_i).\\] words, observed effect sizes outcomes assumed unbiased normally distributed estimates corresponding true effects/outcomes sampling variances equal \\(v_i\\) (\\(v_i\\) just square standard errors estimates). \\(v_i\\) values assumed known. Depending outcome measure used, bias correction, normalizing, /variance stabilizing transformation may necessary ensure assumptions (least approximately) true (e.g., log transformation odds/risk ratios, bias correction standardized mean differences, Fisher's r--z transformation correlations; see escalc details). According random-effects model, assume \\(\\theta_i \\sim N(\\mu, \\tau^2)\\), , true effects/outcomes normally distributed \\(\\mu\\) denoting average true effect/outcome \\(\\tau^2\\) variance true effects/outcomes (\\(\\tau^2\\) therefore often referred amount ‘heterogeneity’ true effects/outcomes). random-effects model can also written \\[y_i = \\mu + u_i + \\epsilon_i,\\] \\(u_i \\sim N(0, \\tau^2)\\) \\(\\epsilon_i \\sim N(0, v_i)\\). fitted model provides estimates \\(\\mu\\) \\(\\tau^2\\), , \\[\\hat{\\mu} = \\frac{\\sum_{=1}^k w_i y_i}{\\sum_{=1}^k w_i},\\] \\(w_i = 1/(\\hat{\\tau}^2 + v_i)\\) \\(\\hat{\\tau}^2\\) denotes estimate \\(\\tau^2\\) obtained one many estimators described literature purpose (standard ‘inverse-variance’ method random-effects models). special case model equal-effects model (also sometimes called common-effects model) arises \\(\\tau^2 = 0\\). case, true effects/outcomes homogeneous (.e., \\(\\theta_1 = \\theta_2 = \\ldots = \\theta_k \\equiv \\theta\\)) hence can write model \\[y_i = \\theta + \\epsilon_i,\\] \\(\\theta\\) denotes true effect/outcome studies, estimated \\[\\hat{\\theta} = \\frac{\\sum_{=1}^k w_i y_i}{\\sum_{=1}^k w_i},\\] \\(w_i = 1/v_i\\) (, standard ‘inverse-variance’ method described meta-analytic literature). Note commonly-used term ‘fixed-effects model’ used -- explanation, see . Study-level variables (often referred ‘moderators’) can also included predictors meta-analytic models, leading -called ‘meta-regression’ analyses (examine whether effects/outcomes tend larger/smaller certain conditions circumstances). including moderator variables random-effects model, obtain mixed-effects meta-regression model. model can written \\[y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\ldots + \\beta_{p'} x_{ip'} + u_i + \\epsilon_i,\\] \\(u_i \\sim N(0, \\tau^2)\\) \\(\\epsilon_i \\sim N(0, v_i)\\) \\(x_{ij}\\) denotes value \\(j\\textrm{th}\\) moderator variable \\(\\textrm{th}\\) study (letting \\(p = p' + 1\\) denote total number coefficients model including model intercept). Therefore, \\(\\beta_j\\) denotes average true effect/outcome changes one-unit increase \\(x_{ij}\\) model intercept \\(\\beta_0\\) denotes average true effect/outcome values moderator variables equal zero. value \\(\\tau^2\\) mixed-effects model denotes amount ‘residual heterogeneity’ true effects/outcomes (.e., amount variability true effects/outcomes accounted moderators included model).","code":""},{"path":"/reference/metafor-package.html","id":"the-rma-mh-function","dir":"Reference","previous_headings":"","what":"The rma.mh Function","title":"metafor: A Meta-Analysis Package for R  — metafor-package","text":"[rma.mh] Mantel-Haenszel method provides alternative approach fitting equal-effects models dealing studies providing data form \\(2 \\times 2\\) tables form event counts (.e., person-time data) two groups (Mantel & Haenszel, 1959). method particularly advantageous aggregating large number studies small sample sizes (-called sparse data increasing strata case). Mantel-Haenszel method implemented rma.mh function. can used combination risk ratios, odds ratios, risk differences, incidence rate ratios, incidence rate differences.","code":""},{"path":"/reference/metafor-package.html","id":"the-rma-peto-function","dir":"Reference","previous_headings":"","what":"The rma.peto Function","title":"metafor: A Meta-Analysis Package for R  — metafor-package","text":"[rma.peto] Yet another method can used context meta-analysis \\(2 \\times 2\\) table data Peto's method (see Yusuf et al., 1985), implemented rma.peto function. method provides estimate (log) odds ratio equal-effects model. method particularly advantageous event interest rare, see documentation function caveats.","code":""},{"path":"/reference/metafor-package.html","id":"the-rma-glmm-function","dir":"Reference","previous_headings":"","what":"The rma.glmm Function","title":"metafor: A Meta-Analysis Package for R  — metafor-package","text":"[rma.glmm] Dichotomous outcomes event counts (based one can calculate outcome measures odds ratios, incidence rate ratios, proportions, incidence rates) often assumed arise binomial Poisson distributed data. Meta-analytic models directly based distributions implemented rma.glmm function. models essentially special cases generalized linear mixed-effects models (.e., mixed-effects logistic Poisson regression models). \\(2 \\times 2\\) table data, mixed-effects conditional logistic model (based non-central hypergeometric distribution) also available. Random/mixed-effects models dichotomous data often referred ‘binomial-normal’ models meta-analytic literature. Analogously, event count data, models referred ‘Poisson-normal’ models.","code":""},{"path":"/reference/metafor-package.html","id":"the-rma-mv-function","dir":"Reference","previous_headings":"","what":"The rma.mv Function","title":"metafor: A Meta-Analysis Package for R  — metafor-package","text":"[rma.mv] Standard meta-analytic models assume independence observed effect sizes outcomes obtained set studies. assumption often violated practice. Dependencies can arise variety reasons. example, sampling errors /true effects/outcomes may correlated multiple treatment studies (e.g., multiple treatment groups compared common control/reference group, data control/reference group used multiple times compute observed effect sizes outcomes) multiple endpoint studies (e.g., one effect size estimate outcome calculated based sample subjects due use multiple endpoints response variables). Correlations true effects/outcomes can also arise due forms clustering (e.g., multiple effects/outcomes derived author, lab, research group may similar effects/outcomes derived different authors, labs, research groups). ecology related fields, shared phylogenetic history among organisms studied (e.g., plants, fungi, animals) can also induce correlations among effects/outcomes. rma.mv function can used fit suitable meta-analytic multivariate/multilevel models data, non-independence effects/outcomes accounted . Network meta-analyses (also called multiple/mixed treatment comparisons) can also carried function.","code":""},{"path":"/reference/metafor-package.html","id":"future-plans-and-updates","dir":"Reference","previous_headings":"","what":"Future Plans and Updates","title":"metafor: A Meta-Analysis Package for R  — metafor-package","text":"metafor package work progress updated regular basis new functions options. metafor.news(), can read NEWS file package installation. Comments, feedback, suggestions improvements always welcome.","code":""},{"path":"/reference/metafor-package.html","id":"citing-the-package","dir":"Reference","previous_headings":"","what":"Citing the Package","title":"metafor: A Meta-Analysis Package for R  — metafor-package","text":"cite package, please use following reference: Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1-48. doi: 10.18637/jss.v036.i03","code":""},{"path":"/reference/metafor-package.html","id":"getting-started-with-the-package","dir":"Reference","previous_headings":"","what":"Getting Started with the Package","title":"metafor: A Meta-Analysis Package for R  — metafor-package","text":"paper mentioned good starting place interested using package. purpose article provide general overview package capabilities (version 1.4-0). functions options described paper, provide useful introduction package. paper can freely downloaded URL given can directly loaded command vignette(\"metafor\"). addition reading paper, carefully read page help pages escalc rma.uni functions (rma.mh, rma.peto, rma.glmm, /rma.mv functions intend use methods). help pages functions provide links many additional functions, can used fitting model. can also read entire documentation online https://wviechtb.github.io/metafor/ (nicely formatted output examples provided). (pdf) diagram showing various functions metafor package (related ) can opened command vignette(\"diagram\"). Finally, additional information package, several detailed analysis examples, examples plots figures provided package (corresponding code), additional tips notes, FAQ can found package website https://www.metafor-project.org.","code":""},{"path":"/reference/metafor-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"metafor: A Meta-Analysis Package for R  — metafor-package","text":"Wolfgang Viechtbauer wvb@metafor-project.org     package website: https://www.metafor-project.org     author homepage: https://www.wvbauer.com Suggestions obtain help using package can found package website : https://www.metafor-project.org/doku.php/help","code":""},{"path":"/reference/metafor-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"metafor: A Meta-Analysis Package for R  — metafor-package","text":"Cooper, H., Hedges, L. V., & Valentine, J. C. (Eds.) (2009). handbook research synthesis meta-analysis (2nd ed.). New York: Russell Sage Foundation. Hedges, L. V., & Olkin, . (1985). Statistical methods meta-analysis. San Diego, CA: Academic Press. Mantel, N., & Haenszel, W. (1959). Statistical aspects analysis data retrospective studies disease. Journal National Cancer Institute, 22(4), 719--748. https://doi.org/10.1093/jnci/22.4.719 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03 Yusuf, S., Peto, R., Lewis, J., Collins, R., & Sleight, P. (1985). Beta blockade myocardial infarction: overview randomized trials. Progress Cardiovascular Disease, 27(5), 335--371. https://doi.org/10.1016/s0033-0620(85)80003-7","code":""},{"path":"/reference/metafor.news.html","id":null,"dir":"Reference","previous_headings":"","what":"Read News File of the Metafor Package — metafor.news","title":"Read News File of the Metafor Package — metafor.news","text":"Read news file metafor-package.","code":""},{"path":"/reference/metafor.news.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read News File of the Metafor Package — metafor.news","text":"","code":"metafor.news()"},{"path":"/reference/metafor.news.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read News File of the Metafor Package — metafor.news","text":"function just wrapper news(package=\"metafor\") parses displays NEWS file package.","code":""},{"path":"/reference/metafor.news.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Read News File of the Metafor Package — metafor.news","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/metafor.news.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Read News File of the Metafor Package — metafor.news","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":"/reference/metafor.news.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read News File of the Metafor Package — metafor.news","text":"","code":"# \\dontrun{ metafor.news()# } #>                  Changes in version 3.1-36 (2021-11-30)                  #>  #>   - added misc-models and misc-options help pages #>  #>   - simplified regtest(), ranktest(), and tes() to single functions #>     instead of using generics and methods; this way, a data argument #>     could be added #>  #>   - added vcalc() and blsplit() functions #>  #>   - robust() gains clubSandwich argument; if set to TRUE, the methods #>     from the clubSandwich package #>     (https://cran.r-project.org/package=clubSandwich) are used to obtain #>     the cluster-robust results #>  #>   - results from robust() are no longer printed with print.robust.rma() #>     but with the print methods print.rma.uni() and print.rma.mv() #>  #>   - anova() now gives a warning when running LRTs not based on ML/REML #>     estimation #>  #>   - setting dfs=\"contain\" in rma.mv() automatically sets test=\"t\" #>  #>   - elements of rho and phi in rma.mv() are now based on the lower #>     triangular part of the respective correlation matrix (instead of the #>     upper triangular part) for consistency with other functions; note #>     that this is in principle a backwards incompatible change, although #>     this should only be a concern in very special circumstances #>  #>   - rma.mv() gains cvvc argument (for calculating the var-cov matrix of #>     the variance/correlation/covariance components) #>  #>   - added measure \"MPORM\" to escalc() for computing marginal log odds #>     ratios based on marginal 2x2 tables directly (which requires #>     specification of the correlation coefficients in the paired tables #>     for the calculation of the sampling variances via the ri argument) #>  #>   - aggregate.escalc() gains checkpd argument and struct=\"CS+CAR\" #>  #>   - rma.glmm() now has entire array of optimizers available for #>     model=\"CM.EL\" and measure=\"OR\"; switched the default from optim() #>     with method BFGS to nlminb() for consistency with rma.mv(), #>     rma.uni(), and selmodel.rma.uni() #>  #>   - rma.glmm() gains coding and cor arguments and hence more flexibility #>     how the group variable should be coded in the random effects #>     structure and whether the random study effects should be allowed to #>     be correlated with the random group effects #>  #>   - rma.uni() now also provides R^2 for fixed-effects models #>  #>   - matreg() can now also analyze a covariance matrix with a #>     corresponding V matrix #>  #>   - renamed argument nearPD to nearpd in matreg() (but nearPD continues #>     to work) #>  #>   - plot.profile.rma() gains refline argument #>  #>   - addpoly.default() and addpoly.rma() gain lty argument #>  #>   - fixed that level argument in addpoly.rma() did not affect the CI #>     width #>  #>   - points.regplot() function now also redraws the labels (if there were #>     any to begin with) #>  #>   - added lbfgsb3c, subplex, and BBoptim as possible optimizer in #>     rma.mv(), rma.glmm(), rma.uni(), and selmodel.rma.uni() #>  #>   - datasets moved to the metadat package #>     (https://cran.r-project.org/package=metadat) #>  #>   - improved the documentation a bit #>  #>                  Changes in version 3.0-2 (2021-06-09)                   #>  #>   - the metafor package now makes use of the mathjaxr package to nicely #>     render equations shown in the HTML help pages #>  #>   - rma() can now also fit location-scale models #>  #>   - added selmodel() for fitting a wide variety of selection models (and #>     added the corresponding plot.rma.uni.selmodel() function for drawing #>     the estimated selection function) #>  #>   - rma.mv() gains dfs argument and now provides an often better way for #>     calculating the (denominator) degrees of freedom for approximate t- #>     and F-tests when dfs=\"contain\" #>  #>   - added tes() function for the test of excess significance #>  #>   - added regplot() function for drawing scatter plots / bubble plots #>     based on meta-regression models #>  #>   - added rcalc() for calculating the variance-covariance matrix of #>     correlation coefficients and matreg() for fitting regression models #>     based on correlation/covariance matrices #>  #>   - added convenience functions dfround() and vec2mat() #>  #>   - added aggregate.escalc() function to aggregate multiple effect sizes #>     or outcomes within studies/clusters #>  #>   - regtest() now shows the 'limit estimate' of the (average) true #>     effect when using sei, vi, ninv, or sqrtninv as predictors (and the #>     model does not contain any other moderators) #>  #>   - vif() gains btt argument and can now also compute generalized #>     variance inflation factors; a proper print.vif.rma() function was #>     also added #>  #>   - anova.rma() argument L renamed to X (the former still works, but is #>     no longer documented) #>  #>   - argument order in cumul() should now just be a variable, not the #>     order of the variable, to be used for ordering the studies and must #>     be of the same length as the original dataset that was used in the #>     model fitting #>  #>   - similarly, vector arguments in various plotting functions such as #>     forest.rma() must now be of the same length as the original dataset #>     that was used in the model fitting (any subsetting and removal of #>     NAs is automatically applied) #>  #>   - the various leave1out() and cumul() functions now provide I^2 and #>     H^2 also for fixed-effects models; accordingly, plot.cumul.rma() now #>     also works with such models #>  #>   - fixed level not getting passed down to the various cumul() functions #>  #>   - plot.cumul.rma() argument addgrid renamed to grid (the former still #>     works, but is no longer documented) #>  #>   - forest.default(), forest.rma(), and labbe() gain plim argument and #>     now provide more flexibility in terms of the scaling of the points #>  #>   - forest.rma() gains colout argument (to adjust the color of the #>     observed effect sizes or outcomes) #>  #>   - in the various forest() functions, the right header is now #>     suppressed when annotate=FALSE and header=TRUE #>  #>   - funnel.default() and funnel.rma() gain label and offset arguments #>  #>   - funnel.default() and funnel.rma() gain lty argument; the reference #>     line is now drawn by default as a dotted line (like the line for the #>     pseudo confidence region) #>  #>   - the forest and funnel arguments of reporter.rma.uni() can now also #>     be logicals to suppress the drawing of these plots #>  #>   - added weighted argument to fsn() (for Orwin's method) #>  #>   - added some more transformation functions #>  #>   - bldiag() now properly handles ?x0 or 0x? matrices #>  #>   - p-values are still given to 2 digits even when digits=1 #>  #>   - summary.escalc() also provides the p-values (of the Wald-type #>     tests); but when using the transf argument, the sampling variances, #>     standard errors, test statistics, and p-values are no longer shown #>  #>   - rma.uni() no longer constrains a fixed tau^2 value to 0 when k=1 #>  #>   - slight speedup in functions that repeatedly fit rma.uni() models by #>     skipping the computation of the pseudo R^2 statistic #>  #>   - started using the pbapply package for showing progress bars, also #>     when using parallel processing #>  #>   - to avoid potential confusion, all references to 'credibility #>     intervals' have been removed from the documentation; these intervals #>     are now exclusively referred to as 'prediction intervals'; in the #>     output, the bounds are therefore indicated now as pi.lb and pi.ub #>     (instead of cr.lb and cr.ub); the corresponding argument names were #>     changed in addpoly.default(); argument addcred was changed to #>     addpred in addpoly.rma() and forest.rma(); however, code using the #>     old arguments names should continue to work #>  #>   - one can now use weights(..., type=\"rowsum\") for intercept-only #>     rma.mv models (to obtain 'row-sum weights') #>  #>   - simulate.rma() gains olim argument; renamed the clim argument in #>     summary.escalc() and the various forest() functions to olim for #>     consistency (the old clim argument should continue to work) #>  #>   - show nicer network graphs for dat.hasselblad1998 and dat.senn2013 in #>     the help files #>  #>   - added 24 datasets (dat.anand1999, dat.assink2016, #>     dat.baskerville2012, dat.bornmann2007, dat.cannon2006, #>     dat.cohen1981, dat.craft2003, dat.crede2010, dat.dagostino1998, #>     dat.damico2009, dat.dorn2007, dat.hahn2001, dat.kalaian1996, #>     dat.kearon1998, dat.knapp2017, dat.landenberger2005, dat.lau1992, #>     dat.lim2014, dat.lopez2019, dat.maire2019, , dat.moura2021 #>     dat.obrien2003, dat.vanhowe1999, dat.viechtbauer2021) #>  #>   - the package now runs a version check on startup in interactive #>     sessions; setting the environment variable METAFOR_VERSION_CHECK to #>     FALSE disables this #>  #>   - refactored various functions (for cleaner/simpler code) #>  #>   - improved the documentation a bit #>  #>                  Changes in version 2.4-0 (2020-03-19)                   #>  #>   - version jump to 2.4-0 for CRAN release (from now on, even minor #>     numbers for CRAN releases, odd numbers for development versions) #>  #>   - the various forest() functions gain header argument #>  #>   - escalc() gains include argument #>  #>   - setting verbose=3 in model fitting functions sets options(warn=1) #>  #>   - forest.rma() and forest.default() now throw informative errors when #>     misusing order and subset arguments #>  #>   - fixed failing tests due to the stringsAsFactors=FALSE change in the #>     upcoming version of R #>  #>   - print.infl.rma.uni() gains infonly argument, to only show the #>     influential studies #>  #>   - removed MASS from Suggests (no longer needed) #>  #>   - argument btt can now also take a string to grep for #>  #>   - added optimParallel as possible optimizer in rma.mv() #>  #>   - added (for now undocumented) option to fit models in rma.glmm() via #>     the GLMMadaptive package (instead of lme4); to try this, use: #>     control=list(package=\"GLMMadaptive\") #>  #>   - started to use numbering scheme for devel version (the number after #>     the dash indicates the devel version) #>  #>   - added contrmat() function (for creating a matrix that indicates #>     which groups have been compared against each other in each row of a #>     dataset) #>  #>   - added to.wide() function (for restructuring long format datasets #>     into the wide format needed for contrast-based analyses) #>  #>   - I^2 and H^2 are also shown in output for fixed-effects models #>  #>   - argument grid in baujat() can now also be a color name #>  #>   - added (for now undocumented) time argument to more functions that #>     are computationally expensive #>  #>   - added (for now undocumented) textpos argument to the various forest #>     functions #>  #>   - added a new dataset (dat.graves2010) #>  #>   - added more tests #>  #>                  Changes in version 2.1-0 (2019-05-13)                   #>  #>   - added formula() method for objects of class rma #>  #>   - llplot() now also allows for measure=\"GEN\"; also, the documentation #>     and y-axis label have been corrected to indicate that the function #>     plots likelihoods (not log likelihoods) #>  #>   - confint.rma.mv() now returns an object of class list.confint.rma #>     when obtaining CIs for all variance and correlation components of #>     the model; added corresponding print.list.confint.rma() function #>  #>   - moved tol argument in permutest() to control and renamed to comptol #>  #>   - added PMM and GENQM estimators in rma.uni() #>  #>   - added vif() function to get variance inflation factors #>  #>   - added .glmulti object for making the interaction with glmulti easier #>  #>   - added reporter() and reporter.rma.uni() for dynamically generating #>     analysis reports for objects of class rma.uni #>  #>   - output is now styled/colored when crayon package is loaded (this #>     only works on a 'proper' terminal with color support; also works in #>     RStudio) #>  #>   - overhauled plot.gosh.rma(); when out is specified, it now shows two #>     distributions, one for the values when the outlier is included and #>     one for the values when for outlier is excluded; dropped the hcol #>     argument and added border argument #>  #>   - refactored influence.rma.uni() to be more consistent internally with #>     other functions; print.infl.rma.uni() and plot.infl.rma.uni() #>     adjusted accordingly; functions cooks.distance.rma.uni(), #>     dfbetas.rma.uni(), and rstudent.rma.uni() now call #>     influence.rma.uni() for the computations #>  #>   - rstudent.rma.uni() now computes the SE of the deleted residuals in #>     such a way that it will yield identical results to a mean shift #>     outlier model even when that model is fitted with test=\"knha\" #>  #>   - rstandard.rma.uni() gains type argument, and can now also compute #>     conditional residuals (it still computes marginal residuals by #>     default) #>  #>   - cooks.distance.rma.mv() gains cluster argument, so that the Cook's #>     distances can be computed for groups of estimates #>  #>   - cooks.distance.rma.mv() gains parallel, ncpus, and cl arguments and #>     can now make use of parallel processing #>  #>   - cooks.distance.rma.mv() should be faster by using the estimates from #>     the full model as starting values when fitting the models with the #>     ith study/cluster deleted from the dataset #>  #>   - cooks.distance.rma.mv() gains reestimate argument; when set to #>     FALSE, variance/correlation components are not reestimated #>  #>   - rstandard.rma.mv() gains cluster argument for computing #>     cluster-level multivariate standardized residuals #>  #>   - added rstudent.rma.mv() and dfbetas.rma.mv() #>  #>   - smarter matching of elements in newmods (when using a named vector) #>     in predict() that also works for models with interactions (thanks to #>     Nicole Erler for pointing out the problem) #>  #>   - rma.uni() and rma.mv() no longer issue (obvious) warnings when user #>     constrains vi or V to 0 (i.e., vi=0 or V=0, respectively) #>  #>   - rma.mv() does more intelligent filtering based on NAs in V matrix #>  #>   - rma.mv() now ensures strict symmetry of any (var-cov or correlation) #>     matrices specified via the R argument #>  #>   - fixed rma.mv() so checks on R argument run as intended; also fixed #>     an issue when multiple formulas with slashes are specified via #>     random (thanks to Andrew Loignon for pointing out the problem) #>  #>   - suppressed showing calls on some warnings/errors in rma.mv() #>  #>   - rma.mv() now allows for a continuous-time autoregressive random #>     effects structure (struct=\"CAR\") and various spatial correlation #>     structures (struct=\"SPEXP\", \"SPGAU\", \"SPLIN\", \"SPRAT\", and \"SPSPH\") #>  #>   - rma.mv() now allows for struct=\"GEN\" which models correlated random #>     effects for any number of predictors, including continuous ones #>     (i.e., this allows for 'random slopes') #>  #>   - in the various forest() functions, when options(na.action=\"na.pass\") #>     or options(na.action=\"na.exclude\") and an annotation contains NA, #>     this is now shown as a blank (instead of NA [NA, NA]) #>  #>   - the various forest() and addpoly() functions gain a fonts argument #>  #>   - the various forest() functions gain a top argument #>  #>   - the various forest() functions now show correct point sizes when the #>     weights of the studies are exactly the same #>  #>   - forest.cumul.rma() gains a col argument #>  #>   - funnel.default() and funnel.rma() can now take vectors as input for #>     the col and bg arguments (and also for pch); both functions also #>     gain a legend argument #>  #>   - addpoly() functions can now also show prediction interval bounds #>  #>   - removed 'formula interface' from escalc(); until this actually adds #>     some kind of extra functionality, this just makes escalc() more #>     confusing to use #>  #>   - escalc() can now compute the coefficient of variation ratio and the #>     variability ratio for pre-post or matched designs (\"CVRC\", \"VRC\") #>  #>   - escalc() does a bit more housekeeping #>  #>   - added (currently undocumented) arguments onlyo1, addyi, and addvi to #>     escalc() that allow for more flexibility when computing certain bias #>     corrections and when computing sampling variances for measures that #>     make use of the add and to arguments #>  #>   - escalc() now sets add=0 for measures where the use of such a bias #>     correction makes little sense; this applies to the following #>     measures: \"AS\", \"PHI\", \"RTET\", \"IRSD\", \"PAS\", \"PFT\", \"IRS\", and #>     \"IRFT\"; one can still force the use of the bias correction by #>     explicitly setting the add argument to some non-zero value #>  #>   - added clim argument to summary.escalc() #>  #>   - added ilim argument to trimfill() #>  #>   - labbe() gains lty argument #>  #>   - labbe() now (invisibly) returns a data frame with the coordinates of #>     the points that were drawn (which may be useful for manual labeling #>     of points in the plot) #>  #>   - added a print method for profile.rma objects #>  #>   - profile.rma.mv() now check whether any of the profiled #>     log-likelihood values is larger than the log-likelihood of the #>     fitted model (using numerical tolerance given by lltol) and issues a #>     warning if so #>  #>   - profile.rma.uni(), profile.rma.mv(), and plot.profile.rma() gain #>     cline argument; plot.profile.rma() gains xlim, ylab, and main #>     arguments #>  #>   - fixed an issue with robust.rma.mv() when the model was fitted with #>     sparse=TRUE (thanks to Roger Martineau for noting the problem) #>  #>   - various method functions (fitted(), resid(), predict(), etc.) behave #>     in a more consistent manner when model omitted studies with missings #>  #>   - predict.rma() gains vcov argument; when set to TRUE, the #>     variance-covariance matrix of the predicted values is also returned #>  #>   - vcov.rma() can now also return the variance-covariance matrix of the #>     fitted values (type=\"fitted\") and the residuals (type=\"resid\") #>  #>   - added $<- and as.matrix() methods for list.rma objects #>  #>   - fixed error in simulate.rma() that would generate too many samples #>     for rma.mv models #>  #>   - added undocumented argument time to all model fitting functions; if #>     set to TRUE, the model fitting time is printed #>  #>   - added more tests (also for parallel operations); also, all tests #>     updated to use proper tolerances instead of rounding #>  #>   - reorganized the documentation a bit #>  #>                  Changes in version 2.0-0 (2017-06-22)                   #>  #>   - added simulate() method for rma objects; added MASS to Suggests #>     (since simulating for rma.mv objects requires mvrnorm() from MASS) #>  #>   - cooks.distance.rma.mv() now works properly even when there are #>     missing values in the data #>  #>   - residuals() gains type argument and can compute Pearson residuals #>  #>   - the newmods argument in predict() can now be a named vector or a #>     matrix/data frame with column names that get properly matched up #>     with the variables in the model #>  #>   - added ranef.rma.mv() for extracting the BLUPs of the random effects #>     for rma.mv models #>  #>   - all functions that repeatedly refit models now have the option to #>     show a progress bar #>  #>   - added ranktest.default(), so user can now pass the outcomes and #>     corresponding sampling variances directly to the function #>  #>   - added regtest.default(), so user can now pass the outcomes and #>     corresponding sampling variances directly to the function #>  #>   - funnel.default() gains subset argument #>  #>   - funnel.default() and funnel.rma() gain col and bg arguments #>  #>   - plot.profile.rma() gains ylab argument #>  #>   - more consistent handling of robust.rma objects #>  #>   - added a print method for rma.gosh objects #>  #>   - the (log) relative risk is now called the (log) risk ratio in all #>     help files, plots, code, and comments #>  #>   - escalc() can now compute outcome measures based on paired binary #>     data (\"MPRR\", \"MPOR\", \"MPRD\", \"MPORC\", and \"MPPETO\") #>  #>   - escalc() can now compute (semi-)partial correlation coefficients #>     (\"PCOR\", \"ZPCOR\", \"SPCOR\") #>  #>   - escalc() can now compute measures of variability for single groups #>     (\"CVLN\", \"SDLN\") and for the difference in variability between two #>     groups (\"CVR\", \"VR\"); also the log transformed mean (\"MNLN\") has #>     been added for consistency #>  #>   - escalc() can now compute the sampling variance for measure=\"PHI\" for #>     studies using stratified sampling (vtpye=\"ST\") #>  #>   - the [ method for escalc objects now properly handles the ni and slab #>     attributes and does a better job of cleaning out superfluous #>     variable name information #>  #>   - added rbind() method for escalc objects #>  #>   - added as.data.frame() method for list.rma objects #>  #>   - added a new dataset (dat.pagliaro1992) for another illustration of a #>     network meta-analysis #>  #>   - added a new dataset (dat.laopaiboon2015) on the effectiveness of #>     azithromycin for treating lower respiratory tract infections #>  #>   - rma.uni() and rma.mv() now check if the ratio of the largest to #>     smallest sampling variance is very large; results may not be stable #>     then (and very large ratios typically indicate wrongly coded data) #>  #>   - model fitting functions now check if extra/superfluous arguments are #>     specified via ... and issues are warning if so #>  #>   - instead of defining own generic ranef(), import ranef() from nlme #>  #>   - improved output formatting #>  #>   - added more tests (but disabled a few tests on CRAN to avoid some #>     issues when R is compiled with --disable-long-double) #>  #>   - some general code cleanup #>  #>   - renamed diagram_metafor.pdf vignette to just diagram.pdf #>  #>   - minor updates in the documentation #>  #>                  Changes in version 1.9-9 (2016-09-25)                   #>  #>   - started to use git as version control system, GitHub to host the #>     repository (https://github.com/wviechtb/metafor) for the development #>     version of the package, Travis CI as continuous integration service #>     (https://travis-ci.org/wviechtb/metafor), and Codecov for automated #>     code coverage reporting (https://app.codecov.io/gh/wviechtb/metafor) #>  #>   - argument knha in rma.uni() and argument tdist in rma.glmm() and #>     rma.mv() are now superseded by argument test in all three functions; #>     for backwards compatibility, the knha and tdist arguments still #>     work, but are no longer documented #>  #>   - rma(yi, vi, weights=1, test=\"knha\") now yields the same results as #>     rma(yi, vi, weighted=FALSE, test=\"knha\") (but use of the Knapp and #>     Hartung method in the context of an unweighted analysis remains an #>     experimental feature) #>  #>   - one can now pass an escalc object directly to rma.uni(), which then #>     tries to automatically determine the yi and vi variables in the data #>     frame (thanks to Christian Roever for the suggestion) #>  #>   - escalc() can now also be used to convert a regular data frame to an #>     escalc object #>  #>   - for measure=\"UCOR\", the exact bias-correction is now used (instead #>     of the approximation); when vtype=\"UB\", the exact equation is now #>     used to compute the unbiased estimate of the variance of the #>     bias-corrected correlation coefficient; hence gsl is now a suggested #>     package (needed to compute the hypergeometric function) and is #>     loaded when required #>  #>   - cooks.distance() now also works with rma.mv objects; and since model #>     fitting can take some time, an option to show a progress bar has #>     been added #>  #>   - fixed an issue with robust.rma.mv() throwing errors when the model #>     was fitted with sparse=TRUE #>  #>   - fixed an error with robust.rma.mv() when the model was fitted with #>     user-defined weights (or a user-defined weight matrix) #>  #>   - added ranef() for extracting the BLUPs of the random effects (only #>     for rma.uni objects at the moment) #>  #>   - reverted back to the pre-1.1-0 way of computing p-values for #>     individual coefficients in permutest.rma.uni(), that is, the p-value #>     is computed with mean(abs(z_perm) >= abs(z_obs) - tol) (where tol is #>     a numerical tolerance) #>  #>   - permutest.rma.uni() gains permci argument, which can be used to #>     obtain permutation-based CIs of the model coefficients (note that #>     this is computationally very demanding and may take a long time to #>     complete) #>  #>   - rma.glmm() continues to work even when the saturated model cannot be #>     fitted (although the tests for heterogeneity are not available then) #>  #>   - rma.glmm() now allows control over the arguments used for #>     method.args (via control=list(hessianCtrl=list(...))) passed to #>     hessian() (from the numDeriv package) when using model=\"CM.EL\" and #>     measure=\"OR\" #>  #>   - in rma.glmm(), default method.args value for r passed to hessian() #>     has been increased to 16 (while this slows things down a bit, this #>     appears to improve the accuracy of the numerical approximation to #>     the Hessian, especially when tau^2 is close to 0) #>  #>   - the various forest() and addpoly() functions now have a new argument #>     called width, which provides manual control over the width of the #>     annotation columns; this is useful when creating complex forest #>     plots with a monospaced font and we want to ensure that all #>     annotations are properly lined up at the decimal point #>  #>   - the annotations created by the various forest() and addpoly() #>     functions are now a bit more compact by default #>  #>   - more flexible efac argument in the various forest() functions #>  #>   - trailing zeros in the axis labels are now dropped in forest and #>     funnel plots by default; but trailing zeros can be retained by #>     specifying a numeric (and not an integer) value for the digits #>     argument #>  #>   - added funnel.default(), which directly takes as input a vector with #>     the observed effect sizes or outcomes and the corresponding sampling #>     variances, standard errors, and/or sample sizes #>  #>   - added plot.profile.rma(), a plot method for objects returned by the #>     profile.rma.uni() and profile.rma.mv() functions #>  #>   - simplified baujat.rma.uni(), baujat.rma.mh(), and baujat.rma.peto() #>     to baujat.rma(), which now handles objects of class rma.uni, rma.mh, #>     and rma.peto #>  #>   - baujat.rma() gains argument symbol for more control over the #>     plotting symbol #>  #>   - labbe() gains a grid argument #>  #>   - more logical placement of labels in qqnorm.rma.uni(), #>     qqnorm.rma.mh(), and qqnorm.rma.peto() functions (and more control #>     thereof) #>  #>   - qqnorm.rma.uni() gains lty argument #>  #>   - added gosh.rma() and plot.gosh.rma() for creating GOSH (i.e., #>     graphical display of study heterogeneity) plots based on Olkin et #>     al. (2012) #>  #>   - in the (rare) case where all observed outcomes are exactly equal to #>     each other, test=\"knha\" (i.e., knha=TRUE) in rma() now leads to more #>     appropriate results #>  #>   - updated datasets so those containing precomputed effect size #>     estimates or observed outcomes are already declared to be escalc #>     objects #>  #>   - added new datasets (dat.egger2001 and dat.li2007) on the #>     effectiveness of intravenous magnesium in acute myocardial #>     infarction #>  #>   - methods package is now under Depends (in addition to Matrix), so #>     that rma.mv(..., sparse=TRUE) always works, even under Rscript #>  #>   - some general code cleanup #>  #>   - added more tests (and used a more consistent naming scheme for #>     tests) #>  #>                  Changes in version 1.9-8 (2015-09-28)                   #>  #>   - due to more stringent package testing, it is increasingly difficult #>     to ensure that the package passes all checks on older versions of R; #>     from now on, the package will therefore require, and be checked #>     under, only the current (and the development) version of R #>  #>   - added graphics, grDevices, and methods to Imports (due to recent #>     change in how CRAN checks packages) #>  #>   - the struct argument for rma.mv() now also allows for \"ID\" and #>     \"DIAG\", which are identical to the \"CS\" and \"HCS\" structures, but #>     with the correlation parameter fixed to 0 #>  #>   - added robust() for (cluster) robust tests and confidence intervals #>     for rma.uni and rma.mv models (this uses a robust sandwich-type #>     estimator of the variance-covariance matrix of the fixed effects #>     along the lines of the Eicker-Huber-White method) #>  #>   - confint() now works for models fitted with the rma.mv() function; #>     for variance and correlation parameters, the function provides #>     profile likelihood confidence intervals; the output generated by the #>     confint() function has been adjusted in general to make the #>     formatting more consistent across the different model types #>  #>   - for objects of class rma.mv, profile() now provides profile plots #>     for all (non-fixed) variance and correlation components of the model #>     when no component is specified by the user (via the sigma2, tau2, #>     rho, gamma2, or phi arguments) #>  #>   - for measure=\"MD\" and measure=\"ROM\", one can now choose between #>     vtype=\"LS\" (the default) and vtype=\"HO\"; the former computes the #>     sampling variances without assuming homoscedasticity, while the #>     latter assumes homoscedasticity #>  #>   - multiple model objects can now be passed to the fitstats(), AIC(), #>     and BIC() functions #>  #>   - check for duplicates in the slab argument is now done after any #>     subsetting is done (as suggested by Michael Dewey) #>  #>   - rma.glmm() now again works when using add=0, in which case some of #>     the observed outcomes (e.g., log odds or log odds ratios) may be NA #>  #>   - when using rma.glmm() with model=\"CM.EL\", the saturated model (used #>     to compute the Wald-type and likelihood ratio tests for the presence #>     of (residual) heterogeneity) often fails to converge; the function #>     now continues to run (instead of stopping with an error) and simply #>     omits the test results from the output #>  #>   - when using rma.glmm() with model=\"CM.EL\" and inversion of the #>     Hessian fails via the Choleski factorization, the function now makes #>     another attempt via the QR decomposition (even when this works, a #>     warning is issued) #>  #>   - for rma.glmm(), BIC and AICc values were switched around; corrected #>  #>   - more use of suppressWarnings() is made when functions repeatedly #>     need to fit the same model, such as cumul(), influence(), and #>     profile(); that way, one does not get inundated with the same #>     warning(s) #>  #>   - some (overdue) updates to the documentation #>  #>                  Changes in version 1.9-7 (2015-05-22)                   #>  #>   - default optimizer for rma.mv() changed to nlminb() (instead of #>     optim() with \"Nelder-Mead\"); extensive testing indicated that #>     nlminb() (and also optim() with \"BFGS\") is typically quicker and #>     more robust; note that this is in principle a non-backwards #>     compatible change, but really a necessary one; and you can always #>     revert to the old behavior with control=list(optimizer=\"optim\", #>     optmethod=\"Nelder-Mead\") #>  #>   - all tests have been updated in accordance with the recommended #>     syntax of the testthat package; for example, expect_equivalent(x,y) #>     is used instead of test_that(x, is_equivalent_to(y)) #>  #>   - changed a few is_identical_to() comparisons to expect_equivalent() #>     ones (that failed on Sparc Solaris) #>  #>                  Changes in version 1.9-6 (2015-05-07)                   #>  #>   - funnel() now works again for rma.glmm objects (note to self: quit #>     breaking things that work!) #>  #>   - rma.glmm() will now only issue a warning (and not an error) when the #>     Hessian for the saturated model cannot be inverted (which is needed #>     to compute the Wald-type test for heterogeneity, so the test #>     statistic is then simply set to NA) #>  #>   - rma.mv() now allows for two terms of the form ~ inner | outer; the #>     variance components corresponding to such a structure are called #>     gamma2 and correlations are called phi; other functions that work #>     with objects of class rma.mv have been updated accordingly #>  #>   - rma.mv() now provides (even) more optimizer choices: nlm() from the #>     stats package, hjk() and nmk() from the dfoptim package, and #>     ucminf() from the ucminf package; choose the desired optimizer via #>     the control argument (e.g., control=list(optimizer=\"nlm\")) #>  #>   - profile.rma.uni() and profile.rma.mv() now can do parallel #>     processing (which is especially relevant for rma.mv objects, where #>     profiling is crucial and model fitting can be slow) #>  #>   - the various confint() functions now have a transf argument (to apply #>     some kind of transformation to the model coefficients and confidence #>     interval bounds); coefficients and bounds for objects of class #>     rma.mh and rma.peto are no longer automatically transformed #>  #>   - the various forest() functions no longer enforce that the actual #>     x-axis limits (alim) encompass the observed outcomes to be plotted; #>     also, outcomes below or above the actual x-axis limits are no longer #>     shown #>  #>   - the various forest() functions now provide control over the #>     horizontal lines (at the top/bottom) that are automatically added to #>     the plot via the lty argument (this also allows for removing them); #>     also, the vertical reference line is now placed behind the #>     points/CIs #>  #>   - forest.default() now has argument col which can be used to specify #>     the color(s) to be used for drawing the study labels, points, CIs, #>     and annotations #>  #>   - the efac argument for forest.rma() now also allows two values, the #>     first for the arrows and CI limits, the second for summary estimates #>  #>   - corrected some axis labels in various plots when measure=\"PLO\" #>  #>   - axes in labbe() plots now have \"(Group 1)\" and \"(Group 2)\" added by #>     default #>  #>   - anova.rma() gains argument L for specifying linear combinations of #>     the coefficients in the model that should be tested to be zero #>  #>   - in case removal of a row of data would lead to one or more #>     inestimable model coefficients, baujat(), cooks.distance(), #>     dfbetas(), influence(), and rstudent() could fail for rma.uni #>     objects; such cases are now handled properly #>  #>   - for models with moderators, the predict() function now shows the #>     study labels when they have been specified by the user (and newmods #>     is not used) #>  #>   - if there is only one fixed effect (model coefficient) in the model, #>     the print.infl.rma.uni() function now shows the DFBETAS values with #>     the other case diagnostics in a single table (for easier #>     inspection); if there is more than one fixed effect, a separate #>     table is still used for the DFBETAS values (with one column for each #>     coefficient) #>  #>   - added measure=\"SMCRH\" to the escalc() function for the standardized #>     mean change using raw score standardization with heteroscedastic #>     population variances at the two measurement occasions #>  #>   - added measure=\"ROMC\" to the escalc() function for the (log #>     transformed) ratio of means (response ratio) when the means reflect #>     two measurement occasions (e.g., for a single group of people) and #>     hence are correlated #>  #>   - added own function for computing/estimating the tetrachoric #>     correlation coefficient (for measure=\"RTET\"); package therefore no #>     longer suggests polycor but now suggest mvtnorm (which is loaded as #>     needed) #>  #>   - element fill returned by trimfill.rma.uni() is now a logical vector #>     (instead of a 0/1 dummy variable) #>  #>   - print.list.rma() now also returns the printed results invisibly as a #>     data frame #>  #>   - added a new dataset (dat.senn2013) as another illustration of a #>     network meta-analysis #>  #>   - metafor now depends on at least version 3.1.0 of R #>  #>                  Changes in version 1.9-5 (2014-11-24)                   #>  #>   - moved the stats and Matrix packages from Depends to Imports; as a #>     result, had to add utils to Imports; moved the Formula package from #>     Depends to Suggests #>  #>   - added update.rma() function (for updating/refitting a model); model #>     objects also now store and keep the call #>  #>   - the vcov() function now also extracts the marginal #>     variance-covariance matrix of the observed effect sizes or outcomes #>     from a fitted model (of class rma.uni or rma.mv) #>  #>   - rma.mv() now makes use of the Cholesky decomposition when there is a #>     random = ~ inner | outer formula and struct=\"UN\"; this is #>     numerically more stable than the old approach that avoided #>     non-positive definite solutions by forcing the log-likelihood to be #>     -Inf in those cases; the old behavior can be restored with control = #>     list(cholesky=FALSE) #>  #>   - rma.mv() now requires the inner variable in an ~ inner | outer #>     formula to be a factor or character variable (except when struct is #>     \"AR\" or \"HAR\"); use ~ factor(inner) | outer in case it isn't #>  #>   - anova.rma.uni() function changed to anova.rma() that works now for #>     both rma.uni and rma.mv objects #>  #>   - the profile.rma.mv() function now omits the number of the variance #>     or correlation component from the plot title and x-axis label when #>     the model only includes one of the respective parameters #>  #>   - profile() functions now pass on the ... argument also to the title() #>     function used to create the figure titles (esp. relevant when using #>     the cex.main argument) #>  #>   - the drop00 argument of the rma.mh() and rma.peto() functions now #>     also accepts a vector with two logicals, the first applies when #>     calculating the observed outcomes, the second when applying the #>     Mantel-Haenszel or Peto's method #>  #>   - weights.rma.uni() now shows the correct weights when weighted=FALSE #>  #>   - argument showweight renamed to showweights in the forest.default() #>     and forest.rma() functions (more consistent with the naming of the #>     various weights() functions) #>  #>   - added model.matrix.rma() function (to extract the model matrix from #>     objects of class rma) #>  #>   - funnel() and radial() now (invisibly) return data frames with the #>     coordinates of the points that were drawn (may be useful for manual #>     labeling of points in the plots) #>  #>   - permutest.rma.uni() function now uses a numerical tolerance when #>     making comparisons (>= or <=) between an observed test statistic and #>     the test statistic under the permuted data; when using random #>     permutations, the function now ensures that the very first #>     permutation correspond to the original data #>  #>   - corrected some missing/redundant row/column labels in some output #>  #>   - most require() calls replaced with requireNamespace() to avoid #>     altering the search path (hopefully this won't break stuff ...) #>  #>   - some non-visible changes including more use of some (non-exported) #>     helper functions for common tasks #>  #>   - dataset dat.collins91985a updated (including all reported outcomes #>     and some more information about the various trials) #>  #>   - oh, and guess what? I updated the documentation ... #>  #>                  Changes in version 1.9-4 (2014-07-30)                   #>  #>   - added method=\"GENQ\" to rma.uni() for the generalized Q-statistic #>     estimator of tau^2, which allows for used-defined weights (note: the #>     DL and HE estimators are just special cases of this method) #>  #>   - when the model was fitted with method=\"GENQ\", then confint() will #>     now use the generalized Q-statistic method to construct the #>     corresponding confidence interval for tau^2 (thanks to Dan Jackson #>     for the code); the iterative method used to obtain the CI makes use #>     of Farebrother's algorithm as implemented in the CompQuadForm #>     package #>  #>   - slight improvements in how the rma.uni() function handles #>     non-positive sampling variances #>  #>   - rma.uni(), rma.mv(), and rma.glmm() now try to detect and remove any #>     redundant predictors before the model fitting; therefore, if there #>     are exact linear relationships among the predictor variables (i.e., #>     perfect multicollinearity), terms are removed to obtain a set of #>     predictors that is no longer perfectly multicollinear (a warning is #>     issued when this happens); note that the order of how the variables #>     are specified in the model formula can influence which terms are #>     removed #>  #>   - the last update introduced an error in how hat values were computed #>     when the model was fitted with the rma() function using the Knapp & #>     Hartung method (i.e., when knha=TRUE); this has been fixed #>  #>   - regtest() no longer works (for now) with rma.mv objects (it wasn't #>     meant to in the first place); if you want to run something along the #>     same lines, just consider adding some measure of the precision of #>     the observed outcomes (e.g., their standard errors) as a predictor #>     to the model #>  #>   - added \"sqrtni\" and \"sqrtninv\" as possible options for the predictor #>     argument of regtest() #>  #>   - more optimizers are now available for the rma.mv() function via the #>     nloptr package by setting control = list(optimizer=\"nloptr\"); when #>     using this optimizer, the default is to use the BOBYQA #>     implementation from that package with a relative convergence #>     criterion of 1e-8 on the function value (see documentation on how to #>     change these defaults) #>  #>   - predict.rma() function now works for rma.mv objects with multiple #>     tau^2 values even if the user specifies the newmods argument but not #>     the tau2.levels argument (but a warning is issued and the prediction #>     intervals are not computed) #>  #>   - argument var.names now works properly in escalc() when the user has #>     not made use of the data argument (thanks to Jarrett Byrnes for #>     bringing this to my attention) #>  #>   - added plot() function for cumulative random-effects models results #>     as obtained with the cumul.rma.uni() function; the plot shows the #>     model estimate on the x-axis and the corresponding tau^2 estimate on #>     the y-axis in the cumulative order of the results #>  #>   - fixed the omitted offset term in the underlying model fitted by the #>     rma.glmm() function when method=\"ML\", measure=\"IRR\", and #>     model=\"UM.FS\", that is, when fitting a mixed-effects Poisson #>     regression model with fixed study effects to two-group event count #>     data (thanks to Peter Konings for pointing out this error) #>  #>   - added two new datasets (dat.bourassa1996, dat.riley2003) #>  #>   - added function replmiss() (just a useful helper function) #>  #>   - package now uses LazyData: TRUE #>  #>   - some improvements to the documentation (do I still need to mention #>     this every time?) #>  #>                  Changes in version 1.9-3 (2014-05-05)                   #>  #>   - some minor tweaks to rma.uni() that should be user transparent #>  #>   - rma.uni() now has a weights argument, allowing the user to specify #>     arbitrary user-defined weights; all functions affected by this have #>     been updated accordingly #>  #>   - better handling of mismatched length of yi and ni vectors in #>     rma.uni() and rma.mv() functions #>  #>   - subsetting is now handled as early as possible within functions with #>     subsetting capabilities; this avoids some (rare) cases where studies #>     ultimately excluded by the subsetting could still affect the results #>  #>   - some general tweaks to rma.mv() that should make it a bit faster #>  #>   - argument V of rma.mv() now also accepts a list of var-cov matrices #>     for the observed effects or outcomes; from the list elements, the #>     full (block diagonal) var-cov matrix V is then automatically #>     constructed #>  #>   - rma.mv() now has a new argument W allowing the user to specify #>     arbitrary user-defined weights or an arbitrary weight matrix #>  #>   - rma.mv() now has a new argument sparse; by setting this to TRUE, the #>     function uses sparse matrix objects to the extent possible; this can #>     speed up model fitting substantially for certain models (hence, the #>     metafor package now depends on the Matrix package) #>  #>   - rma.mv() now allows for struct=\"AR\" and struct=\"HAR\", to fit models #>     with (heteroscedastic) autoregressive (AR1) structures among the #>     true effects (useful for meta-analyses of studies reporting outcomes #>     at multiple time points) #>  #>   - rma.mv() now has a new argument Rscale which can be used to control #>     how matrices specified via the R argument are scaled (see docs for #>     more details) #>  #>   - rma.mv() now only checks for missing values in the rows of the lower #>     triangular part of the V matrix (including the diagonal); this way, #>     if Vi = matrix(c(.5,NA,NA,NA), nrow=2, ncol=2) is the var-cov matrix #>     of the sampling errors for a particular study with two outcomes, #>     then only the second row/column needs to be removed before the model #>     fitting (and not the entire study) #>  #>   - added five new datasets (dat.begg1989, dat.ishak2007, dat.fine1993, #>     dat.konstantopoulos2011, and dat.hasselblad1998) to provide further #>     illustrations of the use of the rma.mv() function (for meta-analyses #>     combining controlled and uncontrolled studies, for meta-analyses of #>     longitudinal studies, for multilevel meta-analyses, and for network #>     meta-analyses / mixed treatment comparison meta-analyses) #>  #>   - added rstandard.rma.mv() function to compute standardized residuals #>     for models fitted with the rma.mv() function (rstudent.rma.mv() to #>     be added at a later point); also added hatvalues.rma.mv() for #>     computing the hat values and weights.rma.uni() for computing the #>     weights (i.e., the diagonal elements of the weight matrix) #>  #>   - the various weights() functions now have a new argument type to #>     indicate whether only the diagonal elements of the weight matrix #>     (default) or the entire weight matrix should be returned #>  #>   - the various hatvalues() functions now have a new argument type to #>     indicate whether only the diagonal elements of the hat matrix #>     (default) or the entire hat matrix should be returned #>  #>   - predict.rma() function now works properly for rma.mv objects (also #>     has a new argument tau2.levels to specify, where applicable, the #>     levels of the inner factor when computing prediction intervals) #>  #>   - forest.rma() function now provides a bit more control over the color #>     of the summary polygon and is now compatible with rma.mv objects; #>     also, has a new argument lty, which provides more control over the #>     line type for the individual CIs and the prediction interval #>  #>   - addpoly.default() and addpoly.rma() now have a border argument (for #>     consistency with the forest.rma() function); addpoly.rma() now #>     yields the correct CI bounds when the model was fitted with #>     knha=TRUE #>  #>   - forest.cumul.rma() now provides the correct CI bounds when the #>     models were fitted with the Knapp & Hartung method (i.e., when #>     knha=TRUE in the original rma() function call) #>  #>   - the various forest() functions now return information about the #>     chosen values for arguments xlim, alim, at, ylim, rows, cex, #>     cex.lab, and cex.axis invisibly (useful for tweaking the default #>     values); thanks to Michael Dewey for the suggestion #>  #>   - the various forest() functions now have a new argument, clim, to set #>     limits for the confidence/prediction interval bounds #>  #>   - cumul.mh() and cumul.peto() now get the order of the studies right #>     when there are missing values in the data #>  #>   - the transf argument of leave1out.rma.mh(), leave1out.rma.peto(), #>     cumul.rma.mh(), and cumul.rma.peto() should now be used to specify #>     the actual function for the transformation (the former behavior of #>     setting this argument to TRUE to exponentiate log RRs, log ORs, or #>     log IRRs still works for back-compatibility); this is more #>     consistent with how the cumul.rma.uni() and leave1out.rma.uni() #>     functions work and is also more flexible #>  #>   - added bldiag() function to construct a block diagonal matrix from (a #>     list of) matrices (may be needed to construct the V matrix when #>     using the rma.mv() function); bdiag() function from the Matrix #>     package does the same thing, but creates sparse matrix objects #>  #>   - profile.rma.mv() now has a startmethod argument; by setting this to #>     \"prev\", successive model fits are started at the parameter estimates #>     from the previous model fit; this may speed things up a bit; also, #>     the method for automatically choosing the xlim values has been #>     changed #>  #>   - slight improvement to profile.rma.mv() function, which would throw #>     an error if the last model fit did not converge #>  #>   - added a new dataset (dat.linde2005) for replication of the analyses #>     in Viechtbauer (2007) #>  #>   - added a new dataset (dat.molloy2014) for illustrating the #>     meta-analysis of (r-to-z transformed) correlation coefficients #>  #>   - added a new dataset (dat.gibson2002) to illustrate the combined #>     analysis of standardized mean differences and probit transformed #>     risk differences #>  #>   - computations in weights.mh() slightly changed to prevent integer #>     overflows for large counts #>  #>   - unnecessary warnings in transf.ipft.hm() are now suppressed (cases #>     that raised those warnings were already handled correctly) #>  #>   - in predict(), blup(), cumul(), and leave1out(), when using the #>     transf argument, the standard errors (which are NA) are no longer #>     shown in the output #>  #>   - argument slab in various functions will now also accept non-unique #>     study labels; make.unique() is used as needed to make them unique #>  #>   - vignettes(\"metafor\") and vignettes(\"metafor_diagram\") work again #>     (yes, I know they are not true vignettes in the strict sense, but I #>     think they should show up on the CRAN website for the package and #>     using a minimal valid Sweave document that is recognized by the R #>     build system makes that happen) #>  #>   - escalc() and its summary() method now keep better track when the #>     data frame contains multiple columns with outcome or effect size #>     values (and corresponding sampling variances) for print formatting; #>     also simplified the class structure a bit (and hence, #>     print.summary.escalc() removed) #>  #>   - summary.escalc() has a new argument H0 to specify the value of the #>     outcome under the null hypothesis for computing the test statistics #>  #>   - added measures \"OR2DN\" and \"D2ORN\" to escalc() for transforming log #>     odds ratios to standardized mean differences and vice-versa, based #>     on the method of Cox & Snell (1989), which assumes normally #>     distributed response variables within the two groups before the #>     dichotomization #>  #>   - permutest.rma.uni() function now catches an error when the number of #>     permutations requested is too large (for R to even create the #>     objects to store the results in) and produces a proper error message #>  #>   - funnel.rma() function now allows the yaxis argument to be set to #>     \"wi\" so that the actual weights (in %) are placed on the y-axis #>     (useful when arbitrary user-defined have been specified) #>  #>   - for rma.glmm(), the control argument optCtrl is now used for passing #>     control arguments to all of the optimizers (hence, control arguments #>     nlminbCtrl and minqaCtrl are now defunct) #>  #>   - rma.glmm() should not throw an error anymore when including only a #>     single moderator/predictor in the model #>  #>   - predict.rma() now returns an object of class list.rma (therefore, #>     function print.predict.rma() has been removed) #>  #>   - for rma.list objects, added [, head(), and tail() methods #>  #>   - automated testing using the testthat package (still many more tests #>     to add, but finally made a start on this) #>  #>   - encoding changed to UTF-8 (to use 'foreign characters' in the docs #>     and to make the HTML help files look a bit nicer) #>  #>   - guess what? some improvements to the documentation! (also combined #>     some of the help files to reduce the size of the manual a bit; and #>     yes, it's still way too big) #>  #>                  Changes in version 1.9-2 (2013-10-07)                   #>  #>   - added function rma.mv() to fit multivariate/multilevel meta-analytic #>     models via appropriate linear (mixed-effects) models; this function #>     allows for modeling of non-independent sampling errors and/or true #>     effects and can be used for network meta-analyses, meta-analyses #>     accounting for phylogenetic relatedness, and other complicated #>     meta-analytic data structures #>  #>   - added the AICc to the information criteria computed by the various #>     model fitting functions #>  #>   - if the value of tau^2 is fixed by the user via the corresponding #>     argument in rma.uni(), then tau^2 is no longer counted as an #>     additional parameter for the computation of the information criteria #>     (i.e., AIC, BIC, and AICc) #>  #>   - rma.uni(), rma.glmm(), and rma.mv() now use a more stringent check #>     whether the model matrix is of full rank #>  #>   - added profile() method functions for objects of class rma.uni and #>     rma.mv (can be used to obtain a plot of the profiled log-likelihood #>     as a function of a specific variance component or correlation #>     parameter of the model) #>  #>   - predict.rma() function now has an intercept argument that allows the #>     user to decide whether the intercept term should be included when #>     calculating the predicted values (rare that this should be changed #>     from the default) #>  #>   - for rma.uni(), rma.glmm(), and rma.mv(), the control argument can #>     now also accept an integer value; values > 1 generate more verbose #>     output about the progress inside of the function #>  #>   - rma.glmm() has been updated to work with lme4 1.0.x for fitting #>     various models; as a result, model=\"UM.RS\" can only use nAGQ=1 at #>     the moment (hopefully this will change in the future) #>  #>   - the control argument of rma.glmm() can now be used to pass all #>     desired control arguments to the various functions and optimizers #>     used for the model fitting (admittedly the use of lists within this #>     argument is a bit unwieldy, but much more flexible) #>  #>   - rma.mh() and rma.peto() also now have a verbose argument (not really #>     needed, but added for sake of consistency across functions) #>  #>   - fixed (silly) error that would prevent rma.glmm() from running for #>     measures \"IRR\", \"PLO\", and \"IRLN\" when there are missing values in #>     the data (lesson: add some missing values to datasets for the unit #>     tests!) #>  #>   - a bit of code reorganization (should be user transparent) #>  #>   - vignettes (\"metafor\" and \"metafor_diagram\") are now just 'other #>     files' in the doc directory (as these were not true vignettes to #>     begin with) #>  #>   - some improvements to the documentation (as always) #>  #>                  Changes in version 1.9-1 (2013-07-20)                   #>  #>   - rma.mh() now also implements the Mantel-Haenszel method for #>     incidence rate differences (measure=\"IRD\") #>  #>   - when analyzing incidence rate ratios (measure=\"IRR\") with the #>     rma.mh() function, the Mantel-Haenszel test for person-time data is #>     now also provided #>  #>   - rma.mh() has a new argument correct (default is TRUE) to indicate #>     whether the continuity correction should be applied when computing #>     the (Cochran-)Mantel-Haenszel test statistic #>  #>   - renamed elements CMH and CMHp (for the Cochran-Mantel-Haenszel test #>     statistic and corresponding p-value) to MH and MHp #>  #>   - added function baujat() to create Baujat plots #>  #>   - added a new dataset (dat.pignon2000) to illustrate the use of the #>     baujat() function #>  #>   - added function to.table() to convert data from vector format into #>     the corresponding table format #>  #>   - added function to.long() to convert data from vector format into the #>     corresponding long format #>  #>   - rma.glmm() now even runs when k=1 (yielding trivial results) #>  #>   - for models with an intercept and moderators, rma.glmm() now #>     internally rescales (non-dummy) variables to z-scores during the #>     model fitting (this improves the stability of the model fitting, #>     especially when model=\"CM.EL\"); results are given after #>     back-scaling, so this should be transparent to the user #>  #>   - in rma.glmm(), default number of quadrature points (nAGQ) is now 7 #>     (setting this to 100 was a bit overkill) #>  #>   - a few more error checks here and there for misspecified arguments #>  #>   - some improvements to the documentation #>  #>                  Changes in version 1.9-0 (2013-06-21)                   #>  #>   - vignette renamed to metafor so vignette(\"metafor\") works now #>  #>   - added a diagram to the documentation, showing the various functions #>     in the metafor package (and how they relate to each other); can be #>     loaded with vignette(\"metafor_diagram\") #>  #>   - anova.rma.uni() function can now also be used to test (sub)sets of #>     model coefficients with a Wald-type test when a single model is #>     passed to the function #>  #>   - the pseudo R^2 statistic is now automatically calculated by the #>     rma.uni() function and supplied in the output (only for #>     mixed-effects models and when the model includes an intercept, so #>     that the random- effects model is clearly nested within the #>     mixed-effects model) #>  #>   - component VAF is now called R2 in anova.rma.uni() function #>  #>   - added function hc() that carries out a random-effects model analysis #>     using the method by Henmi and Copas (2010); thanks to Michael Dewey #>     for the suggestion and providing the code #>  #>   - added new dataset (dat.lee2004), which was used in the article by #>     Henmi and Copas (2010) to illustrate their method #>  #>   - fixed missing x-axis labels in the forest() functions #>  #>   - rma.glmm() now computes Hessian matrices via the numDeriv package #>     when model=\"CM.EL\" and measure=\"OR\" (i.e., for the conditional #>     logistic model with exact likelihood); so numDeriv is now a #>     suggested package and is loaded within rma.glmm() when required #>  #>   - trimfill.rma.uni() now also implements the \"Q0\" estimator (although #>     the \"L0\" and \"R0\" estimators are generally to be preferred) #>  #>   - trimfill.rma.uni() now also calculates the SE of the estimated #>     number of missing studies and, for estimator \"R0\", provides a formal #>     test of the null hypothesis that the number of missing studies on a #>     given side is zero #>  #>   - added new dataset (dat.bangertdrowns2004) #>  #>   - the level argument in various functions now either accepts a value #>     representing a percentage or a proportion (values greater than 1 are #>     assumed to be a percentage) #>  #>   - summary.escalc() now computes confidence intervals correctly when #>     using the transf argument #>  #>   - computation of Cochran-Mantel-Haenszel statistic in rma.mh() changed #>     slightly to avoid integer overflow with very big counts #>  #>   - some internal improvements with respect to object attributes that #>     were getting discarded when subsetting #>  #>   - some general code cleanup #>  #>   - some improvements to the documentation #>  #>                  Changes in version 1.8-0 (2013-04-11)                   #>  #>   - added additional clarifications about the change score outcome #>     measures (\"MC\", \"SMCC\", and \"SMCR\") to the help file for the #>     escalc() function and changed the code so that \"SMCR\" no longer #>     expects argument sd2i to be specified (which is not needed anyways) #>     (thanks to Markus Kösters for bringing this to my attention) #>  #>   - sampling variance for the biserial correlation coefficient (\"RBIS\") #>     is now calculated in a slightly more accurate way #>  #>   - llplot() now properly scales the log-likelihoods #>  #>   - argument which in the plot.infl.rma.uni() function has been replaced #>     with argument plotinf which can now also be set to FALSE to suppress #>     plotting of the various case diagnostics altogether #>  #>   - labeling of the axes in labbe() plots is now correct for odds ratios #>     (and transformations thereof) #>  #>   - added two new datasets (dat.nielweise2007 and dat.nielweise2008) to #>     illustrate some methods/models from the rma.glmm() function #>  #>   - added a new dataset (dat.yusuf1985) to illustrate the use of #>     rma.peto() #>  #>   - test for heterogeneity is now conducted by the rma.peto() function #>     exactly as described by Yusuf et al. (1985) #>  #>   - in rma.glmm(), default number of quadrature points (nAGQ) is now 100 #>     (which is quite a bit slower, but should provide more than #>     sufficient accuracy in most cases) #>  #>   - the standard errors of the HS and DL estimators of tau^2 are now #>     correctly computed when tau^2 is prespecified by the user in the #>     rma() function; in addition, the standard error of the SJ estimator #>     is also now provided when tau^2 is prespecified #>  #>   - rma.uni() and rma.glmm() now use a better method to check whether #>     the model matrix is of full rank #>  #>   - I^2 and H^2 statistics are now also calculated for mixed-effects #>     models by the rma.uni() and rma.glmm() function; confint.rma.uni() #>     provides the corresponding confidence intervals for rma.uni models #>  #>   - various print() methods now have a new argument called signif.stars, #>     which defaults to getOption(\"show.signif.stars\") (which by default #>     is TRUE) to determine whether the infamous 'significance stars' #>     should be printed #>  #>   - slight changes in wording in the output produced by the #>     print.rma.uni() and print.rma.glmm() functions #>  #>   - some improvements to the documentation #>  #>                  Changes in version 1.7-0 (2013-02-06)                   #>  #>   - added rma.glmm() function for fitting of appropriate generalized #>     linear (mixed-effects) models when analyzing odds ratios, incidence #>     rate ratios, proportions, or rates; the function makes use of the #>     lme4 and BiasedUrn packages; these are now suggested packages and #>     loaded within rma.glmm() only when required (this makes for faster #>     loading of the metafor package) #>  #>   - added several method functions for objects of class rma.glmm (not #>     all methods yet implemented; to be completed in the future) #>  #>   - rma.uni() now allows the user to specify a formula for the yi #>     argument, so instead of rma(yi, vi, mods=~mod1+mod2), one can #>     specify the same model with rma(yi~mod1+mod2, vi) #>  #>   - rma.uni() now has a weights argument to specify the inverse of the #>     sampling variances (instead of using the vi or sei arguments); for #>     now, this is all this argument should be used for (in the future, #>     this argument may potentially be used to allow the user to define #>     alternative weights) #>  #>   - rma.uni() now checks whether the model matrix is not of full rank #>     and issues an error accordingly (instead of the rather cryptic error #>     that was issued before) #>  #>   - rma.uni() now has a verbose argument #>  #>   - coef.rma() now returns only the model coefficients (this change was #>     necessary to make the package compatible with the multcomp package; #>     see help(rma) for an example); use coef(summary()) to obtain the #>     full table of results #>  #>   - the escalc() function now does some more extensive error checking #>     for misspecified data and some unusual cases #>  #>   - append argument is now TRUE by default in the escalc() function #>  #>   - objects generated by the escalc() function now have their own class #>  #>   - added print() and summary() methods for objects of class escalc #>  #>   - added [ and cbind() methods for objects of class escalc #>  #>   - added a few additional arguments to the escalc() function (i.e., #>     slab, subset, var.names, replace, digits) #>  #>   - added drop00 argument to the escalc(), rma.uni(), rma.mh(), and #>     rma.peto() functions #>  #>   - added \"MN\", \"MC\", \"SMCC\", and \"SMCR\" measures to the escalc() and #>     rma.uni() functions for the raw mean, the raw mean change, and the #>     standardized mean change (with change score or raw score #>     standardization) as possible outcome measures #>  #>   - the \"IRFT\" measure in the escalc() and rma.uni() functions is now #>     computed with 1/2*(sqrt(xi/ti) + sqrt(xi/ti+1/ti)) which is more #>     consistent with the definition of the Freeman-Tukey transformation #>     for proportions #>  #>   - added \"RTET\" measure to the escalc() and rma.uni() functions to #>     compute the tetrachoric correlation coefficient based on 2x2 table #>     data (the polycor package is therefore now a suggested package, #>     which is loaded within escalc() only when required) #>  #>   - added \"RPB\" and \"RBIS\" measures to the escalc() and rma.uni() #>     functions to compute the point-biserial and biserial correlation #>     coefficient based on means and standard deviations #>  #>   - added \"PBIT\" and \"OR2D\" measures to the escalc() and rma.uni() #>     functions to compute the standardized mean difference based on 2x2 #>     table data #>  #>   - added the \"D2OR\" measure to the escalc() and rma.uni() functions to #>     compute the log odds ratio based on the standardized mean difference #>  #>   - added \"SMDH\" measure to the escalc() and rma.uni() functions to #>     compute the standardized mean difference without assuming equal #>     population variances #>  #>   - added \"ARAW\", \"AHW\", and \"ABT\" measures to the escalc() and #>     rma.uni() functions for the raw value of Cronbach's alpha, the #>     transformation suggested by Hakstian & Whalen (1976), and the #>     transformation suggested by Bonett (2002) for the meta-analysis of #>     reliability coefficients (see help(escalc) for details) #>  #>   - corrected a small mistake in the equation used to compute the #>     sampling variance of the phi coefficient (measure=\"PHI\") in the #>     escalc() function #>  #>   - the permutest.rma.uni() function now uses an algorithm to find only #>     the unique permutations of the model matrix (which may be much #>     smaller than the total number of permutations), making the exact #>     permutation test feasible in a larger set of circumstances (thanks #>     to John Hodgson for making me aware of this issue and to Hans-Jörg #>     Viechtbauer for coming up with a recursive algorithm for finding the #>     unique permutations) #>  #>   - prediction interval in forest.rma() is now indicated with a dotted #>     (instead of a dashed) line; ends of the interval are now marked with #>     vertical bars #>  #>   - completely rewrote the funnel.rma() function which now supports many #>     more options for the values to put on the y-axis; trimfill.rma.uni() #>     function was adapted accordingly #>  #>   - removed the ni argument from the regtest.rma() function; instead, #>     sample sizes can now be explicitly specified via the ni argument #>     when using the rma.uni() function (i.e., when measure=\"GEN\"); the #>     escalc() function also now adds information on the ni values to the #>     resulting data frame (as an attribute of the yi variable), so, if #>     possible, this information is passed on to regtest.rma() #>  #>   - added switch so that regtest() can also provide the full results #>     from the fitted model (thanks to Michael Dewey for the suggestion) #>  #>   - weights.rma.mh() now shows the weights in % as intended (thanks to #>     Gavin Stewart for pointing out this error) #>  #>   - more flexible handling of the digits argument in the various forest #>     functions #>  #>   - forest functions now use pretty() by default to set the x-axis tick #>     locations (alim and at arguments can still be used for complete #>     control) #>  #>   - studies that are considered to be 'influential' are now marked with #>     an asterisk when printing the results returned by the #>     influence.rma.uni() function (see the documentation of this function #>     for details on how such studies are identified) #>  #>   - added additional extractor functions for some of the influence #>     measures (i.e., cooks.distance(), dfbetas()); unfortunately, the #>     covratio() and dffits() functions in the stats package are not #>     generic; so, to avoid masking, there are currently no extractor #>     functions for these measures #>  #>   - better handling of missing values in some unusual situations #>  #>   - corrected small bug in fsn() that would not allow the user to #>     specify the standard errors instead of the sampling variances #>     (thanks to Bernd Weiss for pointing this out) #>  #>   - plot.infl.rma.uni() function now allows the user to specify which #>     plots to draw (and the layout) and adds the option to show study #>     labels on the x-axis #>  #>   - added proper print() method for objects generated by the #>     confint.rma.uni(), confint.rma.mh(), and confint.rma.peto() #>     functions #>  #>   - when transf or atransf argument was a monotonically decreasing #>     function, then confidence and prediction interval bounds were in #>     reversed order; various functions now check for this and order the #>     bounds correctly #>  #>   - trimfill.rma.uni() now only prints information about the number of #>     imputed studies when actually printing the model object #>  #>   - qqnorm.rma.uni(), qqnorm.rma.mh(), and qqnorm.rma.peto() functions #>     now have a new argument called label, which allows for labeling of #>     points; the functions also now return (invisibly) the x and y #>     coordinates of the points drawn #>  #>   - rma.mh() with measure=\"RD\" now computes the standard error of the #>     estimated risk difference based on Sato, Greenland, & Robins (1989), #>     which provides a consistent estimate under both large-stratum and #>     sparse-data limiting models #>  #>   - the restricted maximum likelihood (REML) is now calculated using the #>     full likelihood equation (without leaving out additive constants) #>  #>   - the model deviance is now calculated as -2 times the difference #>     between the model log-likelihood and the log-likelihood under the #>     saturated model (this is a more appropriate definition of the #>     deviance than just taking -2 times the model log-likelihood) #>  #>   - naming scheme of illustrative datasets bundled with the package has #>     been changed; now datasets are called <dat.authoryear>; therefore, #>     the datasets are now called (old name -> new name): #>      #>       - dat.bcg -> dat.colditz1994 #>       - dat.warfarin -> dat.hart1999 #>       - dat.los -> dat.normand1999 #>       - dat.co2 -> dat.curtis1998 #>       - dat.empint -> dat.mcdaniel1994 #>  #>   - but dat.bcg has been kept as an alias for dat.colditz1994, as it has #>     been referenced under that name in some publications #>  #>   - added new dataset (dat.pritz1997) to illustrate the meta-analysis of #>     proportions (raw values and transformations thereof) #>  #>   - added new dataset (dat.bonett2010) to illustrate the meta-analysis #>     of Cronbach's alpha values (raw values and transformations thereof) #>  #>   - added new datasets (dat.hackshaw1998, dat.raudenbush1985) #>  #>   - (approximate) standard error of the tau^2 estimate is now computed #>     and shown for most of the (residual) heterogeneity estimators #>  #>   - added nobs() and df.residual() methods for objects of class rma #>  #>   - metafor.news() is now simply a wrapper for news(package=\"metafor\") #>  #>   - the package code is now byte-compiled, which yields some modest #>     increases in execution speed #>  #>   - some general code cleanup #>  #>   - the metafor package no longer depends on the nlme package #>  #>   - some improvements to the documentation #>  #>                  Changes in version 1.6-0 (2011-04-13)                   #>  #>   - trimfill.rma.uni() now returns a proper object even when the number #>     of missing studies is estimated to be zero #>  #>   - added the (log transformed) ratio of means as a possible outcome #>     measure to the escalc() and rma.uni() functions (measure=\"ROM\") #>  #>   - added new dataset (dat.co2) to illustrate the use of the ratio of #>     means outcome measure #>  #>   - some additional error checking in the various forest functions #>     (especially when using the ilab argument) #>  #>   - in labbe.rma(), the solid and dashed lines are now drawn behind (and #>     not on top of) the points #>  #>   - slight change to transf.ipft.hm() so that missing values in targs$ni #>     are ignored #>  #>   - some improvements to the documentation #>  #>                  Changes in version 1.5-0 (2010-12-16)                   #>  #>   - the metafor package now has its own project website at: #>     https://www.metafor-project.org/ #>  #>   - added labbe() function to create L'Abbe plots #>  #>   - the forest.default() and addpoly.default() functions now allow the #>     user to directly specify the lower and upper confidence interval #>     bounds (this can be useful when the CI bounds have been calculated #>     with other methods/functions) #>  #>   - added the incidence rate for a single group and for two groups (and #>     transformations thereof) as possible outcome measures to the #>     escalc() and rma.uni() functions (measure=\"IRR\", \"IRD\", \"IRSD\", #>     \"IR\", \"IRLN\", \"IRS\", and \"IRFT\") #>  #>   - added the incidence rate ratio as a possible outcome measure to the #>     rma.mh() function #>  #>   - added transformation functions related to incidence rates #>  #>   - added the Freeman-Tukey double arcsine transformation and its #>     inverse to the transformation functions #>  #>   - added some additional error checking for out-of-range p-values in #>     the permutest.rma.uni() function #>  #>   - added some additional checking for out-of-range values in several #>     transformation functions #>  #>   - added confint() methods for rma.mh and rma.peto objects (only for #>     completeness sake; print already provides CIs) #>  #>   - added new datasets (dat.warfarin, dat.los, dat.empint) #>  #>   - some improvements to the documentation #>  #>                  Changes in version 1.4-0 (2010-07-30)                   #>  #>   - a paper about the package has now been published in the Journal of #>     Statistical Software (https://www.jstatsoft.org/v36/i03/) #>  #>   - added citation info; see: citation(\"metafor\") #>  #>   - the metafor package now depends on the nlme package #>  #>   - added extractor functions for the AIC, BIC, and deviance #>  #>   - some updates to the documentation #>  #>                  Changes in version 1.3-0 (2010-06-25)                   #>  #>   - the metafor package now depends on the Formula package #>  #>   - made escalc() generic and implemented a default and a formula #>     interface #>  #>   - added the (inverse) arcsine transformation to the set of #>     transformation functions #>  #>                  Changes in version 1.2-0 (2010-05-18)                   #>  #>   - cases where k is very small (e.g., k equal to 1 or 2) are now #>     handled more gracefully #>  #>   - added sanity check for cases where all observed outcomes are equal #>     to each other (this led to division by zero when using the Knapp & #>     Hartung method) #>  #>   - the \"smarter way to set the number of iterations for permutation #>     tests\" (see notes for previous version below) now actually works #>     like it is supposed to #>  #>   - the permutest.rma.uni() function now provides more sensible results #>     when k is very small; the documentation for the function has also #>     been updated with some notes about the use of permutation tests #>     under those circumstances #>  #>   - made some general improvements to the various forest plot functions #>     making them more flexible in particular when creating more complex #>     displays; most importantly, added a rows argument and removed the #>     addrows argument #>  #>   - some additional examples have been added to the help files for the #>     forest and addpoly functions to demonstrate how to create more #>     complex displays with these functions #>  #>   - added showweight argument to the forest.default() and forest.rma() #>     functions #>  #>   - cumul() functions not showing all of the output columns when using #>     fixed-effects models has been corrected #>  #>   - weights.rma.uni() function now handles NAs appropriately #>  #>   - weights.rma.mh() and weights.rma.peto() functions added #>  #>   - logLik.rma() function now behaves more like other logLik() functions #>     (such as logLik.lm() and logLik.lme()) #>  #>                  Changes in version 1.1-0 (2010-04-28)                   #>  #>   - cint() generic removed and replaced with confint() method for #>     objects of class rma.uni #>  #>   - slightly improved the code to set the x-axis title in the forest() #>     and funnel() functions #>  #>   - added coef() method for permutest.rma.uni objects #>  #>   - added append argument to escalc() function #>  #>   - implemented a smarter way to set the number of iterations for #>     permutation tests (i.e., the permutest.rma.uni() function will now #>     switch to an exact test if the number of iterations required for an #>     exact test is actually smaller than the requested number of #>     iterations for an approximate test) #>  #>   - changed the way how p-values for individual coefficients are #>     calculated in permutest.rma.uni() to 'two times the one-tailed area #>     under the permutation distribution' (more consistent with the way we #>     typically define two-tailed p-values) #>  #>   - added retpermdist argument to permutest.rma.uni() to return the #>     permutation distributions of the test statistics #>  #>   - slight improvements to the various transformation functions to cope #>     better with some extreme cases #>  #>   - p-values are now calculated in such a way that very small p-values #>     stored in fitted model objects are no longer truncated to 0 (the #>     printed results are still truncated depending on the number of #>     digits specified) #>  #>   - changed the default number of iterations for the ML, REML, and EB #>     estimators from 50 to 100 #>  #>                  Changes in version 1.0-1 (2010-02-02)                   #>  #>   - version jump in conjunction with the upcoming publication of a paper #>     in the Journal of Statistical Software describing the metafor #>     package #>  #>   - instead of specifying a model matrix, the user can now specify a #>     model formula for the mods argument in the rma() function (e.g., #>     like in the lm() function) #>  #>   - permutest() function now allows exact permutation tests (but this is #>     only feasible when k is not too large) #>  #>   - forest() function now uses the level argument properly to adjust the #>     CI level of the summary estimate for models without moderators #>     (i.e., for fixed- and random-effets models) #>  #>   - forest() function can now also show the prediction interval as a #>     dashed line for a random-effects model #>  #>   - information about the measure used is now passed on to the forest() #>     and funnel() functions, which try to set an appropriate x-axis title #>     accordingly #>  #>   - funnel() function now has more arguments (e.g., atransf, at) #>     providing more control over the display of the x-axis #>  #>   - predict() function now has its own print() method and has a new #>     argument called addx, which adds the values of the moderator #>     variables to the returned object (when addx=TRUE) #>  #>   - functions now properly handle the na.action \"na.pass\" (treated #>     essentially like \"na.exclude\") #>  #>   - added method for weights() to extract the weights used when fitting #>     models with rma.uni() #>  #>   - some small improvements to the documentation #>  #>                  Changes in version 0.5-7 (2009-12-06)                   #>  #>   - added permutest() function for permutation tests #>  #>   - added metafor.news() function to display the NEWS file of the #>     metafor package within R (based on same idea in the animate package #>     by Yihui Xie) #>  #>   - added some checks for values below machine precision #>  #>   - a bit of code reorganization (nothing that affects how the functions #>     work) #>  #>                  Changes in version 0.5-6 (2009-10-19)                   #>  #>   - small changes to the computation of the DFFITS and DFBETAS values in #>     the influence() function, so that these statistics are more in line #>     with their definitions in regular linear regression models #>  #>   - added option to the plot function for objects returned by #>     influence() to allow plotting the covariance ratios on a log scale #>     (now the default) #>  #>   - slight adjustments to various print() functions (to catch some #>     errors when certain values were NA) #>  #>   - added a control option to rma() to adjust the step length of the #>     Fisher scoring algorithm by a constant factor (this may be useful #>     when the algorithm does not converge) #>  #>                  Changes in version 0.5-5 (2009-10-08)                   #>  #>   - added the phi coefficient (measure=\"PHI\"), Yule's Q (\"YUQ\"), and #>     Yule's Y (\"YUY\") as additional measures to the escalc() function #>     for 2x2 table data #>  #>   - forest plots now order the studies so that the first study is at the #>     top of the plot and the last study at the bottom (the order can #>     still be set with the order or subset argument) #>  #>   - added cumul() function for cumulative meta-analyses (with a #>     corresponding forest() method to plot the cumulative results) #>  #>   - added leave1out() function for leave-one-out diagnostics #>  #>   - added option to qqnorm.rma.uni() so that the user can choose whether #>     to apply the Bonferroni correction to the bounds of the pseudo #>     confidence envelope #>  #>   - some internal changes to the class and methods names #>  #>   - some small corrections to the documentation #>  #>                  Changes in version 0.5-4 (2009-09-18)                   #>  #>   - corrected the trimfill() function #>  #>   - improvements to various print functions #>  #>   - added a regtest() function for various regression tests of funnel #>     plot asymmetry (e.g., Egger's regression test) #>  #>   - made ranktest() generic and added a method for objects of class rma #>     so that the test can be carried out after fitting #>  #>   - added anova() function for full vs reduced model comparisons via fit #>     statistics and likelihood ratio tests #>  #>   - added the Orwin and Rosenberg approaches to fsn() #>  #>   - added H^2 measure to the output for random-effects models #>  #>   - in escalc(), measure=\"COR\" is now used for the (usual) raw #>     correlation coefficient and measure=\"UCOR\" for the bias corrected #>     correlation coefficients #>  #>   - some small corrections to the documentation #>  #>                  Changes in version 0.5-3 (2009-07-31)                   #>  #>   - small changes to some of the examples #>  #>   - added the log transformed proportion (measure=\"PLN\") as another #>     measure to the escalc() function; changed \"PL\" to \"PLO\" for the #>     logit (i.e., log odds) transformation for proportions #>  #>                  Changes in version 0.5-2 (2009-07-06)                   #>  #>   - added an option in plot.infl.rma.uni() to open a new device for #>     plotting the DFBETAS values #>  #>   - thanks to Jim Lemon, added a much better method for adjusting the #>     size of the labels, annotations, and symbols in the forest() #>     function when the number of studies is large #>  #>                  Changes in version 0.5-1 (2009-06-14)                   #>  #>   - made some small changes to the documentation (some typos corrected, #>     some confusing points clarified) #>  #>                  Changes in version 0.5-0 (2009-06-05)                   #>  #>   - first version released on CRAN"},{"path":"/reference/methods.escalc.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for 'escalc' Objects — methods.escalc","title":"Methods for 'escalc' Objects — methods.escalc","text":"Methods objects class \"escalc\".","code":""},{"path":"/reference/methods.escalc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for 'escalc' Objects — methods.escalc","text":"","code":"# S3 method for escalc [(x, i, ...) # S3 method for escalc cbind(..., deparse.level=1) # S3 method for escalc rbind(..., deparse.level=1)"},{"path":"/reference/methods.escalc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for 'escalc' Objects — methods.escalc","text":"x object class \"escalc\". ... arguments.","code":""},{"path":"/reference/methods.escalc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Methods for 'escalc' Objects — methods.escalc","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/methods.escalc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Methods for 'escalc' Objects — methods.escalc","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":"/reference/methods.list.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for 'list.rma' Objects — methods.list.rma","title":"Methods for 'list.rma' Objects — methods.list.rma","text":"Methods objects class \"list.rma\".","code":""},{"path":"/reference/methods.list.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for 'list.rma' Objects — methods.list.rma","text":"","code":"# S3 method for list.rma as.data.frame(x, ...) # S3 method for list.rma as.matrix(x, ...) # S3 method for list.rma [(x, i, ...) # S3 method for list.rma head(x, n=6L, ...) # S3 method for list.rma tail(x, n=6L, ...) # S3 method for list.rma $(x, name) <- value"},{"path":"/reference/methods.list.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for 'list.rma' Objects — methods.list.rma","text":"x object class \"list.rma\". ... arguments.","code":""},{"path":"/reference/methods.list.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Methods for 'list.rma' Objects — methods.list.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/methods.list.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Methods for 'list.rma' Objects — methods.list.rma","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":"/reference/misc-models.html","id":null,"dir":"Reference","previous_headings":"","what":"Fixed-Effects and Random-Effects Models in Meta-Analysis  — misc-models","title":"Fixed-Effects and Random-Effects Models in Meta-Analysis  — misc-models","text":"Books articles meta-analysis often describe discuss difference -called ‘fixed-effects model’ ‘random-effects model’ (e.g., Cooper et al., 2009). former term (mostly) avoided throughout documentation metafor package. term ‘equal-effects model’ used instead, since concretely describes main assumption underlying model (.e., underlying true effects/outcomes homogeneous, words, equal ). terms ‘common-effect(s) model’ ‘homogenous-effect(s) model’ also sometimes used literature describe model equally descriptive. Moreover, term ‘fixed-effects model’ creates bit conundrum. authors use term, really typically referring equal-effects model. however another type model, ‘real’ fixed-effects model, different equal-effects model, now need invent (unnecessarily) different term refer model. done tried make distinction ‘fixed-effect model’ (without s!) ‘fixed-effects model’, subtle difference terminology easily overlooked/missed. Using term ‘equal-effects model’ avoids confusion informative. However, question remains real fixed-effects model . purpose page describe model contrast well-known random-effects model.","code":""},{"path":[]},{"path":"/reference/misc-models.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fixed-Effects and Random-Effects Models in Meta-Analysis  — misc-models","text":"discussions distinction equal-, fixed-, random-effects models, see Laird Mosteller (1990) Hedges Vevea (1998).","code":""},{"path":"/reference/misc-models.html","id":"fixed-effects-model","dir":"Reference","previous_headings":"","what":"Fixed-Effects Model","title":"Fixed-Effects and Random-Effects Models in Meta-Analysis  — misc-models","text":"Assume set \\(= 1, \\ldots, k\\) independent studies let \\(y_i\\) denote observed value effect size outcome measure \\(\\textrm{th}\\) study. Let \\(\\theta_i\\) denote corresponding (unknown) true effect/outcome, \\[y_i | \\theta_i \\sim N(\\theta_i, v_i).\\] words, observed effect sizes outcomes assumed unbiased normally distributed estimates corresponding true effects/outcomes sampling variances equal \\(v_i\\). \\(v_i\\) values assumed known. fixed-effects model simply given \\[y_i = \\theta_i + \\epsilon_i,\\] \\(\\theta_i\\) values (fixed) true effects/outcomes \\(k\\) studies. Therefore, model ‘conditions’ true effects/outcomes provides conditional inference \\(k\\) studies included meta-analysis. using weighted estimation (default rma.uni method=\"FE\"), implies fitted model provides estimate \\[\\bar{\\theta}_w = \\frac{\\sum_{=1}^k w_i \\theta_i}{\\sum_{=1}^k w_i},\\] , weighted average true effects/outcomes \\(k\\) studies, weights equal \\(w_i = 1/v_i\\). example, consider meta-analysis Bangert-Drowns et al. (2004) effectiveness writing--learn interventions academic achievement. dataset (dat.bangertdrowns2004) includes observed standardized mean differences (variable yi) corresponding sampling variances (variable vi) 48 studies. can fit fixed-effects model data : Q-test suggests underlying true standardized mean differences heterogeneous \\((Q(\\textrm{df}=47) = 107.11, p < .0001).\\) Therefore, believe true, value shown estimate estimate inverse-variance weighted average true standardized mean differences 48 studies (.e., \\(\\hat{\\bar{\\theta}}_w = 0.17\\)). One can also employ unweighted estimation method (setting weighted=FALSE rma.uni), provides estimate unweighted average true effects/outcomes \\(k\\) studies, , estimate \\[\\bar{\\theta}_u = \\frac{\\sum_{=1}^k \\theta_i}{k}.\\] Returning example, find: Therefore, estimate value now estimate average true standardized mean differences 48 studies (.e., \\(\\hat{\\bar{\\theta}}_u = 0.26\\)). weighted estimation, one also choose estimate \\(\\bar{\\theta}_w\\), \\(w_i\\) values user-defined weights (via argument weights rma.uni). Hence, using inverse-variance weights unit weights (unweighted estimation) just special cases. user decide extent \\(\\bar{\\theta}_w\\) meaningful parameter estimate (regardless weights used). example, use sample sizes weights: therefore obtain estimate sample-size weighted average true standardized mean differences 48 studies (.e., \\(\\hat{\\bar{\\theta}}_w = 0.17\\)). Since sample sizes inverse sampling variances highly correlated (cor(dat$ni, 1/dat$vi) yields 0.999), results almost identical ones obtained earlier using inverse-variance weighting.","code":"# copy data into 'dat' dat <- dat.bangertdrowns2004  # fit a fixed-effects model res <- rma(yi, vi, data=dat, method=\"FE\") res  # Fixed-Effects Model (k = 48) # # I^2 (total heterogeneity / total variability):   56.12% # H^2 (total variability / sampling variability):  2.28 # # Test for Heterogeneity: # Q(df = 47) = 107.1061, p-val < .0001 # # Model Results: # # estimate      se    zval    pval   ci.lb   ci.ub #   0.1656  0.0269  6.1499  <.0001  0.1128  0.2184 # fit a fixed-effects model using unweighted estimation res <- rma(yi, vi, data=dat, method=\"FE\", weighted=FALSE) res  # Fixed-Effects Model (k = 48) # # I^2 (total heterogeneity / total variability):   56.12% # H^2 (total variability / sampling variability):  2.28 # # Test for Heterogeneity: # Q(df = 47) = 107.1061, p-val < .0001 # # Model Results: # # estimate      se    zval    pval   ci.lb   ci.ub #   0.2598  0.0380  6.8366  <.0001  0.1853  0.3343 # fit a fixed-effects model using the sample sizes as weights res <- rma(yi, vi, data=dat, method=\"FE\", weights=ni) res  # Fixed-Effects Model (k = 48) # # I^2 (total heterogeneity / total variability):   56.12% # H^2 (total variability / sampling variability):  2.28 # # Test for Heterogeneity: # Q(df = 47) = 107.1061, p-val < .0001 # # Model Results: # # estimate      se    zval    pval   ci.lb   ci.ub #   0.1719  0.0269  6.3802  <.0001  0.1191  0.2248"},{"path":"/reference/misc-models.html","id":"random-effects-model","dir":"Reference","previous_headings":"","what":"Random-Effects Model","title":"Fixed-Effects and Random-Effects Models in Meta-Analysis  — misc-models","text":"random-effects model condition true effects/outcomes. Instead, \\(k\\) studies included meta-analysis assumed random sample larger population studies. rare cases, studies included meta-analysis actually sampled larger collection studies. typically, efforts made find include relevant studies providing evidence phenomenon interest hence population studies hypothetical population essentially infinite set studies comprising studies conducted, conducted, may conducted future. assume \\(\\theta_i \\sim N(\\mu, \\tau^2)\\), , true effects/outcomes population studies normally distributed \\(\\mu\\) denoting average true effect/outcome \\(\\tau^2\\) variance true effects/outcomes population (\\(\\tau^2\\) therefore often referred amount ‘heterogeneity’ true effects/outcomes). random-effects model can also written \\[y_i = \\mu + u_i + \\epsilon_i,\\] \\(u_i \\sim N(0, \\tau^2)\\) \\(\\epsilon_i \\sim N(0, v_i)\\). fitted model provides estimates \\(\\mu\\) \\(\\tau^2\\). Consequently, random-effects model provides unconditional inference average true effect/outcome population studies (\\(k\\) studies included meta-analysis assumed random sample). Fitting random-effects model example data yields: value shown estimate now estimate average true standardized mean difference studies population studies 48 studies included dataset come (.e., \\(\\hat{\\mu}_w = 0.22\\)). using weighted estimation context random-effects model, model fitted weights equal \\(w_i = 1/(\\tau^2 + v_i)\\), \\(\\tau^2\\) replaced estimate (default rma.uni method set one possible choices estimating \\(\\tau^2\\)). One can also choose unweighted estimation context random-effects model (weighted=FALSE) specify user-defined weights (via weights), although parameter estimated (.e., \\(\\mu\\)) remains regardless estimation method weights used (opposed fixed-effect model, parameter estimated different weighted versus unweighted estimation using different weights standard inverse-variance weights). Since weighted estimation inverse-variance weights efficient, usually preferred random-effects models (fixed-effect model case, must carefully consider whether \\(\\bar{\\theta}_w\\) \\(\\bar{\\theta}_u\\) meaningful parameter estimate).","code":"# fit a random-effects model (note: method=\"REML\" is the default) res <- rma(yi, vi, data=dat) res  # Random-Effects Model (k = 48; tau^2 estimator: REML) # # tau^2 (estimated amount of total heterogeneity): 0.0499 (SE = 0.0197) # tau (square root of estimated tau^2 value):      0.2235 # I^2 (total heterogeneity / total variability):   58.37% # H^2 (total variability / sampling variability):  2.40 # # Test for Heterogeneity: # Q(df = 47) = 107.1061, p-val < .0001 # # Model Results: # # estimate      se    zval    pval   ci.lb   ci.ub #   0.2219  0.0460  4.8209  <.0001  0.1317  0.3122"},{"path":"/reference/misc-models.html","id":"conditional-versus-unconditional-inferences","dir":"Reference","previous_headings":"","what":"Conditional versus Unconditional Inferences","title":"Fixed-Effects and Random-Effects Models in Meta-Analysis  — misc-models","text":"Contrary often stated literature, important realize fixed-effects model assume true effects/outcomes homogeneous (.e., \\(\\theta_i\\) equal common value \\(\\theta\\) \\(k\\) studies). words, fixed-effects model provides perfectly valid inferences heterogeneity, long one restricting inferences set studies included meta-analysis one realizes model provide estimate \\(\\theta\\) \\(\\mu\\), \\(\\bar{\\theta}_w\\) \\(\\bar{\\theta}_u\\) (depending estimation method used). However, inferences conditional included studies. therefore permissible generalize inferences beyond set studies included meta-analysis. contrast, random-effects model provides unconditional inferences therefore allows generalization beyond set included studies, although population studies can generalize typically vaguely defined (since included studies proper random sample specified sampling frame). Instead, simply must assume included studies representative sample population population generalizing. Leaving aside issue, implies nothing wrong fitting fixed- random-effects models data, since models address inherently different questions (.e., average effect studies conducted included meta-analysis versus average effect larger population studies?).","code":""},{"path":"/reference/misc-models.html","id":"equal-effects-model","dir":"Reference","previous_headings":"","what":"Equal-Effects Model","title":"Fixed-Effects and Random-Effects Models in Meta-Analysis  — misc-models","text":"special case true effects/outcomes actually homogeneous (equal-effects case), distinction fixed- random-effects models disappears, since homogeneity implies \\(\\mu = \\bar{\\theta}_w = \\bar{\\theta}_u \\equiv \\theta\\). Therefore, one belives true effects/outcomes homogeneous, one can fit equal-effects model (using weighted estimation), since provide efficient estimate \\(\\theta\\) (note true effects/outcomes really homogeneous fit random-effects model, can happen estimate \\(\\tau^2\\) actually larger 0, leads loss efficiency). However, since infallible method test whether true effects/outcomes really homogeneous , researcher decide type inference desired examining data choose model accordingly. Note fitting equal-effects model (method=\"EE\") yields exact output fitting fixed-effects model, since equations used fit two models identical. However, interpretation results different. fit equal-effects model, make assumption true effects homogeneous , believe assumption justified, can interpret estimate estimate true effect. hand, reject homogeneity assumption, reject model altogether. contrast, fit fixed-effects model, assume homogeneity instead interpret estimate estimate (weighted) average true effect included studies.","code":""},{"path":"/reference/misc-models.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fixed-Effects and Random-Effects Models in Meta-Analysis  — misc-models","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/misc-models.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fixed-Effects and Random-Effects Models in Meta-Analysis  — misc-models","text":"Cooper, H., Hedges, L. V., & Valentine, J. C. (Eds.) (2009). handbook research synthesis meta-analysis (2nd ed.). New York: Russell Sage Foundation. Hedges, L. V., & Vevea, J. L. (1998). Fixed- random-effects models meta-analysis. Psychological Methods, 3(4), 486--504. https://doi.org/10.1037/1082-989X.3.4.486 Laird, N. M., & Mosteller, F. (1990). statistical methods combining experimental results. International Journal Technology Assessment Health Care, 6(1), 5--30. https://doi.org/10.1017/S0266462300008916 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":"/reference/misc-options.html","id":null,"dir":"Reference","previous_headings":"","what":"Miscellaneous Options and Features — misc-options","title":"Miscellaneous Options and Features — misc-options","text":"page documents miscellaneous options features fit well elsewhere.","code":""},{"path":[]},{"path":[]},{"path":"/reference/misc-options.html","id":"controlling-the-number-of-digits-in-the-output","dir":"Reference","previous_headings":"","what":"Controlling the Number of Digits in the Output","title":"Miscellaneous Options and Features — misc-options","text":"Many functions metafor package digits argument, can used control number digits displayed output printing numeric values. control displayed output, one can set argument named vector form: elements control displayed number digits various aspects output, namely: est estimates (e.g., effect sizes, model coefficients, predicted values), se standard errors, test test statistics, pval p-values, ci confidence/prediction interval bounds, var sampling variances variance components, sevar standard errors thereof, fit fit statistics, het heterogeneity statistics. Instead setting argument function call (tedious), one can also create vector named .digits workspace (beginning analysis script) : controls displayed output. values elements shown sensible choice analyzing various types standardized effect size measures.","code":"digits=c(est=2, se=3, test=2, pval=3, ci=2, var=3, sevar=3, fit=3, het=3) .digits <- c(est=2, se=3, test=2, pval=3, ci=2, var=3, sevar=3, fit=3, het=3)"},{"path":"/reference/misc-options.html","id":"styled-output-with-the-crayon-package","dir":"Reference","previous_headings":"","what":"Styled Output with the crayon Package","title":"Miscellaneous Options and Features — misc-options","text":"crayon package provides way create colored output. metafor package designed automatically make use feature crayon package installed loaded (library(crayon)). Note works terminals support ‘ANSI’ color highlight codes (e.g., RGui Windows R.app macOS, RStudio console modern terminals support ). default color theme used quite plain, work light dark colored background. One can modify color theme creating object workspace named .mtheme, list whose elements specify styles various parts output (see examples documentation crayon package syntax specify styles). following elements recognized: header header tables (underlined default), body1 odd numbered rows body tables, body2 even numbered rows body tables, na missing values tables, section section headers (bold default), text descriptive text output, result corresponding result(s), stop errors (bold red default), warning warnings (yellow default), message messages (green default), verbose text verbose output (cyan default), legend legends (gray default). Elements specified styled according defaults. example, one use: light dark colored background, respectively. slightly colorful theme : light dark colored background, respectively. following code snippet includes output elements (except error) can used test chosen color theme: example, using color scheme (light colored background), output look like : Support 256 different colors formatting underlined bold text differs across terminals.","code":".mstyle <- list(header=combine_styles(\"gray20\", \"underline\"),                 body1=make_style(\"gray40\"),                 body2=make_style(\"gray40\"),                 na=bold,                 section=combine_styles(\"gray15\", \"bold\"),                 text=make_style(\"gray50\"),                 result=make_style(\"gray30\")) .mstyle <- list(header=combine_styles(\"gray80\", \"underline\"),                 body1=make_style(\"gray60\"),                 body2=make_style(\"gray60\"),                 na=bold,                 section=combine_styles(\"gray85\", \"bold\"),                 text=make_style(\"gray50\"),                 result=make_style(\"gray70\")) .mstyle <- list(header=combine_styles(\"snow\", make_style(\"royalblue4\", bg=TRUE)),                 body1=combine_styles(\"gray20\", make_style(\"gray95\", bg=TRUE)),                 body2=combine_styles(\"gray20\", make_style(\"gray85\", bg=TRUE)),                 na=combine_styles(\"red4\", \"bold\"),                 section=combine_styles(\"black\", \"bold\", make_style(\"lightskyblue\", bg=TRUE)),                 text=make_style(\"gray50\"),                 result=make_style(\"blue\")) .mstyle <- list(header=combine_styles(\"snow\", make_style(\"royalblue4\", bg=TRUE)),                 body1=combine_styles(\"gray95\", make_style(\"gray20\", bg=TRUE)),                 body2=combine_styles(\"gray95\", make_style(\"gray30\", bg=TRUE)),                 na=combine_styles(\"orange1\", \"bold\"),                 section=combine_styles(\"white\", \"bold\", make_style(\"blue\", bg=TRUE)),                 text=make_style(\"steelblue4\"),                 result=make_style(\"steelblue1\")) # calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg,                             ci=cpos, di=cneg, data=dat.bcg) dat$yi[1] <- NA # set one estimate to missing so we get a warning below dat  # fit random-effects model res <- rma(yi, vi, mods = ~ ablat, data=dat, verbose=3) summary(res)"},{"path":"/reference/misc-options.html","id":"removing-empty-lines-before-and-after-the-output","dir":"Reference","previous_headings":"","what":"Removing Empty Lines Before and After the Output","title":"Miscellaneous Options and Features — misc-options","text":"printing output, empty line usually added output. compact output, can suppressed creating object named .rmspace workspace. example, running following code: shows difference.","code":"# calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg,                             ci=cpos, di=cneg, data=dat.bcg)  # fit random-effects model res <- rma(yi, vi, data=dat) res  .rmspace <- TRUE res"},{"path":"/reference/misc-options.html","id":"version-check","dir":"Reference","previous_headings":"","what":"Version Check","title":"Miscellaneous Options and Features — misc-options","text":"loading metafor package interactive session, automatic check run compare version number installed package one available CRAN. installed version older one available CRAN, user notified new version available. check can suppressed setting environment variable METAFOR_VERSION_CHECK FALSE (e.g., Sys.setenv(METAFOR_VERSION_CHECK=FALSE)). setting environment variable \"devel\" (e.g., Sys.setenv(METAFOR_VERSION_CHECK=\"devel\")), version check run ‘development version’ available GitHub.","code":""},{"path":"/reference/misc-options.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Miscellaneous Options and Features — misc-options","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/misc-options.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Miscellaneous Options and Features — misc-options","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":"/reference/model.matrix.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Model Matrix for 'rma' Objects — model.matrix.rma","title":"Model Matrix for 'rma' Objects — model.matrix.rma","text":"function extracts model matrix objects class \"rma\".","code":""},{"path":"/reference/model.matrix.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model Matrix for 'rma' Objects — model.matrix.rma","text":"","code":"# S3 method for rma model.matrix(object, ...)"},{"path":"/reference/model.matrix.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model Matrix for 'rma' Objects — model.matrix.rma","text":"object object class \"rma\". ... arguments.","code":""},{"path":"/reference/model.matrix.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model Matrix for 'rma' Objects — model.matrix.rma","text":"model matrix.","code":""},{"path":"/reference/model.matrix.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Model Matrix for 'rma' Objects — model.matrix.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/model.matrix.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Model Matrix for 'rma' Objects — model.matrix.rma","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/model.matrix.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model Matrix for 'rma' Objects — model.matrix.rma","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit mixed-effects model with absolute latitude and publication year as moderators res <- rma(yi, vi, mods = ~ ablat + year, data=dat)  ### extract the model matrix model.matrix(res) #>    intrcpt ablat year #> 1        1    44 1948 #> 2        1    55 1949 #> 3        1    42 1960 #> 4        1    52 1977 #> 5        1    13 1973 #> 6        1    44 1953 #> 7        1    19 1973 #> 8        1    13 1980 #> 9        1    27 1968 #> 10       1    42 1961 #> 11       1    18 1974 #> 12       1    33 1969 #> 13       1    33 1976"},{"path":"/reference/permutest.html","id":null,"dir":"Reference","previous_headings":"","what":"Permutation Tests for 'rma.uni' Objects — permutest","title":"Permutation Tests for 'rma.uni' Objects — permutest","text":"function carries permutation tests objects class \"rma.uni\".","code":""},{"path":"/reference/permutest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Permutation Tests for 'rma.uni' Objects — permutest","text":"","code":"permutest(x, ...)  # S3 method for rma.uni permutest(x, exact=FALSE, iter=1000, permci=FALSE,           progbar=TRUE, retpermdist=FALSE, digits, control, ...)"},{"path":"/reference/permutest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Permutation Tests for 'rma.uni' Objects — permutest","text":"x object class \"rma.uni\". exact logical specify whether exact permutation test carried (default FALSE). See ‘Details’. iter integer specify number iterations permutation test exact test (default 1000 iterations). permci logical specify whether permutation-based CIs also calculated (default FALSE). Can also vector indices specify coefficients permutation-based CI obtained. progbar logical specify whether progress bar shown (default TRUE). retpermdist logical specify whether permutation distributions test statistics returned (default FALSE). digits optional integer specify number decimal places printed results rounded. unspecified, default take value object. control list control values numerical comparisons (comptol) uniroot (.e., tol maxiter). latter relevant permci=TRUE. See ‘Note’. ... arguments.","code":""},{"path":"/reference/permutest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Permutation Tests for 'rma.uni' Objects — permutest","text":"models without moderators, permutation test carried permuting signs observed effect sizes outcomes. (two-sided) p-value permutation test equal proportion times absolute value test statistic permuted data extreme extreme actually observed data. See Follmann Proschan (1999) details. models moderators, permutation test carried permuting rows model matrix (.e., \\(X\\)). (two-sided) p-value particular model coefficient equal proportion times absolute value test statistic coefficient permuted data extreme extreme actually observed data. Similarly, omnibus test, p-value proportion times test statistic omnibus test extreme extreme actually observed one. See Higgins Thompson (2004) Viechtbauer et al. (2015) details. exact=TRUE, function try carry exact permutation test. exact permutation test requires fitting model possible permutation . However, number possible permutations increases rapidly number outcomes/studies (.e., \\(k\\)). models without moderators, \\(2^k\\) possible permutations signs. Therefore, \\(k=5\\), 32 possible permutations, \\(k=10\\), already 1024, \\(k=20\\), one million permutations signs. models moderators, increase number possible permutations may even severe. total number possible permutations model matrix \\(k!\\). Therefore, \\(k=5\\), 120 possible permutations, \\(k=10\\), 3,628,800, \\(k=20\\), \\(10^{18}\\) permutations model matrix. Therefore, going possible permutations may become infeasible. Instead using exact permutation test, one can set exact=FALSE (also default). case, function approximates exact permutation-based p-value(s) going smaller number (specified iter argument) random permutations. Therefore, running function twice data can yield (slightly) different p-values. Setting iter sufficiently large ensures results become stable. Note exact=FALSE iter actually larger number iterations required exact permutation test, exact test carried . models moderators, exact permutation test actually requires fitting model unique permutation model matrix. number unique permutations smaller \\(k!\\) model matrix contains recurring rows. may case including categorical moderators (.e., factors) model quantitative moderators included model can take small number unique values. exact=TRUE, function therefore uses algorithm restrict test unique permutations model matrix, may make use exact test feasible even \\(k\\) large. using random permutations, function ensures first permutation always correspond original data. avoids p-values equal 0. permci=TRUE, function also tries obtain permutation-based CIs model coefficient(s). done shifting observed effect sizes outcomes amount finding extreme values amount permutation-based test just lead non-rejection. computationally expensive may take long time complete. models moderators, one can also set permci vector indices specify coefficient(s) permutation-based CI obtained. algorithm fails determine particular CI bound, shown NA output.","code":""},{"path":"/reference/permutest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Permutation Tests for 'rma.uni' Objects — permutest","text":"object class \"permutest.rma.uni\". object list containing following components: pval p-value(s) based permutation test. QMp p-value omnibus test moderators based permutation test. zval.perm values test statistics coefficients various permutations (retpermdist=TRUE). b.perm model coefficients various permutations (retpermdist=TRUE). QM.perm test statistic omnibus test moderators various permutations (retpermdist=TRUE). ci.lb lower bound confidence intervals coefficients (permutation-based permci=TRUE). ci.ub upper bound confidence intervals coefficients (permutation-based permci=TRUE). ... additional elements/values passed . results formatted printed print function. One can also use coef obtain table model coefficients, corresponding standard errors, test statistics, p-values, confidence interval bounds.","code":""},{"path":"/reference/permutest.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Permutation Tests for 'rma.uni' Objects — permutest","text":"p-values obtained permutation tests reach conventional levels statistical significance (.e., \\(p \\le .05\\)) \\(k\\) small. particular, models without moderators, smallest possible (two-sided) p-value .0625 \\(k=5\\) .03125 \\(k=6\\). Therefore, permutation test able reject null hypothesis \\(\\alpha=.05\\) \\(k\\) least equal 6. models moderators, smallest possible (two-sided) p-value particular model coefficient .0833 \\(k=4\\) .0167 \\(k=5\\) (assuming row model matrix unique). Therefore, permutation test able reject null hypothesis \\(\\alpha=.05\\) \\(k\\) least equal 5. Consequently, permutation-based CIs can also obtained \\(k\\) sufficiently large. number permutations required exact test large essentially indistinguishable infinity (e.g., factorial(200)), function terminate error. Determining whether test statistic permuted data extreme extreme actually observed data requires making >= <= comparisons. avoid problems due finite precision computers generally represent numbers, function uses numerical tolerance (control argument comptol, set equal .Machine$double.eps^0.5 default) making comparisons (e.g., instead sqrt(3)^2 - 3 >= 0, may evaluate FALSE, can use sqrt(3)^2 - 3 >= 0 - .Machine$double.eps^0.5, evaluate TRUE). obtaining permutation-based CIs, function makes use uniroot. default, desired accuracy set equal .Machine$double.eps^0.25 maximum number iterations 100. desired accuracy maximum number iterations can adjusted control argument (.e., control=list(tol=value, maxiter=value)).","code":""},{"path":"/reference/permutest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Permutation Tests for 'rma.uni' Objects — permutest","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/permutest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Permutation Tests for 'rma.uni' Objects — permutest","text":"Follmann, D. ., & Proschan, M. . (1999). Valid inference random effects meta-analysis. Biometrics, 55(3), 732--737. https://doi.org/10.1111/j.0006-341x.1999.00732.x Good, P. . (2009). Permutation, parametric, bootstrap tests hypotheses (3rd ed.). New York: Springer. Higgins, J. P. T., & Thompson, S. G. (2004). Controlling risk spurious findings meta-regression. Statistics Medicine, 23(11), 1663--1682. https://doi.org/10.1002/sim.1752 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03 Viechtbauer, W., López-López, J. ., Sánchez-Meca, J., & Marín-Martínez, F. (2015). comparison procedures test moderators mixed-effects meta-regression models. Psychological Methods, 20(3), 360--374. https://doi.org/10.1037/met0000023","code":""},{"path":[]},{"path":"/reference/permutest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Permutation Tests for 'rma.uni' Objects — permutest","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### random-effects model res <- rma(yi, vi, data=dat) res #>  #> Random-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.3132 (SE = 0.1664) #> tau (square root of estimated tau^2 value):      0.5597 #> I^2 (total heterogeneity / total variability):   92.22% #> H^2 (total variability / sampling variability):  12.86 #>  #> Test for Heterogeneity: #> Q(df = 12) = 152.2330, p-val < .0001 #>  #> Model Results: #>  #> estimate      se     zval    pval    ci.lb    ci.ub     ​  #>  -0.7145  0.1798  -3.9744  <.0001  -1.0669  -0.3622  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   # \\dontrun{ ### permutation test (approximate and exact) set.seed(1234) # for reproducibility permutest(res) #> Running 1000 iterations for approximate permutation test. #>  #> Model Results: #>  #> estimate      se     zval   pval¹    ci.lb    ci.ub    ​  #>  -0.7145  0.1798  -3.9744  0.0020  -1.0669  -0.3622  **  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> 1) p-value based on permutation testing #>  permutest(res, exact=TRUE)# } #> Running 8192 iterations for exact permutation test. #>  #> Model Results: #>  #> estimate      se     zval   pval¹    ci.lb    ci.ub    ​  #>  -0.7145  0.1798  -3.9744  0.0015  -1.0669  -0.3622  **  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> 1) p-value based on permutation testing #>   ### mixed-effects model with two moderators (absolute latitude and publication year) res <- rma(yi, vi, mods = ~ ablat + year, data=dat) res #>  #> Mixed-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.1108 (SE = 0.0845) #> tau (square root of estimated tau^2 value):             0.3328 #> I^2 (residual heterogeneity / unaccounted variability): 71.98% #> H^2 (unaccounted variability / sampling variability):   3.57 #> R^2 (amount of heterogeneity accounted for):            64.63% #>  #> Test for Residual Heterogeneity: #> QE(df = 10) = 28.3251, p-val = 0.0016 #>  #> Test of Moderators (coefficients 2:3): #> QM(df = 2) = 12.2043, p-val = 0.0022 #>  #> Model Results: #>  #>          estimate       se     zval    pval     ci.lb    ci.ub    ​  #> intrcpt   -3.5455  29.0959  -0.1219  0.9030  -60.5724  53.4814      #> ablat     -0.0280   0.0102  -2.7371  0.0062   -0.0481  -0.0080  **  #> year       0.0019   0.0147   0.1299  0.8966   -0.0269   0.0307      #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### permutation test (approximate only; exact not feasible) # \\dontrun{  set.seed(1234) # for reproducibility permres <- permutest(res, iter=10000, retpermdist=TRUE) #> Running 10000 iterations for approximate permutation test. permres #>  #> Test of Moderators (coefficients 2:3):¹ #> QM(df = 2) = 12.2043, p-val = 0.0237 #>  #> Model Results: #>  #>          estimate       se     zval   pval¹     ci.lb    ci.ub   ​  #> intrcpt   -3.5455  29.0959  -0.1219  0.9104  -60.5724  53.4814     #> ablat     -0.0280   0.0102  -2.7371  0.0175   -0.0481  -0.0080  *  #> year       0.0019   0.0147   0.1299  0.9037   -0.0269   0.0307     #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> 1) p-values based on permutation testing #>   ### histogram of permutation distribution for absolute latitude ### dashed horizontal line: the observed value of the test statistic ### red curve: standard normal density ### blue curve: kernel density estimate of the permutation distribution ### note that the tail area under the permutation distribution is larger ### than under a standard normal density (hence, the larger p-value) hist(permres$zval.perm[,2], breaks=120, freq=FALSE, xlim=c(-5,5), ylim=c(0,.4),      main=\"Permutation Distribution\", xlab=\"Value of Test Statistic\", col=\"gray90\") abline(v=res$zval[2], lwd=2, lty=\"dashed\") abline(v=0, lwd=2) curve(dnorm, from=-5, to=5, add=TRUE, lwd=2, col=rgb(1,0,0,alpha=.7)) lines(density(permres$zval.perm[,2]), lwd=2, col=rgb(0,0,1,alpha=.7))  # }"},{"path":"/reference/plot.cumul.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Method for 'cumul.rma' Objects — plot.cumul.rma","title":"Plot Method for 'cumul.rma' Objects — plot.cumul.rma","text":"Plot method objects class \"cumul.rma\".","code":""},{"path":"/reference/plot.cumul.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Method for 'cumul.rma' Objects — plot.cumul.rma","text":"","code":"# S3 method for cumul.rma plot(x, yaxis, xlim, ylim, xlab, ylab,      at, transf, atransf, targs, digits, cols=c(\"gray80\",\"gray10\"),      grid=TRUE, pch=19, cex=1, lwd=2, ...)"},{"path":"/reference/plot.cumul.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Method for 'cumul.rma' Objects — plot.cumul.rma","text":"x object class \"cumul.rma\" obtained cumul. yaxis either \"tau2\", \"I2\", \"H2\" indicate values placed y-axis. See ‘Details’. xlim x-axis limits. unspecified, function tries set x-axis limits sensible values. ylim y-axis limits. unspecified, function tries set y-axis limits sensible values. xlab title x-axis. unspecified, function tries set appropriate axis title. ylab title y-axis. unspecified, function tries set appropriate axis title. position x-axis tick marks corresponding labels. unspecified, function tries set tick mark positions/labels sensible values. transf optional argument specify function used transform summary estimates (e.g., transf=exp; see also transf). unspecified, transformation used. atransf optional argument specify function used transform x-axis labels (e.g., atransf=exp; see also transf). unspecified, transformation used. targs optional arguments needed function specified via transf atransf. digits optional integer specify number decimal places tick mark labels x- y-axis rounded. Can also vector two integers, first specify number decimal places x-axis, second y-axis labels (e.g., digits=c(2,3)). unspecified, function tries set argument sensible values. cols vector two colors use visualizing order cumulative results. grid logical specify whether grid added plot (can also color name). pch plotting symbol use. default, filled circle used. See points options. cex symbol expansion factor. lwd line width. ... arguments.","code":""},{"path":"/reference/plot.cumul.rma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Method for 'cumul.rma' Objects — plot.cumul.rma","text":"function can used visualize results cumulative meta-analysis obtained cumul function. plot shows model estimate (.e., estimated overall/average outcome) x-axis measure heterogeneity y-axis cumulative order results \"cumul.rma\" object. default, \\(\\tau^2\\) shown y-axis random-effects model \\(^2\\) otherwise, one can also use argument yaxis specify measure heterogeneity place y-axis. color gradient points/lines indicates order cumulative results (default, light gray beginning, dark gray end). different set colors can chosen via cols argument. See ‘Examples’.","code":""},{"path":"/reference/plot.cumul.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Method for 'cumul.rma' Objects — plot.cumul.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/plot.cumul.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot Method for 'cumul.rma' Objects — plot.cumul.rma","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/plot.cumul.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Method for 'cumul.rma' Objects — plot.cumul.rma","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### random-effects model res <- rma(yi, vi, data=dat)  ### cumulative meta-analysis (in the order of publication year) sav <- cumul(res, transf=exp, order=dat$year)  ### plot of model estimate and tau^2 over time plot(sav)   ### illustrate some other plot options plot(sav, yaxis=\"I2\", ylim=c(0,100), atransf=exp, at=log(seq(1.3, 1.6, by=.1)),      lwd=5, cex=1.5, cols=c(\"green\",\"blue\",\"red\"))"},{"path":"/reference/plot.gosh.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Method for 'gosh.rma' Objects — plot.gosh.rma","title":"Plot Method for 'gosh.rma' Objects — plot.gosh.rma","text":"Plot method objects class \"gosh.rma\".","code":""},{"path":"/reference/plot.gosh.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Method for 'gosh.rma' Objects — plot.gosh.rma","text":"","code":"# S3 method for gosh.rma plot(x, het=\"I2\", pch=16, cex=0.5, out, col, alpha, border,      xlim, ylim, xhist=TRUE, yhist=TRUE, hh=0.3, breaks,      adjust, lwd, labels, ...)"},{"path":"/reference/plot.gosh.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Method for 'gosh.rma' Objects — plot.gosh.rma","text":"x object class \"gosh.rma\" obtained gosh. het character string specify heterogeneity measure plot. Either \"I2\", \"H2\", \"QE\", \"tau2\" (last random/mixed-effects models). pch plotting symbol use. default, borderless filled circle used. See points options. cex symbol expansion factor. optional integer specify number study may potential outlier. specified, subsets containing specified study drawn different color containing study. col optional character string specify name color use points (provided, points drawn black). used, two colors specified (provided, red used subsets containing specified study blue otherwise). alpha optional alpha transparency value points (0 means fully transparent 1 means opaque). unspecified, function tries set sensible value. border optional character string specify name color use borders histogram (provided, borders drawn white). Set FALSE omit borders. xlim x-axis limits. unspecified, function tries set x-axis limits sensible values. ylim y-axis limits. unspecified, function tries set y-axis limits sensible values. xhist logical specify whether histogram drawn x-axis (default TRUE). yhist logical specify whether histogram drawn y-axis (default TRUE). hh optional numeric value (vector two values) adjust height histogram(s). Must 0 1, close 0 1, otherwise plot drawn. breaks optional argument passed hist choosing (number ) breakpoints histogram(s). adjust optional argument passed density adjusting bandwidth kernel density estimate(s) (values larger 1 result smoothing). lwd optional numeric value specify line width estimated densities. Set 0 omit line(s). labels optional argument specify x-axis y-axis labels (passed pairs specify names variables scatter plot matrix). ... arguments.","code":""},{"path":"/reference/plot.gosh.rma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Method for 'gosh.rma' Objects — plot.gosh.rma","text":"models without moderators, function draws scatter plot model estimates x-axis chosen measure heterogeneity y-axis. Histograms respective distributions (kernel density estimates superimposed) shown margins (xhist=TRUE yhist=TRUE). models moderators, function draws scatter plot matrix (pairs function) chosen measure heterogeneity model coefficients. Histograms variables plotted shown along diagonal, kernel density estimates distributions superimposed. Arguments xlim, ylim, xhist, yhist ignored (argument hh can used compress/stretch height distributions shown along diagonal).","code":""},{"path":"/reference/plot.gosh.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Method for 'gosh.rma' Objects — plot.gosh.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/plot.gosh.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot Method for 'gosh.rma' Objects — plot.gosh.rma","text":"Olkin, ., Dahabreh, . J., & Trikalinos, T. . (2012). GOSH - graphical display study heterogeneity. Research Synthesis Methods, 3(3), 214--223. https://doi.org/10.1002/jrsm.1053 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03 Viechtbauer, W. (2021). Model checking meta-analysis. C. H. Schmid, T. Stijnen, & . R. White (Eds.), Handbook meta-analysis (pp. 219--254). Boca Raton, FL: CRC Press. https://doi.org/10.1201/9781315119403","code":""},{"path":[]},{"path":"/reference/plot.gosh.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Method for 'gosh.rma' Objects — plot.gosh.rma","text":"","code":"### calculate log odds ratios and corresponding sampling variances dat <- escalc(measure=\"OR\", ai=ai, n1i=n1i, ci=ci, n2i=n2i, data=dat.egger2001)  ### meta-analysis of all trials including ISIS-4 using an equal-effects model res <- rma(yi, vi, data=dat, method=\"EE\")  ### fit FE model to all possible subsets (65535 models) # \\dontrun{ sav <- gosh(res, progbar=FALSE)  ### create GOSH plot ### red points for subsets that include and blue points ### for subsets that exclude study 16 (the ISIS-4 trial) plot(sav, out=16, breaks=100)# }"},{"path":"/reference/plot.infl.rma.uni.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Method for 'infl.rma.uni' Objects — plot.infl.rma.uni","title":"Plot Method for 'infl.rma.uni' Objects — plot.infl.rma.uni","text":"Plot method objects class \"infl.rma.uni\".","code":""},{"path":"/reference/plot.infl.rma.uni.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Method for 'infl.rma.uni' Objects — plot.infl.rma.uni","text":"","code":"# S3 method for infl.rma.uni plot(x, plotinf=TRUE, plotdfbs=FALSE, dfbsnew=FALSE, logcov=TRUE,      layout, slab.style=1, las=0, pch=21, bg=\"black\",      bg.infl=\"red\", col.na=\"lightgray\", ...)"},{"path":"/reference/plot.infl.rma.uni.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Method for 'infl.rma.uni' Objects — plot.infl.rma.uni","text":"x object class \"infl.rma.uni\" obtained influence. plotinf logical specify whether various case diagnostics plotted (default TRUE). Can also vector 8 integers specify plots draw. See ‘Details’ numbers corresponding various plots. plotdfbs logical specify whether DFBETAS values plotted (default FALSE). Can also vector integers specify coefficient(s) plot DFBETAS values. dfbsnew logical specify whether new device opened plotting DFBETAS values (default FALSE). logcov logical specify whether covariance ratios plotted log scale (default TRUE). layout optional vector two numbers specify number rows columns layout figure. slab.style integer indicate style x-axis labels: 1 = study number, 2 = study label, 3 = abbreviated study label. Note study labels, even abbreviated, may long fit margins.) las integer 0 3 specify alignment axis labels (see par). useful alternative 0 3, x-axis labels drawn vertical axis. pch plotting symbol use. default, filled circle used. See points options. bg color use filling plotting symbol (default \"black\"). bg.infl color use filling plotting symbol point considered influential (default \"red\"). col.na color use lines connecting two points NA values (default \"lightgray\"). ... arguments.","code":""},{"path":"/reference/plot.infl.rma.uni.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Method for 'infl.rma.uni' Objects — plot.infl.rma.uni","text":"plotinf=TRUE, function plots (1) externally standardized residuals, (2) DFFITS values, (3) Cook's distances, (4) covariance ratios, (5) leave-one-\\(\\tau^2\\) estimates, (6) leave-one-(residual) heterogeneity test statistics, (7) hat values, (8) weights. plotdfbs=TRUE, DFBETAS values also plotted either confirming page change (dfbsnew=FALSE) separate device (dfbsnew=TRUE). case (typically synonymous study) may considered ‘influential’ least one following true: absolute DFFITS value larger \\(3 \\times \\sqrt{p/(k-p)}\\), \\(p\\) number model coefficients \\(k\\) number cases. lower tail area chi-square distribution \\(p\\) degrees freedom cut Cook's distance larger 50%. hat value larger \\(3 \\times (p/k)\\). DFBETAS value larger \\(1\\). Cases considered influential respect measures indicated color specified bg.infl argument (default \"red\"). cut-offs described indicated plot horizontal reference lines. addition, plot externally standardized residuals, horizontal reference lines drawn -1.96, 0, 1.96. plot hat values, horizontal reference line drawn \\(p/k\\). Since sum hat values equal \\(p\\), value \\(p/k\\) indicates equal hat values \\(k\\) cases. Finally, plot weights, horizontal reference line drawn \\(100/k\\), corresponding value equal weights (%) \\(k\\) cases. Note weights automatically equal using unweighted model fitting. Also, hat values equal weights values (except scaling) models without moderators. chosen cut-offs (somewhat) arbitrary. Substantively informed judgment always used examining influence case results.","code":""},{"path":"/reference/plot.infl.rma.uni.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Method for 'infl.rma.uni' Objects — plot.infl.rma.uni","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/plot.infl.rma.uni.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot Method for 'infl.rma.uni' Objects — plot.infl.rma.uni","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03 Viechtbauer, W., & Cheung, M. W.-L. (2010). Outlier influence diagnostics meta-analysis. Research Synthesis Methods, 1(2), 112--125. https://doi.org/10.1002/jrsm.11","code":""},{"path":[]},{"path":"/reference/plot.infl.rma.uni.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Method for 'infl.rma.uni' Objects — plot.infl.rma.uni","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit mixed-effects model with absolute latitude and publication year as moderators res <- rma(yi, vi, mods = ~ ablat + year, data=dat)  ### compute the diagnostics inf <- influence(res)  ### plot the values plot(inf)   ### select which plots to show plot(inf, plotinf=1:4) plot(inf, plotinf=1:4, layout=c(4,1))   ### plot the DFBETAS values plot(inf, plotinf=FALSE, plotdfbs=TRUE)"},{"path":"/reference/plot.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Method for 'rma' Objects — plot.rma","title":"Plot Method for 'rma' Objects — plot.rma","text":"Plot method objects class \"rma.uni\", \"rma.mh\", \"rma.peto\", \"rma.glmm\".","code":""},{"path":"/reference/plot.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Method for 'rma' Objects — plot.rma","text":"","code":"# S3 method for rma.uni plot(x, qqplot=FALSE, ...)  # S3 method for rma.mh plot(x, qqplot=FALSE, ...)  # S3 method for rma.peto plot(x, qqplot=FALSE, ...)  # S3 method for rma.glmm plot(x, qqplot=FALSE, ...)"},{"path":"/reference/plot.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Method for 'rma' Objects — plot.rma","text":"x object class \"rma.uni\", \"rma.mh\", \"rma.peto\". method yet implemented objects class \"rma.glmm\". qqplot logical specify whether normal QQ plot drawn (default FALSE). ... arguments.","code":""},{"path":"/reference/plot.rma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Method for 'rma' Objects — plot.rma","text":"Four plots produced. model contain moderators, forest plot, funnel plot, radial plot, plot standardized residuals provided. qqplot=TRUE, last plot replaced normal QQ plot standardized residuals. model contains moderators, forest plot, funnel plot, plot standardized residuals fitted values, plot standardized residuals provided. qqplot=TRUE, last plot replaced normal QQ plot standardized residuals.","code":""},{"path":"/reference/plot.rma.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Plot Method for 'rma' Objects — plot.rma","text":"number studies large, forest plot may become difficult read due small font size. Stretching plotting device vertically provide space.","code":""},{"path":"/reference/plot.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Method for 'rma' Objects — plot.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/plot.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot Method for 'rma' Objects — plot.rma","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/plot.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Method for 'rma' Objects — plot.rma","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit random-effects model res <- rma(yi, vi, data=dat)  ### plot results plot(res, qqplot=TRUE)   ### fit mixed-effects model with absolute latitude and publication year as moderators res <- rma(yi, vi, mods = ~ ablat + year, data=dat)  ### plot results plot(res, qqplot=TRUE)"},{"path":"/reference/plot.rma.uni.selmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Method for 'plot.rma.uni.selmodel' Objects — plot.rma.uni.selmodel","title":"Plot Method for 'plot.rma.uni.selmodel' Objects — plot.rma.uni.selmodel","text":"Plot method objects class \"plot.rma.uni.selmodel\".","code":""},{"path":"/reference/plot.rma.uni.selmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Method for 'plot.rma.uni.selmodel' Objects — plot.rma.uni.selmodel","text":"","code":"# S3 method for rma.uni.selmodel plot(x, xlim, ylim, n=1000, prec=\"max\", scale=FALSE,       ci=FALSE, reps=1000, rug=TRUE, add=FALSE,       lty=c(\"solid\",\"dotted\"), lwd=c(2,1), ...)"},{"path":"/reference/plot.rma.uni.selmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Method for 'plot.rma.uni.selmodel' Objects — plot.rma.uni.selmodel","text":"x object class \"rma.uni.selmodel\" obtained selmodel. xlim x-axis limits. Essentially range p-values selection function drawn. unspecified, function sets limits automatically. ylim y-axis limits. unspecified, function sets limits automatically. n numeric value specify many p-values within x-axis limits function value computed (default 1000). prec either character string (options \"max\", \"min\", \"mean\", \"median\") numeric value. See ‘Details’. scale logical specify whether function values rescaled 0 1 range (default FALSE). ci logical specify whether confidence interval drawn around selection function (default FALSE). Can also string (options \"boot\" \"wald\"). See ‘Details’. reps numeric value specify number bootstrap samples draw generating confidence interval bounds (default 1000). rug logical specify whether observed p-values added tick marks x-axis (default TRUE). add logical specify whether function added existing plot (default FALSE). lty line types selection function confidence interval bounds. lwd line widths selection function confidence interval bounds. ... arguments.","code":""},{"path":"/reference/plot.rma.uni.selmodel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Method for 'plot.rma.uni.selmodel' Objects — plot.rma.uni.selmodel","text":"function can used draw estimated selection function based objects class \"plot.rma.uni.selmodel\". selection function incorporates measure precision (, strictly speaking, really measure imprecision), one can specify level precision selection function drawn. prec=\"max\", function drawn least precise study (maximum imprecision), prec=\"min\", function drawn precise study (minimum imprecision), prec=\"mean\" prec=\"median\" show function mean median level imprecision, respectively. Alternatively, one can specify numeric value argument prec specify precision value (prec=\"max\" corresponds prec=1 higher levels precision prec values 1). ci=TRUE (equivalently, ci=\"boot\"), confidence interval drawn around selection function. bounds interval generated using parametric bootstrapping, argument reps controlling number bootstrap samples draw generating confidence interval bounds. n reps large, constructing confidence interval can take moments complete. models selection function involves single \\(\\delta\\) parameter, one can also set ci=\"wald\", case confidence interval constructed based Wald-type CI \\(\\delta\\) parameter (much quicker using parametric bootstrapping). option also available step function models (even involve multiple \\(\\delta\\) parameters).","code":""},{"path":"/reference/plot.rma.uni.selmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Method for 'plot.rma.uni.selmodel' Objects — plot.rma.uni.selmodel","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/plot.rma.uni.selmodel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot Method for 'plot.rma.uni.selmodel' Objects — plot.rma.uni.selmodel","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/plot.rma.uni.selmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Method for 'plot.rma.uni.selmodel' Objects — plot.rma.uni.selmodel","text":"","code":"### copy data into 'dat' and examine data dat <- dat.hackshaw1998  ### fit random-effects model using the log odds ratios res <- rma(yi, vi, data=dat, method=\"ML\") res #>  #> Random-Effects Model (k = 37; tau^2 estimator: ML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.0204 (SE = 0.0165) #> tau (square root of estimated tau^2 value):      0.1427 #> I^2 (total heterogeneity / total variability):   27.62% #> H^2 (total variability / sampling variability):  1.38 #>  #> Test for Heterogeneity: #> Q(df = 36) = 47.4979, p-val = 0.0952 #>  #> Model Results: #>  #> estimate      se    zval    pval   ci.lb   ci.ub     ​  #>   0.2171  0.0486  4.4712  <.0001  0.1219  0.3123  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### fit step selection model sel1 <- selmodel(res, type=\"stepfun\", steps=c(0.05, 0.10, 0.50, 1.00))  ### plot selection function plot(sel1, scale=TRUE)  ### fit negative exponential selection model sel2 <- selmodel(res, type=\"negexp\")  ### add selection function to the existing plot plot(sel2, add=TRUE, col=\"blue\")   ### plot selection function with CI plot(sel1, ci=\"wald\")"},{"path":"/reference/predict.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Predicted Values for 'rma' Objects — predict.rma","title":"Predicted Values for 'rma' Objects — predict.rma","text":"function computes predicted values, corresponding standard errors, confidence intervals, prediction intervals objects class \"rma\".","code":""},{"path":"/reference/predict.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predicted Values for 'rma' Objects — predict.rma","text":"","code":"# S3 method for rma predict(object, newmods, intercept, tau2.levels, gamma2.levels, addx=FALSE,         level, digits, transf, targs, vcov=FALSE, ...)  # S3 method for rma.ls predict(object, newmods, intercept, addx=FALSE, newscale, addz=FALSE,         level, digits, transf, targs, vcov=FALSE, ...)"},{"path":"/reference/predict.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predicted Values for 'rma' Objects — predict.rma","text":"object object class \"rma\" \"rma.ls\". newmods optional vector matrix specify values moderator values predicted values calculated. See ‘Details’. intercept logical specify whether intercept included calculating predicted values newmods. unspecified, intercept automatically added original model also included intercept. tau2.levels vector specify levels inner factor computing prediction intervals. relevant models class \"rma.mv\" (see rma.mv) model includes single \\(\\tau^2\\) value. See ‘Details’. gamma2.levels vector specify levels inner factor computing prediction intervals. relevant models class \"rma.mv\" (see rma.mv) model includes single \\(\\gamma^2\\) value. See ‘Details’. addx logical specify whether values moderator variables added returned object. See ‘Examples’. newscale optional vector matrix specify values scale variables predicted values calculated. relevant location-scale models (see rma.uni). See ‘Details’. addz logical specify whether values scale variables added returned object. level numeric value 0 100 specify confidence prediction interval level. unspecified, default take value object. digits optional integer specify number decimal places printed results rounded. unspecified, default take value object. transf optional argument specify function used transform predicted values interval bounds (e.g., transf=exp; see also transf). unspecified, transformation used. targs optional arguments needed function specified transf. vcov logical specify whether variance-covariance matrix predicted values also returned (default FALSE). ... arguments.","code":""},{"path":"/reference/predict.rma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predicted Values for 'rma' Objects — predict.rma","text":"equal-effects model, predict(object) returns estimated (average) outcome set studies included meta-analysis. estimated intercept equal-effects model (.e., \\(\\hat{\\theta}\\)). random-effects model, predict(object) returns estimated (average) outcome hypothetical population studies set studies included meta-analysis assumed random selection. estimated intercept random-effects model (.e., \\(\\hat{\\mu}\\)). models including one moderators, predict(object) returns estimated (average) outcomes values moderator(s) equal \\(k\\) studies included meta-analysis (.e., ‘fitted values’ \\(k\\) studies). models including \\(p'\\) moderator variables, new moderator values (\\(k_{new}\\) hypothetical new studies) can specified setting newmods equal \\(k_{new} \\times p'\\) matrix corresponding new moderator values. model object included intercept, explicitly specified newmods, added default (unless one sets intercept=FALSE). Also, factors original model get turned appropriate contrast variables within rma function, newmods actually include values contrast variables. Examples shown . random/mixed-effects models, approximate prediction interval also calculated (Riley et al., 2011). interval estimates level % true effect sizes outcomes fall hypothetical population studies (hence true effect outcome new study population studies fall level % cases). random-effects models fitted rma.mv function, model may actually include multiple \\(\\tau^2\\) values (.e., random argument includes ‘~ inner | outer’ term struct=\"HCS\", struct=\"DIAG\", struct=\"HAR\", struct=\"UN\"). case, function provide prediction intervals level inner factor (since prediction intervals differ depending \\(\\tau^2\\) value). Alternatively, one can use tau2.levels argument specify level(s) prediction interval provided. model includes second ‘~ inner | outer’ term multiple \\(\\gamma^2\\) values, prediction intervals combination levels inner factors provided. Alternatively, one can use tau2.levels gamma2.levels arguments specify level combination(s) prediction interval provided. using newmods argument mixed-effects models fitted rma.mv function, model includes multiple \\(\\tau^2\\) (multiple \\(\\gamma^2\\)) values, one must use tau2.levels (gamma2.levels) argument specify levels inner factor(s) (.e., vector length \\(k_{new}\\)) obtain appropriate prediction interval(s). location-scale models fitted rma.uni function, one can use newmods specify values \\(p'\\) moderator variables included model newscale specify values \\(q'\\) scale variables included model. Whenever newmods specified, function computes predicted effects/outcomes specified moderators values. obtain corresponding prediction intervals, one must also specify corresponding newscale values. newscale specified (newmods), function computes predicted log-transformed \\(\\tau^2\\) values (using log link) specified scale values. setting transf=exp, one can obtain predicted \\(\\tau^2\\) values.","code":""},{"path":"/reference/predict.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predicted Values for 'rma' Objects — predict.rma","text":"object class \"list.rma\". object list containing following components: pred predicted value(s). se corresponding standard error(s). ci.lb lower bound confidence interval(s). ci.ub upper bound confidence interval(s). pi.lb lower bound prediction interval(s) (random/mixed-effects models). pi.ub upper bound prediction interval(s) (random/mixed-effects models). tau2.level level(s) inner factor (models class \"rma.mv\" multiple \\(\\tau^2\\) values). gamma2.level level(s) inner factor (models class \"rma.mv\" multiple \\(\\gamma^2\\) values). X moderator value(s) used calculate predicted values (addx=TRUE). Z scale value(s) used calculate predicted values (addz=TRUE location-scale models). ... additional elements/values. vcov=TRUE, returned object list first element equal one described second element equal variance-covariance matrix predicted values.    object formatted printed print function.","code":""},{"path":"/reference/predict.rma.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Predicted Values for 'rma' Objects — predict.rma","text":"Confidence prediction intervals calculated based critical values standard normal distribution (.e., \\(\\pm 1.96\\) level=95). model fitted test=\"t\" test=\"knha\", t-distribution \\(k-p\\) degrees freedom used. random-effects model (\\(p=1\\)) fitted rma.uni function, note differs slightly Riley et al. (2001), suggest use t-distribution \\(k-2\\) degrees freedom constructing prediction interval. Neither normal, t-distribution \\(k-1\\) \\(k-2\\) degrees freedom correct; approximations. computations done way described , prediction interval identical confidence interval \\(\\hat{\\tau}^2 = 0\\), argued logical thing happen. prediction interval computed exactly described Riley et al. (2001), one can use argument pi.type=\"riley\". predicted values based fixed effects model. Best linear unbiased predictions (BLUPs) combine fitted values based fixed effects estimated contributions random effects can obtained blup (currently objects class \"rma.uni\"). using transf option, transformation applied predicted values corresponding interval bounds. standard errors omitted printed output. Also, vcov=TRUE ignored using transf option.","code":""},{"path":"/reference/predict.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Predicted Values for 'rma' Objects — predict.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/predict.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Predicted Values for 'rma' Objects — predict.rma","text":"Hedges, L. V., & Olkin, . (1985). Statistical methods meta-analysis. San Diego, CA: Academic Press. Riley, R. D., Higgins, J. P. T., & Deeks, J. J. (2011). Interpretation random effects meta-analyses. British Medical Journal, 342, d549. https://doi.org/10.1136/bmj.d549 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/predict.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predicted Values for 'rma' Objects — predict.rma","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit random-effects model res <- rma(yi, vi, data=dat)  ### average risk ratio with 95% CI predict(res, transf=exp) #>  #>    pred  ci.lb  ci.ub  pi.lb  pi.ub  #>  0.4894 0.3441 0.6962 0.1546 1.5490  #>   ### fit mixed-effects model with absolute latitude as a moderator res <- rma(yi, vi, mods = ~ ablat, data=dat)  ### predicted average risk ratios for given absolute latitude values predict(res, transf=exp, addx=TRUE) #>  #>      pred  ci.lb  ci.ub  pi.lb  pi.ub X.intrcpt X.ablat  #> 1  0.3574 0.2714 0.4705 0.1947 0.6560         1      44  #> 2  0.2595 0.1749 0.3848 0.1328 0.5070         1      55  #> 3  0.3788 0.2927 0.4901 0.2079 0.6900         1      42  #> 4  0.2831 0.1977 0.4054 0.1478 0.5422         1      52  #> 5  0.8809 0.6321 1.2276 0.4667 1.6625         1      13  #> 6  0.3574 0.2714 0.4705 0.1947 0.6560         1      44  #> 7  0.7397 0.5639 0.9704 0.4036 1.3557         1      19  #> 8  0.8809 0.6321 1.2276 0.4667 1.6625         1      13  #> 9  0.5861 0.4716 0.7284 0.3270 1.0505         1      27  #> 10 0.3788 0.2927 0.4901 0.2079 0.6900         1      42  #> 11 0.7616 0.5752 1.0083 0.4138 1.4016         1      18  #> 12 0.4922 0.3989 0.6073 0.2753 0.8799         1      33  #> 13 0.4922 0.3989 0.6073 0.2753 0.8799         1      33  #>   ### predicted average risk ratios for 10-60 degrees absolute latitude predict(res, newmods=c(10, 20, 30, 40, 50, 60), transf=exp, addx=TRUE) #>  #>     pred  ci.lb  ci.ub  pi.lb  pi.ub X.intrcpt X.ablat  #> 1 0.9612 0.6668 1.3857 0.5000 1.8478         1      10  #> 2 0.7185 0.5526 0.9343 0.3936 1.3117         1      20  #> 3 0.5371 0.4355 0.6623 0.3005 0.9600         1      30  #> 4 0.4015 0.3151 0.5115 0.2218 0.7266         1      40  #> 5 0.3001 0.2144 0.4201 0.1586 0.5678         1      50  #> 6 0.2243 0.1423 0.3538 0.1105 0.4552         1      60  #>   ### fit mixed-effects model with absolute latitude and publication year as moderators res <- rma(yi, vi, mods = ~ ablat + year, data=dat)  ### predicted average risk ratios for 10 and 60 degrees latitude in 1950 and 1980 predict(res, newmods=cbind(c(10,60,10,60),c(1950,1950,1980,1980)), transf=exp, addx=TRUE) #>  #>     pred  ci.lb  ci.ub  pi.lb  pi.ub X.intrcpt X.ablat X.year  #> 1 0.8995 0.3689 2.1933 0.2981 2.7146         1      10   1950  #> 2 0.2217 0.1278 0.3847 0.0944 0.5208         1      60   1950  #> 3 0.9525 0.6199 1.4637 0.4361 2.0802         1      10   1980  #> 4 0.2348 0.1005 0.5481 0.0805 0.6843         1      60   1980  #>   ### fit mixed-effects model with two moderators (one of which is a factor) res <- rma(yi, vi, mods = ~ ablat + factor(alloc), data=dat)  ### examine how the factor was actually coded for the studies in the dataset predict(res, addx=TRUE) #>  #>       pred     se   ci.lb   ci.ub   pi.lb   pi.ub X.intrcpt X.ablat X.factor.alloc.random  #> 1  -1.1744 0.2137 -1.5932 -0.7557 -2.0293 -0.3196         1      44                     1  #> 2  -1.4745 0.2742 -2.0119 -0.9370 -2.3933 -0.5556         1      55                     1  #> 3  -1.1199 0.2061 -1.5238 -0.7159 -1.9676 -0.2722         1      42                     1  #> 4  -1.3926 0.2552 -1.8928 -0.8925 -2.2902 -0.4951         1      52                     1  #> 5  -0.0614 0.3336 -0.7152  0.5924 -1.0528  0.9300         1      13                     0  #> 6  -0.9069 0.3176 -1.5295 -0.2844 -1.8780  0.0642         1      44                     0  #> 7  -0.4925 0.2338 -0.9508 -0.0343 -1.3674  0.3823         1      19                     1  #> 8  -0.3289 0.2694 -0.8568  0.1991 -1.2422  0.5845         1      13                     1  #> 9  -0.7107 0.2007 -1.1040 -0.3175 -1.5534  0.1320         1      27                     1  #> 10 -0.7939 0.2667 -1.3166 -0.2712 -1.7042  0.1164         1      42                     0  #> 11 -0.1393 0.2654 -0.6594  0.3808 -1.0481  0.7695         1      18                     0  #> 12 -0.5484 0.2438 -1.0263 -0.0706 -1.4337  0.3369         1      33                     0  #> 13 -0.5484 0.2438 -1.0263 -0.0706 -1.4337  0.3369         1      33                     0  #>    X.factor.alloc.systematic  #> 1                          0  #> 2                          0  #> 3                          0  #> 4                          0  #> 5                          0  #> 6                          0  #> 7                          0  #> 8                          0  #> 9                          0  #> 10                         1  #> 11                         1  #> 12                         1  #> 13                         1  #>   ### predictd average risk ratios at 30 degrees for the three factor levels ### note: the contrast (dummy) variables need to specified explicitly here predict(res, newmods=c(30, 0, 0), addx=TRUE)   # for alternate  allocation #>  #>     pred     se   ci.lb  ci.ub   pi.lb  pi.ub X.intrcpt X.ablat X.factor.alloc.random  #>  -0.5251 0.2923 -1.0980 0.0478 -1.4651 0.4149         1      30                     0  #>  X.factor.alloc.systematic  #>                          0  #>  predict(res, newmods=c(30, 1, 0), addx=TRUE)   # for random     allocation #>  #>     pred     se   ci.lb   ci.ub   pi.lb  pi.ub X.intrcpt X.ablat X.factor.alloc.random  #>  -0.7926 0.1941 -1.1729 -0.4122 -1.6293 0.0442         1      30                     1  #>  X.factor.alloc.systematic  #>                          0  #>  predict(res, newmods=c(30, 0, 1), addx=TRUE)   # for systematic allocation #>  #>     pred     se   ci.lb  ci.ub   pi.lb  pi.ub X.intrcpt X.ablat X.factor.alloc.random  #>  -0.4666 0.2420 -0.9410 0.0078 -1.3501 0.4168         1      30                     0  #>  X.factor.alloc.systematic  #>                          1  #>   ### can also use named vector with arbitrary order and abbreviated variable names predict(res, newmods=c(sys=0, ran=0, abl=30)) #>  #>     pred     se   ci.lb  ci.ub   pi.lb  pi.ub  #>  -0.5251 0.2923 -1.0980 0.0478 -1.4651 0.4149  #>  predict(res, newmods=c(sys=0, ran=1, abl=30)) #>  #>     pred     se   ci.lb   ci.ub   pi.lb  pi.ub  #>  -0.7926 0.1941 -1.1729 -0.4122 -1.6293 0.0442  #>  predict(res, newmods=c(sys=1, ran=0, abl=30)) #>  #>     pred     se   ci.lb  ci.ub   pi.lb  pi.ub  #>  -0.4666 0.2420 -0.9410 0.0078 -1.3501 0.4168  #>"},{"path":"/reference/print.anova.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for 'anova.rma' Objects — print.anova.rma","title":"Print Method for 'anova.rma' Objects — print.anova.rma","text":"Print method objects class \"anova.rma\".","code":""},{"path":"/reference/print.anova.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for 'anova.rma' Objects — print.anova.rma","text":"","code":"# S3 method for anova.rma print(x, digits=x$digits, ...)"},{"path":"/reference/print.anova.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for 'anova.rma' Objects — print.anova.rma","text":"x object class \"anova.rma\" obtained anova. digits integer specify number decimal places printed results rounded (default take value object). ... arguments.","code":""},{"path":"/reference/print.anova.rma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print Method for 'anova.rma' Objects — print.anova.rma","text":"output includes: number parameters full reduced model. AIC, BIC, AICc, log-likelihood full reduced model. value likelihood ratio test statistic. corresponding p-value. test statistic test (residual) heterogeneity full reduced model. estimate \\(\\tau^2\\) full reduced model. Suppressed equal-effects models. R2amount (percent) heterogeneity reduced model accounted full model (NA \"rma.mv\" objects). can regarded pseudo \\(R^2\\) statistic (Raudenbush, 2009). Note value may accurate unless \\(k\\) large (Lopez-Lopez et al., 2014). last two items provided comparing \"rma.mv\" models.","code":""},{"path":"/reference/print.anova.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for 'anova.rma' Objects — print.anova.rma","text":"function return object.","code":""},{"path":"/reference/print.anova.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print Method for 'anova.rma' Objects — print.anova.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/print.anova.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print Method for 'anova.rma' Objects — print.anova.rma","text":"López-López, J. ., Marín-Martínez, F., Sánchez-Meca, J., Van den Noortgate, W., & Viechtbauer, W. (2014). Estimation predictive power model mixed-effects meta-regression: simulation study. British Journal Mathematical Statistical Psychology, 67(1), 30--48. https://doi.org/10.1111/bmsp.12002 Raudenbush, S. W. (2009). Analyzing effect sizes: Random effects models. H. Cooper, L. V. Hedges, & J. C. Valentine (Eds.), handbook research synthesis meta-analysis (2nd ed., pp. 295--315). New York: Russell Sage Foundation. Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/print.confint.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Methods for 'confint.rma' and 'list.confint.rma' Objects — print.confint.rma","title":"Print Methods for 'confint.rma' and 'list.confint.rma' Objects — print.confint.rma","text":"Print methods objects class \"confint.rma\" \"list.confint.rma\".","code":""},{"path":"/reference/print.confint.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Methods for 'confint.rma' and 'list.confint.rma' Objects — print.confint.rma","text":"","code":"# S3 method for confint.rma print(x, digits=x$digits, ...) # S3 method for list.confint.rma print(x, digits=x$digits, ...)"},{"path":"/reference/print.confint.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Methods for 'confint.rma' and 'list.confint.rma' Objects — print.confint.rma","text":"x object class \"confint.rma\" \"list.confint.rma\" obtained confint. digits integer specify number decimal places printed results rounded (default take value object). ... arguments.","code":""},{"path":"/reference/print.confint.rma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print Methods for 'confint.rma' and 'list.confint.rma' Objects — print.confint.rma","text":"output includes: estimate model coefficient variance/correlation parameter lower bound confidence interval upper bound confidence interval","code":""},{"path":"/reference/print.confint.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Methods for 'confint.rma' and 'list.confint.rma' Objects — print.confint.rma","text":"function return object.","code":""},{"path":"/reference/print.confint.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print Methods for 'confint.rma' and 'list.confint.rma' Objects — print.confint.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/print.confint.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print Methods for 'confint.rma' and 'list.confint.rma' Objects — print.confint.rma","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/print.escalc.html","id":null,"dir":"Reference","previous_headings":"","what":"Print and Summary Methods for 'escalc' Objects — print.escalc","title":"Print and Summary Methods for 'escalc' Objects — print.escalc","text":"Print summary methods objects class \"escalc\".","code":""},{"path":"/reference/print.escalc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print and Summary Methods for 'escalc' Objects — print.escalc","text":"","code":"# S3 method for escalc print(x, digits=attr(x,\"digits\"), ...)  # S3 method for escalc summary(object, out.names=c(\"sei\",\"zi\",\"pval\",\"ci.lb\",\"ci.ub\"), var.names,         H0=0, append=TRUE, replace=TRUE, level=95, olim, digits, transf, ...)"},{"path":"/reference/print.escalc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print and Summary Methods for 'escalc' Objects — print.escalc","text":"x object class \"escalc\" obtained escalc. object object class \"escalc\" obtained escalc. digits integer specify number decimal places printed results rounded (default take value object). .names character string four elements specify variable names standard errors, test statistics, lower/upper confidence interval bounds. var.names character string two elements specify variable names observed effect sizes outcomes sampling variances (default take value object possible). H0 numeric value specify value effect size outcome null hypothesis (default 0). append logical specify whether data frame specified via object argument returned together additional variables calculated summary function (default TRUE). replace logical specify whether existing values sei, zi, ci.lb, ci.ub data frame replaced . relevant data frame already contains variables. replace=TRUE (default), existing values overwritten. replace=FALSE, NA values replaced. level numeric value 0 100 specify confidence interval level (default 95). olim optional argument specify observation/outcome limits. unspecified, limits used. transf optional argument specify function used transform observed effect sizes outcomes interval bounds (e.g., transf=exp; see also transf). unspecified, transformation used. additional arguments needed function specified can passed via .... ... arguments.","code":""},{"path":"/reference/print.escalc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print and Summary Methods for 'escalc' Objects — print.escalc","text":"print.escalc function formats prints data frame, observed effect sizes outcomes sampling variances rounded (number digits specified).    summary.escalc function creates object data frame containing original data (append=TRUE) following components: yi observed effect sizes outcomes (transformed transf specified). vi corresponding sampling variances. sei correponding standard errors. zi test statistics testing \\(\\mbox{H}_0{:}\\; \\theta_i = \\mbox{H0}\\) (.e., (yi-H0)/sei). pval corresponding p-values. ci.lb lower confidence interval bounds (transformed transf specified). ci.ub upper confidence interval bounds (transformed transf specified). transf argument specified, elements vi, sei, zi, pval included (since apply untransformed effect sizes outcomes).    Note actual variable names depend .names (var.names) arguments. data frame already contains variables names specified .names argument, values variables overwritten replace=TRUE (default). setting replace=FALSE, values NA replaced.    print.escalc function formats prints data frame, rounding added variables number digits specified.","code":""},{"path":"/reference/print.escalc.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Print and Summary Methods for 'escalc' Objects — print.escalc","text":"transformation function specified transf argument, yi, ci.lb, ci.ub transformed accordingly. However, vi sei still reflect sampling variances standard errors untransformed values. summary.escalc function computes level % Wald-type confidence intervals, may may accurate method computing confidence intervals chosen effect size outcome measure. outcome measure used bounded (e.g., correlations bounded -1 +1, proportions bounded 0 1), one can use olim argument enforce observation/outcome limits (observed outcomes confidence intervals exceed bounds ).","code":""},{"path":"/reference/print.escalc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print and Summary Methods for 'escalc' Objects — print.escalc","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/print.escalc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print and Summary Methods for 'escalc' Objects — print.escalc","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/print.escalc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print and Summary Methods for 'escalc' Objects — print.escalc","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg) dat #>  #>    trial               author year tpos  tneg cpos  cneg ablat      alloc      yi     vi  #> 1      1              Aronson 1948    4   119   11   128    44     random -0.8893 0.3256  #> 2      2     Ferguson & Simes 1949    6   300   29   274    55     random -1.5854 0.1946  #> 3      3      Rosenthal et al 1960    3   228   11   209    42     random -1.3481 0.4154  #> 4      4    Hart & Sutherland 1977   62 13536  248 12619    52     random -1.4416 0.0200  #> 5      5 Frimodt-Moller et al 1973   33  5036   47  5761    13  alternate -0.2175 0.0512  #> 6      6      Stein & Aronson 1953  180  1361  372  1079    44  alternate -0.7861 0.0069  #> 7      7     Vandiviere et al 1973    8  2537   10   619    19     random -1.6209 0.2230  #> 8      8           TPT Madras 1980  505 87886  499 87892    13     random  0.0120 0.0040  #> 9      9     Coetzee & Berjak 1968   29  7470   45  7232    27     random -0.4694 0.0564  #> 10    10      Rosenthal et al 1961   17  1699   65  1600    42 systematic -1.3713 0.0730  #> 11    11       Comstock et al 1974  186 50448  141 27197    18 systematic -0.3394 0.0124  #> 12    12   Comstock & Webster 1969    5  2493    3  2338    33 systematic  0.4459 0.5325  #> 13    13       Comstock et al 1976   27 16886   29 17825    33 systematic -0.0173 0.0714  #>   ### apply summary function summary(dat) #>  #>    trial               author year tpos  tneg cpos  cneg ablat      alloc      yi     vi    sei  #> 1      1              Aronson 1948    4   119   11   128    44     random -0.8893 0.3256 0.5706  #> 2      2     Ferguson & Simes 1949    6   300   29   274    55     random -1.5854 0.1946 0.4411  #> 3      3      Rosenthal et al 1960    3   228   11   209    42     random -1.3481 0.4154 0.6445  #> 4      4    Hart & Sutherland 1977   62 13536  248 12619    52     random -1.4416 0.0200 0.1415  #> 5      5 Frimodt-Moller et al 1973   33  5036   47  5761    13  alternate -0.2175 0.0512 0.2263  #> 6      6      Stein & Aronson 1953  180  1361  372  1079    44  alternate -0.7861 0.0069 0.0831  #> 7      7     Vandiviere et al 1973    8  2537   10   619    19     random -1.6209 0.2230 0.4722  #> 8      8           TPT Madras 1980  505 87886  499 87892    13     random  0.0120 0.0040 0.0629  #> 9      9     Coetzee & Berjak 1968   29  7470   45  7232    27     random -0.4694 0.0564 0.2376  #> 10    10      Rosenthal et al 1961   17  1699   65  1600    42 systematic -1.3713 0.0730 0.2702  #> 11    11       Comstock et al 1974  186 50448  141 27197    18 systematic -0.3394 0.0124 0.1114  #> 12    12   Comstock & Webster 1969    5  2493    3  2338    33 systematic  0.4459 0.5325 0.7297  #> 13    13       Comstock et al 1976   27 16886   29 17825    33 systematic -0.0173 0.0714 0.2672  #>          zi   pval   ci.lb   ci.ub  #> 1   -1.5586 0.1191 -2.0077  0.2290  #> 2   -3.5941 0.0003 -2.4500 -0.7208  #> 3   -2.0917 0.0365 -2.6113 -0.0849  #> 4  -10.1908 <.0001 -1.7188 -1.1643  #> 5   -0.9613 0.3364 -0.6611  0.2260  #> 6   -9.4599 <.0001 -0.9490 -0.6232  #> 7   -3.4323 0.0006 -2.5465 -0.6953  #> 8    0.1899 0.8494 -0.1114  0.1353  #> 9   -1.9760 0.0482 -0.9350 -0.0038  #> 10  -5.0747 <.0001 -1.9010 -0.8417  #> 11  -3.0460 0.0023 -0.5577 -0.1210  #> 12   0.6111 0.5412 -0.9843  1.8762  #> 13  -0.0648 0.9483 -0.5410  0.5064  #>  summary(dat, transf=exp) #>  #>    trial               author year tpos  tneg cpos  cneg ablat      alloc     yi  ci.lb  ci.ub  #> 1      1              Aronson 1948    4   119   11   128    44     random 0.4109 0.1343 1.2574  #> 2      2     Ferguson & Simes 1949    6   300   29   274    55     random 0.2049 0.0863 0.4864  #> 3      3      Rosenthal et al 1960    3   228   11   209    42     random 0.2597 0.0734 0.9186  #> 4      4    Hart & Sutherland 1977   62 13536  248 12619    52     random 0.2366 0.1793 0.3121  #> 5      5 Frimodt-Moller et al 1973   33  5036   47  5761    13  alternate 0.8045 0.5163 1.2536  #> 6      6      Stein & Aronson 1953  180  1361  372  1079    44  alternate 0.4556 0.3871 0.5362  #> 7      7     Vandiviere et al 1973    8  2537   10   619    19     random 0.1977 0.0784 0.4989  #> 8      8           TPT Madras 1980  505 87886  499 87892    13     random 1.0120 0.8946 1.1449  #> 9      9     Coetzee & Berjak 1968   29  7470   45  7232    27     random 0.6254 0.3926 0.9962  #> 10    10      Rosenthal et al 1961   17  1699   65  1600    42 systematic 0.2538 0.1494 0.4310  #> 11    11       Comstock et al 1974  186 50448  141 27197    18 systematic 0.7122 0.5725 0.8860  #> 12    12   Comstock & Webster 1969    5  2493    3  2338    33 systematic 1.5619 0.3737 6.5284  #> 13    13       Comstock et al 1976   27 16886   29 17825    33 systematic 0.9828 0.5821 1.6593  #>"},{"path":"/reference/print.fsn.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for 'fsn' Objects — print.fsn","title":"Print Method for 'fsn' Objects — print.fsn","text":"Print method objects class \"fsn\".","code":""},{"path":"/reference/print.fsn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for 'fsn' Objects — print.fsn","text":"","code":"# S3 method for fsn print(x, digits=x$digits, ...)"},{"path":"/reference/print.fsn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for 'fsn' Objects — print.fsn","text":"x object class \"fsn\" obtained fsn. digits integer specify number decimal places printed results rounded (default take value object). ... arguments.","code":""},{"path":"/reference/print.fsn.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print Method for 'fsn' Objects — print.fsn","text":"output shows results fail-safe N calculation.","code":""},{"path":"/reference/print.fsn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for 'fsn' Objects — print.fsn","text":"function return object.","code":""},{"path":"/reference/print.fsn.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print Method for 'fsn' Objects — print.fsn","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/print.fsn.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print Method for 'fsn' Objects — print.fsn","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/print.gosh.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for 'gosh.rma' Objects — print.gosh.rma","title":"Print Method for 'gosh.rma' Objects — print.gosh.rma","text":"Print method objects class \"gosh.rma\".","code":""},{"path":"/reference/print.gosh.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for 'gosh.rma' Objects — print.gosh.rma","text":"","code":"# S3 method for gosh.rma print(x, digits=x$digits, ...)"},{"path":"/reference/print.gosh.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for 'gosh.rma' Objects — print.gosh.rma","text":"x object class \"gosh.rma\" obtained gosh. digits integer specify number decimal places printed results rounded (default take value object). ... arguments.","code":""},{"path":"/reference/print.gosh.rma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print Method for 'gosh.rma' Objects — print.gosh.rma","text":"output shows many model fits attempted, many succeeded, summary statistics (.e., mean, minimum, first quartile, median, third quartile, maximum) various measures (residual) heterogeneity model coefficient(s) computed across subsets.","code":""},{"path":"/reference/print.gosh.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for 'gosh.rma' Objects — print.gosh.rma","text":"function return object.","code":""},{"path":"/reference/print.gosh.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print Method for 'gosh.rma' Objects — print.gosh.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/print.gosh.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print Method for 'gosh.rma' Objects — print.gosh.rma","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/print.hc.rma.uni.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for 'hc.rma.uni' Objects — print.hc.rma.uni","title":"Print Method for 'hc.rma.uni' Objects — print.hc.rma.uni","text":"Print method objects class \"hc.rma.uni\".","code":""},{"path":"/reference/print.hc.rma.uni.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for 'hc.rma.uni' Objects — print.hc.rma.uni","text":"","code":"# S3 method for hc.rma.uni print(x, digits=x$digits, ...)"},{"path":"/reference/print.hc.rma.uni.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for 'hc.rma.uni' Objects — print.hc.rma.uni","text":"x object class \"hc.rma.uni\" obtained hc. digits integer specify number decimal places printed results rounded (default take value object). ... arguments.","code":""},{"path":"/reference/print.hc.rma.uni.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print Method for 'hc.rma.uni' Objects — print.hc.rma.uni","text":"output data frame two rows, first (labeled rma) corresponding results based usual estimation method, second (labeled hc) corresponding results based method Henmi Copas (2010). data frame includes following variables: method used estimate \\(\\tau^2\\) (always DL hc) estimated amount heterogeneity estimated average true outcome corresponding standard error (NA transf argument used) lower upper confidence interval bounds","code":""},{"path":"/reference/print.hc.rma.uni.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for 'hc.rma.uni' Objects — print.hc.rma.uni","text":"function returns data frame invisibly.","code":""},{"path":"/reference/print.hc.rma.uni.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print Method for 'hc.rma.uni' Objects — print.hc.rma.uni","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/print.hc.rma.uni.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print Method for 'hc.rma.uni' Objects — print.hc.rma.uni","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/print.list.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for 'list.rma' Objects — print.list.rma","title":"Print method for 'list.rma' Objects — print.list.rma","text":"Print method objects class \"list.rma\".","code":""},{"path":"/reference/print.list.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for 'list.rma' Objects — print.list.rma","text":"","code":"# S3 method for list.rma print(x, digits=x$digits, ...)"},{"path":"/reference/print.list.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for 'list.rma' Objects — print.list.rma","text":"x object class \"list.rma\". digits integer specify number decimal places printed results rounded (default take value object). ... arguments.","code":""},{"path":"/reference/print.list.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for 'list.rma' Objects — print.list.rma","text":"See documentation function creates \"list.rma\" object details printed. Regardless printed, data frame results also returned invisibly.    See methods.list.rma additional method functions \"list.rma\" objects.","code":""},{"path":"/reference/print.list.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print method for 'list.rma' Objects — print.list.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/print.list.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print method for 'list.rma' Objects — print.list.rma","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":"/reference/print.matreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for 'matreg' Objects — print.matreg","title":"Print Method for 'matreg' Objects — print.matreg","text":"Print method objects class \"matreg\".","code":""},{"path":"/reference/print.matreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for 'matreg' Objects — print.matreg","text":"","code":"# S3 method for matreg print(x, digits=x$digits,       signif.stars=getOption(\"show.signif.stars\"), signif.legend=signif.stars, ...)"},{"path":"/reference/print.matreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for 'matreg' Objects — print.matreg","text":"x object class \"matreg\" obtained matreg. digits integer specify number decimal places printed results rounded. unspecified, default take value object. signif.stars logical specify whether p-values encoded visually ‘significance stars’. Defaults show.signif.stars slot options. signif.legend logical specify whether legend ‘significance stars’ printed. Defaults value signif.stars. ... arguments.","code":""},{"path":"/reference/print.matreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print Method for 'matreg' Objects — print.matreg","text":"output table estimated coefficients, corresponding standard errors, test statistics, p-values, confidence interval bounds.","code":""},{"path":"/reference/print.matreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for 'matreg' Objects — print.matreg","text":"function return object.","code":""},{"path":"/reference/print.matreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print Method for 'matreg' Objects — print.matreg","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":[]},{"path":"/reference/print.permutest.rma.uni.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for 'permutest.rma.uni' Objects — print.permutest.rma.uni","title":"Print Method for 'permutest.rma.uni' Objects — print.permutest.rma.uni","text":"Print method objects class \"permutest.rma.uni\".","code":""},{"path":"/reference/print.permutest.rma.uni.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for 'permutest.rma.uni' Objects — print.permutest.rma.uni","text":"","code":"# S3 method for permutest.rma.uni print(x, digits=x$digits, signif.stars=getOption(\"show.signif.stars\"),       signif.legend=signif.stars, ...)"},{"path":"/reference/print.permutest.rma.uni.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for 'permutest.rma.uni' Objects — print.permutest.rma.uni","text":"x object class \"permutest.rma.uni\" obtained permutest. digits integer specify number decimal places printed results rounded (default take value object). signif.stars logical specify whether p-values encoded visually ‘significance stars’. Defaults show.signif.stars slot options. signif.legend logical specify whether legend ‘significance stars’ printed. Defaults value signif.stars. ... arguments.","code":""},{"path":"/reference/print.permutest.rma.uni.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print Method for 'permutest.rma.uni' Objects — print.permutest.rma.uni","text":"output includes: results omnibus test moderators. Suppressed model includes one coefficient (e.g., intercept, like equal- random-effects models). p-value based permutation test. table estimated coefficients, corresponding standard errors, test statistics, p-values, confidence interval bounds. p-values based permutation tests. permci set TRUE, permutation-based CI bounds shown.","code":""},{"path":"/reference/print.permutest.rma.uni.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for 'permutest.rma.uni' Objects — print.permutest.rma.uni","text":"function return object.","code":""},{"path":"/reference/print.permutest.rma.uni.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print Method for 'permutest.rma.uni' Objects — print.permutest.rma.uni","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/print.permutest.rma.uni.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print Method for 'permutest.rma.uni' Objects — print.permutest.rma.uni","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/print.ranktest.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for 'ranktest' Objects — print.ranktest","title":"Print Method for 'ranktest' Objects — print.ranktest","text":"Print method objects class \"ranktest\".","code":""},{"path":"/reference/print.ranktest.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for 'ranktest' Objects — print.ranktest","text":"","code":"# S3 method for ranktest print(x, digits=x$digits, ...)"},{"path":"/reference/print.ranktest.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for 'ranktest' Objects — print.ranktest","text":"x object class \"ranktest\" obtained ranktest. digits integer specify number decimal places printed results rounded (default take value object). ... arguments.","code":""},{"path":"/reference/print.ranktest.rma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print Method for 'ranktest' Objects — print.ranktest","text":"output includes: estimated value Kendall's tau rank correlation coefficient corresponding p-value test true tau equal zero","code":""},{"path":"/reference/print.ranktest.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for 'ranktest' Objects — print.ranktest","text":"function return object.","code":""},{"path":"/reference/print.ranktest.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print Method for 'ranktest' Objects — print.ranktest","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/print.ranktest.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print Method for 'ranktest' Objects — print.ranktest","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/print.regtest.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for 'regtest' Objects — print.regtest","title":"Print Method for 'regtest' Objects — print.regtest","text":"Print method objects class \"regtest\".","code":""},{"path":"/reference/print.regtest.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for 'regtest' Objects — print.regtest","text":"","code":"# S3 method for regtest print(x, digits=x$digits, ret.fit=x$ret.fit, ...)"},{"path":"/reference/print.regtest.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for 'regtest' Objects — print.regtest","text":"x object class \"regtest\" obtained regtest. digits integer specify number decimal places printed results rounded (default take value object). ret.fit logical specify whether full results fitted model also returned. unspecified, default take value object. ... arguments.","code":""},{"path":"/reference/print.regtest.rma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print Method for 'regtest' Objects — print.regtest","text":"output includes: model used regression test predictor used regression test results fitted model (ret.fit=TRUE) test statistic test predictor unreleated outcomes degrees freedom test statistic (test statistic follows t-distribution) corresponding p-value ‘limit estimate’ corresponding CI (predictors \"sei\" \"vi\", \"ninv\", \"sqrtninv\" model contain additional moderators)","code":""},{"path":"/reference/print.regtest.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for 'regtest' Objects — print.regtest","text":"function return object.","code":""},{"path":"/reference/print.regtest.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print Method for 'regtest' Objects — print.regtest","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/print.regtest.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print Method for 'regtest' Objects — print.regtest","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/print.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Print and Summary Methods for 'rma' Objects — print.rma","title":"Print and Summary Methods for 'rma' Objects — print.rma","text":"Print summary methods objects class \"rma.uni\", \"rma.mh\", \"rma.peto\", \"rma.glmm\", \"rma.glmm\", \"rma.mv\".","code":""},{"path":"/reference/print.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print and Summary Methods for 'rma' Objects — print.rma","text":"","code":"# S3 method for rma.uni print(x, digits, showfit=FALSE, signif.stars=getOption(\"show.signif.stars\"),       signif.legend=signif.stars, ...)  # S3 method for rma.mh print(x, digits, showfit=FALSE, ...)  # S3 method for rma.peto print(x, digits, showfit=FALSE, ...)  # S3 method for rma.glmm print(x, digits, showfit=FALSE, signif.stars=getOption(\"show.signif.stars\"),       signif.legend=signif.stars, ...)  # S3 method for rma.mv print(x, digits, showfit=FALSE, signif.stars=getOption(\"show.signif.stars\"),       signif.legend=signif.stars, ...)  # S3 method for rma summary(object, digits, showfit=TRUE, ...)  # S3 method for summary.rma print(x, digits, showfit=TRUE, signif.stars=getOption(\"show.signif.stars\"),       signif.legend=signif.stars, ...)"},{"path":"/reference/print.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print and Summary Methods for 'rma' Objects — print.rma","text":"x object class \"rma.uni\", \"rma.mh\", \"rma.peto\", \"rma.glmm\", \"rma.mv\", \"summary.rma\" (print). object object class \"rma\" (summary). digits integer specify number decimal places printed results rounded. unspecified, default take value object. See also details control number digits output. showfit logical specify whether fit statistics information criteria printed (default FALSE print TRUE summary). signif.stars logical specify whether p-values encoded visually ‘significance stars’. Defaults show.signif.stars slot options. signif.legend logical specify whether legend ‘significance stars’ printed. Defaults value signif.stars. ... arguments.","code":""},{"path":"/reference/print.rma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print and Summary Methods for 'rma' Objects — print.rma","text":"output includes: log-likelihood, deviance, AIC, BIC, AICc value (setting showfit=TRUE default summary). objects class \"rma.uni\" \"rma.glmm\", amount (residual) heterogeneity random/mixed-effects model (.e., estimate \\(\\tau^2\\) square root). Suppressed equal-effects models. (asymptotic) standard error estimate \\(\\tau^2\\) also provided (possible). objects \"rma.mv\", table providing information variance components correlations model. \\(\\sigma^2\\) components, estimate square root provided, addition number values/levels, whether component fixed estimated, name grouping variable/factor. R argument used specify known correlation matrices, also indicated. models ‘~ inner | outer’ formula term, name inner outer grouping variable/factor given number values/levels variables/factors. addition, \\(\\tau^2\\) component, estimate square root provided, number effects outcomes observed level inner grouping variable/factor (struct=\"HCS\", struct=\"DIAG\", struct=\"HAR\", struct=\"UN\"), whether component fixed estimated. Finally, either estimate \\(\\rho\\) (struct=\"CS\", struct=\"AR\", struct=\"CAR\", struct=\"HAR\", struct=\"HCS\") entire estimated correlation matrix (struct=\"UN\") levels inner grouping variable/factor provided, information whether particular correlation fixed estimated, often combination levels inner grouping variable/factor observed across levels outer grouping variable/factor. second ‘~ inner | outer’ formula term, information described provided, now \\(\\gamma^2\\) \\(\\phi\\) components. \\(^2\\) statistic, estimates (percent) much total variability observed effect sizes outcomes (composed heterogeneity plus sampling variability) can attributed heterogeneity among true effects. meta-regression model, \\(^2\\) estimates much unaccounted variability (composed residual heterogeneity plus sampling variability) can attributed residual heterogeneity. See ‘Note’ \\(^2\\) computed. \\(H^2\\) statistic, estimates ratio total amount variability observed effect sizes outcomes amount sampling variability. meta-regression model, \\(H^2\\) estimates ratio unaccounted variability observed effect sizes outcomes amount sampling variability. See ‘Note’ \\(H^2\\) computed. objects class \"rma.uni\", \\(R^2\\) statistic, estimates amount heterogeneity accounted moderators included model can regarded pseudo \\(R^2\\) statistic (Raudenbush, 2009). provided fitting model including moderators. suppressed (set NULL) models without moderators model contain intercept. See ‘Note’ \\(R^2\\) computed. objects class \"rma.glmm\", amount study level variability (using model models study level differences random effect). results test (residual) heterogeneity. usual \\(Q\\)-test heterogeneity including moderators model \\(Q_E\\)-test residual heterogeneity moderators included. objects class \"rma.glmm\", results Wald-type test likelihood ratio test provided (see rma.glmm details). results omnibus (Wald-type) test coefficients model (indices coefficients tested also indicated). Suppressed model includes one coefficient (e.g., intercept, like equal- random-effects models). table estimated coefficients, corresponding standard errors, test statistics, p-values, confidence interval bounds. Cochran-Mantel-Haenszel test Tarone's test heterogeneity (analyzing odds ratios using Mantel-Haenszel method, .e., \"rma.mh\"). See also details option create styled/colored output help crayon package.","code":""},{"path":"/reference/print.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print and Summary Methods for 'rma' Objects — print.rma","text":"print functions return object. summary function returns object passed (additional class \"summary.rma\").","code":""},{"path":"/reference/print.rma.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Print and Summary Methods for 'rma' Objects — print.rma","text":"random-effects models, \\(^2\\) statistic computed \\[^2 = 100\\% \\times \\frac{\\hat{\\tau}^2}{\\hat{\\tau}^2 + \\tilde{v}},\\] \\(\\hat{\\tau}^2\\) estimated value \\(\\tau^2\\) \\[\\tilde{v} = \\frac{(k-1) \\sum w_i}{(\\sum w_i)^2 - \\sum w_i^2},\\] \\(w_i = 1 / v_i\\) inverse sampling variance \\(\\textrm{th}\\) study (\\(\\tilde{v}\\) equation 9 Higgins & Thompson, 2002, can regarded ‘typical’ within-study variance observed effect sizes outcomes). \\(H^2\\) statistic computed \\[H^2 = \\frac{\\hat{\\tau}^2 + \\tilde{v}}{\\tilde{v}}.\\] Analogous equations used mixed-effects models. Therefore, depending estimator \\(\\tau^2\\) used, values \\(^2\\) \\(H^2\\) change. random-effects models, \\(^2\\) \\(H^2\\) often computed \\(^2 = (Q-(k-1))/Q\\) \\(H^2 = Q/(k-1)\\), \\(Q\\) denotes statistic test heterogeneity \\(k\\) number studies (.e., observed effect sizes outcomes) included meta-analysis. equations used metafor package compute statistics general advantage values \\(^2\\) \\(H^2\\) consistent estimated value \\(\\tau^2\\) (.e., \\(\\hat{\\tau}^2 = 0\\), \\(^2 = 0\\) \\(H^2 = 1\\) \\(\\hat{\\tau}^2 > 0\\), \\(^2 > 0\\) \\(H^2 > 1\\)). two definitions \\(^2\\) \\(H^2\\) actually coincide using DerSimonian-Laird estimator \\(\\tau^2\\) (.e., commonly used equations actually special cases general definitions given ). Therefore, prefer conventional definitions statistics, use method=\"DL\" fitting random/mixed-effects model rma.uni function. conventional definitions also automatically used fitting equal-effects models. mixed-effects models, pseudo \\(R^2\\) statistic (Raudenbush, 2009) computed \\[R^2 = \\frac{\\hat{\\tau}_{RE}^2 - \\hat{\\tau}_{}^2}{\\hat{\\tau}_{RE}^2},\\] \\(\\hat{\\tau}_{RE}^2\\) denotes estimated value \\(\\tau^2\\) based random-effects model (.e., total amount heterogeneity) \\(\\hat{\\tau}_{}^2\\) denotes estimated value \\(\\tau^2\\) based mixed-effects model (.e., residual amount heterogeneity). can happen \\(\\hat{\\tau}_{RE}^2 < \\hat{\\tau}_{}^2\\), case \\(R^2\\) set zero (also \\(\\hat{\\tau}_{RE}^2 = 0\\)). , value \\(R^2\\) change depending estimator \\(\\tau^2\\) used. statistic computed mixed-effects model includes intercept (random-effects model clearly nested within mixed-effects model). can also use anova function compute \\(R^2\\) two models known nested. Note pseudo \\(R^2\\) statistic may accurate unless \\(k\\) large (Lopez-Lopez et al., 2014). fixed-effects moderators models, \\(R^2\\) statistic simply standard \\(R^2\\) statistic (also known ‘coefficient determination’) computed based weighted least squares estimation. precise, -called ‘adjusted’ \\(R^2\\) statistic provided, since \\(k\\) often relatively small meta-analyses, case adjustment relevant.","code":""},{"path":"/reference/print.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print and Summary Methods for 'rma' Objects — print.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/print.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print and Summary Methods for 'rma' Objects — print.rma","text":"Higgins, J. P. T., & Thompson, S. G. (2002). Quantifying heterogeneity meta-analysis. Statistics Medicine, 21(11), 1539--1558. https://doi.org/10.1002/sim.1186 López-López, J. ., Marín-Martínez, F., Sánchez-Meca, J., Van den Noortgate, W., & Viechtbauer, W. (2014). Estimation predictive power model mixed-effects meta-regression: simulation study. British Journal Mathematical Statistical Psychology, 67(1), 30--48. https://doi.org/10.1111/bmsp.12002 Raudenbush, S. W. (2009). Analyzing effect sizes: Random effects models. H. Cooper, L. V. Hedges, & J. C. Valentine (Eds.), handbook research synthesis meta-analysis (2nd ed., pp. 295--315). New York: Russell Sage Foundation. Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/profile.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Profile Plots for 'rma' Objects — profile.rma","title":"Profile Plots for 'rma' Objects — profile.rma","text":"Function profile (restricted) log-likelihood objects class \"rma.uni\", \"rma.mv\", \"rma.uni.selmodel\", \"rma.ls\".","code":""},{"path":"/reference/profile.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Profile Plots for 'rma' Objects — profile.rma","text":"","code":"# S3 method for rma.uni profile(fitted, xlim, ylim, steps=20,         lltol=1e-03, progbar=TRUE, parallel=\"no\", ncpus=1, cl,         plot=TRUE, pch=19, refline=TRUE, cline=FALSE, ...)  # S3 method for rma.mv profile(fitted, sigma2, tau2, rho, gamma2, phi,         xlim, ylim, steps=20, lltol=1e-03, progbar=TRUE,         parallel=\"no\", ncpus=1, cl,         plot=TRUE, pch=19, refline=TRUE, cline=FALSE, ...)  # S3 method for rma.uni.selmodel profile(fitted, tau2, delta,         xlim, ylim, steps=20, lltol=1e-03, progbar=TRUE,         parallel=\"no\", ncpus=1, cl,         plot=TRUE, pch=19, refline=TRUE, cline=FALSE, ...)  # S3 method for rma.ls profile(fitted, alpha, xlim, ylim, steps=20,         lltol=1e-03, progbar=TRUE, parallel=\"no\", ncpus=1, cl,         plot=TRUE, pch=19, refline=TRUE, cline=FALSE, ...)  # S3 method for profile.rma print(x, ...) # S3 method for profile.rma plot(x, xlim, ylim, pch=19,      xlab, ylab, main, refline=TRUE, cline=FALSE, ...)"},{"path":"/reference/profile.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Profile Plots for 'rma' Objects — profile.rma","text":"fitted object class \"rma.uni\", \"rma.mv\", \"rma.uni.selmodel\", \"rma.ls\". x object class \"profile.rma\" (plot print). sigma2 optional integer specify \\(\\sigma^2\\) value likelihood profiled. tau2 optional integer specify \\(\\tau^2\\) value likelihood profiled. rho optional integer specify \\(\\rho\\) value likelihood profiled. gamma2 optional integer specify \\(\\gamma^2\\) value likelihood profiled. phi optional integer specify \\(\\phi\\) value likelihood profiled. delta optional integer specify \\(\\delta\\) value likelihood profiled. alpha optional integer specify \\(\\alpha\\) value likelihood profiled. xlim optional vector specify lower upper limit parameter profiling done. unspecified, function tries set limits automatically. ylim optional vector specify y-axis limits plotting profiled likelihood. unspecified, function tries set limits automatically. steps number points xlim[1] xlim[2] (inclusive) likelihood evaluated (default 20). lltol numerical tolerance used comparing values profiled log-likelihood log-likelihood fitted model (default 1e-03). progbar logical specify whether progress bar shown (default TRUE). parallel character string specify whether parallel processing used (default \"\"). parallel processing, set either \"snow\" \"multicore\". See ‘Details’. ncpus integer specify number processes use parallel processing. cl optional cluster use parallel=\"snow\". unspecified, cluster local machine created duration call. plot logical specify whether profile plot drawn profiling finished (default TRUE). pch plotting symbol use. default, filled circle used. See points options. refline logical specify whether value parameter estimate indicated dotted vertical line log-likelihood value dotted horizontal line (default TRUE). cline logical specify whether horizontal reference line added plot indicates log-likelihood value corresponding 95% profile confidence interval (default FALSE). xlab title x-axis. unspecified, function tries set appropriate axis title. ylab title y-axis. unspecified, function tries set appropriate axis title. main title plot. unspecified, function tries set appropriate title. ... arguments.","code":""},{"path":"/reference/profile.rma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Profile Plots for 'rma' Objects — profile.rma","text":"function fixes particular parameter model computes maximized (restricted) log-likelihood remaining parameters model. range values parameter fixed, profile (restricted) log-likelihood constructed.","code":""},{"path":"/reference/profile.rma.html","id":"selecting-the-parameter-s-to-profile","dir":"Reference","previous_headings":"","what":"Selecting the Parameter(s) to Profile","title":"Profile Plots for 'rma' Objects — profile.rma","text":"parameters can profiled depend model object: objects class \"rma.uni\" obtained rma.uni function, function profiles \\(\\tau^2\\) (equal-effects models). objects class \"rma.mv\" obtained rma.mv function, profiling done default (non-fixed) variance correlation components model. Alternatively, one can use sigma2, tau2, rho, gamma2, phi arguments specify parameter profiling done. one arguments can used time. single integer used specify number parameter. selection model objects class \"rma.uni.selmodel\" obtained selmodel function, profiling done default \\(\\tau^2\\) (models estimated parameter) (non-fixed) selection model parameters. Alternatively, one can choose profile \\(\\tau^2\\) setting tau2=TRUE one can select one selection model parameters profile specifying number via delta argument. location-scale model objects class \"rma.ls\" obtained rma.uni function, profiling done default (non-fixed) \\(\\alpha\\) parameters part scale model.","code":""},{"path":"/reference/profile.rma.html","id":"interpreting-a-likelihood-profile","dir":"Reference","previous_headings":"","what":"Interpreting a Likelihood Profile","title":"Profile Plots for 'rma' Objects — profile.rma","text":"profile plot show single peak corresponding ML/REML estimate (assuming model fitted ML/REML estimation). refline=TRUE (default), value parameter estimate indicated dotted vertical line log-likelihood value dotted horizontal line. Hence, intersection two lines correspond peak. profiling variance component (parameter negative), peak may zero (corresponds ML/REML estimate parameter). case, profiled log-likelihood monotonically decreasing function parameter. profiled log-likelihood multiple peaks, indicates likelihood surface unimodal. cases, ML/REML estimate may correspond local optimum (intersection two dotted lines highest peak). profile flat (entire parameter space large portions ), suggests least parameters model identifiable (parameter estimates obtained extent arbitrary). See Raue et al. (2009) discussion parameter identifiability (structurally practically) use profile likelihoods check . function checks whether profiled log-likelihood value actually larger log-likelihood fitted model (using numerical tolerance lltol). , warning issued might indicate optimizer identify actual ML/REML estimate.","code":""},{"path":"/reference/profile.rma.html","id":"parallel-processing","dir":"Reference","previous_headings":"","what":"Parallel Processing","title":"Profile Plots for 'rma' Objects — profile.rma","text":"Profiling requires repeatedly refitting model, can slow \\(k\\) large /model complex (latter especially applies \"rma.mv\" objects also certain \"rma.uni.selmodel\" \"rma.ls\" objects). machines multiple cores, one can usually speed things delegating model fitting separate worker processes, , setting parallel=\"snow\" parallel=\"multicore\" ncpus value larger 1. Parallel processing makes use parallel package, using makePSOCKcluster parLapply functions parallel=\"snow\" using mclapply parallel=\"multicore\" (latter works Unix/Linux-alikes). parallel::detectCores(), one can check number available cores local machine.","code":""},{"path":"/reference/profile.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Profile Plots for 'rma' Objects — profile.rma","text":"object class \"profile.rma\". object list (list lists) containing following components:    One following (depending parameter actually profiled): sigma2 values \\(\\sigma^2\\) likelihood profiled. tau2 values \\(\\tau^2\\) likelihood profiled. rho values \\(\\rho\\) likelihood profiled. gamma2 values \\(\\gamma^2\\) likelihood profiled. phi values \\(\\phi\\) likelihood profiled. delta values \\(\\delta\\) likelihood profiled. alpha values \\(\\alpha\\) likelihood profiled. addition, following components included: ll (restricted) log-likelihood values corresponding parameter values. beta matrix estimated model coefficients corresponding parameter values. ci.lb matrix lower confidence interval bounds model coefficients corresponding parameter values. ci.ub matrix upper confidence interval bounds model coefficients corresponding parameter values. ... additional elements/values. Note list returned invisibly.","code":""},{"path":"/reference/profile.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Profile Plots for 'rma' Objects — profile.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/profile.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Profile Plots for 'rma' Objects — profile.rma","text":"Raue, ., Kreutz, C., Maiwald, T., Bachmann, J., Schilling, M., Klingmuller, U., & Timmer, J. (2009). Structural practical identifiability analysis partially observed dynamical models exploiting profile likelihood. Bioinformatics, 25(15), 1923--1929. https://doi.org/10.1093/bioinformatics/btp358 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/profile.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Profile Plots for 'rma' Objects — profile.rma","text":"","code":"### calculate log odds ratios and corresponding sampling variances dat <- escalc(measure=\"OR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit random-effects model using rma.uni() res <- rma(yi, vi, data=dat)  ### profile over tau^2 profile(res, progbar=FALSE)   ### change data into long format dat.long <- to.long(measure=\"OR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### set levels of group variable (\"exp\" = experimental/vaccinated; \"con\" = control/non-vaccinated) levels(dat.long$group) <- c(\"exp\", \"con\")  ### set \"con\" to reference level dat.long$group <- relevel(dat.long$group, ref=\"con\")  ### calculate log odds and corresponding sampling variances dat.long <- escalc(measure=\"PLO\", xi=out1, mi=out2, data=dat.long)  ### fit bivariate random-effects model using rma.mv() res <- rma.mv(yi, vi, mods = ~ group, random = ~ group | study, struct=\"UN\", data=dat.long) res #>  #> Multivariate Meta-Analysis Model (k = 26; method: REML) #>  #> Variance Components: #>  #> outer factor: study (nlvls = 13) #> inner factor: group (nlvls = 2) #>  #>             estim    sqrt  k.lvl  fixed  level  #> tau^2.1    1.5486  1.2444     13     no    con  #> tau^2.2    2.6173  1.6178     13     no    exp  #>  #>      rho.con  rho.exp    con  exp  #> con        1               -   13  #> exp   0.9450        1     no    -  #>  #> Test for Residual Heterogeneity: #> QE(df = 24) = 5270.3863, p-val < .0001 #>  #> Test of Moderators (coefficient 2): #> QM(df = 1) = 15.5470, p-val < .0001 #>  #> Model Results: #>  #>           estimate      se      zval    pval    ci.lb    ci.ub     ​  #> intrcpt    -4.8374  0.3528  -13.7113  <.0001  -5.5289  -4.1459  ***  #> groupexp    0.7414  0.1880    3.9430  <.0001   0.3729   1.1099  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### profile over tau^2_1, tau^2_2, and rho ### note: for rho, adjust region over which profiling is done ('zoom in' on area around estimate) # \\dontrun{ par(mfrow=c(3,1)) profile(res, tau2=1) profile(res, tau2=2) profile(res, rho=1, xlim=c(.90, .98))# }   ### an example where the peak is at 0 dat <- escalc(measure=\"RD\", n1i=n1i, n2i=n2i, ai=ai, ci=ci, data=dat.hine1989) res <- rma(yi, vi, data=dat) par(mfrow=c(1,1)) profile(res, progbar=FALSE)"},{"path":"/reference/qqnorm.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Normal QQ Plots for 'rma' Objects — qqnorm.rma","title":"Normal QQ Plots for 'rma' Objects — qqnorm.rma","text":"Function create normal QQ plots objects class \"rma.uni\", \"rma.mh\", \"rma.peto\".","code":""},{"path":"/reference/qqnorm.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normal QQ Plots for 'rma' Objects — qqnorm.rma","text":"","code":"# S3 method for rma.uni qqnorm(y, type=\"rstandard\", pch=19, envelope=TRUE,        level=y$level, bonferroni=FALSE, reps=1000, smooth=TRUE, bass=0,        label=FALSE, offset=0.3, pos=13, lty, ...) # S3 method for rma.mh qqnorm(y, type=\"rstandard\", pch=19, label=FALSE, offset=0.3, pos=13, ...) # S3 method for rma.peto qqnorm(y, type=\"rstandard\", pch=19, label=FALSE, offset=0.3, pos=13, ...) # S3 method for rma.glmm qqnorm(y, ...) # S3 method for rma.mv qqnorm(y, ...)"},{"path":"/reference/qqnorm.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normal QQ Plots for 'rma' Objects — qqnorm.rma","text":"y object class \"rma.uni\", \"rma.mh\", \"rma.peto\". method yet implemented objects class \"rma.glmm\" \"rma.mv\". type character string (either \"rstandard\" (default) \"rstudent\") specify whether standardized residuals studentized deleted residuals used creating plot. See ‘Details’. pch plotting symbol use observed outcomes. default, filled circle used. See points options. envelope logical specify whether pseudo confidence envelope simulated added plot (default TRUE)). objects class \"rma.uni\". See ‘Details’. level numeric value 0 100 specify level pseudo confidence envelope (default take value object). bonferroni logical specify whether bounds envelope Bonferroni corrected. reps numeric value specify number iterations use simulating pseudo confidence envelope (default 1000). smooth logical specify whether results simulation smoothed (default TRUE). bass numeric value controls degree smoothing (default 0). label argument control labeling points (default FALSE). See ‘Details’. offset argument control distance points corresponding labels. pos argument control position labels. lty optional character string specify line type diagonal line pseudo confidence envelope. unspecified, function sets c(\"solid\", \"dotted\") default. ... arguments.","code":""},{"path":"/reference/qqnorm.rma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Normal QQ Plots for 'rma' Objects — qqnorm.rma","text":"plot shows theoretical quantiles normal distribution horizontal axis observed quantiles either standardized residuals (type=\"rstandard\", default) externally standardized residuals (type=\"rstudent\") vertical axis (see residuals details definition residual types). reference, line added plot slope 1, going (0,0) point. objects class \"rma.uni\", also possible add pseudo confidence envelope plot. envelope created based quantiles sets pseudo residuals simulated given model (details, see Cook & Weisberg, 1982). number sets simulated can controlled reps argument. smooth=TRUE, simulated bounds smoothed Friedman's SuperSmoother (see supsmu). bass argument can set number 0 10, higher numbers indicating increasing smoothness. bonferroni=TRUE, envelope bounds Bonferroni corrected, envelope can regarded confidence region \\(k\\) residuals simultaneously. default however bonferroni=FALSE, makes plot sensitive deviations normality. label argument, one can control whether points plot labeled (e.g., identify outliers). label=\"\" (label=TRUE), points plot labeled. label=\"\", points falling outside confidence envelope labeled (available objects class \"rma.uni\"). Finally, one can also set argument numeric value (1 \\(k\\)), indicating many extreme points labeled (example, label=1 extreme point labeled, label=3, extreme, second third extreme points labeled). offset argument, one can adjust distance labels corresponding points. pos argument position specifier labels (1, 2, 3, 4, respectively indicate positions , left , , right points; 13 places labels points points fall reference line otherwise; 24 places labels left points points fall reference line right otherwise).","code":""},{"path":"/reference/qqnorm.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normal QQ Plots for 'rma' Objects — qqnorm.rma","text":"list components: x x-axis coordinates points plotted. y y-axis coordinates points plotted. Note list returned invisibly.","code":""},{"path":"/reference/qqnorm.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Normal QQ Plots for 'rma' Objects — qqnorm.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/qqnorm.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Normal QQ Plots for 'rma' Objects — qqnorm.rma","text":"Cook, R. D., & Weisberg, S. (1982). Residuals influence regression. London: Chapman Hall. Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03 Wang, M. C., & Bushman, B. J. (1998). Using normal quantile plot explore meta-analytic data sets. Psychological Methods, 3(1), 46--54. https://doi.org/10.1037/1082-989X.3.1.46","code":""},{"path":[]},{"path":"/reference/qqnorm.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normal QQ Plots for 'rma' Objects — qqnorm.rma","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit random-effects model res <- rma(yi, vi, data=dat)  ### draw QQ plot qqnorm(res)   ### fit mixed-effects model with absolute latitude as moderator res <- rma(yi, vi, mods = ~ ablat, data=dat)  ### draw QQ plot qqnorm(res)"},{"path":"/reference/radial.html","id":null,"dir":"Reference","previous_headings":"","what":"Radial (Galbraith) Plots for 'rma' Objects — radial","title":"Radial (Galbraith) Plots for 'rma' Objects — radial","text":"Function create radial (also called Galbraith) plots objects class \"rma\".","code":""},{"path":"/reference/radial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Radial (Galbraith) Plots for 'rma' Objects — radial","text":"","code":"radial(x, ...) galbraith(x, ...)  # S3 method for rma radial(x, center=FALSE, xlim, zlim, xlab, zlab,        atz, aty, steps=7, level=x$level, digits=2, back=\"lightgray\",        transf, targs, pch=19, arc.res=100, cex, ...)"},{"path":"/reference/radial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Radial (Galbraith) Plots for 'rma' Objects — radial","text":"x object class \"rma\". center logical indicate whether plot centered horizontally model estimate (default FALSE). xlim x-axis limits. unspecified, function tries set x-axis limits sensible values. zlim z-axis limits. unspecified, function tries set z-axis limits sensible values (note z-axis limits actual vertical limit plotting region). xlab title x-axis. unspecified, function tries set appropriate axis title. zlab title z-axis. unspecified, function tries set appropriate axis title. atz position z-axis tick marks labels. unspecified, values set function. aty position y-axis tick marks labels. unspecified, values set function. steps number tick marks y-axis (default 7). Ignored argument aty used. level numeric value 0 100 specify level z-axis error region (default take value object). digits integer specify number decimal places tick mark labels y-axis rounded (default 2). back color z-axis error region. Set NA suppress shading region. transf optional argument specify function used transform y-axis labels (e.g., transf=exp; see also transf). unspecified, transformation used. targs optional arguments needed function specified via transf. pch plotting symbol. default, filled circle used. See points options. arc.res integer specify number line segments use drawing y-axis confidence interval arcs (default 100). cex optional character symbol expansion factor. unspecified, function tries set sensible value. ... arguments.","code":""},{"path":"/reference/radial.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Radial (Galbraith) Plots for 'rma' Objects — radial","text":"equal-effects model, plot shows inverse standard errors horizontal axis observed effect sizes outcomes standardized corresponding standard errors vertical axis. Since vertical axis corresponds standardized values, referred z-axis within function. right hand side plot, arc drawn (referred y-axis within function) corresponding observed effect sizes outcomes. line projected (0,0) particular point within plot onto arc indicates value observed effect size outcome point. random-effects model, function uses \\(1/\\sqrt{v_i + \\tau^2}\\) horizontal axis, \\(v_i\\) sampling variance observed effect size outcome \\(\\tau^2\\) amount heterogeneity estimated based model. z-axis, \\(\\sqrt{v_i + \\tau^2}\\) used standardize observed effect sizes outcomes. model contains moderators, function returns error.","code":""},{"path":"/reference/radial.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Radial (Galbraith) Plots for 'rma' Objects — radial","text":"data frame components: x x-axis coordinates points plotted. y y-axis coordinates points plotted. ids study id numbers. slab study labels. Note data frame returned invisibly.","code":""},{"path":"/reference/radial.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Radial (Galbraith) Plots for 'rma' Objects — radial","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/radial.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Radial (Galbraith) Plots for 'rma' Objects — radial","text":"Galbraith, R. F. (1988). Graphical display estimates differing standard errors. Technometrics, 30(3), 271--281. https://doi.org/10.1080/00401706.1988.10488400 Galbraith, R. F. (1988). note graphical presentation estimated odds ratios several clinical trials. Statistics Medicine, 7(8), 889--894. https://doi.org/10.1002/sim.4780070807 Galbraith, R. F (1994). applications radial plots. Journal American Statistical Association, 89(428), 1232--1242. https://doi.org/10.1080/01621459.1994.10476864 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/radial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Radial (Galbraith) Plots for 'rma' Objects — radial","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg) dat #>  #>    trial               author year tpos  tneg cpos  cneg ablat      alloc      yi     vi  #> 1      1              Aronson 1948    4   119   11   128    44     random -0.8893 0.3256  #> 2      2     Ferguson & Simes 1949    6   300   29   274    55     random -1.5854 0.1946  #> 3      3      Rosenthal et al 1960    3   228   11   209    42     random -1.3481 0.4154  #> 4      4    Hart & Sutherland 1977   62 13536  248 12619    52     random -1.4416 0.0200  #> 5      5 Frimodt-Moller et al 1973   33  5036   47  5761    13  alternate -0.2175 0.0512  #> 6      6      Stein & Aronson 1953  180  1361  372  1079    44  alternate -0.7861 0.0069  #> 7      7     Vandiviere et al 1973    8  2537   10   619    19     random -1.6209 0.2230  #> 8      8           TPT Madras 1980  505 87886  499 87892    13     random  0.0120 0.0040  #> 9      9     Coetzee & Berjak 1968   29  7470   45  7232    27     random -0.4694 0.0564  #> 10    10      Rosenthal et al 1961   17  1699   65  1600    42 systematic -1.3713 0.0730  #> 11    11       Comstock et al 1974  186 50448  141 27197    18 systematic -0.3394 0.0124  #> 12    12   Comstock & Webster 1969    5  2493    3  2338    33 systematic  0.4459 0.5325  #> 13    13       Comstock et al 1976   27 16886   29 17825    33 systematic -0.0173 0.0714  #>   ### fit equal-effects model res <- rma(yi, vi, data=dat, method=\"EE\")  ### draw radial plot radial(res)  ### line from (0,0) with slope equal to the log risk ratio from the 4th study abline(a=0, b=dat$yi[4], lty=\"dotted\")   ### meta-analysis of the log risk ratios using a random-effects model res <- rma(yi, vi, data=dat)  ### draw radial plot radial(res)"},{"path":"/reference/ranef.html","id":null,"dir":"Reference","previous_headings":"","what":"Best Linear Unbiased Predictions for 'rma.uni' and 'rma.mv' Objects — ranef","title":"Best Linear Unbiased Predictions for 'rma.uni' and 'rma.mv' Objects — ranef","text":"function calculates best linear unbiased predictions (BLUPs) random effects objects class \"rma.uni\" \"rma.mv\". Corresponding standard errors prediction interval bounds also provided.","code":""},{"path":"/reference/ranef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Best Linear Unbiased Predictions for 'rma.uni' and 'rma.mv' Objects — ranef","text":"","code":"# S3 method for rma.uni ranef(object, level, digits, transf, targs, ...) # S3 method for rma.mv ranef(object, level, digits, transf, targs, verbose=FALSE, ...)"},{"path":"/reference/ranef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Best Linear Unbiased Predictions for 'rma.uni' and 'rma.mv' Objects — ranef","text":"object object class \"rma.uni\" \"rma.mv\". level numeric value 0 100 specify prediction interval level. unspecified, default take value object. digits optional integer specify number decimal places printed results rounded. unspecified, default take value object. transf optional argument specify function used transform predicted values interval bounds (e.g., transf=exp; see also transf). unspecified, transformation used. targs optional arguments needed function specified transf. verbose logical specify whether output generated progress computations (default FALSE). ... arguments.","code":""},{"path":"/reference/ranef.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Best Linear Unbiased Predictions for 'rma.uni' and 'rma.mv' Objects — ranef","text":"objects class \"rma.uni\", object class \"list.rma\". object list containing following components: pred predicted values. se corresponding standard errors. pi.lb lower bound prediction intervals. pi.ub upper bound prediction intervals. ... additional elements/values. object formatted printed print function.    objects class \"rma.mv\", list data frames components described .","code":""},{"path":"/reference/ranef.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Best Linear Unbiased Predictions for 'rma.uni' and 'rma.mv' Objects — ranef","text":"best linear unbiased predictions combine fitted values based fixed effects estimated contributions random effects, see blup. predicted/fitted values based fixed effects model, see fitted predict. Equal-effects models contain random study effects. BLUPs models therefore 0. using transf argument, transformation applied predicted values corresponding interval bounds. standard errors set equal NA omitted printed output. default, standard normal distribution used calculate prediction intervals. model fitted test=\"t\" test=\"knha\", t-distribution \\(k-p\\) degrees freedom used. precise, noted function actually calculates empirical BLUPs (eBLUPs), since predicted values function estimated variance component(s).","code":""},{"path":"/reference/ranef.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Best Linear Unbiased Predictions for 'rma.uni' and 'rma.mv' Objects — ranef","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/ranef.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Best Linear Unbiased Predictions for 'rma.uni' and 'rma.mv' Objects — ranef","text":"Kackar, R. N., & Harville, D. . (1981). Unbiasedness two-stage estimation prediction procedures mixed linear models. Communications Statistics, Theory Methods, 10(13), 1249--1261. https://doi.org/10.1080/03610928108828108 Raudenbush, S. W., & Bryk, . S. (1985). Empirical Bayes meta-analysis. Journal Educational Statistics, 10(2), 75--98. https://doi.org/10.3102/10769986010002075 Robinson, G. K. (1991). BLUP good thing: estimation random effects. Statistical Science, 6(1), 15--32. https://doi.org/10.1214/ss/1177011926 Searle, S. R., Casella, G., & McCulloch, C. E. (1992). Variance components. Hoboken, NJ: Wiley. Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/ranef.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Best Linear Unbiased Predictions for 'rma.uni' and 'rma.mv' Objects — ranef","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### meta-analysis of the log risk ratios using a random-effects model res <- rma(yi, vi, data=dat)  ### BLUPs of the random effects ranef(res) #>  #>       pred     se   pi.lb   pi.ub  #> 1  -0.0857 0.4092 -0.8877  0.7163  #> 2  -0.5372 0.3638 -1.2501  0.1758  #> 3  -0.2724 0.4296 -1.1144  0.5696  #> 4  -0.6834 0.2176 -1.1099 -0.2568  #> 5   0.4272 0.2606 -0.0835  0.9378  #> 6  -0.0700 0.1942 -0.4506  0.3105  #> 7  -0.5294 0.3759 -1.2662  0.2073  #> 8   0.7174 0.1882  0.3485  1.0863  #> 9   0.2077 0.2665 -0.3146  0.7300  #> 10 -0.5326 0.2837 -1.0886  0.0234  #> 11  0.3609 0.2046 -0.0401  0.7618  #> 12  0.4298 0.4491 -0.4504  1.3100  #> 13  0.5678 0.2821  0.0149  1.1207  #>"},{"path":"/reference/ranktest.html","id":null,"dir":"Reference","previous_headings":"","what":"Rank Correlation Test for Funnel Plot Asymmetry — ranktest","title":"Rank Correlation Test for Funnel Plot Asymmetry — ranktest","text":"function can used carry rank correlation test funnel plot asymmetry.","code":""},{"path":"/reference/ranktest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rank Correlation Test for Funnel Plot Asymmetry — ranktest","text":"","code":"ranktest(x, vi, sei, subset, data, digits, ...)"},{"path":"/reference/ranktest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rank Correlation Test for Funnel Plot Asymmetry — ranktest","text":"x vector observed effect sizes outcomes object class \"rma\". vi vector corresponding sampling variances (ignored x object class \"rma\"). sei vector corresponding standard errors (note: one two, vi sei, needs specified). subset optional (logical numeric) vector specify subset studies included test (ignored x object class \"rma\"). data optional data frame containing variables given arguments . digits optional integer specify number decimal places printed results rounded. ... arguments.","code":""},{"path":"/reference/ranktest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Rank Correlation Test for Funnel Plot Asymmetry — ranktest","text":"function carries rank correlation test described Begg Mazumdar (1994). test can used examine whether observed effect sizes outcomes corresponding sampling variances correlated. high correlation indicate funnel plot asymmetric, may result publication bias. One can either pass vector observed effect sizes outcomes (via x) corresponding sampling variances via vi (standard errors via sei) function object class \"rma\".","code":""},{"path":"/reference/ranktest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rank Correlation Test for Funnel Plot Asymmetry — ranktest","text":"object class \"ranktest\". object list containing following components: tau estimated value Kendall's tau rank correlation coefficient. pval corresponding p-value test true tau value equal zero. results formatted printed print function.","code":""},{"path":"/reference/ranktest.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Rank Correlation Test for Funnel Plot Asymmetry — ranktest","text":"method depend model fitted. Therefore, regardless model passed function, results rank test always . See regtest tests funnel plot asymmetry based regression models model dependent. function makes use cor.test function method=\"kendall\". possible, exact p-value provided; otherwise, large-sample approximation used.","code":""},{"path":"/reference/ranktest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Rank Correlation Test for Funnel Plot Asymmetry — ranktest","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/ranktest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Rank Correlation Test for Funnel Plot Asymmetry — ranktest","text":"Begg, C. B., & Mazumdar, M. (1994). Operating characteristics rank correlation test publication bias. Biometrics, 50(4), 1088--1101. https://doi.org/10.2307/2533446 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/ranktest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rank Correlation Test for Funnel Plot Asymmetry — ranktest","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit random-effects model res <- rma(yi, vi, data=dat)  ### carry out the rank correlation test ranktest(res) #>  #> Rank Correlation Test for Funnel Plot Asymmetry #>  #> Kendall's tau = 0.0256, p = 0.9524 #>   ### can also pass the observed outcomes and corresponding sampling variances to the function ranktest(yi, vi, data=dat) #>  #> Rank Correlation Test for Funnel Plot Asymmetry #>  #> Kendall's tau = 0.0256, p = 0.9524 #>"},{"path":"/reference/rcalc.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the Variance-Covariance of Dependent Correlation Coefficients — rcalc","title":"Calculate the Variance-Covariance of Dependent Correlation Coefficients — rcalc","text":"function can used calculate variance-covariance matrix correlation coefficients computed based sample subjects.","code":""},{"path":"/reference/rcalc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the Variance-Covariance of Dependent Correlation Coefficients — rcalc","text":"","code":"rcalc(x, ni, data, rtoz=FALSE, nfun=\"min\", sparse=FALSE, ...)"},{"path":"/reference/rcalc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the Variance-Covariance of Dependent Correlation Coefficients — rcalc","text":"x formula form ri ~ var1 + var2 | study. See ‘Details’. ni vector specify sample sizes based correlations computed. data data frame containing variables specified via formula (sample sizes). rtoz logical specify whether transform correlations via Fisher's r--z transformation (default FALSE). nfun character string specify ‘common’ sample size within study computed. Possible options \"min\" (minimum), \"harmonic\" (harmonic mean), \"mean\" (arithmetic mean). Can also function. See ‘Details’. sparse logical specify whether variance-covariance matrix returned sparse matrix (default FALSE). ... arguments.","code":""},{"path":"/reference/rcalc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate the Variance-Covariance of Dependent Correlation Coefficients — rcalc","text":"meta-analysis correlation coefficients may involve multiple correlation coefficients extracted study. correlations computed based sample subjects, typically independent. rcalc function can used create dataset correlation coefficients (possibly transformed Fisher's r--z transformation) corresponding variance-covariance matrix. dataset variance-covariance matrix can meta-analyzed using rma.mv function. computing covariance two correlation coefficients, can distinguish two cases: first case, one variables involved two correlation coefficients . example, \\(r_{12}\\) \\(r_{13}\\), variable 1 common correlation coefficients. sometimes called (partially) ‘overlapping’ case. covariance two correlation coefficients, \\(\\mbox{Cov}[r_{12}, r_{13}]\\), depends degree correlation variables 2 3 (.e., \\(r_{23}\\)). second case, none variables common correlation coefficients. example, case correlations \\(r_{12}\\) \\(r_{34}\\) based 4 variables. sometimes called ‘non-overlapping’ case. covariance two correlation coefficients, \\(\\mbox{Cov}[r_{12}, r_{34}]\\), depends \\(r_{13}\\), \\(r_{14}\\), \\(r_{23}\\), \\(r_{24}\\). Equations compute covariances can found, example, Steiger (1980) Olkin Finn (1990). use rcalc function, one needs construct data frame contains study identifier (say study), two variable identifiers (say var1 var2), corresponding correlation coefficients (say ri), sample sizes based correlation coefficients computed (say ni). first argument formula form ri ~ var1 + var2 | study, argument ni set equal variable name containing sample sizes, data frame containing variables specified via data argument. using function single study, one can leave study identifier formula. argument rtoz set TRUE, correlations transformed Fisher's r--z transformation (Fisher, 1921) variance-covariance matrix computed transformed values. cases, sample size may identical within study (e.g., \\(r_{12}\\) may computed based 120 subjects \\(r_{13}\\) computed based 118 subjects due 2 missing values variable 3). constructing variance-covariance matrix, need assume ‘common’ sample size correlation coefficients within study. Argument nfun provides options common sample size computed. Possible options \"min\" (using minimum sample size within study common sample size), \"harmonic\" (using harmonic mean), \"mean\" (using arithmetic mean). default \"min\", conservative choice (.e., overestimate sampling variances coefficients computed based sample size actually larger minimum sample size). One can also specify function via nfun argument (take numeric vector input return single value).","code":""},{"path":"/reference/rcalc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the Variance-Covariance of Dependent Correlation Coefficients — rcalc","text":"list containing following components: dat data frame study identifier, two variable identifiers, variable pair identifier, correlation coefficients (possibly transformed Fisher's r--z transformation), (common) sample sizes. V corresponding variance-covariance matrix (given sparse matrix sparse=TRUE). Note particular covariance can computed correlation coefficients involved covariance equation included dataset. one coefficients needed computation missing, resulting covariance also missing (.e., NA).","code":""},{"path":"/reference/rcalc.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate the Variance-Covariance of Dependent Correlation Coefficients — rcalc","text":"raw correlation coefficients, variance-covariance matrix computed \\(n-1\\) denominator (instead \\(n\\) suggested Steiger, 1980, Olkin & Finn, 1990). consistent usual equation computing sampling variance correlation coefficient (\\(n-1\\) denominator). raw r--z transformed coefficients, variance-covariance matrix computed (common) sample size study least 5.","code":""},{"path":"/reference/rcalc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate the Variance-Covariance of Dependent Correlation Coefficients — rcalc","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/rcalc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate the Variance-Covariance of Dependent Correlation Coefficients — rcalc","text":"Fisher, R. . (1921). “probable error” coefficient correlation deduced small sample. Metron, 1, 1--32. http://hdl.handle.net/2440/15169 Olkin, ., & Finn, J. D. (1990). Testing correlated correlations. Psychological Bulletin, 108(2), 330--333. https://doi.org/10.1037/0033-2909.108.2.330 Steiger, J. H. (1980). Tests comparing elements correlation matrix. Psychological Bulletin, 87(2), 245--251. https://doi.org/10.1037/0033-2909.87.2.245","code":""},{"path":[]},{"path":"/reference/rcalc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the Variance-Covariance of Dependent Correlation Coefficients — rcalc","text":"","code":"### copy data into 'dat' dat <- dat.craft2003  ### construct dataset and var-cov matrix of the correlations tmp <- rcalc(ri ~ var1 + var2 | study, ni=ni, data=dat) V <- tmp$V dat <- tmp$dat  ### examine data for study 1 dat[dat$study == 1,] #>   study var1 var2 var1.var2    yi  ni #> 1     1 acog perf acog.perf -0.55 142 #> 2     1 asom perf asom.perf -0.48 142 #> 3     1 conf perf conf.perf  0.66 142 #> 4     1 acog asom acog.asom  0.47 142 #> 5     1 acog conf acog.conf -0.38 142 #> 6     1 asom conf asom.conf -0.46 142 blsplit(V, dat$study)$`6` #>             acog.perf   asom.perf conf.perf   acog.asom acog.conf asom.conf #> acog.perf 0.043352064 0.025583395        NA 0.009529623        NA        NA #> asom.perf 0.025583395 0.041438304        NA 0.008459787        NA        NA #> conf.perf          NA          NA        NA          NA        NA        NA #> acog.asom 0.009529623 0.008459787        NA 0.020247414        NA        NA #> acog.conf          NA          NA        NA          NA        NA        NA #> asom.conf          NA          NA        NA          NA        NA        NA  ### examine data for study 6 dat[dat$study == 6,] #>    study var1 var2 var1.var2   yi ni #> 13     6 acog perf acog.perf 0.44 16 #> 14     6 asom perf asom.perf 0.46 16 #> 15     6 conf perf conf.perf   NA 16 #> 16     6 acog asom acog.asom 0.67 16 #> 17     6 acog conf acog.conf   NA 16 #> 18     6 asom conf asom.conf   NA 16 blsplit(V, dat$study)$`6` #>             acog.perf   asom.perf conf.perf   acog.asom acog.conf asom.conf #> acog.perf 0.043352064 0.025583395        NA 0.009529623        NA        NA #> asom.perf 0.025583395 0.041438304        NA 0.008459787        NA        NA #> conf.perf          NA          NA        NA          NA        NA        NA #> acog.asom 0.009529623 0.008459787        NA 0.020247414        NA        NA #> acog.conf          NA          NA        NA          NA        NA        NA #> asom.conf          NA          NA        NA          NA        NA        NA  ### examine data for study 17 dat[dat$study == 17,] #>    study var1 var2 var1.var2    yi ni #> 25    17 acog perf acog.perf  0.10 45 #> 26    17 asom perf asom.perf  0.31 45 #> 27    17 conf perf conf.perf -0.17 45 #> 28    17 acog asom acog.asom    NA 45 #> 29    17 acog conf acog.conf    NA 45 #> 30    17 asom conf asom.conf    NA 45 blsplit(V, dat$study)$`17` #>           acog.perf  asom.perf  conf.perf acog.asom acog.conf asom.conf #> acog.perf  0.022275         NA         NA        NA        NA        NA #> asom.perf        NA 0.01856898         NA        NA        NA        NA #> conf.perf        NA         NA 0.02143262        NA        NA        NA #> acog.asom        NA         NA         NA        NA        NA        NA #> acog.conf        NA         NA         NA        NA        NA        NA #> asom.conf        NA         NA         NA        NA        NA        NA"},{"path":"/reference/regplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Scatter Plots / Bubble Plots — regplot","title":"Scatter Plots / Bubble Plots — regplot","text":"Function create scatter plots / bubble plots based meta-regression models.","code":""},{"path":"/reference/regplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scatter Plots / Bubble Plots — regplot","text":"","code":"regplot(x, ...)  # S3 method for rma regplot(x, mod, pred=TRUE, ci=TRUE, pi=FALSE, shade=TRUE,         xlim, ylim, predlim, olim, xlab, ylab, at, digits=2L,         transf, atransf, targs, level=x$level,         pch=21, psize, plim=c(0.5,3), col=\"black\", bg=\"darkgray\",         grid=FALSE, refline, label=FALSE, offset=c(1,1), labsize=1,         lcol, lwd, lty, legend=FALSE, xvals, ...)  # S3 method for regplot points(x, ...)"},{"path":"/reference/regplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scatter Plots / Bubble Plots — regplot","text":"x object class \"rma.uni\", \"rma.mv\", \"rma.glmm\" including one multiple moderators (object class \"regplot\" points). mod either scalar specify position moderator variable model character string specify name moderator variable. pred logical indicate whether (marginal) regression line based moderator added plot (default TRUE). Can also object predict. See ‘Details’. ci logical indicate whether corresponding confidence interval bounds added plot (default TRUE). pi logical indicate whether corresponding prediction interval bounds added plot (default FALSE). shade logical indicate whether confidence/prediction interval regions shaded (default TRUE). Can also two-element character vector specify colors shading confidence prediction interval regions (shading former, single color can also specified). xlim x-axis limits. unspecified, function tries set x-axis limits sensible values. ylim y-axis limits. unspecified, function tries set y-axis limits sensible values. predlim optional argument specify limits (marginal) regression line. unspecified, limits based range moderator variable. olim optional argument specify observation/outcome limits. unspecified, limits used. xlab title x-axis. unspecified, function tries set appropriate axis title. ylab title y-axis. unspecified, function tries set appropriate axis title. position y-axis tick marks corresponding labels. unspecified, function tries set tick mark positions/labels sensible values. digits integer specify number decimal places tick mark labels y-axis rounded. specifying integer (e.g., 2L), trailing zeros decimal mark dropped y-axis labels. specifying numeric value (e.g., 2), trailing zeros retained. transf optional argument specify function used transform observed outcomes, predicted values, confidence/prediction interval bounds (e.g., transf=exp; see also transf). unspecified, transformation used. atransf optional argument specify function used transform y-axis labels (e.g., atransf=exp; see also transf). unspecified, transformation used. targs optional arguments needed function specified via transf atransf. level numeric value 0 100 specify confidence/prediction interval level (default take value object). pch plotting symbol use observed outcomes. default, filled circle used. Can also vector values. See points options. psize optional numeric value specify point sizes observed outcomes. unspecified, point sizes function model weights. Can also vector values. Can also character string (either \"seinv\" \"vinv\") make point sizes proportional inverse standard errors inverse sampling variances. plim numeric vector length 2 scale point sizes (ignored numeric value vector specified psize). See ‘Details’. col character string specify name color use plotting observed outcomes (default \"black\"). Can also vector color names. bg character string specify name background color open plot symbols (default \"darkgray\"). Can also vector color names. grid logical specify whether grid added plot. Can also color name. refline optional numeric value specify location horizontal reference line added plot. label argument control labeling points (default FALSE). See ‘Details’. offset argument control distance points corresponding labels. See ‘Details’. labsize numeric value control size labels. lcol optional vector () four elements specify color regression line, confidence interval bounds, prediction interval bounds, horizontal reference line. lty optional vector () four elements specify line type regression line, confidence interval bounds, prediction interval bounds, horizontal reference line. lwd optional vector () four elements specify line width regression line, confidence interval bounds, prediction interval bounds, horizontal reference line. legend logical indicate whether legend added plot (default FALSE). Can also keyword indicate position legend (see legend). xvals optional numeric vector specify values moderator predicted values computed. Needs specified passing object predict pred argument. See ‘Details’. ... arguments.","code":""},{"path":"/reference/regplot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Scatter Plots / Bubble Plots — regplot","text":"function draws scatter plot values moderator variable meta-regression model (x-axis) observed effect sizes outcomes (y-axis). regression line model (corresponding confidence interval bounds) added plot default. types plots also often referred ‘bubble plots’ points typically drawn different sizes reflect precision weight model. default (.e., psize specified), size points function square root model weights. way, area proportional weights. However, point sizes rescaled smallest point size plim[1] largest point size plim[2]. result, relative sizes (.e., areas) longer exactly correspond relative weights. exactly relative point sizes desired, one can set plim[2] NA, case points rescaled smallest point size corresponds plim[1] points scaled accordingly. result, largest point may large. Alternatively, one can set plim[1] NA, case points rescaled largest point size corresponds plim[2] points scaled accordingly. result, smallest point may small. avoid latter, one can also set plim[3], enforces minimal point size. One can also set psize scalar (e.g., psize=1) avoid points drawn different sizes. One can also specify point sizes manually passing vector appropriate length psize. Finally, one can also set psize either \"seinv\" \"vinv\" make point sizes proportional inverse standard errors inverse sampling variances. model one predictor, regression line reflects ‘marginal’ relationship chosen moderator effect sizes outcomes (.e., moderators except one plotted held constant means). label argument, one can control whether points plot labeled. label=\"\" (label=TRUE), points plot labeled. label=\"ciout\" label=\"piout\", points falling outside confidence/prediction interval labeled. Alternatively, one can set argument logical numeric vector specify points labeled. labels placed points fall regression line otherwise . offset argument, one can adjust distance labels corresponding points. can either single numeric value, used multiplicative factor point sizes (distance labels points larger larger points) numeric vector two values, first used additive factor independent point sizes second multiplicative factor point sizes. values given percentages y-axis range. may take trial error find two values offset argument labels placed right next boundary points. labsize, one can control size labels. One can also pass object predict pred argument. can useful meta-regression model reflects complex relationship moderator variable effect sizes outcomes (e.g., using polynomials splines) model involves interactions. case, one also needs specify xvals argument. See ‘Examples’.","code":""},{"path":"/reference/regplot.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Scatter Plots / Bubble Plots — regplot","text":"certain types models, may possible draw prediction interval bounds (case, warning issued). specifying vectors pch, psize, col, bg, /label, variables specified assumed length data passed model fitting function. subsetting removal studies missing values automatically applied variables specified via arguments. outcome measure used creating plot bounded (e.g., correlations bounded -1 +1, proportions bounded 0 1), one can use olim argument enforce limits (observed outcomes confidence/prediction intervals exceed bounds ).","code":""},{"path":"/reference/regplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scatter Plots / Bubble Plots — regplot","text":"object class \"regplot\" components: slab study labels ids study ids xi x-axis coordinates points plotted. yi y-axis coordinates points plotted. pch plotting symbols points plotted. psize point sizes points plotted. col colors points plotted. bg background colors points plotted. label logical vector indicating whether point labeled . Note object returned invisibly. Using points.regplot, one can redraw points (labels) case one wants superimpose points top elements added manually plot (see ‘Examples’).","code":""},{"path":"/reference/regplot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Scatter Plots / Bubble Plots — regplot","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/regplot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Scatter Plots / Bubble Plots — regplot","text":"Thompson, S. G., & Higgins, J. P. T. (2002). meta-regression analyses undertaken interpreted? Statistics Medicine, 21(11), 1559--1573. https://doi.org/10.1002/sim.1187 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/regplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scatter Plots / Bubble Plots — regplot","text":"","code":"### copy BCG vaccine data into 'dat' dat <- dat.bcg  ### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat)  ############################################################################  ### fit mixed-effects model with absolute latitude as a moderator res <- rma(yi, vi, mods = ~ ablat, data=dat) res #>  #> Mixed-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.0764 (SE = 0.0591) #> tau (square root of estimated tau^2 value):             0.2763 #> I^2 (residual heterogeneity / unaccounted variability): 68.39% #> H^2 (unaccounted variability / sampling variability):   3.16 #> R^2 (amount of heterogeneity accounted for):            75.62% #>  #> Test for Residual Heterogeneity: #> QE(df = 11) = 30.7331, p-val = 0.0012 #>  #> Test of Moderators (coefficient 2): #> QM(df = 1) = 16.3571, p-val < .0001 #>  #> Model Results: #>  #>          estimate      se     zval    pval    ci.lb    ci.ub     ​  #> intrcpt    0.2515  0.2491   1.0095  0.3127  -0.2368   0.7397       #> ablat     -0.0291  0.0072  -4.0444  <.0001  -0.0432  -0.0150  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### draw plot regplot(res, mod=\"ablat\", xlab=\"Absolute Latitude\")   ### adjust x-axis limits and back-transform to risk ratios regplot(res, mod=\"ablat\", xlab=\"Absolute Latitude\", xlim=c(0,60), transf=exp)   ### also extend the prediction limits for the regression line regplot(res, mod=\"ablat\", xlab=\"Absolute Latitude\", xlim=c(0,60), predlim=c(0,60), transf=exp)   ### add the prediction interval to the plot, add a reference line at 1, and add a legend regplot(res, mod=\"ablat\", pi=TRUE, xlab=\"Absolute Latitude\",         xlim=c(0,60), predlim=c(0,60), transf=exp, refline=1, legend=TRUE)   ### label points outside of the prediction interval regplot(res, mod=\"ablat\", pi=TRUE, xlab=\"Absolute Latitude\",         xlim=c(0,60), predlim=c(0,60), transf=exp, refline=1, legend=TRUE,         label=\"piout\", labsize=0.8)   ############################################################################  ### fit mixed-effects model with absolute latitude and publication year as moderators res <- rma(yi, vi, mods = ~ ablat + year, data=dat) res #>  #> Mixed-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.1108 (SE = 0.0845) #> tau (square root of estimated tau^2 value):             0.3328 #> I^2 (residual heterogeneity / unaccounted variability): 71.98% #> H^2 (unaccounted variability / sampling variability):   3.57 #> R^2 (amount of heterogeneity accounted for):            64.63% #>  #> Test for Residual Heterogeneity: #> QE(df = 10) = 28.3251, p-val = 0.0016 #>  #> Test of Moderators (coefficients 2:3): #> QM(df = 2) = 12.2043, p-val = 0.0022 #>  #> Model Results: #>  #>          estimate       se     zval    pval     ci.lb    ci.ub    ​  #> intrcpt   -3.5455  29.0959  -0.1219  0.9030  -60.5724  53.4814      #> ablat     -0.0280   0.0102  -2.7371  0.0062   -0.0481  -0.0080  **  #> year       0.0019   0.0147   0.1299  0.8966   -0.0269   0.0307      #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### plot the marginal relationships regplot(res, mod=\"ablat\", xlab=\"Absolute Latitude\")  regplot(res, mod=\"year\",  xlab=\"Publication Year\")   ############################################################################  ### fit a quadratic polynomial meta-regression model res <- rma(yi, vi, mods = ~ ablat + I(ablat^2), data=dat) res #>  #> Mixed-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.0806 (SE = 0.0658) #> tau (square root of estimated tau^2 value):             0.2840 #> I^2 (residual heterogeneity / unaccounted variability): 66.62% #> H^2 (unaccounted variability / sampling variability):   3.00 #> R^2 (amount of heterogeneity accounted for):            74.26% #>  #> Test for Residual Heterogeneity: #> QE(df = 10) = 28.4961, p-val = 0.0015 #>  #> Test of Moderators (coefficients 2:3): #> QM(df = 2) = 16.9151, p-val = 0.0002 #>  #> Model Results: #>  #>             estimate      se     zval    pval    ci.lb   ci.ub   ​  #> intrcpt      -0.3889  0.6285  -0.6188  0.5360  -1.6207  0.8429     #> ablat         0.0218  0.0464   0.4699  0.6385  -0.0692  0.1128     #> I(ablat^2)   -0.0008  0.0007  -1.1100  0.2670  -0.0022  0.0006     #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### compute predicted values using predict() xs <- seq(0,60,length=601) tmp <- predict(res, newmods=cbind(xs, xs^2))  ### can now pass these results to the 'pred' argument (and have to specify xvals accordingly) regplot(res, mod=\"ablat\", pred=tmp, xlab=\"Absolute Latitude\", xlim=c(0,60), xvals=xs)   ### back-transform to risk ratios and add reference line regplot(res, mod=\"ablat\", pred=tmp, xlab=\"Absolute Latitude\", xlim=c(0,60), xvals=xs,         transf=exp, refline=1)   ############################################################################  ### fit a model with an interaction between a quantitative and a categorical predictor ### (note: just for illustration purposes; this model is too complex for this dataset) res <- rma(yi, vi, mods = ~ ablat * alloc, data=dat) res #>  #> Mixed-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.2465 (SE = 0.2085) #> tau (square root of estimated tau^2 value):             0.4965 #> I^2 (residual heterogeneity / unaccounted variability): 70.49% #> H^2 (unaccounted variability / sampling variability):   3.39 #> R^2 (amount of heterogeneity accounted for):            21.30% #>  #> Test for Residual Heterogeneity: #> QE(df = 7) = 20.7809, p-val = 0.0041 #>  #> Test of Moderators (coefficients 2:6): #> QM(df = 5) = 7.4799, p-val = 0.1873 #>  #> Model Results: #>  #>                        estimate      se     zval    pval    ci.lb   ci.ub   ​  #> intrcpt                  0.0209  0.8027   0.0260  0.9792  -1.5525  1.5942     #> ablat                   -0.0183  0.0239  -0.7658  0.4438  -0.0653  0.0286     #> allocrandom              0.0068  0.9689   0.0070  0.9944  -1.8922  1.9058     #> allocsystematic          0.4711  1.2713   0.3705  0.7110  -2.0206  2.9627     #> ablat:allocrandom       -0.0098  0.0279  -0.3518  0.7250  -0.0645  0.0449     #> ablat:allocsystematic   -0.0125  0.0391  -0.3193  0.7495  -0.0892  0.0642     #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### draw bubble plot but do not add regression line or CI tmp <- regplot(res, mod=\"ablat\", xlab=\"Absolute Latitude\", xlim=c(0,60), pred=FALSE, ci=FALSE)  ### add regression lines for the three alloc levels xs <- seq(0, 60, length=100) preds <- predict(res, newmods=cbind(xs, 0, 0, 0, 0)) lines(xs, preds$pred, lwd=3) preds <- predict(res, newmods=cbind(xs, 1, 0, xs, 0)) lines(xs, preds$pred, lwd=3) preds <- predict(res, newmods=cbind(xs, 0, 1, 0, xs)) lines(xs, preds$pred, lwd=3)  ### add points back to the plot (so they are on top of the lines) points(tmp)"},{"path":"/reference/regtest.html","id":null,"dir":"Reference","previous_headings":"","what":"Regression Test for Funnel Plot Asymmetry — regtest","title":"Regression Test for Funnel Plot Asymmetry — regtest","text":"function can used carry (various versions ) Egger's regression test funnel plot asymmetry.","code":""},{"path":"/reference/regtest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Regression Test for Funnel Plot Asymmetry — regtest","text":"","code":"regtest(x, vi, sei, ni, subset, data,         model=\"rma\", predictor=\"sei\", ret.fit=FALSE, digits, ...)"},{"path":"/reference/regtest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regression Test for Funnel Plot Asymmetry — regtest","text":"x vector observed effect sizes outcomes object class \"rma\". vi vector corresponding sampling variances (ignored x object class \"rma\"). sei vector corresponding standard errors (note: one two, vi sei, needs specified). ni optional vector corresponding sample sizes (relevant using sample sizes (transformation thereof) predictor). subset optional (logical numeric) vector specify subset studies included test (ignored x object class \"rma\"). data optional data frame containing variables given arguments . model either \"rma\" \"lm\" indicate type model use regression test. See ‘Details’. predictor either \"sei\" \"vi\", \"ni\", \"ninv\", \"sqrtni\", \"sqrtninv\" indicate predictor use regression test. See ‘Details’. ret.fit logical specify whether full results fitted model also returned. digits optional integer specify number decimal places printed results rounded. ... arguments.","code":""},{"path":"/reference/regtest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Regression Test for Funnel Plot Asymmetry — regtest","text":"Various tests funnel plot asymmetry suggested literature, including rank correlation test Begg Mazumdar (1994) regression test Egger et al. (1997). Extensions, modifications, developments regression test described (among others) Macaskill, Walter, Irwig (2001), Sterne Egger (2005), Harbord, Egger, Sterne (2006), Peters et al. (2006), Rücker et al. (2008), Moreno et al. (2009). various versions regression test differ terms model (either weighted regression model multiplicative dispersion term fixed/mixed-effects meta-regression model used), terms predictor variable observed effect sizes outcomes hypothesized related publication bias present (suggested predictors include standard error, sampling variance, sample size transformations thereof), terms outcome measure used (e.g., \\(2 \\times 2\\) table data, one choice various outcome measures). idea behind various tests though: relationship observed effect sizes outcomes chosen predictor, usually implies asymmetry funnel plot, turn may indication publication bias. regtest function can used carry various versions regression test. One can either pass vector observed effect sizes outcomes (via x) corresponding sampling variances via vi (standard errors via sei) function object class \"rma\". model type regression test chosen via model argument, model=\"lm\" weighted regression model multiplicative dispersion term model=\"rma\" (mixed-effects) meta-regression model (default). predictor test chosen via predictor argument: predictor=\"sei\" standard errors (default), predictor=\"vi\" sampling variances, predictor=\"ni\" sample sizes, predictor=\"ninv\" inverse sample sizes, predictor=\"sqrtni\" square root sample sizes, predictor=\"sqrtninv\" inverse square root sample sizes. outcome measure used regression test simply determined values passed function measure used fitting original model (passing object class \"rma\" function). using sample sizes (transformation thereof) predictor, one can use ni argument specify sample sizes. x vector observed effect sizes outcomes computed escalc, sample sizes automatically stored attribute x ni need specified. also case passing object class \"rma\" function input model fitting function came escalc. passing object class \"rma\" function, arguments method, weighted, test used initial model fitting also used regression test. model already included one moderators, regtest add chosen predictor moderator(s) already included model. way, one can test funnel plot asymmetry accounting first influence moderator(s) already included model. model used conducting regression test can also used obtain ‘limit estimate’ (average) true effect outcome. particular, standard errors, sampling variances, inverse (square root) sample sizes used predictor, model intercept essence reflects estimate infinite precision. sometimes (cautiously) interpreted estimate (average) true effect outcome adjusted publication bias.","code":""},{"path":"/reference/regtest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Regression Test for Funnel Plot Asymmetry — regtest","text":"object class \"regtest\". object list containing following components: model model used regression test. predictor predictor used regression test. zval value test statistic. pval corresponding p-value dfs degrees freedom test statistic (test based t-distribution). fit full results fitted model. est limit estimate (predictors \"sei\" \"vi\", \"ninv\", \"sqrtninv\" model contain additional moderators; NULL otherwise). ci.lb lower bound confidence interval limit estimate. ci.ub upper bound confidence intervals limit estimate. results formatted printed print function.","code":""},{"path":"/reference/regtest.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Regression Test for Funnel Plot Asymmetry — regtest","text":"classical ‘Egger test’ obtained setting model=\"lm\" predictor=\"sei\". random/mixed-effects version test, set model=\"rma\" (default). See Sterne Egger (2005) details two types models/tests. conducting classical ‘Egger test’, test limit estimate ‘precision-effect test’ (PET) Stanley Doucouliagos (2014). limit estimate using sampling variance predictor sometimes called ‘precision-effect estimate SE’ (PEESE) (Stanley & Doucouliagos, 2014). conditional procedure use limit estimate PET significant (.e., using standard error predictor) PEESE (.e., using sampling variance predictor) PET significant sometimes called PET-PEESE procedure (Stanley & Doucouliagos, 2014). tests directly test publication bias, relationship observed effect sizes outcomes chosen predictor. relationship present, usually implies asymmetry funnel plot, turn may indication publication bias. However, important keep mind can reasons besides publication bias lead asymmetry funnel plot.","code":""},{"path":"/reference/regtest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Regression Test for Funnel Plot Asymmetry — regtest","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/regtest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Regression Test for Funnel Plot Asymmetry — regtest","text":"Begg, C. B., & Mazumdar, M. (1994). Operating characteristics rank correlation test publication bias. Biometrics, 50(4), 1088--1101. https://doi.org/10.2307/2533446 Egger, M., Davey Smith, G., Schneider, M., & Minder, C. (1997). Bias meta-analysis detected simple, graphical test. British Medical Journal, 315(7109), 629--634. https://doi.org/10.1136/bmj.315.7109.629 Harbord, R. M., Egger, M., & Sterne, J. . C. (2006). modified test small-study effects meta-analyses controlled trials binary endpoints. Statistics Medicine, 25(20), 3443--3457. https://doi.org/10.1002/sim.2380 Macaskill, P., Walter, S. D., & Irwig, L. (2001). comparison methods detect publication bias meta-analysis. Statistics Medicine, 20(4), 641--654. https://doi.org/10.1002/sim.698 Moreno, S. G., Sutton, . J., Ades, . E., Stanley, T. D., Abrams, K. R., Peters, J. L., & Cooper, N. J. (2009). Assessment regression-based methods adjust publication bias comprehensive simulation study. BMC Medical Research Methodology, 9, 2. https://doi.org/10.1186/1471-2288-9-2 Peters, J. L., Sutton, . J., Jones, D. R., Abrams, K. R., & Rushton, L. (2006). Comparison two methods detect publication bias meta-analysis. Journal American Medical Association, 295(6), 676--680. https://doi.org/10.1001/jama.295.6.676 Rücker, G., Schwarzer, G., & Carpenter, J. (2008). Arcsine test publication bias meta-analyses binary outcomes. Statistics Medicine, 27(5), 746--763. https://doi.org/10.1002/sim.2971 Stanley, T. D., & Doucouliagos, H. (2014). Meta-regression approximations reduce publication selection bias. Research Synthesis Methods, 5(1), 60--78. https://doi.org/10.1002/jrsm.1095 Sterne, J. . C., & Egger, M. (2005). Regression methods detect publication bias meta-analysis. H. R. Rothstein, . J. Sutton, & M. Borenstein (Eds.) Publication bias meta-analysis: Prevention, assessment, adjustments (pp. 99--110). Chichester, England: Wiley. Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/regtest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Regression Test for Funnel Plot Asymmetry — regtest","text":"","code":"### copy data into 'dat' and examine data dat <- dat.egger2001  ### calculate log odds ratios and corresponding sampling variances (but remove ISIS-4 trial) dat <- escalc(measure=\"OR\", ai=ai, n1i=n1i, ci=ci, n2i=n2i, data=dat, subset=-16)  ### fit random-effects model res <- rma(yi, vi, data=dat) res #>  #> Random-Effects Model (k = 15; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.1911 (SE = 0.2106) #> tau (square root of estimated tau^2 value):      0.4371 #> I^2 (total heterogeneity / total variability):   38.19% #> H^2 (total variability / sampling variability):  1.62 #>  #> Test for Heterogeneity: #> Q(df = 14) = 20.9184, p-val = 0.1037 #>  #> Model Results: #>  #> estimate      se     zval    pval    ci.lb    ci.ub     ​  #>  -0.8745  0.2080  -4.2049  <.0001  -1.2822  -0.4669  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### classical Egger test regtest(res, model=\"lm\") #>  #> Regression Test for Funnel Plot Asymmetry #>  #> Model:     weighted regression with multiplicative dispersion #> Predictor: standard error #>  #> Test for Funnel Plot Asymmetry: t = -3.1783, df = 13, p = 0.0073 #> Limit Estimate (as sei -> 0):   b = -0.1512 (CI: -0.5130, 0.2106) #>   ### mixed-effects meta-regression version of the Egger test regtest(res) #>  #> Regression Test for Funnel Plot Asymmetry #>  #> Model:     mixed-effects meta-regression model #> Predictor: standard error #>  #> Test for Funnel Plot Asymmetry: z = -2.8062, p = 0.0050 #> Limit Estimate (as sei -> 0):   b = -0.1639 (CI: -0.5681, 0.2402) #>   ### same tests, but passing outcomes directly regtest(yi, vi, data=dat, model=\"lm\") #>  #> Regression Test for Funnel Plot Asymmetry #>  #> Model:     weighted regression with multiplicative dispersion #> Predictor: standard error #>  #> Test for Funnel Plot Asymmetry: t = -3.1783, df = 13, p = 0.0073 #> Limit Estimate (as sei -> 0):   b = -0.1512 (CI: -0.5130, 0.2106) #>  regtest(yi, vi, data=dat) #>  #> Regression Test for Funnel Plot Asymmetry #>  #> Model:     mixed-effects meta-regression model #> Predictor: standard error #>  #> Test for Funnel Plot Asymmetry: z = -2.8062, p = 0.0050 #> Limit Estimate (as sei -> 0):   b = -0.1639 (CI: -0.5681, 0.2402) #>   ### if dat$yi is computed with escalc(), sample size information is stored in attributes dat$yi #>  [1] -0.83034830 -1.05605267 -1.27833981 -0.04348511  0.22314355 -2.40751999 -1.28093385 -1.19170271 #>  [9] -0.69574796 -2.20827441 -2.03815988 -0.85015093 -0.79323064 -0.29933987 -1.57078846 #> attr(,\"ni\") #>  [1]   76  270  400   94  298  115   48   43  151   54  169   56  252 2316  215 #> attr(,\"measure\") #> [1] \"OR\"  ### then this will also work regtest(yi, vi, data=dat, predictor=\"ni\") #>  #> Regression Test for Funnel Plot Asymmetry #>  #> Model:     mixed-effects meta-regression model #> Predictor: sample size #>  #> Test for Funnel Plot Asymmetry: z = 1.7938, p = 0.0728 #>   ### similarly when passing a model object to the function regtest(res, model=\"lm\", predictor=\"ni\") #>  #> Regression Test for Funnel Plot Asymmetry #>  #> Model:     weighted regression with multiplicative dispersion #> Predictor: sample size #>  #> Test for Funnel Plot Asymmetry: t = 2.8955, df = 13, p = 0.0125 #>  regtest(res, model=\"lm\", predictor=\"ninv\") #>  #> Regression Test for Funnel Plot Asymmetry #>  #> Model:     weighted regression with multiplicative dispersion #> Predictor: inverse of the sample size #>  #> Test for Funnel Plot Asymmetry: t = -2.3230, df = 13, p = 0.0370 #> Limit Estimate (as ni -> inf):  b = -0.3731 (CI: -0.6872, -0.0591) #>  regtest(res, predictor=\"ni\") #>  #> Regression Test for Funnel Plot Asymmetry #>  #> Model:     mixed-effects meta-regression model #> Predictor: sample size #>  #> Test for Funnel Plot Asymmetry: z = 1.7938, p = 0.0728 #>  regtest(res, predictor=\"ninv\") #>  #> Regression Test for Funnel Plot Asymmetry #>  #> Model:     mixed-effects meta-regression model #> Predictor: inverse of the sample size #>  #> Test for Funnel Plot Asymmetry: z = -1.4313, p = 0.1524 #> Limit Estimate (as ni -> inf):  b = -0.5636 (CI: -1.0712, -0.0559) #>   ### otherwise have to supply sample sizes manually dat$nitotal <- with(dat, n1i + n2i) dat$yi <- c(dat$yi) # this removes the 'ni' attribute from 'yi' regtest(yi, vi, ni=nitotal, data=dat, predictor=\"ni\") #>  #> Regression Test for Funnel Plot Asymmetry #>  #> Model:     mixed-effects meta-regression model #> Predictor: sample size #>  #> Test for Funnel Plot Asymmetry: z = 1.7938, p = 0.0728 #>  res <- rma(yi, vi, data=dat) regtest(res, predictor=\"ni\", ni=nitotal, data=dat) #>  #> Regression Test for Funnel Plot Asymmetry #>  #> Model:     mixed-effects meta-regression model #> Predictor: sample size #>  #> Test for Funnel Plot Asymmetry: z = 1.7938, p = 0.0728 #>   ### standard funnel plot (with standard errors on the y-axis) funnel(res, refline=0)  ### regression test (by default the standard errors are used as predictor) reg <- regtest(res) reg #>  #> Regression Test for Funnel Plot Asymmetry #>  #> Model:     mixed-effects meta-regression model #> Predictor: standard error #>  #> Test for Funnel Plot Asymmetry: z = -2.8062, p = 0.0050 #> Limit Estimate (as sei -> 0):   b = -0.1639 (CI: -0.5681, 0.2402) #>   ### add regression line to funnel plot se <- seq(0,1.8,length=100) lines(coef(reg$fit)[1] + coef(reg$fit)[2]*se, se, lwd=3)  ### regression test (using the sampling variances as predictor) reg <- regtest(res, predictor=\"vi\")  ### add regression line to funnel plot (using the sampling variances as predictor) lines(coef(reg$fit)[1] + coef(reg$fit)[2]*se^2, se, lwd=3)   ### testing for asymmetry after accounting for the influence of a moderator res <- rma(yi, vi, mods = ~ year, data=dat) regtest(res, model=\"lm\") #>  #> Regression Test for Funnel Plot Asymmetry #>  #> Model:     weighted regression with multiplicative dispersion #> Predictor: standard error #>  #> Test for Funnel Plot Asymmetry: t = -3.1057, df = 12, p = 0.0091 #>  regtest(res) #>  #> Regression Test for Funnel Plot Asymmetry #>  #> Model:     mixed-effects meta-regression model #> Predictor: standard error #>  #> Test for Funnel Plot Asymmetry: z = -2.3198, p = 0.0204 #>"},{"path":"/reference/replmiss.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace Missing Values in a Vector — replmiss","title":"Replace Missing Values in a Vector — replmiss","text":"Function replace missing (NA) values vector.","code":""},{"path":"/reference/replmiss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace Missing Values in a Vector — replmiss","text":"","code":"replmiss(x, y)"},{"path":"/reference/replmiss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace Missing Values in a Vector — replmiss","text":"x vector may include one missing values. y either scalar vector length x value(s) replace missing values .","code":""},{"path":"/reference/replmiss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Replace Missing Values in a Vector — replmiss","text":"Vector x missing values replaced based scalar vector y.","code":""},{"path":"/reference/replmiss.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Replace Missing Values in a Vector — replmiss","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/replmiss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Replace Missing Values in a Vector — replmiss","text":"","code":"x <- c(4,2,7,NA,1,NA,5) x <- replmiss(x,0) x #> [1] 4 2 7 0 1 0 5  x <- c(4,2,7,NA,1,NA,5) y <- c(2,3,6,5,8,1,2) x <- replmiss(x,y) x #> [1] 4 2 7 5 1 1 5"},{"path":"/reference/reporter.html","id":null,"dir":"Reference","previous_headings":"","what":"Dynamically Generated Analysis Reports for 'rma.uni' Objects — reporter","title":"Dynamically Generated Analysis Reports for 'rma.uni' Objects — reporter","text":"function dynamically generates analysis reports objects class \"rma.uni\".","code":""},{"path":"/reference/reporter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dynamically Generated Analysis Reports for 'rma.uni' Objects — reporter","text":"","code":"reporter(x, ...)  # S3 method for rma.uni reporter(x, dir, filename, format=\"html_document\", open=TRUE,          digits, forest, funnel, footnotes=FALSE, verbose=TRUE, ...)"},{"path":"/reference/reporter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dynamically Generated Analysis Reports for 'rma.uni' Objects — reporter","text":"x object class \"rma.uni\". dir optional character string specify directory creating report. unspecified, tempdir used. filename optional character string specify filename (without file extension) report. unspecified, function sets filename automatically. format output format report (either html_document, pdf_document, word_document). Can abbreviated. See ‘Note’. open logical specify whether report opened generated (default TRUE). See ‘Note’. digits optional integer specify number decimal places printed results rounded. unspecified, default take value object. forest either logical suppress drawing forest plot set FALSE character string arguments added call forest generating forest plot. funnel either logical suppress drawing funnel plot set FALSE character string arguments added call funnel generating funnel plot. footnotes logical specify whether additional explanatory footnotes added report (default FALSE). verbose logical specify whether information progress report generation provided (default TRUE). ... arguments.","code":""},{"path":"/reference/reporter.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Dynamically Generated Analysis Reports for 'rma.uni' Objects — reporter","text":"function dynamically generates analysis report based model object. report includes information model fitted, distribution observed effect sizes outcomes, estimate average outcome based fitted model, tests statistics informative potential (residual) heterogeneity outcomes, checks outliers /influential studies, tests funnel plot asymmetry. default, forest plot funnel plot also provided (can suppressed setting forest=FALSE /funnel=FALSE).","code":""},{"path":"/reference/reporter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dynamically Generated Analysis Reports for 'rma.uni' Objects — reporter","text":"function generates either html, pdf, docx file returns (invisibly) path generated document.","code":""},{"path":"/reference/reporter.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Dynamically Generated Analysis Reports for 'rma.uni' Objects — reporter","text":"Since report created based R markdown document generated function, rmarkdown package pandoc must installed. render report pdf document (.e., using format=\"pdf_document\") requires LaTeX installation. LaTeX already installed, try using tinytex package install lightweight LaTeX distribution based TeX Live. report generated, function tries open output file (either .html, .pdf, .docx file) appropriate application (open=TRUE). work appropriate application file type installed associated extension. filename unspecified, default use report, followed underscore (.e., _) name object passed function. R markdown file (extension .rmd) actual report (extension .html, .pdf, .docx) named accordingly. generate report, model object also saved file (filename , extension .rdata). Also, files references.bib apa.csl copied directory (files needed generate references APA format). Since report put together based predefined text blocks, writing elegant. Also, using personal pronouns (‘’ ‘’) make sense report, lot passive voice used. generated report provides illustration results model can reported, substitute careful examination results.","code":""},{"path":"/reference/reporter.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Dynamically Generated Analysis Reports for 'rma.uni' Objects — reporter","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/reporter.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Dynamically Generated Analysis Reports for 'rma.uni' Objects — reporter","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/reporter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dynamically Generated Analysis Reports for 'rma.uni' Objects — reporter","text":"","code":"### copy BCG vaccine data into 'dat' dat <- dat.bcg  ### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat,               slab=paste(author, \", \", year, sep=\"\"))  ### fit random-effects model res <- rma(yi, vi, data=dat)  # \\dontrun{ ### generate pdf report reporter(res)# } #>  #> Directory for generating the report is: /tmp/RtmpsGlX5K #> Copying references.bib and apa.csl to report directory ... #> Saving model object to report_res.rdata ... #> Creating report_res.rmd file ... #> Rendering report_res.rmd file ... #> Generated /tmp/RtmpsGlX5K/report_res.html ... #> Opening report ..."},{"path":"/reference/residuals.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Residual Values based on 'rma' Objects — residuals.rma","title":"Residual Values based on 'rma' Objects — residuals.rma","text":"residuals, rstandard, rstudent functions compute residuals, corresponding standard errors, standardized residuals models fitted rma.uni, rma.mh, rma.peto, rma.mv functions.","code":""},{"path":"/reference/residuals.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Residual Values based on 'rma' Objects — residuals.rma","text":"","code":"# S3 method for rma residuals(object, type=\"response\", ...)  # S3 method for rma.uni rstandard(model, digits, type=\"marginal\", ...) # S3 method for rma.mh rstandard(model, digits, ...) # S3 method for rma.peto rstandard(model, digits, ...) # S3 method for rma.mv rstandard(model, digits, cluster, ...)  # S3 method for rma.uni rstudent(model, digits, progbar=FALSE, ...) # S3 method for rma.mh rstudent(model, digits, progbar=FALSE, ...) # S3 method for rma.peto rstudent(model, digits, progbar=FALSE, ...) # S3 method for rma.mv rstudent(model, digits, progbar=FALSE, cluster,          reestimate=TRUE, parallel=\"no\", ncpus=1, cl, ...)"},{"path":"/reference/residuals.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Residual Values based on 'rma' Objects — residuals.rma","text":"object object class \"rma\" (residuals). type type residuals returned. residuals, alternatives : \"response\" (default), \"rstandard\", \"rstudent\", \"pearson\". rstandard.rma.uni, alternatives : \"marginal\" (default) \"conditional\". See ‘Details’. model object class \"rma\" (residuals) object class \"rma.uni\", \"rma.mh\", \"rma.peto\", \"rma.mv\" (rstandard rstudent). cluster optional vector specify clustering variable use computing cluster-level multivariate standardized residuals (\"rma.mv\" objects). reestimate logical specify whether variance/correlation components re-estimated deletion \\(\\textrm{th}\\) case computing externally standardized residuals \"rma.mv\" objects (default TRUE). parallel character string specify whether parallel processing used (default \"\"). parallel processing, set either \"snow\" \"multicore\". See ‘Details’. ncpus integer specify number processes use parallel processing. cl optional cluster use parallel=\"snow\". unspecified, cluster local machine created duration call. digits optional integer specify number decimal places printed results rounded. unspecified, default take value object. progbar logical specify whether progress bar shown (rstudent) (default FALSE). ... arguments.","code":""},{"path":"/reference/residuals.rma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Residual Values based on 'rma' Objects — residuals.rma","text":"observed residuals (obtained residuals) simply equal ‘observed - fitted’ values. can obtained residuals(object) (using default type=\"response\"). Dividing observed residuals model-implied standard errors observed effect sizes outcomes yields Pearson (semi-standardized) residuals. can obtained residuals(object, type=\"pearson\"). Dividing observed residuals corresponding standard errors yields (internally) standardized residuals. can obtained rstandard(model) residuals(object, type=\"rstandard\"). rstudent(model) (residuals(object, type=\"rstudent\")), one can obtain externally standardized residuals (also called standardized deleted residuals (externally) studentized residuals). externally standardized residual \\(\\textrm{th}\\) case obtained deleting \\(\\textrm{th}\\) case dataset, fitting model based remaining cases, calculating predicted value \\(\\textrm{th}\\) case based fitted model, taking difference observed predicted value \\(\\textrm{th}\\) case (yields deleted residual), standardizing deleted residual based standard error. particular case fits model, standardized residual follows (asymptotically) standard normal distribution. large standardized residual case therefore may suggest case fit assumed model (.e., may outlier). \"rma.uni\" objects, rstandard(model, type=\"conditional\") computes conditional residuals, deviations observed effect sizes outcomes best linear unbiased predictions (BLUPs) study-specific true effect sizes outcomes (see blup). \"rma.mv\" objects, one can specify clustering variable (via cluster argument). specified, rstandard(model) rstudent(model) also compute cluster-level multivariate (internally externally) standardized residuals. outcomes within cluster fit model, multivariate standardized residual cluster follows (asymptotically) chi-square distribution \\(k_i\\) degrees freedom (\\(k_i\\) denotes number outcomes within cluster). See also influence.rma.uni influence.rma.mv leave-one-diagnostics useful detecting influential cases models fitted rma.uni rma.mv functions.","code":""},{"path":"/reference/residuals.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Residual Values based on 'rma' Objects — residuals.rma","text":"Either vector residuals requested type (residuals) object class \"list.rma\", list containing following components: resid observed residuals (rstandard) deleted residuals (rstudent). se corresponding standard errors. z standardized residuals (internally standardized rstandard externally standardized rstudent). clustering variable specified \"rma.mv\" objects, returned object list first element (named obs) described second element (named cluster class \"list.rma\" : X2 cluster-level multivariate standardized residuals. k number observed effect sizes outcomes within clusters. object formatted printed print.list.rma.","code":""},{"path":"/reference/residuals.rma.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Residual Values based on 'rma' Objects — residuals.rma","text":"Right now, externally standardized residuals (obtained rstudent) calculated refitting model \\(k\\) times (\\(k\\) number cases). Depending large \\(k\\) , may take moments finish calculations. complex models fitted rma.mv, can become computationally expensive. machines multiple cores, one can usually speed things delegating model fitting separate worker processes, , setting parallel=\"snow\" parallel=\"multicore\" ncpus value larger 1 (objects class \"rma.mv\"). Parallel processing makes use parallel package, using makePSOCKcluster parLapply functions parallel=\"snow\" using mclapply parallel=\"multicore\" (latter works Unix/Linux-alikes). parallel::detectCores(), one can check number available cores local machine. Alternatively (addition using parallel processing), one can also set reestimate=FALSE, case variance/correlation components model re-estimated deleting \\(\\textrm{th}\\) case dataset. yields approximation externally standardized residuals (cluster-level multivariate standardized residuals) ignores influence \\(\\textrm{th}\\) case variance/correlation components, considerably faster (often yields similar results). may possible fit model deletion \\(\\textrm{th}\\) case dataset. result NA values case calling rstudent. Also, \"rma.mv\" objects clustering variable specified, may possible compute cluster-level multivariate standardized residual particular cluster (var-cov matrix residuals within cluster full rank). result NA cluster. objects class \"rma.mh\" \"rma.peto\", rstandard actually computes Pearson (semi-standardized) residuals.","code":""},{"path":"/reference/residuals.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Residual Values based on 'rma' Objects — residuals.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/residuals.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Residual Values based on 'rma' Objects — residuals.rma","text":"Hedges, L. V., & Olkin, . (1985). Statistical methods meta-analysis. San Diego, CA: Academic Press. Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03 Viechtbauer, W., & Cheung, M. W.-L. (2010). Outlier influence diagnostics meta-analysis. Research Synthesis Methods, 1(2), 112--125. https://doi.org/10.1002/jrsm.11","code":""},{"path":[]},{"path":"/reference/residuals.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Residual Values based on 'rma' Objects — residuals.rma","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit random-effects model res <- rma(yi, vi, data=dat)  ### compute the studentized residuals rstudent(res) #>  #>      resid     se       z  #> 1  -0.1822 0.8354 -0.2181  #> 2  -0.9314 0.7210 -1.2918  #> 3  -0.6625 0.8778 -0.7547  #> 4  -0.8131 0.5603 -1.4512  #> 5   0.5466 0.6448  0.8477  #> 6  -0.0752 0.6376 -0.1180  #> 7  -0.9657 0.7407 -1.3037  #> 8   0.8067 0.5563  1.4501  #> 9   0.2718 0.6668  0.4076  #> 10 -0.7183 0.6369 -1.1277  #> 11  0.4185 0.6255  0.6691  #> 12  1.2057 0.9348  1.2898  #> 13  0.7602 0.6400  1.1879  #>   ### fit mixed-effects model with absolute latitude as moderator res <- rma(yi, vi, mods = ~ ablat, data=dat)  ### compute the studentized residuals rstudent(res) #>  #>      resid     se       z  #> 1   0.1488 0.6587  0.2259  #> 2  -0.2801 0.5811 -0.4819  #> 3  -0.3906 0.7177 -0.5442  #> 4  -0.2709 0.4078 -0.6644  #> 5  -0.1044 0.4489 -0.2325  #> 6   0.3183 0.3296  0.9657  #> 7  -1.4026 0.5256 -2.6687  #> 8   0.2270 0.4082  0.5560  #> 9   0.0804 0.4226  0.1903  #> 10 -0.4538 0.4002 -1.1338  #> 11 -0.0704 0.3993 -0.1764  #> 12  1.1763 0.7867  1.4954  #> 13  0.7315 0.3529  2.0730  #>"},{"path":"/reference/rma.glmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Meta-Analysis via Generalized Linear (Mixed-Effects) Models — rma.glmm","title":"Meta-Analysis via Generalized Linear (Mixed-Effects) Models — rma.glmm","text":"Function fit meta-analytic equal-, fixed-, random-effects models (mixed-effects) meta-regression models using generalized linear (mixed-effects) model framework. See introduction metafor-package details models.","code":""},{"path":"/reference/rma.glmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Meta-Analysis via Generalized Linear (Mixed-Effects) Models — rma.glmm","text":"","code":"rma.glmm(ai, bi, ci, di, n1i, n2i, x1i, x2i, t1i, t2i, xi, mi, ti, ni,          mods, measure, intercept=TRUE, data, slab, subset,          add=1/2, to=\"only0\", drop00=TRUE, vtype=\"LS\",          model=\"UM.FS\", method=\"ML\", coding=1/2, cor=FALSE, test=\"z\",          level=95, digits, btt, nAGQ=7, verbose=FALSE, control, ...)"},{"path":"/reference/rma.glmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Meta-Analysis via Generalized Linear (Mixed-Effects) Models — rma.glmm","text":"ai see documentation escalc function details. bi see documentation escalc function details. ci see documentation escalc function details. di see documentation escalc function details. n1i see documentation escalc function details. n2i see documentation escalc function details. x1i see documentation escalc function details. x2i see documentation escalc function details. t1i see documentation escalc function details. t2i see documentation escalc function details. xi see documentation escalc function details. mi see documentation escalc function details. ti see documentation escalc function details. ni see documentation escalc function details. mods optional argument include one moderators model. single moderator can given vector length \\(k\\) specifying values moderator. Multiple moderators specified giving matrix \\(k\\) rows many columns moderator variables. Alternatively, model formula can used specify model. See ‘Details’. measure character string specify outcome measure use meta-analysis. Possible options odds ratio (\"\"), incidence rate ratio (\"IRR\"), logit transformed proportion (\"PLO\"), log transformed incidence rate (\"IRLN\"). intercept logical specify whether intercept added model (default TRUE). data optional data frame containing data supplied function. slab optional vector labels \\(k\\) studies. subset optional (logical numeric) vector specify subset studies used analysis. add non-negative number specify amount add zero cells, counts, frequencies calculating observed effect sizes outcomes individual studies. See documentation escalc function details. character string specify values add added (either \"only0\", \"\", \"if0all\", \"none\"). See documentation escalc function details. drop00 logical specify whether studies cases/events (cases) groups dropped. See documentation escalc function details. vtype character string specify type sampling variances calculate calculating observed effect sizes outcomes. See documentation escalc function details. model character string specify general model type use analysis (either \"UM.FS\" (default), \"UM.RS\", \"CM.EL\", \"CM.AL\"). See ‘Details’. method character string specify whether equal- random-effects model fitted. equal-effects model fitted using method=\"EE\". random-effects model fitted setting method=\"ML\" (default). See ‘Details’. coding numeric scalar indicate group variable coded random effects structure random/mixed-effects models (default 1/2). See ‘Note’. cor logical indicate whether random study effects allowed correlated random group effects random/mixed-effects models model=\"UM.RS\" (default FALSE). See ‘Note’. test character string specify test statistics confidence intervals fixed effects computed. default (test=\"z\"), Wald-type tests CIs obtained, based standard normal distribution. test=\"t\", t-distribution used instead. See ‘Details’. level numeric value 0 100 specify confidence interval level (default 95). digits optional integer specify number decimal places printed results rounded. unspecified, default 4. See also details control number digits output. btt optional vector indices specify coefficients include omnibus test moderators. Can also string grep . See ‘Details’. nAGQ positive integer specify number points per axis evaluating adaptive Gauss-Hermite approximation log-likelihood. default 7. Setting 1 corresponds Laplacian approximation. See ‘Note’. verbose logical specify whether output generated progress model fitting (default FALSE). Can also integer. Values > 1 generate verbose output. See ‘Note’. control optional list control values estimation algorithms. unspecified, default values defined inside function. See ‘Note’. ... additional arguments.","code":""},{"path":[]},{"path":"/reference/rma.glmm.html","id":"specifying-the-data","dir":"Reference","previous_headings":"","what":"Specifying the Data","title":"Meta-Analysis via Generalized Linear (Mixed-Effects) Models — rma.glmm","text":"function can used combination following effect size outcome measures: measure=\"\" odds ratios (analyzed log units) measure=\"IRR\" incidence rate ratios (analyzed log units) measure=\"PLO\" logit transformed proportions (.e., log odds) measure=\"IRLN\" log transformed incidence rates. escalc function describes data/arguments specified/used measures.","code":""},{"path":"/reference/rma.glmm.html","id":"specifying-the-model","dir":"Reference","previous_headings":"","what":"Specifying the Model","title":"Meta-Analysis via Generalized Linear (Mixed-Effects) Models — rma.glmm","text":"variety model types available analyzing \\(2 \\times 2\\) table data (.e., measure=\"\") two-group event count data (.e., measure=\"IRR\"): model=\"UM.FS\" unconditional generalized linear mixed-effects model fixed study effects model=\"UM.RS\" unconditional generalized linear mixed-effects model random study effects model=\"CM.AL\" conditional generalized linear mixed-effects model (approximate likelihood) model=\"CM.EL\" conditional generalized linear mixed-effects model (exact likelihood). measure=\"\", models \"UM.FS\" \"UM.RS\" essentially (mixed-effects) logistic regression models, measure=\"IRR\", models (mixed-effects) Poisson regression models. choice must made model study level variability (.e., differences outcomes across studies irrespective group membership). One can choose using fixed study effects (means \\(k\\) dummy variables added model) random study effects (means random effects corresponding levels study factor added model). conditional model (model=\"CM.EL\") avoids model study level variability conditioning total numbers cases/events study. measure=\"\", leads non-central hypergeometric distribution data within study corresponding model (mixed-effects) conditional logistic model. Fitting model can difficult computationally expensive. number cases study small relative group sizes, one can approximate exact likelihood binomial distribution, leads regular (mixed-effects) logistic regression model (model=\"CM.AL\"). measure=\"IRR\", conditional model leads directly binomial distribution data within study resulting model (mixed-effects) logistic regression model (approximate likelihood model needed ). analyzing proportions (.e., measure=\"PLO\") incidence rates (.e., measure=\"IRLN\") individual groups, model type always (mixed-effects) logistic Poisson regression model, respectively (.e., model argument relevant ). Aside choosing general model type, one decide whether fit equal- random-effects model data. equal-effects model fitted setting method=\"EE\". random-effects model fitted setting method=\"ML\" (default). Note random-effects models dichotomous data often referred ‘binomial-normal’ models meta-analytic literature. Analogously, event count data, models referred ‘Poisson-normal’ models. One moderators can included model via mods argument. single moderator can given (row column) vector length \\(k\\) specifying values moderator. Multiple moderators specified giving appropriate model matrix (.e., \\(X\\)) \\(k\\) rows many columns moderator variables (e.g., mods = cbind(mod1, mod2, mod3), mod1, mod2, mod3 correspond names variables three moderator variables). intercept added model matrix default unless intercept=FALSE. Alternatively, one can use standard formula syntax specify model. case, mods argument set equal one-sided formula form mods = ~ model (e.g., mods = ~ mod1 + mod2 + mod3). Interactions, polynomial terms, factors can easily added model manner. specifying model formula via mods argument, intercept argument ignored. Instead, inclusion/exclusion intercept controlled specified formula (e.g., mods = ~ mod1 + mod2 + mod3 - 1 lead removal intercept).","code":""},{"path":"/reference/rma.glmm.html","id":"equal-saturated-and-random-mixed-effects-models","dir":"Reference","previous_headings":"","what":"Equal-, Saturated-, and Random/Mixed-Effects Models","title":"Meta-Analysis via Generalized Linear (Mixed-Effects) Models — rma.glmm","text":"fitting particular model, actually three different models fitted within function: equal-effects model (.e., \\(\\tau^2\\) set 0), saturated model (.e., model deviance 0), random/mixed-effects model (.e., \\(\\tau^2\\) estimated) (method=\"ML\"). saturated model obtained adding many dummy variables model needed model deviance equal zero. Even method=\"ML\", equal- saturated models also fitted, used compute test statistics Wald-type likelihood ratio tests (residual) heterogeneity (see ).","code":""},{"path":"/reference/rma.glmm.html","id":"omnibus-test-of-moderators","dir":"Reference","previous_headings":"","what":"Omnibus Test of Moderators","title":"Meta-Analysis via Generalized Linear (Mixed-Effects) Models — rma.glmm","text":"models including moderators, omnibus test model coefficients conducted excludes intercept (first coefficient) included model. intercept included model, omnibus test includes coefficients model including first. Alternatively, one can manually specify indices coefficients test via btt argument. example, btt=c(3,4), third fourth coefficient model included test (intercept included model, corresponds first coefficient model). Instead specifying coefficient numbers, one can specify string btt. case, grep used search coefficient names match string. omnibus test called \\(Q_M\\)-test follows, assumptions model, chi-square distribution \\(m\\) degrees freedom (\\(m\\) denoting number coefficients tested) null hypothesis (true value coefficients tested equal 0).","code":""},{"path":"/reference/rma.glmm.html","id":"categorical-moderators","dir":"Reference","previous_headings":"","what":"Categorical Moderators","title":"Meta-Analysis via Generalized Linear (Mixed-Effects) Models — rma.glmm","text":"Categorical moderator variables can included model via mods argument way appropriately (dummy) coded categorical variables can included linear models. One can either dummy coding manually use model formula together factor function autoamte coding (note string/character variables model formula automatically converted factors).","code":""},{"path":"/reference/rma.glmm.html","id":"tests-and-confidence-intervals","dir":"Reference","previous_headings":"","what":"Tests and Confidence Intervals","title":"Meta-Analysis via Generalized Linear (Mixed-Effects) Models — rma.glmm","text":"default, tests individual coefficients model (corresponding confidence intervals) based standard normal distribution, omnibus test based chi-square distribution (see ). alternative, one can set test=\"t\", case tests individual coefficients confidence intervals based t-distribution \\(k-p\\) degrees freedom, omnibus test statistic uses F-distribution \\(m\\) \\(k-p\\) degrees freedom (\\(k\\) denoting total number estimates included analysis \\(p\\) total number model coefficients including intercept present). Note test=\"t\" test=\"knha\" rma.uni, adjustment standard errors estimated coefficients made.","code":""},{"path":"/reference/rma.glmm.html","id":"tests-for-residual-heterogeneity","dir":"Reference","previous_headings":"","what":"Tests for (Residual) Heterogeneity","title":"Meta-Analysis via Generalized Linear (Mixed-Effects) Models — rma.glmm","text":"Two different tests (residual) heterogeneity automatically carried function. first Wald-type test, tests coefficients corresponding dummy variables added saturated model significance. second likelihood ratio test, tests set coefficients, computing \\(-2\\) times difference log-likelihoods equal-effects saturated models. two tests identical types models fitted rma.glmm function may even lead conflicting conclusions.","code":""},{"path":"/reference/rma.glmm.html","id":"observed-effect-sizes-or-outcomes-of-the-individual-studies","dir":"Reference","previous_headings":"","what":"Observed Effect Sizes or Outcomes of the Individual Studies","title":"Meta-Analysis via Generalized Linear (Mixed-Effects) Models — rma.glmm","text":"various models require calculation observed effect sizes outcomes individual studies (e.g., observed odds ratios \\(k\\) studies) directly make use table/event counts. Zero cells/events problem (except extreme cases, one two outcomes never occurs events studies). Therefore, unnecessary add constant cell/event counts zero cells/events. However, plotting various functions, necessary calculate observed effect sizes outcomes \\(k\\) studies. , zero cells/events can problematic, adding constant value cell/event counts ensures \\(k\\) values can calculated. add arguments used specify value added cell/event counts circumstances calculating observed effect sizes outcomes. documentation escalc function explains add arguments work. Note drop00 set TRUE default, since studies ai=ci=0 bi=di=0 studies x1i=x2i=0 uninformative size effect.","code":""},{"path":"/reference/rma.glmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Meta-Analysis via Generalized Linear (Mixed-Effects) Models — rma.glmm","text":"object class c(\"rma.glmm\",\"rma\"). object list containing following components: beta estimated coefficients model. se standard errors coefficients. zval test statistics coefficients. pval corresponding p-values. ci.lb lower bound confidence intervals coefficients. ci.ub upper bound confidence intervals coefficients. vb variance-covariance matrix estimated coefficients. tau2 estimated amount (residual) heterogeneity. Always 0 method=\"EE\". sigma2 estimated amount study level variability (model=\"UM.RS\"). k number studies included analysis. p number coefficients model (including intercept). m number coefficients included omnibus test moderators. QE.Wld Wald-type test statistic test (residual) heterogeneity. QEp.Wld corresponding p-value. QE.LRT likelihood ratio test statistic test (residual) heterogeneity. QEp.LRT corresponding p-value. QM test statistic omnibus test moderators. QMp corresponding p-value. I2 value \\(^2\\). H2 value \\(H^2\\). int.logical indicates whether model intercept-model. yi, vi, X vector outcomes, corresponding sampling variances, model matrix. fit.stats list log-likelihood, deviance, AIC, BIC, AICc values. ... additional elements/values.","code":""},{"path":"/reference/rma.glmm.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Meta-Analysis via Generalized Linear (Mixed-Effects) Models — rma.glmm","text":"results fitted model formatted printed print function. fit statistics also given, use summary (use fitstats function extract ).","code":""},{"path":"/reference/rma.glmm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Meta-Analysis via Generalized Linear (Mixed-Effects) Models — rma.glmm","text":"measure=\"\" measure=\"IRR\", model=\"UM.FS\" model=\"UM.RS\", method=\"ML\", one choose coding scheme group variable random effects structure. code=1/2 (default), two groups coded +1/2 -1/2 (.e., contrast coding), invariant group label switching. code=1, first group coded 1 second group 0. Finally, code=0, first group coded 0 second group 1. Note coding schemes invariant group label switching. Also, model=\"UM.RS\" method=\"ML\", one decide whether random study effects allowed correlated random group effects. default (.e., cor=FALSE), correlation allowed (typically appropriate assumption code=1/2). using different coding scheme group variable (.e., code=1 code=0), allowing random study group effects correlated (.e., using cor=TRUE) usually recommended. Fitting various types models requires several different iterative algorithms: model=\"UM.FS\" model=\"CM.AL\", iteratively reweighted least squares (IWLS) implemented glm function used fitting equal-effects saturated models. method=\"ML\", adaptive Gauss-Hermite quadrature implemented glmer function used. applies model=\"CM.EL\" used combination measure=\"IRR\" measure=\"PLO\" measure=\"IRLN\" (regardless model type). model=\"UM.RS\", adaptive Gauss-Hermite quadrature implemented glmer function used fit models. model=\"CM.EL\" measure=\"\", quasi-Newton method optimizer implemented nlminb function used default fitting equal-effects saturated models. method=\"ML\", algorithm used, together adaptive quadrature implemented integrate function (integration density non-central hypergeometric distribution). Standard errors parameter estimates obtained inverting Hessian, numerically approximated using hessian function numDeriv package. One can also chose different optimizer via control argument (e.g., control=list(optimizer=\"optim\")). using optim, one can set particular method via optmethod argument (e.g., control=list(optimizer=\"optim\", optmethod=\"BFGS\")). Besides nlminb optim, one can also choose one optimizers minqa package (.e., uobyqa, newuoa, bobyqa), one (derivative-free) algorithms nloptr package, Newton-type algorithm implemented nlm, various algorithms implemented dfoptim package (hjk Hooke-Jeeves, nmk Nelder-Mead, mads Mesh Adaptive Direct Searches (MADS) algorithm), quasi-Newton type optimizers ucminf lbfgsb3c subspace-searching simplex algorithm subplex packages name, Barzilai-Borwein gradient method decent implemented BBoptim, parallelized version L-BFGS-B algorithm implemented optimParallel package name. optimizer name must given character string (.e., quotes). Additional control parameters can specified via optCtrl elements control argument (e.g., control=list(optCtrl=list(iter.max=1000, rel.tol=1e-8))). nloptr, default use BOBYQA implementation package relative convergence criterion 1e-8 function value (.e., log-likelihood), can changed via algorithm ftop_rel arguments (e.g., control=list(optimizer=\"nloptr\", optCtrl=list(algorithm=\"NLOPT_LN_SBPLX\", ftol_rel=1e-6))). optimParallel, control argument ncpus can used specify number cores use parallelization (e.g., control=list(optimizer=\"optimParallel\", ncpus=2)). parallel::detectCores(), one can check number available cores local machine. model=\"CM.EL\" measure=\"\", actually model=\"CM.AL\" used first obtain starting values optim, either 4 (method=\"EE\") 6 (method=\"ML\") models need fitted total. Various additional control parameters can adjusted via control argument: glmCtrl list named arguments passed control argument glm function, glmerCtrl list named arguments passed control argument glmer function, intCtrl list named arguments (.e., rel.tol subdivisions) passed integrate function. hessianCtrl list named arguments passed method.args argument hessian function. borderline cases, may necessary bump r argument higher number get sufficient accuracy approximating Hessian numerically (default control=list(hessianCtrl=list(r=16))). Also, glmer, nAGQ argument used specify number quadrature points. default value 7, provide sufficient accuracy evaluation log-likelihood cases, expense speed. Setting 1 corresponds Laplacian approximation (faster, less accurate). Information progress various algorithms can obtained setting verbose=TRUE. Since fitting various models can computationally expensive, option useful determine model fitting progressing. One can also set verbose integer (verbose=2 yields even information verbose=3 also sets option(warn=1) temporarily). model=\"CM.EL\" measure=\"\", optimization involves repeated calculation density non-central hypergeometric distribution. method=\"ML\", also requires integration density. currently implemented rather brute-force manner may numerically stable, especially models moderators fitted. Stability can improved scaling moderators similar manner (.e., use moderator coded 0 1, another uses values 1000s). models intercept moderators, function actually rescales (non-dummy) variables z-scores model fitting (results given back-scaling, transparent user). models without intercept, done, sensitivity analyses highly recommended (ensure results depend scaling moderators).","code":""},{"path":"/reference/rma.glmm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Meta-Analysis via Generalized Linear (Mixed-Effects) Models — rma.glmm","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org Code computing density non-central hypergeometric distribution comes MCMCpack package, turn based Liao Rosen (2001).","code":""},{"path":"/reference/rma.glmm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Meta-Analysis via Generalized Linear (Mixed-Effects) Models — rma.glmm","text":"Agresti, . (2002). Categorical data analysis (2nd. ed). Hoboken, NJ: Wiley. Bagos, P. G., & Nikolopoulos, G. K. (2009). Mixed-effects Poisson regression models meta-analysis follow-studies constant varying durations. International Journal Biostatistics, 5(1). https://doi.org/10.2202/1557-4679.1168 van Houwelingen, H. C., Zwinderman, K. H., & Stijnen, T. (1993). bivariate approach meta-analysis. Statistics Medicine, 12(24), 2273--2284. https://doi.org/10.1002/sim.4780122405 Jackson, D., Law, M., Stijnen, T., Viechtbauer, W., & White, . R. (2018). comparison seven random-effects models meta-analyses estimate summary odds ratio. Statistics Medicine, 37(7), 1059-1085. https://doi.org/10.1002/sim.7588 Liao, J. G., & Rosen, O. (2001). Fast stable algorithms computing sampling noncentral hypergeometric distribution. American Statistician, 55(4), 366--369. https://doi.org/10.1198/000313001753272547 Simmonds, M. C., & Higgins, J. P. T. (2016). general framework use logistic regression models meta-analysis. Statistical Methods Medical Research, 25(6), 2858--2877. https://doi.org/10.1177/0962280214534409 Stijnen, T., Hamza, T. H., & Ozdemir, P. (2010). Random effects meta-analysis event outcome framework generalized linear mixed model applications sparse data. Statistics Medicine, 29(29), 3046--3067. https://doi.org/10.1002/sim.4040 Turner, R. M., Omar, R. Z., Yang, M., Goldstein, H., & Thompson, S. G. (2000). multilevel model framework meta-analysis clinical trials binary outcomes. Statistics Medicine, 19(24), 3417--3432. https://doi.org/10.1002/1097-0258(20001230)19:24<3417::aid-sim614>3.0.co;2-l Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/rma.glmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Meta-Analysis via Generalized Linear (Mixed-Effects) Models — rma.glmm","text":"","code":"### random-effects model using rma.uni() (standard RE model analysis) rma(measure=\"OR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg, method=\"ML\") #>  #> Random-Effects Model (k = 13; tau^2 estimator: ML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.3025 (SE = 0.1549) #> tau (square root of estimated tau^2 value):      0.5500 #> I^2 (total heterogeneity / total variability):   91.23% #> H^2 (total variability / sampling variability):  11.40 #>  #> Test for Heterogeneity: #> Q(df = 12) = 163.1649, p-val < .0001 #>  #> Model Results: #>  #> estimate      se     zval    pval    ci.lb    ci.ub     ​  #>  -0.7420  0.1780  -4.1694  <.0001  -1.0907  -0.3932  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### random-effects models using rma.glmm() (require 'lme4' package)  ### unconditional model with fixed study effects # \\dontrun{ rma.glmm(measure=\"OR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg, model=\"UM.FS\")# } #>  #> Random-Effects Model (k = 13; tau^2 estimator: ML) #> Model Type: Unconditional Model with Fixed Study Effects #>  #> tau^2 (estimated amount of total heterogeneity): 0.2949 #> tau (square root of estimated tau^2 value):      0.5430 #> I^2 (total heterogeneity / total variability):   91.0235% #> H^2 (total variability / sampling variability):  11.1402 #>  #> Tests for Heterogeneity: #> Wld(df = 12) = 163.1649, p-val < .0001 #> LRT(df = 12) = 176.9544, p-val < .0001 #>  #> Model Results: #>  #> estimate      se     zval    pval    ci.lb    ci.ub     ​  #>  -0.7450  0.1756  -4.2435  <.0001  -1.0891  -0.4009  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### unconditional model with random study effects # \\dontrun{ rma.glmm(measure=\"OR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg, model=\"UM.RS\")# } #> Warning: Currently not possible to fit RE/ME model='UM.RS' with nAGQ > 1. nAGQ automatically set to 1. #>  #> Random-Effects Model (k = 13; tau^2 estimator: ML) #> Model Type: Unconditional Model with Random Study Effects #>  #> tau^2 (estimated amount of total heterogeneity): 0.3198 #> tau (square root of estimated tau^2 value):      0.5655 #> I^2 (total heterogeneity / total variability):   91.6652% #> H^2 (total variability / sampling variability):  11.9979 #>  #> sigma^2 (estimated amount of study level variability): 1.8616 #> sigma (square root of estimated sigma^2 value):        1.3644 #>  #> Tests for Heterogeneity: #> Wld(df = 12) = 161.1955, p-val < .0001 #> LRT(df = 12) = 174.1317, p-val < .0001 #>  #> Model Results: #>  #> estimate      se     zval    pval    ci.lb    ci.ub     ​  #>  -0.7616  0.1815  -4.1969  <.0001  -1.1172  -0.4059  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### conditional model with approximate likelihood # \\dontrun{ rma.glmm(measure=\"OR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg, model=\"CM.AL\")# } #>  #> Random-Effects Model (k = 13; tau^2 estimator: ML) #> Model Type: Conditional Model with Approximate Likelihood #>  #> tau^2 (estimated amount of total heterogeneity): 0.2887 #> tau (square root of estimated tau^2 value):      0.5373 #> I^2 (total heterogeneity / total variability):   90.8488% #> H^2 (total variability / sampling variability):  10.9276 #>  #> Tests for Heterogeneity: #> Wld(df = 12) = 147.9061, p-val < .0001 #> LRT(df = 12) = 161.8210, p-val < .0001 #>  #> Model Results: #>  #> estimate      se     zval    pval    ci.lb    ci.ub     ​  #>  -0.7221  0.1744  -4.1405  <.0001  -1.0639  -0.3803  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### conditional model with exact likelihood ### note: fitting this model may take a bit of time, so be patient # \\dontrun{ rma.glmm(measure=\"OR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg, model=\"CM.EL\")# } #>  #> Random-Effects Model (k = 13; tau^2 estimator: ML) #> Model Type: Conditional Model with Exact Likelihood #>  #> tau^2 (estimated amount of total heterogeneity): 0.3116 (SE = 0.1612) #> tau (square root of estimated tau^2 value):      0.5582 #> I^2 (total heterogeneity / total variability):   91.4646% #> H^2 (total variability / sampling variability):  11.7159 #>  #> Tests for Heterogeneity: #> Wld(df = 12) = 268.4283, p-val < .0001 #> LRT(df = 12) = 176.8738, p-val < .0001 #>  #> Model Results: #>  #> estimate      se     zval    pval    ci.lb    ci.ub     ​  #>  -0.7538  0.1801  -4.1860  <.0001  -1.1068  -0.4009  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>"},{"path":"/reference/rma.mh.html","id":null,"dir":"Reference","previous_headings":"","what":"Meta-Analysis via the Mantel-Haenszel Method — rma.mh","title":"Meta-Analysis via the Mantel-Haenszel Method — rma.mh","text":"Function fit equal-effects models \\(2 \\times 2\\) table person-time data via Mantel-Haenszel method. See introduction metafor-package details models.","code":""},{"path":"/reference/rma.mh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Meta-Analysis via the Mantel-Haenszel Method — rma.mh","text":"","code":"rma.mh(ai, bi, ci, di, n1i, n2i, x1i, x2i, t1i, t2i,        measure=\"OR\", data, slab, subset,        add=1/2, to=\"only0\", drop00=TRUE,        correct=TRUE, level=95, digits, verbose=FALSE, ...)"},{"path":"/reference/rma.mh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Meta-Analysis via the Mantel-Haenszel Method — rma.mh","text":"ai vector specify \\(2 \\times 2\\) table frequencies (upper left cell). See documentation escalc function details. bi vector specify \\(2 \\times 2\\) table frequencies (upper right cell). See documentation escalc function details. ci vector specify \\(2 \\times 2\\) table frequencies (lower left cell). See documentation escalc function details. di vector specify \\(2 \\times 2\\) table frequencies (lower right cell). See documentation escalc function details. n1i vector specify group sizes row totals (first group). See documentation escalc function details. n2i vector specify group sizes row totals (second group). See documentation escalc function details. x1i vector specify number events (first group). See documentation escalc function details. x2i vector specify number events (second group). See documentation escalc function details. t1i vector specify total person-times (first group). See documentation escalc function details. t2i vector specify total person-times (second group). See documentation escalc function details. measure character string specify outcome measure use meta-analysis. Possible options risk ratio (\"RR\"), odds ratio (\"\"), risk difference (\"RD\"), incidence rate ratio (\"IRR\"), incidence rate difference (\"IRD\"). data optional data frame containing data supplied function. slab optional vector labels \\(k\\) studies. subset optional (logical numeric) vector specify subset studies used analysis. add non-negative number specify amount add zero cells, counts, frequencies calculating observed effect sizes outcomes individual studies. Can also vector two numbers, first number used calculation observed effect sizes outcomes second number used applying Mantel-Haenszel method. See documentation escalc function details. character string specify values add added (either \"only0\", \"\", \"if0all\", \"none\"). Can also character vector, first string applies calculating observed effect sizes outcomes second string applying Mantel-Haenszel method. See documentation escalc function details. drop00 logical specify whether studies cases/events (cases) groups dropped calculating observed effect sizes outcomes (outcomes studies set NA). Can also vector two logicals, first applies calculation observed effect sizes outcomes second applying Mantel-Haenszel method. See documentation escalc function details. correct logical specify whether apply continuity correction computing Cochran-Mantel-Haenszel test statistic. level numeric value 0 100 specify confidence interval level (default 95). digits optional integer specify number decimal places printed results rounded. unspecified, default 4. See also details control number digits output. verbose logical specify whether output generated progress model fitting (default FALSE). ... additional arguments.","code":""},{"path":[]},{"path":"/reference/rma.mh.html","id":"specifying-the-data","dir":"Reference","previous_headings":"","what":"Specifying the Data","title":"Meta-Analysis via the Mantel-Haenszel Method — rma.mh","text":"outcome measure either risk ratio (measure=\"RR\"), odds ratio (measure=\"\"), risk difference (measure=\"RD\"), studies assumed provide data terms \\(2 \\times 2\\) tables form: ai, bi, ci, di denote cell frequencies n1i n2i row totals. example, set randomized clinical trials (RCTs) cohort studies, group 1 group 2 may refer treatment (exposed) placebo/control (exposed) group, outcome 1 denoting event interest (e.g., death) outcome 2 complement. set case-control studies, group 1 group 2 may refer group cases group controls, outcome 1 denoting, example, exposure risk factor outcome 2 non-exposure. outcome measures, one needs specify either ai, bi, ci, di alternatively ai, ci, n1i, n2i. Alternatively, outcome measure incidence rate ratio (measure=\"IRR\") incidence rate difference (measure=\"IRD\"), studies assumed provide data terms tables form: x1i x2i denote number events first second group, respectively, t1i t2i corresponding total person-times risk.","code":""},{"path":"/reference/rma.mh.html","id":"mantel-haenszel-method","dir":"Reference","previous_headings":"","what":"Mantel-Haenszel Method","title":"Meta-Analysis via the Mantel-Haenszel Method — rma.mh","text":"approach aggregating data types suggested Mantel Haenszel (1959) later extended various authors (see references). Mantel-Haenszel method provides weighted estimate equal-effects model. method particularly advantageous aggregating large number studies small sample sizes (-called sparse data increasing strata case). analyzing odds ratios, Cochran-Mantel-Haenszel (CMH) test (Cochran, 1954; Mantel & Haenszel, 1959) Tarone's test heterogeneity (Tarone, 1985) also provided (default, CMH test statistic computed continuity correction; can switched correct=FALSE). analyzing incidence rate ratios, Mantel-Haenszel (MH) test (Rothman et al., 2008) person-time data also provided (, correct argument controls whether continuity correction applied). analyzing risk ratios, odds ratios, incidence rate ratios, printed results given terms log raw units (easier interpretation).","code":""},{"path":"/reference/rma.mh.html","id":"observed-effect-sizes-or-outcomes-of-the-individual-studies","dir":"Reference","previous_headings":"","what":"Observed Effect Sizes or Outcomes of the Individual Studies","title":"Meta-Analysis via the Mantel-Haenszel Method — rma.mh","text":"Mantel-Haenszel method require calculation observed effect sizes outcomes individual studies (e.g., observed odds incidence rate ratios \\(k\\) studies) directly makes use table/event counts. Zero cells/events problem (except extreme cases, one two outcomes never occurs \\(2 \\times 2\\) tables events one two groups tables). Therefore, unnecessary add constant cell/event counts zero cells/events. However, plotting various functions, necessary calculate observed effect sizes outcomes \\(k\\) studies. , zero cells/events can problematic, adding constant value cell/event counts ensures \\(k\\) values can calculated. add arguments used specify value added cell/event counts circumstances calculating observed effect sizes outcomes applying Mantel-Haenszel method. Similarly, drop00 argument used specify studies cases/events (cases) groups handled. documentation escalc function explains add, , drop00 arguments work. single value arguments specified (per default), values used calculating observed effect sizes outcomes adjustment cell/event counts made applying Mantel-Haenszel method. Alternatively, specifying two values arguments, first value applies calculating observed effect sizes outcomes second value applying Mantel-Haenszel method. Note drop00 set TRUE default. Therefore, observed effect sizes outcomes studies ai=ci=0 bi=di=0 studies x1i=x2i=0 set NA. applying Mantel-Haenszel method, studies explicitly dropped (unless second value drop00 argument also set TRUE), practically necessary, actually influence results (assuming adjustment cell/event counts made applying Mantel-Haenszel method).","code":""},{"path":"/reference/rma.mh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Meta-Analysis via the Mantel-Haenszel Method — rma.mh","text":"object class c(\"rma.mh\",\"rma\"). object list containing following components: beta aggregated log risk ratio, log odds ratio, risk difference, log rate ratio, rate difference. se standard error aggregated value. zval test statistics aggregated value. pval corresponding p-value. ci.lb lower bound confidence interval. ci.ub upper bound confidence interval. QE test statistic test heterogeneity. QEp correspinding p-value. MH Cochran-Mantel-Haenszel test statistic (measure=\"\") Mantel-Haenszel test statistic (measure=\"IRR\"). MHp corresponding p-value. TA test statistic Tarone's test heterogeneity (measure=\"\"). TAp corresponding p-value (measure=\"\"). k number studies included analysis. yi, vi vector outcomes corresponding sampling variances. fit.stats list log-likelihood, deviance, AIC, BIC, AICc values unrestricted restricted likelihood. ... additional elements/values.","code":""},{"path":"/reference/rma.mh.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Meta-Analysis via the Mantel-Haenszel Method — rma.mh","text":"results fitted model formatted printed print function. fit statistics also given, use summary (use fitstats function extract ). residuals, rstandard, rstudent functions extract raw standardized residuals. Leave-one-diagnostics can obtained leave1out. Forest, funnel, radial, L'Abbé, Baujat plots can obtained forest, funnel, radial, labbe, baujat. qqnorm function provides normal QQ plots standardized residuals. One can also just call plot fitted model object obtain various plots . cumulative meta-analysis (.e., adding one observation time) can obtained cumul. extractor functions include coef, vcov, logLik, deviance, AIC, BIC.","code":""},{"path":"/reference/rma.mh.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Meta-Analysis via the Mantel-Haenszel Method — rma.mh","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/rma.mh.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Meta-Analysis via the Mantel-Haenszel Method — rma.mh","text":"Cochran, W. G. (1954). methods strengthening common \\(\\chi^2\\) tests. Biometrics, 10(4), 417--451. https://doi.org/10.2307/3001616 Greenland, S., & Robins, J. M. (1985). Estimation common effect parameter sparse follow-data. Biometrics, 41(1), 55--68. https://doi.org/10.2307/2530643 Mantel, N., & Haenszel, W. (1959). Statistical aspects analysis data retrospective studies disease. Journal National Cancer Institute, 22(4), 719--748. https://doi.org/10.1093/jnci/22.4.719 Nurminen, M. (1981). Asymptotic efficiency general noniterative estimators common relative risk. Biometrika, 68(2), 525--530. https://doi.org/10.1093/biomet/68.2.525 Robins, J., Breslow, N., & Greenland, S. (1986). Estimators Mantel-Haenszel variance consistent sparse data large-strata limiting models. Biometrics, 42(2), 311--323. https://doi.org/10.2307/2531052 Rothman, K. J., Greenland, S., & Lash, T. L. (2008). Modern epidemiology (3rd ed.). Philadelphia: Lippincott Williams & Wilkins. Sato, T., Greenland, S., & Robins, J. M. (1989). variance estimator Mantel-Haenszel risk difference. Biometrics, 45(4), 1323--1324. https://www.jstor.org/stable/2531784 Tarone, R. E. (1981). summary estimators relative risk. Journal Chronic Diseases, 34(9-10), 463--468. https://doi.org/10.1016/0021-9681(81)90006-0 Tarone, R. E. (1985). heterogeneity tests based efficient scores. Biometrika, 72(1), 91--95. https://doi.org/10.1093/biomet/72.1.91 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/rma.mh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Meta-Analysis via the Mantel-Haenszel Method — rma.mh","text":"","code":"### meta-analysis of the (log) odds ratios using the Mantel-Haenszel method rma.mh(measure=\"OR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg) #>  #> Equal-Effects Model (k = 13) #>  #> I^2 (total heterogeneity / total variability):  92.68% #> H^2 (total variability / sampling variability): 13.66 #>  #> Test for Heterogeneity:  #> Q(df = 12) = 163.9426, p-val < .0001 #>  #> Model Results (log scale): #>  #> estimate      se      zval    pval    ci.lb    ci.ub  #>  -0.4734  0.0410  -11.5444  <.0001  -0.5538  -0.3930  #>  #> Model Results (OR scale): #>  #> estimate   ci.lb   ci.ub  #>   0.6229  0.5748  0.6750  #>  #> Cochran-Mantel-Haenszel Test:    CMH = 135.6889, df = 1,  p-val < 0.0001 #> Tarone's Test for Heterogeneity: X^2 = 171.7567, df = 12, p-val < 0.0001 #>   ### meta-analysis of the (log) risk ratios using the Mantel-Haenszel method rma.mh(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg) #>  #> Equal-Effects Model (k = 13) #>  #> I^2 (total heterogeneity / total variability):  92.13% #> H^2 (total variability / sampling variability): 12.71 #>  #> Test for Heterogeneity:  #> Q(df = 12) = 152.5676, p-val < .0001 #>  #> Model Results (log scale): #>  #> estimate      se      zval    pval    ci.lb    ci.ub  #>  -0.4537  0.0393  -11.5338  <.0001  -0.5308  -0.3766  #>  #> Model Results (RR scale): #>  #> estimate   ci.lb   ci.ub  #>   0.6353  0.5881  0.6862  #>"},{"path":"/reference/rma.mv.html","id":null,"dir":"Reference","previous_headings":"","what":"Meta-Analysis via Multivariate/Multilevel Linear (Mixed-Effects) Models — rma.mv","title":"Meta-Analysis via Multivariate/Multilevel Linear (Mixed-Effects) Models — rma.mv","text":"Function fit meta-analytic multivariate/multilevel fixed- random/mixed-effects models without moderators via linear (mixed-effects) models. See introduction metafor-package details models.","code":""},{"path":"/reference/rma.mv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Meta-Analysis via Multivariate/Multilevel Linear (Mixed-Effects) Models — rma.mv","text":"","code":"rma.mv(yi, V, W, mods, random, struct=\"CS\", intercept=TRUE,        data, slab, subset, method=\"REML\", test=\"z\", dfs=\"residual\",        level=95, digits, btt, R, Rscale=\"cor\",        sigma2, tau2, rho, gamma2, phi,        cvvc=FALSE, sparse=FALSE, verbose=FALSE, control, ...)"},{"path":"/reference/rma.mv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Meta-Analysis via Multivariate/Multilevel Linear (Mixed-Effects) Models — rma.mv","text":"yi vector length \\(k\\) observed effect sizes outcomes. See ‘Details’. V vector length \\(k\\) corresponding sampling variances \\(k \\times k\\) variance-covariance matrix sampling errors. See ‘Details’. W optional argument specify vector length \\(k\\) user-defined weights \\(k \\times k\\) user-defined weight matrix. See ‘Details’. mods optional argument include one moderators model. single moderator can given vector length \\(k\\) specifying values moderator. Multiple moderators specified giving matrix \\(k\\) rows many columns moderator variables. Alternatively, model formula can used specify model. See ‘Details’. random either single one-sided formula list one-sided formulas specify random-effects structure model. See ‘Details’. struct character string specify variance structure ~ inner | outer formula random argument. Either \"CS\" compound symmetry, \"HCS\" heteroscedastic compound symmetry, \"UN\" \"GEN\" unstructured variance-covariance matrix, \"ID\" scaled identity matrix, \"DIAG\" diagonal matrix, \"AR\" AR(1) autoregressive structure, \"HAR\" heteroscedastic AR(1) autoregressive structure, \"CAR\" continuous-time autoregressive structure, one \"SPEXP\", \"SPGAU\", \"SPLIN\", \"SPRAT\", \"SPSPH\" one spatial correlation structures. See ‘Details’. intercept logical specify whether intercept added model (default TRUE). Ignored mods formula. data optional data frame containing data supplied function. slab optional vector labels \\(k\\) outcomes/studies. subset optional (logical numeric) vector specify subset studies (precisely, rows dataset) used analysis. method character string specify whether model fitted via maximum-likelihood (\"ML\") via restricted maximum-likelihood (\"REML\") estimation. Default \"REML\". test character string specify test statistics confidence intervals fixed effects computed. default (test=\"z\"), Wald-type tests CIs obtained, based standard normal distribution. test=\"t\", t-distribution used instead. See ‘Details’. dfs character string specify (denominator) degrees freedom calculated test=\"t\". Either dfs=\"residual\" dfs=\"contain\". Can also numeric vector degrees freedom model coefficient. See ‘Details’. level numeric value 0 100 specify confidence interval level (default 95). digits optional integer specify number decimal places printed results rounded. unspecified, default 4. See also details control number digits output. btt optional vector indices specify coefficients include omnibus test moderators. Can also string grep . See ‘Details’. R optional named list known correlation matrices corresponding () components specified via random argument. See ‘Details’. Rscale character string, integer, logical specify matrices specified via R argument scaled. See ‘Details’. sigma2 optional numeric vector (length number random intercept components specified via random argument) fix corresponding \\(\\sigma^2\\) value(s). specific \\(\\sigma^2\\) value can fixed setting corresponding element argument desired value. specific \\(\\sigma^2\\) value estimated corresponding element set equal NA. See ‘Details’. tau2 optional numeric value (struct=\"CS\", \"AR\", \"CAR\", spatial correlation structure) vector (struct=\"HCS\", \"UN\", \"HAR\") fix amount (residual) heterogeneity levels inner factor corresponding ~ inner | outer formula specified random argument. numeric value fixes particular \\(\\tau^2\\) value, NA means value estimated. See ‘Details’. rho optional numeric value (struct=\"CS\", \"HCS\", \"AR\", \"HAR\", \"CAR\", spatial correlation structure) vector (struct=\"UN\") fix correlation levels inner factor corresponding ~ inner | outer formula specified random argument. numeric value fixes particular \\(\\rho\\) value, NA means value estimated. See ‘Details’. gamma2 tau2 argument, second ~ inner | outer formula specified random argument. See ‘Details’. phi rho argument, second ~ inner | outer formula specified random argument. See ‘Details’. cvvc logical specify whether calculate variance-covariance matrix variance/correlation component estimates (can also set \"varcov\" \"varcor\"). See ‘Details’. sparse logical specify whether function use sparse matrix objects extent possible (can speed model fitting substantially certain models). See ‘Note’. verbose logical specify whether output generated progress model fitting (default FALSE). Can also integer. Values > 1 generate verbose output. See ‘Note’. control optional list control values estimation algorithms. unspecified, default values defined inside function. See ‘Note’. ... additional arguments.","code":""},{"path":[]},{"path":"/reference/rma.mv.html","id":"specifying-the-data","dir":"Reference","previous_headings":"","what":"Specifying the Data","title":"Meta-Analysis via Multivariate/Multilevel Linear (Mixed-Effects) Models — rma.mv","text":"function can used combination usual effect size outcome measures used meta-analyses (e.g., log risk ratios, log odds ratios, risk differences, mean differences, standardized mean differences, log transformed ratios means, raw correlation coefficients, correlation coefficients transformed Fisher's r--z transformation), , generally, set estimates (corresponding sampling variances) one like meta-analyze. Simply specify observed effect sizes outcomes via yi argument corresponding sampling variances via V argument. case sampling errors correlated, one can specify entire variance-covariance matrix sampling errors via V argument. escalc function can used compute wide variety effect size outcome measures (corresponding sampling variances) based summary statistics. Equations computing covariance sampling errors variety different effect size outcome measures can found, example, Gleser Olkin (2009), Lajeunesse (2011), Wei Higgins (2013). raw Fisher r--z transformed correlations, one can find suitable equations, example, Steiger (1980). latter implemented rcalc function. See also vcalc function can used construct approximate variance-covariance matrix dependent effect sizes outcomes wide variety circumstances.","code":""},{"path":"/reference/rma.mv.html","id":"specifying-fixed-effects","dir":"Reference","previous_headings":"","what":"Specifying Fixed Effects","title":"Meta-Analysis via Multivariate/Multilevel Linear (Mixed-Effects) Models — rma.mv","text":"rma.mv(yi, V), fixed-effects model fitted data (note: arguments struct, sigma2, tau2, rho, gamma2, phi, R, Rscale relevant ignored). model simply given \\(y \\sim N(\\theta, V)\\), \\(y\\) (column) vector observed outcomes, \\(\\theta\\) (average) true outcome, \\(V\\) variance-covariance matrix sampling errors (vector sampling variances provided via V argument, \\(V\\) assumed diagonal). Note argument V, v (R case sensitive!). One moderators can included model via mods argument. single moderator can given (row column) vector length \\(k\\) specifying values moderator. Multiple moderators specified giving appropriate model matrix (.e., \\(X\\)) \\(k\\) rows many columns moderator variables (e.g., mods = cbind(mod1, mod2, mod3), mod1, mod2, mod3 correspond names variables three moderator variables). intercept added model matrix default unless intercept=FALSE. Alternatively, one can use standard formula syntax specify model. case, mods argument set equal one-sided formula form mods = ~ model (e.g., mods = ~ mod1 + mod2 + mod3). Interactions, polynomial terms, factors can easily added model manner. specifying model formula via mods argument, intercept argument ignored. Instead, inclusion/exclusion intercept controlled specified formula (e.g., mods = ~ mod1 + mod2 + mod3 - 1 lead removal intercept). One can also directly specify moderators via yi argument (e.g., rma.mv(yi ~ mod1 + mod2 + mod3, V)). case, mods argument ignored inclusion/exclusion intercept controlled specified formula. moderators included, model given \\(y \\sim N(X \\beta, V)\\), \\(X\\) denotes model matrix containing moderator values (possibly intercept) \\(\\beta\\) column vector containing corresponding model coefficients. model coefficients (.e., \\(\\beta\\)) estimated \\(b = (X'WX')^{-1} X'Wy\\), \\(W = V^{-1}\\) weight matrix (without moderators, \\(X\\) just column vector 1's). W argument, one can also specify user-defined weights (weight matrix).","code":""},{"path":"/reference/rma.mv.html","id":"specifying-random-effects","dir":"Reference","previous_headings":"","what":"Specifying Random Effects","title":"Meta-Analysis via Multivariate/Multilevel Linear (Mixed-Effects) Models — rma.mv","text":"One can fit random/mixed-effects models data specifying desired random effects structure via random argument. random argument either single one-sided formula list one-sided formulas. One formula type can specified via argument form random = ~ 1 | id. formula adds random effect corresponding grouping variable id model. Outcomes value id variable receive value random effect, outcomes different values id variable assumed independent. variance component corresponding formula denoted \\(\\sigma^2\\). arbitrary number formulas can specified list formulas (e.g., random = list(~ 1 | id1, ~ 1 | id2)), variance components \\(\\sigma^2_1\\), \\(\\sigma^2_2\\), . Nested random effects form can also added using random = ~ 1 | id1/id2, adds random effect corresponding grouping variable id1 random effect corresponding id2 within id1 model. can extended models even levels nesting (e.g., random = ~ 1 | id1/id2/id3). Random effects form useful model clustering (hence non-independence) induced multilevel structure data (e.g., outcomes derived paper, lab, research group, species may similar outcomes derived different papers, labs, research groups, species). See, example, Konstantopoulos (2011) Nakagawa Santos (2012) details. See dat.konstantopoulos2011, dat.bornmann2007, dat.obrien2003, dat.crede2010 examples multilevel meta-analyses. addition alternatively specifying one multiple ~ 1 | id terms, random argument can also contain formula form ~ inner | outer. Outcomes value outer grouping variable share correlated random effects corresponding levels inner grouping variable, outcomes different values outer grouping variable assumed independent (note inner variable automatically treated factor). struct argument used specify variance structure corresponding inner variable. struct=\"CS\", compound symmetric structure assumed (.e., single variance component \\(\\tau^2\\) corresponding \\(j = 1, \\ldots, J\\) levels inner variable single correlation coefficient \\(\\rho\\) correlation different levels). struct=\"HCS\", heteroscedastic compound symmetric structure assumed (\\(\\tau^2_j\\) denoting variance component corresponding \\(j\\textrm{th}\\) level inner variable single correlation coefficient \\(\\rho\\) correlation different levels). struct=\"UN\", unstructured (positive definite) variance-covariance matrix assumed (\\(\\tau^2_j\\) described correlation coefficient \\(\\rho_{jj'}\\) combination \\(j\\textrm{th}\\) \\(j'\\textrm{th}\\) level inner variable). example, inner variable four levels, three structures correspond variance-covariance matrices form: \\[\\begin{array}{ccc}\\texttt{struct=\"CS\"} & \\texttt{struct=\"HCS\"} & \\texttt{struct=\"UN\"} \\\\ \\begin{bmatrix} \\tau^2 & & & \\\\ \\rho\\tau^2 & \\tau^2 & & \\\\ \\rho\\tau^2 & \\rho\\tau^2 & \\tau^2 & \\\\ \\rho\\tau^2 & \\rho\\tau^2 & \\rho\\tau^2 & \\tau^2 \\end{bmatrix} & \\begin{bmatrix} \\tau_1^2 & & & \\\\ \\rho\\tau_2\\tau_1 & \\tau_2^2 & & \\\\ \\rho\\tau_3\\tau_1 & \\rho\\tau_3\\tau_2 & \\tau_3^2 & \\\\ \\rho\\tau_4\\tau_1 & \\rho\\tau_4\\tau_2 & \\rho\\tau_4\\tau_3 & \\tau_4^2 \\end{bmatrix} & \\begin{bmatrix} \\tau_1^2 & & & \\\\ \\rho_{21}\\tau_2\\tau_1 & \\tau_2^2 & & \\\\ \\rho_{31}\\tau_3\\tau_1 & \\rho_{32}\\tau_3\\tau_2 & \\tau_3^2 & \\\\ \\rho_{41}\\tau_4\\tau_1 & \\rho_{42}\\tau_4\\tau_2 & \\rho_{43}\\tau_4\\tau_3 & \\tau_4^2 \\end{bmatrix} \\end{array}\\] Structures struct=\"ID\" struct=\"DIAG\" just like struct=\"CS\" struct=\"HCS\", respectively, except \\(\\rho\\) set 0, either get scaled identity matrix diagonal matrix. outer term corresponding study identification variable inner term variable indicating treatment type study arm, random effect used estimate strongly different treatment effects outcomes within study correlated /whether amount heterogeneity differs across different treatment types/arms. Network meta-analyses (also known mixed treatment comparisons) also typically require random effect (e.g., Salanti et al., 2008). meta-analytic bivariate model (e.g., van Houwelingen, Arends, & Stijnen, 2002) can also fitted manner (see examples ). inner term also correspond variable indicating different types outcomes measured within study, allows fitting multivariate models multiple correlated effects/outcomes per study (e.g., Berkey et al., 1998; Kalaian & Raudenbush, 1996). See dat.berkey1998, dat.assink2016, dat.kalaian1996, dat.dagostino1998, dat.craft2003 examples multivariate meta-analyses multiple outcomes. See dat.knapp2017 dat.mccurdy2020 examples multilevel/multivariate models complex data structures. See dat.kearon1998 example using bivariate model analyze sensitivity specificity. See dat.hasselblad1998, dat.pagliaro1992, dat.lopez2019, dat.senn2013 examples network meta-analyses. meta-analyses studies reporting outcomes multiple time points, may also reasonable assume true effects/outcomes correlated time according autoregressive structure (Ishak et al., 2007; Trikalinos & Olkin, 2012). purpose, one can choose struct=\"AR\", corresponding structure single variance component \\(\\tau^2\\) AR(1) autocorrelation among values random effect. values inner variable reflect various time points, increasing values reflecting later time points. structure assumes equally spaced time points, actual values inner variable relevant, ordering. One can also use struct=\"HAR\", allows fitting heteroscedastic AR(1) structure (\\(\\tau^2_j\\) denoting variance component \\(j\\textrm{th}\\) measurement occasion). Finally, time points evenly spaced, one might consider using struct=\"CAR\" continuous-time autoregressive structure, case values inner variable reflect exact time points measurement occasions. example, inner variable four time points, structures correspond variance-covariance matrices form: \\[\\begin{array}{ccc}\\texttt{struct=\"AR\"} & \\texttt{struct=\"HAR\"} & \\texttt{struct=\"CAR\"} \\\\ \\begin{bmatrix} \\tau^2 & & & \\\\ \\rho\\tau^2 & \\tau^2 & & \\\\ \\rho^2\\tau^2 & \\rho\\tau^2 & \\tau^2 & \\\\ \\rho^3\\tau^2 & \\rho^2\\tau^2 & \\rho\\tau^2 & \\tau^2 \\end{bmatrix} & \\begin{bmatrix} \\tau_1^2 & & & \\\\ \\rho\\tau_2\\tau_1 & \\tau_2^2 & & \\\\ \\rho^2\\tau_3\\tau_1 & \\rho\\tau_3\\tau_2 & \\tau_3^2 & \\\\ \\rho^3\\tau_4\\tau_1 & \\rho^2\\tau_4\\tau_2 & \\rho\\tau_4\\tau_3 & \\tau_4^2 \\end{bmatrix} & \\begin{bmatrix} \\tau^2 & & & \\\\ \\rho^{|t_2-t_1|}\\tau^2 & \\tau^2 & & \\\\ \\rho^{|t_3-t_1|}\\tau^2 & \\rho^{|t_3-t_2|}\\tau^2 & \\tau^2 & \\\\ \\rho^{|t_4-t_1|}\\tau^2 & \\rho^{|t_4-t_2|}\\tau^2 & \\rho^{|t_4-t_3|}\\tau^2 & \\tau^2 \\end{bmatrix} \\end{array}\\] See dat.fine1993 dat.ishak2007 examples involving structures. outcomes known spatial configuration, various spatial correlation structures also available. structures, formula form random = ~ var1 + var2 + ... | outer, var1, var2, variables indicate spatial coordinates (e.g., longitude latitude) based distances (default Euclidean) computed. Let \\(d\\) denote distance two points share value outer variable (true effects/outcomes allowed spatially correlated, simply set outer variable constant). correlation true effects/outcomes corresponding two points function \\(d\\) parameter \\(\\rho\\). following table shows types spatial correlation structures can specified equations correlation. covariance true effects/outcomes correlation times \\(\\tau^2\\).  Note \\((d < \\rho)\\) equal \\(1\\) \\(d < \\rho\\) \\(0\\) otherwise. parameterization various structures based Pinheiro Bates (2000). Instead Euclidean distances, one can also use distance measures setting (undocumented) argument dist either \"maximum\" maximum distance two points (supremum norm), \"manhattan\" absolute distance coordinate vectors (L1 norm), \"gcd\" great-circle distance (WGS84 ellipsoid method). latter case, two variables, namely longitude latitude (decimal degrees, minus signs West South), must specified. distance matrix already computed, one can also pass matrix list element dist argument. case, one use formula form random = ~ id | outer, id location identifiers, corresponding row/column names distance matrix specified via dist argument. See dat.maire2019 example meta-analysis spatial correlation structure. ~ inner | outer formula can also used add random effects model corresponding set predictor variables struct=\"GEN\". , inner term used specify one multiple variables (e.g., random = ~ var1 + var2 | outer) corresponding ‘random slopes’ added model (‘random intercept’ unless intercept removed inner term). variance-covariance matrix random effects added manner assumed general unstructured (positive definite) matrix. random effects structure may useful meta-analysis examining dose-response relationship moderator variable size true effects/outcomes (sometimes called ‘dose-response meta-analysis’). See dat.obrien2003 example meta-analysis examining dose-response relationship. random argument can also contain second formula form ~ inner | outer (!). second formula form works exactly described , variance components denoted \\(\\gamma^2\\) correlation components \\(\\phi\\). struct argument length 2 specify variance-covariance structure first second component, respectively. random argument contains formula form ~ 1 | id, one can use (optional) argument R specify corresponding known correlation matrix random effect (.e., R = list(id = Cor), Cor correlation matrix). case, outcomes value id variable receive value random effect, outcomes different values id variable receive values correlated specified corresponding correlation matrix given via R argument. column/row names correlation matrix given via R argument must therefore correspond unique values id variable. random argument contains multiple formulas form ~ 1 | id, one can specify known correlation matrices none, , terms (e.g., random = list(~ 1 | id1, ~ 1 | id2), one specify R = list(id1 = Cor1) R = list(id1 = Cor1, id2 = Cor2), Cor1 Cor2 correlation matrices corresponding grouping variables id1 id2, respectively). random effect known (least approximately known) correlation structure useful variety contexts. example, component can used account correlations induced shared phylogenetic history among organisms (e.g., plants, fungi, animals). case, ~ 1 | species used specify species argument R used specify phylogenetic correlation matrix species studied meta-analysis. corresponding variance component indicates much variance/heterogeneity attributable specified phylogeny. See Nakagawa Santos (2012) details. another example, genetic meta-analysis studying disease association several single nucleotide polymorphisms (SNPs), linkage disequilibrium (LD) among SNPs can induce approximately known degree correlation among effects/outcomes. case, ~ 1 | snp used specify SNPs R corresponding LD correlation matrix SNPs included meta-analysis. Rscale argument controls matrices specified via R argument scaled. Rscale=\"none\" (Rscale=0 Rscale=FALSE), scaling used. Rscale=\"cor\" (Rscale=1 Rscale=TRUE), cov2cor function used ensure matrices correlation matrices (assuming covariance matrices begin ). Rscale=\"cor0\" (Rscale=2), first cov2cor used elements correlation matrix scaled \\((R - \\min(R)) / (1 - \\min(R))\\) (ensures correlation zero phylogenetic correlation matrix corresponds split root node tree comprising species actually analyzed). Finally, Rscale=\"cov0\" (Rscale=3) rescales \\(R - \\min(R)\\) (ensures phylogenetic covariance matrix rooted lowest split). See dat.moura2021 dat.lim2014 examples meta-analyses phylogenetic correlation structures. Together variance-covariance matrix sampling errors (.e., \\(V\\)), specified random effects structure model implies particular ‘marginal’ variance-covariance matrix observed effect sizes outcomes. estimates variance components (.e., \\(\\sigma^2\\), \\(\\tau^2\\), \\(\\rho\\), \\(\\gamma^2\\), /\\(\\phi\\) values) obtained (either using maximum likelihood restricted maximum likelihood estimation), estimated marginal variance-covariance matrix can constructed (denoted \\(M\\)). model coefficients (.e., \\(\\beta\\)) estimated \\(b = (X'WX')^{-1} X'Wy\\), \\(W = M^{-1}\\) weight matrix. W argument, one can specify user-defined weights (weight matrix).","code":""},{"path":"/reference/rma.mv.html","id":"fixing-variance-correlation-components","dir":"Reference","previous_headings":"","what":"Fixing Variance/Correlation Components","title":"Meta-Analysis via Multivariate/Multilevel Linear (Mixed-Effects) Models — rma.mv","text":"Arguments sigma2, tau2, rho, gamma2, phi can used fix particular variance/correlation components given value. useful sensitivity analyses (e.g., plotting regular/restricted log-likelihood function particular variance/correlation component), likelihood ratio tests, imposing desired variance-covariance structure data. example, random = list(~ 1 | id1, ~ 1 | id2) random = ~ 1 | id1/id2, sigma2 must length 2 (corresponding \\(\\sigma^2_1\\) \\(\\sigma^2_2\\)) fixed value can assigned either variance components. Setting particular component NA means component estimated function (e.g., sigma2=c(0,NA) fix \\(\\sigma^2_1\\) 0 estimate \\(\\sigma^2_2\\)). Argument tau2 relevant random argument contains ~ inner | outer formula. case, tau2 argument used, must either length 1 (\"CS\", \"ID\", \"AR\", \"CAR\", one spatial correlation structures) length number unique values inner variable (\"HCS\", \"DIAG\", \"UN\", \"HAR\"). numeric value tau2 argument fixes corresponding variance component value, NA means component estimated. Similarly, argument rho used, must either length 1 (\"CS\", \"HCS\", \"AR\", \"HAR\", one spatial correlation structures) length \\(J(J-1)/2\\) (\"UN\"), \\(J\\) denotes number unique values inner variable. , numeric value fixes corresponding correlation, NA means correlation estimated. example, struct=\"CS\" rho=0, variance-covariance matrix inner variable diagonal \\(\\tau^2\\) along diagonal. struct=\"UN\", values specified rho given column-wise order (e.g., inner variable four levels, order \\(\\rho_{21}\\), \\(\\rho_{31}\\), \\(\\rho_{41}\\), \\(\\rho_{32}\\), \\(\\rho_{42}\\), \\(\\rho_{43}\\)). Similarly, arguments gamma2 phi relevant random argument contains second ~ inner | outer formula. arguments work exactly described .","code":""},{"path":"/reference/rma.mv.html","id":"omnibus-test-of-moderators","dir":"Reference","previous_headings":"","what":"Omnibus Test of Moderators","title":"Meta-Analysis via Multivariate/Multilevel Linear (Mixed-Effects) Models — rma.mv","text":"models including moderators, omnibus test model coefficients conducted excludes intercept (first coefficient) included model. intercept included model, omnibus test includes coefficients model including first. Alternatively, one can manually specify indices coefficients test via btt argument. example, btt=c(3,4), third fourth coefficient model included test (intercept included model, corresponds first coefficient model). Instead specifying coefficient numbers, one can specify string btt. case, grep used search coefficient names match string. omnibus test called \\(Q_M\\)-test follows, assumptions model, chi-square distribution \\(m\\) degrees freedom (\\(m\\) denoting number coefficients tested) null hypothesis (true value coefficients tested equal 0).","code":""},{"path":"/reference/rma.mv.html","id":"categorical-moderators","dir":"Reference","previous_headings":"","what":"Categorical Moderators","title":"Meta-Analysis via Multivariate/Multilevel Linear (Mixed-Effects) Models — rma.mv","text":"Categorical moderator variables can included model via mods argument way appropriately (dummy) coded categorical variables can included linear models. One can either dummy coding manually use model formula together factor function automate coding (note string/character variables model formula automatically converted factors).","code":""},{"path":"/reference/rma.mv.html","id":"tests-and-confidence-intervals","dir":"Reference","previous_headings":"","what":"Tests and Confidence Intervals","title":"Meta-Analysis via Multivariate/Multilevel Linear (Mixed-Effects) Models — rma.mv","text":"default, tests individual coefficients model (corresponding confidence intervals) based standard normal distribution, omnibus test based chi-square distribution (see ). alternative, one can set test=\"t\", case tests individual coefficients confidence intervals based t-distribution \\(k-p\\) degrees freedom, omnibus test statistic uses F-distribution \\(m\\) \\(k-p\\) degrees freedom (\\(k\\) denoting total number estimates included analysis \\(p\\) total number model coefficients including intercept present). Note test=\"t\" test=\"knha\" rma.uni, adjustment standard errors estimated coefficients made. method calculating (denominator) degrees freedom described (corresponds dfs=\"residual\") quite simplistic may lead tests inflated Type error rates confidence intervals narrow average. alternative, one can set dfs=\"contain\" (automatically also sets test=\"t\"), case degrees freedom test particular model coefficient, \\(b_j\\), determined checking whether \\(x_j\\), corresponding column model matrix \\(X\\), varies level corresponding particular random effect model. random effect can found, degrees freedom set \\(l-p\\), \\(l\\) denotes number unique values random effect (.e., ~ 1 | id term, number unique values id variable ~ inner | outer term, number unique values outer variable). random effect can found, \\(k-p\\) used degrees freedom. omnibus F-test, minimum degrees freedom coefficients involved test used denominator degrees freedom. approach calculating degrees freedom often lead tests better control Type error rate confidence intervals closer nominal coverage rates. One can also set dfs numeric vector desired values degrees freedom testing model coefficients (e.g., method determining degrees freedom used).","code":""},{"path":"/reference/rma.mv.html","id":"tests-and-confidence-intervals-for-variance-correlation-components","dir":"Reference","previous_headings":"","what":"Tests and Confidence Intervals for Variance/Correlation Components","title":"Meta-Analysis via Multivariate/Multilevel Linear (Mixed-Effects) Models — rma.mv","text":"Depending random effects structure specified, model may include one multiple variance/correlation components. Profile likelihood confidence intervals components can obtained using confint function. Corresponding likelihood ratio tests can obtained using anova function (comparing two models size component tested constrained null value reduced model). also always good idea examine plots (restricted) log-likelihood function variance/correlation components model using profile function check parameter identifiability (see ‘Note’).","code":""},{"path":"/reference/rma.mv.html","id":"test-for-residual-heterogeneity","dir":"Reference","previous_headings":"","what":"Test for (Residual) Heterogeneity","title":"Meta-Analysis via Multivariate/Multilevel Linear (Mixed-Effects) Models — rma.mv","text":"test (residual) heterogeneity automatically carried function. Without moderators model, test generalized/weighted least squares extension Cochran's \\(Q\\)-test, tests whether variability observed effect sizes outcomes larger one expect based sampling variability (given covariances among sampling errors) alone. significant test suggests true effects/outcomes heterogeneous. moderators included model, \\(Q_E\\)-test residual heterogeneity, tests whether variability observed effect sizes outcomes accounted moderators included model larger one expect based sampling variability (given covariances among sampling errors) alone.","code":""},{"path":"/reference/rma.mv.html","id":"var-cov-matrix-of-the-variance-correlation-component-estimates","dir":"Reference","previous_headings":"","what":"Var-Cov Matrix of the Variance/Correlation Component Estimates","title":"Meta-Analysis via Multivariate/Multilevel Linear (Mixed-Effects) Models — rma.mv","text":"cases, one might want obtain variance-covariance matrix variance/correlation component estimates (.e., estimated \\(\\sigma^2\\), \\(\\tau^2\\), \\(\\rho\\), \\(\\gamma^2\\), \\(\\phi\\) values). function try calculate matrix cvvc=TRUE (equivalently, cvvc=\"varcor\"). done inverting Hessian, numerically approximated using hessian function numDeriv package. Note computations may numerically stable, especially estimates close parameter bounds /likelihood surface relatively flat around maximum. struct=\"UN\", one can also set cvvc=\"varcov\" case variance-covariance matrix given variance covariance components (instead correlation components).","code":""},{"path":"/reference/rma.mv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Meta-Analysis via Multivariate/Multilevel Linear (Mixed-Effects) Models — rma.mv","text":"object class c(\"rma.mv\",\"rma\"). object list containing following components: beta estimated coefficients model. se standard errors coefficients. zval test statistics coefficients. pval corresponding p-values. ci.lb lower bound confidence intervals coefficients. ci.ub upper bound confidence intervals coefficients. vb variance-covariance matrix estimated coefficients. sigma2 estimated \\(\\sigma^2\\) value(s). tau2 estimated \\(\\tau^2\\) value(s). rho estimated \\(\\rho\\) value(s). gamma2 estimated \\(\\gamma^2\\) value(s). phi estimated \\(\\phi\\) value(s). k number observed effect sizes outcomes included analysis. p number coefficients model (including intercept). m number coefficients included omnibus test moderators. QE test statistic test (residual) heterogeneity. QEp corresponding p-value. QM test statistic omnibus test moderators. QMp corresponding p-value. int.logical indicates whether model intercept-model. yi, V, X vector outcomes, corresponding variance-covariance matrix sampling errors, model matrix. M estimated marginal variance-covariance matrix observed effect sizes outcomes. fit.stats list log-likelihood, deviance, AIC, BIC, AICc values. vvc variance-covariance matrix variance/correlation component estimates (NA cvvc=FALSE). ... additional elements/values.","code":""},{"path":"/reference/rma.mv.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Meta-Analysis via Multivariate/Multilevel Linear (Mixed-Effects) Models — rma.mv","text":"results fitted model formatted printed print function. fit statistics also given, use summary (use fitstats function extract ). Full versus reduced model comparisons terms fit statistics likelihood ratio tests can obtained anova. Wald-type tests sets model coefficients linear combinations thereof can obtained function. Tests confidence intervals based (cluster) robust methods can obtained robust. Predicted/fitted values can obtained predict fitted. best linear unbiased predictions, see ranef. residuals, rstandard, rstudent functions extract raw standardized residuals. See influence additional diagnostics (e.g., determine influential studies). models moderators, variance inflation factors can obtained vif. Confidence intervals variance/correlation components model can obtained confint. random/mixed-effects models, profile function can used obtain plot (restricted) log-likelihood function specific variance/correlation component model. models moderators, regplot draws scatter plots / bubble plots, showing (marginal) relationship observed outcomes selected moderator model. extractor functions include coef, vcov, logLik, deviance, AIC, BIC, hatvalues, weights.","code":""},{"path":"/reference/rma.mv.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Meta-Analysis via Multivariate/Multilevel Linear (Mixed-Effects) Models — rma.mv","text":"Argument V also accepts list variance-covariance matrices observed effect sizes outcomes. list elements, full (block diagonal) variance-covariance matrix automatically constructed. work correctly, list elements must order observed outcomes. Model fitting done via numerical optimization model parameters. default, nlminb used optimization. One can also chose different optimizer via control argument (e.g., control=list(optimizer=\"optim\")). using optim, one can set particular method via optmethod argument (e.g., control=list(optimizer=\"optim\", optmethod=\"BFGS\")). Besides nlminb optim, one can also choose one optimizers minqa package (.e., uobyqa, newuoa, bobyqa), one (derivative-free) algorithms nloptr package, Newton-type algorithm implemented nlm, various algorithms implemented dfoptim package (hjk Hooke-Jeeves, nmk Nelder-Mead, mads Mesh Adaptive Direct Searches (MADS) algorithm), quasi-Newton type optimizers ucminf lbfgsb3c subspace-searching simplex algorithm subplex packages name, Barzilai-Borwein gradient decent method implemented BBoptim, parallelized version L-BFGS-B algorithm implemented optimParallel package name. optimizer name must given character string (.e., quotes). Additional control parameters can specified via control argument (e.g., control=list(iter.max=1000, rel.tol=1e-8)). nloptr, default use BOBYQA implementation package relative convergence criterion 1e-8 function value (.e., log-likelihood), can changed via algorithm ftop_rel arguments (e.g., control=list(optimizer=\"nloptr\", algorithm=\"NLOPT_LN_SBPLX\", ftol_rel=1e-6)). optimParallel, control argument ncpus can used specify number cores use parallelization (e.g., control=list(optimizer=\"optimParallel\", ncpus=2)). parallel::detectCores(), one can check number available cores local machine. moment, starting values chosen terribly clever way far . result, optimizer may slow converge may even get stuck local maximum. One can set starting values manually various variance/correlation components model via control argument specifying vectors sigma2.init, tau2.init, rho.init, gamma2.init, /phi.init needed. Especially complex models, good idea try different starting values make sure estimates obtained. Information progress optimization algorithm can obtained setting verbose=TRUE (work using parallelization). Since fitting complex models many random effects can computationally expensive, option useful determine model fitting progressing. One can also set verbose integer (verbose=2 yields even information verbose=3 also sets option(warn=1) temporarily). Whether particular variance/correlation component actually identifiable needs carefully examined fitting complex models. function limited checking internally fix variances /correlations zero clear insufficient information available estimate particular parameter (e.g., particular factor single level, corresponding variance component estimated). However, strongly advised general post model fitting checks make sure likelihood surface around ML/REML estimates flat combination parameter estimates (imply estimates essentially arbitrary). example, one can plot (restricted) log-likelihood function variance/correlation component model make sure profile plot shows clear peak corresponding ML/REML estimate. profile function can used purpose. Finally, note model fitting done efficient manner moment, partly result allowing crossed random effects correlations across entire dataset (e.g., using R argument). result, function works directly entire \\(k \\times k\\) (marginal) variance-covariance matrix observed effect sizes outcomes (instead working smaller blocks block diagonal structure). result, model fitting can slow large \\(k\\). However, variance-covariance structure actually sparse, lot speed can gained setting sparse=TRUE, case sparse matrix objects used (via Matrix package). Also, model fitting appears slow, setting verbose=TRUE useful obtain information model fitting progressing.","code":""},{"path":"/reference/rma.mv.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Meta-Analysis via Multivariate/Multilevel Linear (Mixed-Effects) Models — rma.mv","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/rma.mv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Meta-Analysis via Multivariate/Multilevel Linear (Mixed-Effects) Models — rma.mv","text":"Berkey, C. S., Hoaglin, D. C., Antczak-Bouckoms, ., Mosteller, F., & Colditz, G. . (1998). Meta-analysis multiple outcomes regression random effects. Statistics Medicine, 17(22), 2537--2550. https://doi.org/10.1002/(sici)1097-0258(19981130)17:22<2537::aid-sim953>3.0.co;2-c Gleser, L. J., & Olkin, . (2009). Stochastically dependent effect sizes. H. Cooper, L. V. Hedges, & J. C. Valentine (Eds.), handbook research synthesis meta-analysis (2nd ed., pp. 357--376). New York: Russell Sage Foundation. van Houwelingen, H. C., Arends, L. R., & Stijnen, T. (2002). Advanced methods meta-analysis: Multivariate approach meta-regression. Statistics Medicine, 21(4), 589--624. https://doi.org/10.1002/sim.1040 Ishak, K. J., Platt, R. W., Joseph, L., Hanley, J. ., & Caro, J. J. (2007). Meta-analysis longitudinal studies. Clinical Trials, 4(5), 525--539. https://doi.org/10.1177/1740774507083567 Kalaian, H. ., & Raudenbush, S. W. (1996). multivariate mixed linear model meta-analysis. Psychological Methods, 1(3), 227-235. https://doi.org/10.1037/1082-989X.1.3.227 Konstantopoulos, S. (2011). Fixed effects variance components estimation three-level meta-analysis. Research Synthesis Methods, 2(1), 61--76. https://doi.org/10.1002/jrsm.35 Lajeunesse, M. J. (2011). meta-analysis response ratios studies correlated multi-group designs. Ecology, 92(11), 2049--2055. https://doi.org/10.1890/11-0423.1 Nakagawa, S., & Santos, E. S. . (2012). Methodological issues advances biological meta-analysis. Evolutionary Ecology, 26(5), 1253--1274. https://doi.org/10.1007/s10682-012-9555-5 Pinheiro, J. C., & Bates, D. (2000). Mixed-effects models S S-PLUS. New York: Springer. Steiger, J. H. (1980). Tests comparing elements correlation matrix. Psychological Bulletin, 87(2), 245--251. https://doi.org/10.1037/0033-2909.87.2.245 Salanti, G., Higgins, J. P. T., Ades, . E., & Ioannidis, J. P. . (2008). Evaluation networks randomized trials. Statistical Methods Medical Research, 17(3), 279--301. https://doi.org/10.1177/0962280207080643 Trikalinos, T. ., & Olkin, . (2012). Meta-analysis effect sizes reported multiple time points: multivariate approach. Clinical Trials, 9(5), 610--620. https://doi.org/10.1177/1740774512453218 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03 Wei, Y., & Higgins, J. P. (2013). Estimating within-study covariances multivariate meta-analysis multiple outcomes. Statistics Medicine, 32(7), 1191--1205. https://doi.org/10.1002/sim.5679","code":""},{"path":[]},{"path":"/reference/rma.mv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Meta-Analysis via Multivariate/Multilevel Linear (Mixed-Effects) Models — rma.mv","text":"","code":"### calculate log odds ratios and corresponding sampling variances dat <- escalc(measure=\"OR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit random-effects model using rma.uni() rma(yi, vi, data=dat) #>  #> Random-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.3378 (SE = 0.1784) #> tau (square root of estimated tau^2 value):      0.5812 #> I^2 (total heterogeneity / total variability):   92.07% #> H^2 (total variability / sampling variability):  12.61 #>  #> Test for Heterogeneity: #> Q(df = 12) = 163.1649, p-val < .0001 #>  #> Model Results: #>  #> estimate      se     zval    pval    ci.lb    ci.ub     ​  #>  -0.7452  0.1860  -4.0057  <.0001  -1.1098  -0.3806  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### fit random-effects model using rma.mv() ### note: sigma^2 in this model is the same as tau^2 from the previous model rma.mv(yi, vi, random = ~ 1 | trial, data=dat) #>  #> Multivariate Meta-Analysis Model (k = 13; method: REML) #>  #> Variance Components: #>  #>             estim    sqrt  nlvls  fixed  factor  #> sigma^2    0.3378  0.5812     13     no   trial  #>  #> Test for Heterogeneity: #> Q(df = 12) = 163.1649, p-val < .0001 #>  #> Model Results: #>  #> estimate      se     zval    pval    ci.lb    ci.ub     ​  #>  -0.7452  0.1860  -4.0057  <.0001  -1.1098  -0.3806  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### change data into long format dat.long <- to.long(measure=\"OR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### set levels of group variable (\"exp\" = experimental/vaccinated; \"con\" = control/non-vaccinated) levels(dat.long$group) <- c(\"exp\", \"con\")  ### set \"con\" to reference level dat.long$group <- relevel(dat.long$group, ref=\"con\")  ### calculate log odds and corresponding sampling variances dat.long <- escalc(measure=\"PLO\", xi=out1, mi=out2, data=dat.long)  ### fit bivariate random-effects model using rma.mv() res <- rma.mv(yi, vi, mods = ~ group, random = ~ group | study, struct=\"UN\", data=dat.long) res #>  #> Multivariate Meta-Analysis Model (k = 26; method: REML) #>  #> Variance Components: #>  #> outer factor: study (nlvls = 13) #> inner factor: group (nlvls = 2) #>  #>             estim    sqrt  k.lvl  fixed  level  #> tau^2.1    1.5486  1.2444     13     no    con  #> tau^2.2    2.6173  1.6178     13     no    exp  #>  #>      rho.con  rho.exp    con  exp  #> con        1               -   13  #> exp   0.9450        1     no    -  #>  #> Test for Residual Heterogeneity: #> QE(df = 24) = 5270.3863, p-val < .0001 #>  #> Test of Moderators (coefficient 2): #> QM(df = 1) = 15.5470, p-val < .0001 #>  #> Model Results: #>  #>           estimate      se      zval    pval    ci.lb    ci.ub     ​  #> intrcpt    -4.8374  0.3528  -13.7113  <.0001  -5.5289  -4.1459  ***  #> groupexp    0.7414  0.1880    3.9430  <.0001   0.3729   1.1099  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>"},{"path":"/reference/rma.peto.html","id":null,"dir":"Reference","previous_headings":"","what":"Meta-Analysis via Peto's Method — rma.peto","title":"Meta-Analysis via Peto's Method — rma.peto","text":"Function fit equal-effects models \\(2 \\times 2\\) table data via Peto's method. See introduction metafor-package details models.","code":""},{"path":"/reference/rma.peto.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Meta-Analysis via Peto's Method — rma.peto","text":"","code":"rma.peto(ai, bi, ci, di, n1i, n2i,          data, slab, subset,          add=1/2, to=\"only0\", drop00=TRUE,          level=95, digits, verbose=FALSE, ...)"},{"path":"/reference/rma.peto.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Meta-Analysis via Peto's Method — rma.peto","text":"ai vector specify \\(2 \\times 2\\) table frequencies (upper left cell). See documentation escalc function details. bi vector specify \\(2 \\times 2\\) table frequencies (upper right cell). See documentation escalc function details. ci vector specify \\(2 \\times 2\\) table frequencies (lower left cell). See documentation escalc function details. di vector specify \\(2 \\times 2\\) table frequencies (lower right cell). See documentation escalc function details. n1i vector specify group sizes row totals (first group). See documentation escalc function details. n2i vector specify group sizes row totals (second group). See documentation escalc function details. data optional data frame containing data supplied function. slab optional vector labels \\(k\\) studies. subset optional (logical numeric) vector specify subset studies used analysis. add non-negative number specify amount add zero cells, counts, frequencies calculating observed effect sizes outcomes individual studies. Can also vector two numbers, first number used calculation observed effect sizes outcomes second number used applying Peto's method. See documentation escalc function details. character string specify values add added (either \"only0\", \"\", \"if0all\", \"none\"). Can also character vector, first string applies calculating observed effect sizes outcomes second string applying Peto's method. See documentation escalc function details. drop00 logical specify whether studies cases (cases) groups dropped calculating observed effect sizes outcomes (outcomes studies set NA). Can also vector two logicals, first applies calculation observed effect sizes outcomes second applying Peto's method. See documentation escalc function details. level numeric value 0 100 specify confidence interval level (default 95). digits optional integer specify number decimal places printed results rounded. unspecified, default 4. See also details control number digits output. verbose logical specify whether output generated progress model fitting (default FALSE). ... additional arguments.","code":""},{"path":[]},{"path":"/reference/rma.peto.html","id":"specifying-the-data","dir":"Reference","previous_headings":"","what":"Specifying the Data","title":"Meta-Analysis via Peto's Method — rma.peto","text":"studies assumed provide data terms \\(2 \\times 2\\) tables form: ai, bi, ci, di denote cell frequencies n1i n2i row totals. example, set randomized clinical trials (RCTs) cohort studies, group 1 group 2 may refer treatment (exposed) placebo/control (exposed) group, outcome 1 denoting event interest (e.g., death) outcome 2 complement. set case-control studies, group 1 group 2 may refer group cases group controls, outcome 1 denoting, example, exposure risk factor outcome 2 non-exposure.","code":""},{"path":"/reference/rma.peto.html","id":"peto-s-method","dir":"Reference","previous_headings":"","what":"Peto's Method","title":"Meta-Analysis via Peto's Method — rma.peto","text":"approach aggregating data type suggested Peto (see Yusuf et al., 1985). method provides weighted estimate (log) odds ratio equal-effects model. method particularly advantageous event interest rare, used group sizes within individual studies dissimilar effect sizes generally small (Greenland & Salvan, 1990; Sweeting et al., 2004; Bradburn et al., 2007). Note printed results given terms log raw units (easier interpretation).","code":""},{"path":"/reference/rma.peto.html","id":"observed-effect-sizes-or-outcomes-of-the-individual-studies","dir":"Reference","previous_headings":"","what":"Observed Effect Sizes or Outcomes of the Individual Studies","title":"Meta-Analysis via Peto's Method — rma.peto","text":"Peto's method require calculation observed (log) odds ratios individual studies directly makes use \\(2 \\times 2\\) table counts. Zero cells problem (except extreme cases, one two outcomes never occurs tables). Therefore, unnecessary add constant cell counts zero cells. However, plotting various functions, necessary calculate observed (log) odds ratios \\(k\\) studies. , zero cells can problematic, adding constant value cell counts ensures \\(k\\) values can calculated. add arguments used specify value added cell frequencies circumstances calculating observed (log) odds ratios applying Peto's method. Similarly, drop00 argument used specify studies cases (cases) groups handled. documentation escalc function explains add, , drop00 arguments work. single value arguments specified (per default), values used calculating observed (log) odds ratios adjustment cell counts made applying Peto's method. Alternatively, specifying two values arguments, first value applies calculating observed (log) odds ratios second value applying Peto's method. Note drop00 set TRUE default. Therefore, observed (log) odds ratios studies ai=ci=0 bi=di=0 set NA. applying Peto's method, studies explicitly dropped (unless second value drop00 argument also set TRUE), practically necessary, actually influence results (assuming adjustment cell/event counts made applying Peto's method).","code":""},{"path":"/reference/rma.peto.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Meta-Analysis via Peto's Method — rma.peto","text":"object class c(\"rma.peto\",\"rma\"). object list containing following components: beta aggregated log odds ratio. se standard error aggregated value. zval test statistics aggregated value. pval corresponding p-value. ci.lb lower bound confidence interval. ci.ub upper bound confidence interval. QE test statistic test heterogeneity. QEp corresponding p-value. k number studies included analysis. yi, vi vector individual log odds ratios corresponding sampling variances. fit.stats list log-likelihood, deviance, AIC, BIC, AICc values unrestricted restricted likelihood. ... additional elements/values.","code":""},{"path":"/reference/rma.peto.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Meta-Analysis via Peto's Method — rma.peto","text":"results fitted model formatted printed print function. fit statistics also given, use summary (use fitstats function extract ). residuals, rstandard, rstudent functions extract raw standardized residuals. Leave-one-diagnostics can obtained leave1out. Forest, funnel, radial, L'Abbé, Baujat plots can obtained forest, funnel, radial, labbe, baujat. qqnorm function provides normal QQ plots standardized residuals. One can also just call plot fitted model object obtain various plots . cumulative meta-analysis (.e., adding one observation time) can obtained cumul. extractor functions include coef, vcov, logLik, deviance, AIC, BIC.","code":""},{"path":"/reference/rma.peto.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Meta-Analysis via Peto's Method — rma.peto","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/rma.peto.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Meta-Analysis via Peto's Method — rma.peto","text":"Bradburn, M. J., Deeks, J. J., Berlin, J. ., & Localio, . R. (2007). Much ado nothing: comparison performance meta-analytical methods rare events. Statistics Medicine, 26(1), 53--77. https://doi.org/10.1002/sim.2528 Greenland, S., & Salvan, . (1990). Bias one-step method pooling study results. Statistics Medicine, 9(3), 247--252. https://doi.org/10.1002/sim.4780090307 Sweeting, M. J., Sutton, . J., & Lambert, P. C. (2004). add nothing? Use avoidance continuity corrections meta-analysis sparse data. Statistics Medicine, 23(9), 1351--1375. https://doi.org/10.1002/sim.1761 Yusuf, S., Peto, R., Lewis, J., Collins, R., & Sleight, P. (1985). Beta blockade myocardial infarction: overview randomized trials. Progress Cardiovascular Disease, 27(5), 335--371. https://doi.org/10.1016/s0033-0620(85)80003-7 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/rma.peto.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Meta-Analysis via Peto's Method — rma.peto","text":"","code":"### meta-analysis of the (log) odds ratios using Peto's method rma.peto(ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg) #>  #> Equal-Effects Model (k = 13) #>  #> I^2 (total heterogeneity / total variability):  92.85% #> H^2 (total variability / sampling variability): 13.98 #>  #> Test for Heterogeneity:  #> Q(df = 12) = 167.7302, p-val < .0001 #>  #> Model Results (log scale): #>  #> estimate      se      zval    pval    ci.lb    ci.ub  #>  -0.4744  0.0407  -11.6689  <.0001  -0.5541  -0.3948  #>  #> Model Results (OR scale): #>  #> estimate   ci.lb   ci.ub  #>   0.6222  0.5746  0.6738  #>"},{"path":"/reference/rma.uni.html","id":null,"dir":"Reference","previous_headings":"","what":"Meta-Analysis via Linear (Mixed-Effects) Models — rma.uni","title":"Meta-Analysis via Linear (Mixed-Effects) Models — rma.uni","text":"Function fit meta-analytic equal-, fixed-, random-effects models (mixed-effects) meta-regression models using linear (mixed-effects) model framework. See introduction metafor-package details models.","code":""},{"path":"/reference/rma.uni.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Meta-Analysis via Linear (Mixed-Effects) Models — rma.uni","text":"","code":"rma.uni(yi, vi, sei, weights, ai, bi, ci, di, n1i, n2i, x1i, x2i, t1i, t2i,         m1i, m2i, sd1i, sd2i, xi, mi, ri, ti, sdi, r2i, ni, mods, scale,         measure=\"GEN\", intercept=TRUE, data, slab, subset,         add=1/2, to=\"only0\", drop00=FALSE, vtype=\"LS\",         method=\"REML\", weighted=TRUE, test=\"z\",         level=95, digits, btt, att, tau2, verbose=FALSE, control, ...) rma(yi, vi, sei, weights, ai, bi, ci, di, n1i, n2i, x1i, x2i, t1i, t2i,         m1i, m2i, sd1i, sd2i, xi, mi, ri, ti, sdi, r2i, ni, mods, scale,         measure=\"GEN\", intercept=TRUE, data, slab, subset,         add=1/2, to=\"only0\", drop00=FALSE, vtype=\"LS\",         method=\"REML\", weighted=TRUE, test=\"z\",         level=95, digits, btt, att, tau2, verbose=FALSE, control, ...)"},{"path":"/reference/rma.uni.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Meta-Analysis via Linear (Mixed-Effects) Models — rma.uni","text":"yi vector length \\(k\\) observed effect sizes outcomes. See ‘Details’. vi vector length \\(k\\) corresponding sampling variances. See ‘Details’. sei vector length \\(k\\) corresponding standard errors (relevant using vi). See ‘Details’. weights optional argument specify vector length \\(k\\) user-defined weights. See ‘Details’. ai see documentation escalc function details. bi see documentation escalc function details. ci see documentation escalc function details. di see documentation escalc function details. n1i see documentation escalc function details. n2i see documentation escalc function details. x1i see documentation escalc function details. x2i see documentation escalc function details. t1i see documentation escalc function details. t2i see documentation escalc function details. m1i see documentation escalc function details. m2i see documentation escalc function details. sd1i see documentation escalc function details. sd2i see documentation escalc function details. xi see documentation escalc function details. mi see documentation escalc function details. ri see documentation escalc function details. ti see documentation escalc function details. sdi see documentation escalc function details. r2i see documentation escalc function details. ni see documentation escalc function details. mods optional argument include one moderators model. single moderator can given vector length \\(k\\) specifying values moderator. Multiple moderators specified giving matrix \\(k\\) rows many columns moderator variables. Alternatively, model formula can used specify model. See ‘Details’. scale optional argument include one predictors scale part location-scale model. See ‘Details’. measure character string specify type data supplied function. measure=\"GEN\" (default), observed effect sizes outcomes corresponding sampling variances (standard errors) supplied function via yi, vi, sei arguments (one two, vi sei, needs specified). Alternatively, one can set measure one effect size outcome measures described documentation escalc function case one must specify required data via appropriate arguments. intercept logical specify whether intercept added model (default TRUE). Ignored mods formula. data optional data frame containing data supplied function. slab optional vector labels \\(k\\) studies. subset optional (logical numeric) vector specify subset studies used analysis. add see documentation escalc function. see documentation escalc function. drop00 see documentation escalc function. vtype see documentation escalc function. method character string specify whether equal- random-effects model fitted. equal-effects model fitted using method=\"EE\". random-effects model fitted setting method equal one following: \"DL\", \"\", \"HS\", \"HSk\", \"SJ\", \"ML\", \"REML\", \"EB\", \"PM\", \"GENQ\", \"PMM\", \"GENQM\". Default \"REML\". See ‘Details’. weighted logical specify whether weighted (default) unweighted estimation used fit model (default TRUE). test character string specify test statistics confidence intervals fixed effects computed. default (test=\"z\"), Wald-type tests CIs obtained, based standard normal distribution. test=\"t\", t-distribution used instead. test=\"knha\", method Knapp Hartung (2003) used. See ‘Details’. level numeric value 0 100 specify confidence interval level (default 95). digits optional integer specify number decimal places printed results rounded. unspecified, default 4. See also details control number digits output. btt optional vector indices specify coefficients include omnibus test moderators. Can also string grep . See ‘Details’. att optional vector indices specify scale coefficients include omnibus test. relevant location-scale models. See ‘Details’. tau2 optional numeric value specify amount (residual) heterogeneity random- mixed-effects model (instead estimating ). Useful sensitivity analyses (e.g., plotting results function \\(\\tau^2\\)). unspecified, value \\(\\tau^2\\) estimated data. verbose logical specify whether output generated progress model fitting (default FALSE). Can also integer. Values > 1 generate verbose output. See ‘Note’. control optional list control values iterative estimation algorithms. unspecified, default values defined inside function. See ‘Note’. ... additional arguments.","code":""},{"path":[]},{"path":"/reference/rma.uni.html","id":"specifying-the-data","dir":"Reference","previous_headings":"","what":"Specifying the Data","title":"Meta-Analysis via Linear (Mixed-Effects) Models — rma.uni","text":"function can used combination usual effect size outcome measures used meta-analyses (e.g., log risk ratios, log odds ratios, risk differences, mean differences, standardized mean differences, log transformed ratios means, raw correlation coefficients, correlation coefficients transformed Fisher's r--z transformation), , generally, set estimates (corresponding sampling variances) one like analyze. Simply specify observed effect sizes outcomes via yi argument corresponding sampling variances via vi argument. Instead specifying vi, one can specify standard errors (square root sampling variances) via sei argument. escalc function can used compute wide variety effect size outcome measures (corresponding sampling variances) based summary statistics. Alternatively, function can automatically calculate values chosen effect size outcome measure (corresponding sampling variances) supplied necessary data. escalc function describes effect size outcome measures currently implemented data/arguments specified/used. measure argument set desired effect size outcome measure.","code":""},{"path":"/reference/rma.uni.html","id":"specifying-the-model","dir":"Reference","previous_headings":"","what":"Specifying the Model","title":"Meta-Analysis via Linear (Mixed-Effects) Models — rma.uni","text":"function can used fit equal-, fixed-, random-effects models, well (mixed-effects) meta-regression models including one multiple moderators (difference various models described detail introductory metafor-package help page). Assuming observed effect sizes outcomes corresponding sampling variances supplied via yi vi arguments, equal-effects model can fitted rma(yi, vi, method=\"EE\"). Setting method=\"FE\" fits fixed-effects model (see discussion model). Weighted estimation (inverse-variance weights) used default. User-defined weights can supplied via weights argument. Unweighted estimation can used setting weighted=FALSE (setting weights equal constant). random-effects model can fitted code setting method argument one various estimators amount heterogeneity: method=\"DL\" = DerSimonian-Laird estimator, method=\"\" = Hedges estimator, method=\"HS\" = Hunter-Schmidt estimator, method=\"HSk\" = Hunter-Schmidt estimator small sample-size correction, method=\"SJ\" = Sidik-Jonkman estimator, method=\"ML\" = maximum-likelihood estimator, method=\"REML\" = restricted maximum-likelihood estimator, method=\"EB\" = empirical Bayes estimator, method=\"PM\" = Paule-Mandel estimator, method=\"GENQ\" = generalized Q-statistic estimator, method=\"PMM\" = median-unbiased Paule-Mandel estimator, method=\"GENQM\" = median-unbiased generalized Q-statistic estimator. description various estimators, see Brannick et al. (2019), DerSimonian Kacker (2007), Raudenbush (2009), Veroniki et al. (2016), Viechtbauer (2005), Viechtbauer et al. (2015). Note Hedges estimator also called ‘variance component estimator’ ‘Cochran estimator’, Sidik-Jonkman estimator also called ‘model error variance estimator’, empirical Bayes estimator actually identical Paule-Mandel estimator (Paule & Mandel, 1982), generalized Q-statistic estimator general method--moments estimator (DerSimonian & Kacker, 2007) requiring specification weights (DL estimators just special cases equal inverse sampling variance weights, respectively). Finally, two median-unbiased estimators versions Paule-Mandel generalized Q-statistic estimators equate respective estimating equations expected values, medians theoretical distributions. One moderators can included model via mods argument. single moderator can given (row column) vector length \\(k\\) specifying values moderator. Multiple moderators specified giving appropriate model matrix (.e., \\(X\\)) \\(k\\) rows many columns moderator variables (e.g., mods = cbind(mod1, mod2, mod3), mod1, mod2, mod3 correspond names variables three moderator variables). intercept added model matrix default unless intercept=FALSE. Alternatively, one can use standard formula syntax specify model. case, mods argument set equal one-sided formula form mods = ~ model (e.g., mods = ~ mod1 + mod2 + mod3). Interactions, polynomial terms, factors can easily added model manner. specifying model formula via mods argument, intercept argument ignored. Instead, inclusion/exclusion intercept controlled specified formula (e.g., mods = ~ mod1 + mod2 + mod3 - 1 lead removal intercept). observed effect sizes outcomes corresponding sampling variances supplied via yi vi (sei) arguments, one can also specify moderators via yi argument (e.g., rma(yi ~ mod1 + mod2 + mod3, vi)). case, mods argument ignored inclusion/exclusion intercept controlled specified formula.","code":""},{"path":"/reference/rma.uni.html","id":"omnibus-test-of-moderators","dir":"Reference","previous_headings":"","what":"Omnibus Test of Moderators","title":"Meta-Analysis via Linear (Mixed-Effects) Models — rma.uni","text":"models including moderators, omnibus test model coefficients conducted excludes intercept (first coefficient) included model. intercept included model, omnibus test includes coefficients model including first. Alternatively, one can manually specify indices coefficients test via btt argument. example, btt=c(3,4), third fourth coefficient model included test (intercept included model, corresponds first coefficient model). Instead specifying coefficient numbers, one can specify string btt. case, grep used search coefficient names match string. omnibus test called \\(Q_M\\)-test follows, assumptions model, chi-square distribution \\(m\\) degrees freedom (\\(m\\) denoting number coefficients tested) null hypothesis (true value coefficients tested equal 0).","code":""},{"path":"/reference/rma.uni.html","id":"categorical-moderators","dir":"Reference","previous_headings":"","what":"Categorical Moderators","title":"Meta-Analysis via Linear (Mixed-Effects) Models — rma.uni","text":"Categorical moderator variables can included model via mods argument way appropriately (dummy) coded categorical variables can included linear models. One can either dummy coding manually use model formula together factor function automate coding (note string/character variables model formula automatically converted factors). example illustrate different approaches provided .","code":""},{"path":"/reference/rma.uni.html","id":"tests-and-confidence-intervals","dir":"Reference","previous_headings":"","what":"Tests and Confidence Intervals","title":"Meta-Analysis via Linear (Mixed-Effects) Models — rma.uni","text":"default, tests individual coefficients model (corresponding confidence intervals) based standard normal distribution, omnibus test based chi-square distribution (see ). alternative, one can set test=\"t\", case tests individual coefficients confidence intervals based t-distribution \\(k-p\\) degrees freedom, omnibus test statistic uses F-distribution \\(m\\) \\(k-p\\) degrees freedom (\\(k\\) denoting total number estimates included analysis \\(p\\) total number model coefficients including intercept present). Furthermore, test=\"knha\", Knapp Hartung (2003) method used, applies adjustment standard errors estimated coefficients (account uncertainty estimate amount (residual) heterogeneity) uses t- F-distributions described . Finally, one can set test=\"adhoc\", case Knapp Hartung (2003) method used, restriction adjustment standard errors can never result adjusted standard errors smaller unadjusted ones (see Jackson et al., 2017, section 4.3).","code":""},{"path":"/reference/rma.uni.html","id":"test-for-residual-heterogeneity","dir":"Reference","previous_headings":"","what":"Test for (Residual) Heterogeneity","title":"Meta-Analysis via Linear (Mixed-Effects) Models — rma.uni","text":"test (residual) heterogeneity automatically carried function. Without moderators model, simply Cochran's \\(Q\\)-test (Cochran, 1954), tests whether variability observed effect sizes outcomes larger expected based sampling variability alone. significant test suggests true effects/outcomes heterogeneous. moderators included model, \\(Q_E\\)-test residual heterogeneity, tests whether variability observed effect sizes outcomes accounted moderators included model larger expected based sampling variability alone.","code":""},{"path":"/reference/rma.uni.html","id":"location-scale-models","dir":"Reference","previous_headings":"","what":"Location-Scale Models","title":"Meta-Analysis via Linear (Mixed-Effects) Models — rma.uni","text":"function can also used fit -called ‘location-scale models’. models, one can specify predictors size average true outcome (.e., ‘location’), also predictors amount heterogeneity outcomes (.e., ‘scale’). model given \\[y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\ldots + \\beta_{p'} x_{ip'} + u_i + \\epsilon_i,\\] \\[u_i \\sim N(0, \\tau_i^2), \\; \\epsilon_i \\sim N(0, v_i),\\] \\[\\ln(\\tau_i^2) = \\alpha_0 + \\alpha_1 z_{i1} + \\alpha_2 z_{i2} + \\ldots + \\alpha_{q'} z_{iq'},\\] \\(x_{i1}, \\ldots, x_{ip'}\\) values \\(p'\\) predictor variables may related size average true outcome (letting \\(p = p' + 1\\) denote total number location coefficients model including model intercept \\(\\beta_0\\)) \\(z_{i1}, \\ldots, z_{iq'}\\) values \\(q'\\) scale variables may related amount heterogeneity outcomes (letting \\(q = q' + 1\\) denote total number scale coefficients model including model intercept \\(\\alpha_0\\)). Location variables can specified via mods argument described (e.g., mods = ~ mod1 + mod2 + mod3). Scale variables can specified via scale argument (e.g., scale = ~ var1 + var2 + var3). log link used specifying relationship scale variables amount heterogeneity \\(\\tau_i^2\\) guaranteed non-negative. Estimates location scale coefficients can obtained either maximum likelihood (method=\"ML\") restricted maximum likelihood (method=\"REML\") estimation. omnibus test scale coefficients conducted described (att argument can used specify scale coefficients include test).","code":""},{"path":"/reference/rma.uni.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Meta-Analysis via Linear (Mixed-Effects) Models — rma.uni","text":"object class c(\"rma.uni\",\"rma\"). object list containing following components: beta estimated coefficients model. se standard errors coefficients. zval test statistics coefficients. pval corresponding p-values. ci.lb lower bound confidence intervals coefficients. ci.ub upper bound confidence intervals coefficients. vb variance-covariance matrix estimated coefficients. tau2 estimated amount (residual) heterogeneity. Always 0 method=\"EE\". se.tau2 standard error estimated amount (residual) heterogeneity. k number studies included analysis. p number coefficients model (including intercept). m number coefficients included omnibus test moderators. QE test statistic test (residual) heterogeneity. QEp corresponding p-value. QM test statistic omnibus test moderators. QMp corresponding p-value. I2 value \\(^2\\). See print details. H2 value \\(H^2\\). See print details. R2 value \\(R^2\\). See print details. int.logical indicates whether model intercept-model. yi, vi, X vector outcomes, corresponding sampling variances, model matrix. fit.stats list log-likelihood, deviance, AIC, BIC, AICc values unrestricted restricted likelihood. ... additional elements/values. location-scale models, object class c(\"rma.ls\",\"rma.uni\",\"rma\") includes following components addition ones listed : alpha estimated scale coefficients model. se.alpha standard errors coefficients. zval.alpha test statistics coefficients. pval.alpha corresponding p-values. ci.lb.alpha lower bound confidence intervals coefficients. ci.ub.alpha upper bound confidence intervals coefficients. va variance-covariance matrix estimated coefficients. tau2 , now vector values. q number scale coefficients model (including intercept). QS test statistic omnibus test scale coefficients. QSp corresponding p-value. ... additional elements/values.","code":""},{"path":"/reference/rma.uni.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Meta-Analysis via Linear (Mixed-Effects) Models — rma.uni","text":"results fitted model formatted printed print function. fit statistics also given, use summary (use fitstats function extract ). Full versus reduced model comparisons terms fit statistics likelihood ratio tests can obtained anova. Wald-type tests sets model coefficients linear combinations thereof can obtained function. Permutation tests model coefficient(s) can obtained permutest. Tests confidence intervals based (cluster) robust methods can obtained robust. Predicted/fitted values can obtained predict fitted. best linear unbiased predictions, see blup ranef. residuals, rstandard, rstudent functions extract raw standardized residuals. Additional diagnostics (e.g., determine influential studies) can obtained influence function. models without moderators, leave-one-diagnostics can also obtained leave1out. models moderators, variance inflation factors can obtained vif. confidence interval amount (residual) heterogeneity random/mixed-effects model can obtained confint. location-scale models, confint can provide confidence intervals scale coefficients. Forest, funnel, radial, L'Abbé, Baujat plots can obtained forest, funnel, radial, labbe, baujat (radial L'Abbé plots models without moderators). qqnorm function provides normal QQ plots standardized residuals. One can also just call plot fitted model object obtain various plots . random/mixed-effects models, profile function can used obtain plot (restricted) log-likelihood function \\(\\tau^2\\). location-scale models, profile draws analogous plots based scale coefficients. models moderators, regplot draws scatter plots / bubble plots, showing (marginal) relationship observed outcomes selected moderator model. Tests funnel plot asymmetry (may indicative publication bias) can obtained ranktest regtest. models without moderators, trimfill method can used carry trim fill analysis hc provides random-effects model analysis robust publication bias (based method Henmi & Copas, 2010). test ‘excess significance’ can carried tes function. Selection models can fitted selmodel function. models without moderators, cumulative meta-analysis (.e., adding one observation time) can obtained cumul. extractor functions include coef, vcov, logLik, deviance, AIC, BIC, hatvalues, weights.","code":""},{"path":"/reference/rma.uni.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Meta-Analysis via Linear (Mixed-Effects) Models — rma.uni","text":"HS, HSk, , DL, SJ, GENQ estimators \\(\\tau^2\\) based closed-form solutions, ML, REML, EB estimators must obtained iteratively. , function makes use Fisher scoring algorithm, robust poor starting values usually converges quickly (Harville, 1977; Jennrich & Sampson, 1976). default, starting value set equal value Hedges () estimator algorithm terminates change estimated value \\(\\tau^2\\) smaller \\(10^{-5}\\) one iteration next. maximum number iterations 100 default (sufficient cases). Information progress algorithm can obtained setting verbose=TRUE. One can also set verbose integer (verbose=2 yields even information verbose=3 also sets option(warn=1) temporarily). different starting value, threshold, maximum number iterations can specified via control argument setting control=list(tau2.init=value, threshold=value, maxiter=value). step length Fisher scoring algorithm can also adjusted desired factor control=list(stepadj=value) (values 1 reduce step length). using verbose=TRUE shows estimate jumping around erratically (cycling values), decreasing step length (increasing maximum number iterations) can often help convergence (e.g., control=list(stepadj=0.5, maxiter=1000)). PM, PMM, GENQM estimators also involve iterative algorithms, make use uniroot function. default, desired accuracy (tol) set equal .Machine$double.eps^0.25 maximum number iterations (maxiter) 100 (). upper bound interval searched (tau2.max) set 100 (large enough cases). values can adjusted control=list(tol=value, maxiter=value, tau2.max=value). heterogeneity estimators except SJ can principle yield negative estimates amount (residual) heterogeneity. However, negative estimates \\(\\tau^2\\) outside parameter space. HS, HSk, , DL, GENQ estimators, negative estimates therefore truncated zero. ML, REML, EB estimators, Fisher scoring algorithm makes use step halving (Jennrich & Sampson, 1976) guarantee non-negative estimate. Finally, PM, PMM, GENQM estimators, lower bound interval searched set zero default. brave enough step risky territory, option set lower bound estimators value besides zero (even negative one) control=list(tau2.min=value), lowest value permitted -min(vi) (ensure marginal variances always non-negative). Hunter-Schmidt estimator amount heterogeneity defined Hunter Schmidt (1990) context random-effects model analyzing correlation coefficients. general version estimator random- mixed-effects models specific particular outcome measure described Viechtbauer (2005) Viechtbauer et al. (2015) implemented . Sidik-Jonkman estimator starts crude estimate \\(\\tau^2\\), updated described Sidik Jonkman (2005b, 2007). , instead crude estimate, one wants use better priori estimate, one can passing value via control=list(tau2.init=value). Outcomes non-positive sampling variances problematic. sampling variance equal zero, weight \\(1/0\\) equal-effects models using weighted estimation. Switching unweighted estimation possible solution . random/mixed-effects model, estimators \\(\\tau^2\\) undefined least one sampling variance equal zero. estimators may work, may still necessary switch unweighted model fitting, especially estimate \\(\\tau^2\\) converges zero. including moderators model, possible model matrix full rank (.e., linear relationship moderator variables included model). function automatically tries reduce model matrix full rank removing redundant predictors, fails model fitted error issued. Deleting (redundant) moderator variables model needed solve problem. general words caution assumptions underlying models: sampling variances (.e., vi values) treated known constants, even though practice usually estimates . implies distributions test statistics corresponding confidence intervals exact nominal coverage within-study sample sizes large (.e., error sampling variance estimates small). Certain outcome measures (e.g., arcsine square root transformed risk difference Fisher's r--z transformed correlation coefficient) based variance stabilizing transformations also help make assumption known sampling variances much reasonable. fitting mixed/random-effects model, \\(\\tau^2\\) estimated treated known constant thereafter. ignores uncertainty estimate \\(\\tau^2\\). consequence, standard errors parameter estimates tend small, yielding test statistics large confidence intervals wide enough. Knapp Hartung (2003) adjustment (.e., using test=\"knha\") can used counter problem, yielding test statistics confidence intervals whose properties closer nominal. effect size outcome measures exactly normal sampling distributions assumed various models. However, normal approximation usually becomes accurate effect size outcome measures within-study sample sizes increase. Therefore, sufficiently large within-study sample sizes (usually) needed certain tests confidence intervals nominal levels/coverage. , certain outcome measures (e.g., Fisher's r--z transformed correlation coefficient) may preferable perspective well. location-scale models, model fitting done via numerical optimization model parameters. default, nlminb used optimization. One can also chose different optimizer via control argument (e.g., control=list(optimizer=\"optim\")). using optim, one can set particular method via optmethod argument (e.g., control=list(optimizer=\"optim\", optmethod=\"BFGS\")). Besides nlminb optim, one can also choose one optimizers minqa package (.e., uobyqa, newuoa, bobyqa), one (derivative-free) algorithms nloptr package, Newton-type algorithm implemented nlm, various algorithms implemented dfoptim package (hjk Hooke-Jeeves, nmk Nelder-Mead, mads Mesh Adaptive Direct Searches (MADS) algorithm), quasi-Newton type optimizers ucminf lbfgsb3c subspace-searching simplex algorithm subplex packages name, Barzilai-Borwein gradient decent method implemented BBoptim, parallelized version L-BFGS-B algorithm implemented optimParallel package name. optimizer name must given character string (.e., quotes). Additional control parameters can specified via control argument (e.g., control=list(iter.max=1000, rel.tol=1e-8)). nloptr, default use BOBYQA implementation package relative convergence criterion 1e-8 function value (.e., log-likelihood), can changed via algorithm ftop_rel arguments (e.g., control=list(optimizer=\"nloptr\", algorithm=\"NLOPT_LN_SBPLX\", ftol_rel=1e-6)). optimParallel, control argument ncpus can used specify number cores use parallelization (e.g., control=list(optimizer=\"optimParallel\", ncpus=2)). parallel::detectCores(), one can check number available cores local machine. certain circumstances (e.g., amount heterogeneity small certain combinations values scale variables scale coefficients), values scale coefficients may try drift towards minus plus infinity, can lead problems optimization. One can impose constraints scale coefficients via control=list(alpha.min=minval, alpha.max=maxval) minval maxval either scalars vectors appropriate length. Finally, location-scale models, standard errors scale coefficients obtained inverting Hessian, numerically approximated using hessian function numDeriv package. may fail, leading NA values standard errors hence test statistics, p-values, confidence interval bounds. One can set control argument hessianCtrl list named arguments passed method.args argument hessian function (default control=list(hessianCtrl=list(r=8))). Even Hessian can approximated inverted, standard errors may unreasonably large likelihood surface flat around estimated scale coefficients. likely happen \\(k\\) small amount heterogeneity small conditions defined scale coefficients/variables. Setting constraints scale coefficients described can also help mitigate issue.","code":""},{"path":"/reference/rma.uni.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Meta-Analysis via Linear (Mixed-Effects) Models — rma.uni","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/rma.uni.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Meta-Analysis via Linear (Mixed-Effects) Models — rma.uni","text":"Berkey, C. S., Hoaglin, D. C., Mosteller, F., & Colditz, G. . (1995). random-effects regression model meta-analysis. Statistics Medicine, 14(4), 395--411. https://doi.org/10.1002/sim.4780140406 Brannick, M. T., Potter, S. M., Benitez, B., & Morris, S. B. (2019). Bias precision alternate estimators meta-analysis: Benefits blending Schmidt–Hunter Hedges approaches. Organizational Research Methods, 22(2), 490--514. https://doi.org/10.1177/1094428117741966 Cochran, W. G. (1954). combination estimates different experiments. Biometrics, 10(1), 101--129. https://doi.org/10.2307/3001666 DerSimonian, R., & Laird, N. (1986). Meta-analysis clinical trials. Controlled Clinical Trials, 7(3), 177--188. https://doi.org/10.1016/0197-2456(86)90046-2 DerSimonian, R., & Kacker, R. (2007). Random-effects model meta-analysis clinical trials: update. Contemporary Clinical Trials, 28(2), 105--114. https://doi.org/10.1016/j.cct.2006.04.004 Harville, D. . (1977). Maximum likelihood approaches variance component estimation related problems. Journal American Statistical Association, 72(358), 320--338. https://doi.org/10.2307/2286796 Hedges, L. V. (1983). random effects model effect sizes. Psychological Bulletin, 93(2), 388--395. https://doi.org/10.1037/0033-2909.93.2.388 Hedges, L. V., & Olkin, . (1985). Statistical methods meta-analysis. San Diego, CA: Academic Press. Henmi, M., & Copas, J. B. (2010). Confidence intervals random effects meta-analysis robustness publication bias. Statistics Medicine, 29(29), 2969--2983. https://doi.org/10.1002/sim.4029 Hunter, J. E., & Schmidt, F. L. (2004). Methods meta-analysis: Correcting error bias research findings (2nd ed.). Thousand Oaks, CA: Sage. Jackson, D., Law, M., Rücker, G., & Schwarzer, G. (2017). Hartung-Knapp modification random-effects meta-analysis: useful refinement residual concerns? Statistics Medicine, 36(25), 3923--3934. https://doi.org/10.1002/sim.7411 Jennrich, R. ., & Sampson, P. F. (1976). Newton-Raphson related algorithms maximum likelihood variance component estimation. Technometrics, 18(1), 11--17. https://doi.org/10.2307/1267911 Knapp, G., & Hartung, J. (2003). Improved tests random effects meta-regression single covariate. Statistics Medicine, 22(17), 2693--2710. https://doi.org/10.1002/sim.1482 Morris, C. N. (1983). Parametric empirical Bayes inference: Theory applications. Journal American Statistical Association, 78(381), 47--55. https://doi.org/10.2307/2287098 Paule, R. C., & Mandel, J. (1982). Consensus values weighting factors. Journal Research National Bureau Standards, 87(5), 377--385. https://doi.org/10.6028/jres.087.022 Raudenbush, S. W. (2009). Analyzing effect sizes: Random effects models. H. Cooper, L. V. Hedges, & J. C. Valentine (Eds.), handbook research synthesis meta-analysis (2nd ed., pp. 295--315). New York: Russell Sage Foundation. Sidik, K., & Jonkman, J. N. (2005a). note variance estimation random effects meta-regression. Journal Biopharmaceutical Statistics, 15(5), 823--838. https://doi.org/10.1081/BIP-200067915 Sidik, K., & Jonkman, J. N. (2005b). Simple heterogeneity variance estimation meta-analysis. Journal Royal Statistical Society, Series C, 54(2), 367--384. https://doi.org/10.1111/j.1467-9876.2005.00489.x Sidik, K., & Jonkman, J. N. (2007). comparison heterogeneity variance estimators combining results studies. Statistics Medicine, 26(9), 1964--1981. https://doi.org/10.1002/sim.2688 Veroniki, . ., Jackson, D., Viechtbauer, W., Bender, R., Bowden, J., Knapp, G., Kuss, O., Higgins, J. P., Langan, D., & Salanti, G. (2016). Methods estimate -study variance uncertainty meta-analysis. Research Synthesis Methods, 7(1), 55--79. https://doi.org/10.1002/jrsm.1164 Viechtbauer, W. (2005). Bias efficiency meta-analytic variance estimators random-effects model. Journal Educational Behavioral Statistics, 30(3), 261--293. https://doi.org/10.3102/10769986030003261 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03 Viechtbauer, W., López-López, J. ., Sánchez-Meca, J., & Marín-Martínez, F. (2015). comparison procedures test moderators mixed-effects meta-regression models. Psychological Methods, 20(3), 360--374. https://doi.org/10.1037/met0000023","code":""},{"path":[]},{"path":"/reference/rma.uni.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Meta-Analysis via Linear (Mixed-Effects) Models — rma.uni","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit a random-effects model using the log risk ratios and variances as input ### note: method=\"REML\" is the default, so one could leave this out rma(yi, vi, data=dat, method=\"REML\") #>  #> Random-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.3132 (SE = 0.1664) #> tau (square root of estimated tau^2 value):      0.5597 #> I^2 (total heterogeneity / total variability):   92.22% #> H^2 (total variability / sampling variability):  12.86 #>  #> Test for Heterogeneity: #> Q(df = 12) = 152.2330, p-val < .0001 #>  #> Model Results: #>  #> estimate      se     zval    pval    ci.lb    ci.ub     ​  #>  -0.7145  0.1798  -3.9744  <.0001  -1.0669  -0.3622  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### fit a random-effects model using the log risk ratios and standard errors as input ### note: the second argument of rma() is for the *variances*, so we use the ### named argument 'sei' to supply the standard errors to the function dat$sei <- sqrt(dat$vi) rma(yi, sei=sei, data=dat) #>  #> Random-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.3132 (SE = 0.1664) #> tau (square root of estimated tau^2 value):      0.5597 #> I^2 (total heterogeneity / total variability):   92.22% #> H^2 (total variability / sampling variability):  12.86 #>  #> Test for Heterogeneity: #> Q(df = 12) = 152.2330, p-val < .0001 #>  #> Model Results: #>  #> estimate      se     zval    pval    ci.lb    ci.ub     ​  #>  -0.7145  0.1798  -3.9744  <.0001  -1.0669  -0.3622  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### fit a random-effects model supplying the 2x2 table cell frequencies to the function rma(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat) #>  #> Random-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.3132 (SE = 0.1664) #> tau (square root of estimated tau^2 value):      0.5597 #> I^2 (total heterogeneity / total variability):   92.22% #> H^2 (total variability / sampling variability):  12.86 #>  #> Test for Heterogeneity: #> Q(df = 12) = 152.2330, p-val < .0001 #>  #> Model Results: #>  #> estimate      se     zval    pval    ci.lb    ci.ub     ​  #>  -0.7145  0.1798  -3.9744  <.0001  -1.0669  -0.3622  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### fit a mixed-effects model with two moderators (absolute latitude and publication year) rma(yi, vi, mods=cbind(ablat, year), data=dat) #>  #> Mixed-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.1108 (SE = 0.0845) #> tau (square root of estimated tau^2 value):             0.3328 #> I^2 (residual heterogeneity / unaccounted variability): 71.98% #> H^2 (unaccounted variability / sampling variability):   3.57 #> R^2 (amount of heterogeneity accounted for):            64.63% #>  #> Test for Residual Heterogeneity: #> QE(df = 10) = 28.3251, p-val = 0.0016 #>  #> Test of Moderators (coefficients 2:3): #> QM(df = 2) = 12.2043, p-val = 0.0022 #>  #> Model Results: #>  #>          estimate       se     zval    pval     ci.lb    ci.ub    ​  #> intrcpt   -3.5455  29.0959  -0.1219  0.9030  -60.5724  53.4814      #> ablat     -0.0280   0.0102  -2.7371  0.0062   -0.0481  -0.0080  **  #> year       0.0019   0.0147   0.1299  0.8966   -0.0269   0.0307      #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### using a model formula to specify the same model rma(yi, vi, mods = ~ ablat + year, data=dat) #>  #> Mixed-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.1108 (SE = 0.0845) #> tau (square root of estimated tau^2 value):             0.3328 #> I^2 (residual heterogeneity / unaccounted variability): 71.98% #> H^2 (unaccounted variability / sampling variability):   3.57 #> R^2 (amount of heterogeneity accounted for):            64.63% #>  #> Test for Residual Heterogeneity: #> QE(df = 10) = 28.3251, p-val = 0.0016 #>  #> Test of Moderators (coefficients 2:3): #> QM(df = 2) = 12.2043, p-val = 0.0022 #>  #> Model Results: #>  #>          estimate       se     zval    pval     ci.lb    ci.ub    ​  #> intrcpt   -3.5455  29.0959  -0.1219  0.9030  -60.5724  53.4814      #> ablat     -0.0280   0.0102  -2.7371  0.0062   -0.0481  -0.0080  **  #> year       0.0019   0.0147   0.1299  0.8966   -0.0269   0.0307      #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### using a model formula as part of the yi argument rma(yi ~ ablat + year, vi, data=dat) #>  #> Mixed-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.1108 (SE = 0.0845) #> tau (square root of estimated tau^2 value):             0.3328 #> I^2 (residual heterogeneity / unaccounted variability): 71.98% #> H^2 (unaccounted variability / sampling variability):   3.57 #> R^2 (amount of heterogeneity accounted for):            64.63% #>  #> Test for Residual Heterogeneity: #> QE(df = 10) = 28.3251, p-val = 0.0016 #>  #> Test of Moderators (coefficients 2:3): #> QM(df = 2) = 12.2043, p-val = 0.0022 #>  #> Model Results: #>  #>          estimate       se     zval    pval     ci.lb    ci.ub    ​  #> intrcpt   -3.5455  29.0959  -0.1219  0.9030  -60.5724  53.4814      #> ablat     -0.0280   0.0102  -2.7371  0.0062   -0.0481  -0.0080  **  #> year       0.0019   0.0147   0.1299  0.8966   -0.0269   0.0307      #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### manual dummy coding of the allocation factor alloc.random     <- ifelse(dat$alloc == \"random\",     1, 0) alloc.alternate  <- ifelse(dat$alloc == \"alternate\",  1, 0) alloc.systematic <- ifelse(dat$alloc == \"systematic\", 1, 0)  ### test the allocation factor (in the presence of the other moderators) ### note: 'alternate' is the reference level of the allocation factor, ###       since this is the dummy/level we leave out of the model ### note: the intercept is the first coefficient, so with btt=2:3 we test ###       coefficients 2 and 3, corresponding to the coefficients for the ###       allocation factor rma(yi, vi, mods = ~ alloc.random + alloc.systematic + year + ablat, data=dat, btt=2:3) #>  #> Mixed-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.1796 (SE = 0.1425) #> tau (square root of estimated tau^2 value):             0.4238 #> I^2 (residual heterogeneity / unaccounted variability): 73.09% #> H^2 (unaccounted variability / sampling variability):   3.72 #> R^2 (amount of heterogeneity accounted for):            42.67% #>  #> Test for Residual Heterogeneity: #> QE(df = 8) = 26.2030, p-val = 0.0010 #>  #> Test of Moderators (coefficients 2:3): #> QM(df = 2) = 1.3663, p-val = 0.5050 #>  #> Model Results: #>  #>                   estimate       se     zval    pval     ci.lb    ci.ub   ​  #> intrcpt           -14.4984  38.3943  -0.3776  0.7057  -89.7498  60.7531     #> alloc.random       -0.3421   0.4180  -0.8183  0.4132   -1.1613   0.4772     #> alloc.systematic    0.0101   0.4467   0.0226  0.9820   -0.8654   0.8856     #> year                0.0075   0.0194   0.3849  0.7003   -0.0306   0.0456     #> ablat              -0.0236   0.0132  -1.7816  0.0748   -0.0495   0.0024  .  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### using a model formula to specify the same model rma(yi, vi, mods = ~ factor(alloc) + year + ablat, data=dat, btt=2:3) #>  #> Mixed-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.1796 (SE = 0.1425) #> tau (square root of estimated tau^2 value):             0.4238 #> I^2 (residual heterogeneity / unaccounted variability): 73.09% #> H^2 (unaccounted variability / sampling variability):   3.72 #> R^2 (amount of heterogeneity accounted for):            42.67% #>  #> Test for Residual Heterogeneity: #> QE(df = 8) = 26.2030, p-val = 0.0010 #>  #> Test of Moderators (coefficients 2:3): #> QM(df = 2) = 1.3663, p-val = 0.5050 #>  #> Model Results: #>  #>                          estimate       se     zval    pval     ci.lb    ci.ub   ​  #> intrcpt                  -14.4984  38.3943  -0.3776  0.7057  -89.7498  60.7531     #> factor(alloc)random       -0.3421   0.4180  -0.8183  0.4132   -1.1613   0.4772     #> factor(alloc)systematic    0.0101   0.4467   0.0226  0.9820   -0.8654   0.8856     #> year                       0.0075   0.0194   0.3849  0.7003   -0.0306   0.0456     #> ablat                     -0.0236   0.0132  -1.7816  0.0748   -0.0495   0.0024  .  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### factor() is not needed as character variables are automatically converted to factors rma(yi, vi, mods = ~ alloc + year + ablat, data=dat, btt=2:3) #>  #> Mixed-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.1796 (SE = 0.1425) #> tau (square root of estimated tau^2 value):             0.4238 #> I^2 (residual heterogeneity / unaccounted variability): 73.09% #> H^2 (unaccounted variability / sampling variability):   3.72 #> R^2 (amount of heterogeneity accounted for):            42.67% #>  #> Test for Residual Heterogeneity: #> QE(df = 8) = 26.2030, p-val = 0.0010 #>  #> Test of Moderators (coefficients 2:3): #> QM(df = 2) = 1.3663, p-val = 0.5050 #>  #> Model Results: #>  #>                  estimate       se     zval    pval     ci.lb    ci.ub   ​  #> intrcpt          -14.4984  38.3943  -0.3776  0.7057  -89.7498  60.7531     #> allocrandom       -0.3421   0.4180  -0.8183  0.4132   -1.1613   0.4772     #> allocsystematic    0.0101   0.4467   0.0226  0.9820   -0.8654   0.8856     #> year               0.0075   0.0194   0.3849  0.7003   -0.0306   0.0456     #> ablat             -0.0236   0.0132  -1.7816  0.0748   -0.0495   0.0024  .  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### test all pairwise differences with Holm's method (using the 'multcomp' package if installed) res <- rma(yi, vi, mods = ~ factor(alloc) - 1, data=dat) res #>  #> Mixed-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.3615 (SE = 0.2111) #> tau (square root of estimated tau^2 value):             0.6013 #> I^2 (residual heterogeneity / unaccounted variability): 88.77% #> H^2 (unaccounted variability / sampling variability):   8.91 #>  #> Test for Residual Heterogeneity: #> QE(df = 10) = 132.3676, p-val < .0001 #>  #> Test of Moderators (coefficients 1:3): #> QM(df = 3) = 15.9842, p-val = 0.0011 #>  #> Model Results: #>  #>                          estimate      se     zval    pval    ci.lb    ci.ub     ​  #> factor(alloc)alternate    -0.5180  0.4412  -1.1740  0.2404  -1.3827   0.3468       #> factor(alloc)random       -0.9658  0.2672  -3.6138  0.0003  -1.4896  -0.4420  ***  #> factor(alloc)systematic   -0.4289  0.3449  -1.2434  0.2137  -1.1050   0.2472       #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  if (require(multcomp))    summary(glht(res, linfct=contrMat(c(\"alternate\"=1,\"random\"=1,\"systematic\"=1),            type=\"Tukey\")), test=adjusted(\"holm\")) #> Loading required package: multcomp #> Loading required package: mvtnorm #> Loading required package: survival #> Loading required package: TH.data #> Loading required package: MASS #>  #> Attaching package: ‘TH.data’ #> The following object is masked from ‘package:MASS’: #>  #>     geyser #>  #> \t Simultaneous Tests for General Linear Hypotheses #>  #> Multiple Comparisons of Means: Tukey Contrasts #>  #>  #> Fit: rma(yi = yi, vi = vi, mods = ~factor(alloc) - 1, data = dat) #>  #> Linear Hypotheses: #>                             Estimate Std. Error z value Pr(>|z|) #> random - alternate == 0     -0.44782    0.51582  -0.868    0.771 #> systematic - alternate == 0  0.08904    0.56004   0.159    0.874 #> systematic - random == 0     0.53686    0.43636   1.230    0.656 #> (Adjusted p values reported -- holm method) #>   ### subgrouping versus using a single model with a factor (subgrouping provides ### an estimate of tau^2 within each subgroup, but the number of studies in each ### subgroup is quite small; the model with the allocation factor provides a ### single estimate of tau^2 based on a larger number of studies, but assumes ### that tau^2 is the same within each subgroup) res.a <- rma(yi, vi, data=dat, subset=(alloc==\"alternate\")) res.r <- rma(yi, vi, data=dat, subset=(alloc==\"random\")) res.s <- rma(yi, vi, data=dat, subset=(alloc==\"systematic\")) res.a #>  #> Random-Effects Model (k = 2; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.1326 (SE = 0.2286) #> tau (square root of estimated tau^2 value):      0.3641 #> I^2 (total heterogeneity / total variability):   82.02% #> H^2 (total variability / sampling variability):  5.56 #>  #> Test for Heterogeneity: #> Q(df = 1) = 5.5625, p-val = 0.0183 #>  #> Model Results: #>  #> estimate      se     zval    pval    ci.lb   ci.ub   ​  #>  -0.5408  0.2816  -1.9204  0.0548  -1.0927  0.0111  .  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  res.r #>  #> Random-Effects Model (k = 7; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.3925 (SE = 0.3029) #> tau (square root of estimated tau^2 value):      0.6265 #> I^2 (total heterogeneity / total variability):   89.93% #> H^2 (total variability / sampling variability):  9.93 #>  #> Test for Heterogeneity: #> Q(df = 6) = 110.2133, p-val < .0001 #>  #> Model Results: #>  #> estimate      se     zval    pval    ci.lb    ci.ub     ​  #>  -0.9710  0.2760  -3.5186  0.0004  -1.5118  -0.4301  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  res.s #>  #> Random-Effects Model (k = 4; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.4003 (SE = 0.4199) #> tau (square root of estimated tau^2 value):      0.6327 #> I^2 (total heterogeneity / total variability):   86.42% #> H^2 (total variability / sampling variability):  7.36 #>  #> Test for Heterogeneity: #> Q(df = 3) = 16.5919, p-val = 0.0009 #>  #> Model Results: #>  #> estimate      se     zval    pval    ci.lb   ci.ub   ​  #>  -0.4242  0.3597  -1.1792  0.2383  -1.1293  0.2809     #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  res <- rma(yi, vi, mods = ~ factor(alloc) - 1, data=dat) res #>  #> Mixed-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.3615 (SE = 0.2111) #> tau (square root of estimated tau^2 value):             0.6013 #> I^2 (residual heterogeneity / unaccounted variability): 88.77% #> H^2 (unaccounted variability / sampling variability):   8.91 #>  #> Test for Residual Heterogeneity: #> QE(df = 10) = 132.3676, p-val < .0001 #>  #> Test of Moderators (coefficients 1:3): #> QM(df = 3) = 15.9842, p-val = 0.0011 #>  #> Model Results: #>  #>                          estimate      se     zval    pval    ci.lb    ci.ub     ​  #> factor(alloc)alternate    -0.5180  0.4412  -1.1740  0.2404  -1.3827   0.3468       #> factor(alloc)random       -0.9658  0.2672  -3.6138  0.0003  -1.4896  -0.4420  ***  #> factor(alloc)systematic   -0.4289  0.3449  -1.2434  0.2137  -1.1050   0.2472       #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ############################################################################  ### demonstrating that Q_E + Q_M = Q_Total for fixed-effects models ### note: this does not work for random/mixed-effects models, since Q_E and ### Q_Total are calculated under the assumption that tau^2 = 0, while the ### calculation of Q_M incorporates the estimate of tau^2 res <- rma(yi, vi, data=dat, method=\"FE\") res ### this gives Q_Total #>  #> Fixed-Effects Model (k = 13) #>  #> I^2 (total heterogeneity / total variability):   92.12% #> H^2 (total variability / sampling variability):  12.69 #>  #> Test for Heterogeneity: #> Q(df = 12) = 152.2330, p-val < .0001 #>  #> Model Results: #>  #> estimate      se      zval    pval    ci.lb    ci.ub     ​  #>  -0.4303  0.0405  -10.6247  <.0001  -0.5097  -0.3509  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  res <- rma(yi, vi, mods = ~ ablat + year, data=dat, method=\"FE\") res ### this gives Q_E and Q_M #>  #> Fixed-Effects with Moderators Model (k = 13) #>  #> I^2 (residual heterogeneity / unaccounted variability): 64.70% #> H^2 (unaccounted variability / sampling variability):   2.83 #> R^2 (amount of heterogeneity accounted for):            77.67% #>  #> Test for Residual Heterogeneity: #> QE(df = 10) = 28.3251, p-val = 0.0016 #>  #> Test of Moderators (coefficients 2:3): #> QM(df = 2) = 123.9079, p-val < .0001 #>  #> Model Results: #>  #>          estimate       se     zval    pval    ci.lb    ci.ub     ​  #> intrcpt   17.1518  10.8321   1.5834  0.1133  -4.0786  38.3822       #> ablat     -0.0339   0.0040  -8.4766  <.0001  -0.0417  -0.0260  ***  #> year      -0.0085   0.0055  -1.5518  0.1207  -0.0192   0.0022       #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  res$QE + res$QM #> [1] 152.233  ### decomposition of Q_E into subgroup Q-values res <- rma(yi, vi, mods = ~ factor(alloc), data=dat) res #>  #> Mixed-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.3615 (SE = 0.2111) #> tau (square root of estimated tau^2 value):             0.6013 #> I^2 (residual heterogeneity / unaccounted variability): 88.77% #> H^2 (unaccounted variability / sampling variability):   8.91 #> R^2 (amount of heterogeneity accounted for):            0.00% #>  #> Test for Residual Heterogeneity: #> QE(df = 10) = 132.3676, p-val < .0001 #>  #> Test of Moderators (coefficients 2:3): #> QM(df = 2) = 1.7675, p-val = 0.4132 #>  #> Model Results: #>  #>                          estimate      se     zval    pval    ci.lb   ci.ub   ​  #> intrcpt                   -0.5180  0.4412  -1.1740  0.2404  -1.3827  0.3468     #> factor(alloc)random       -0.4478  0.5158  -0.8682  0.3853  -1.4588  0.5632     #> factor(alloc)systematic    0.0890  0.5600   0.1590  0.8737  -1.0086  1.1867     #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   res.a <- rma(yi, vi, data=dat, subset=(alloc==\"alternate\")) res.r <- rma(yi, vi, data=dat, subset=(alloc==\"random\")) res.s <- rma(yi, vi, data=dat, subset=(alloc==\"systematic\"))  res.a$QE ### Q-value within subgroup \"alternate\" #> [1] 5.562514 res.r$QE ### Q-value within subgroup \"random\" #> [1] 110.2133 res.s$QE ### Q-value within subgroup \"systematic\" #> [1] 16.59186  res$QE #> [1] 132.3676 res.a$QE + res.r$QE + res.s$QE #> [1] 132.3676  ############################################################################  ### an example of a location-scale model dat <- dat.bangertdrowns2004  ### fit a standard random-effects model res <- rma(yi, vi, data=dat) res #>  #> Random-Effects Model (k = 48; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.0499 (SE = 0.0197) #> tau (square root of estimated tau^2 value):      0.2235 #> I^2 (total heterogeneity / total variability):   58.37% #> H^2 (total variability / sampling variability):  2.40 #>  #> Test for Heterogeneity: #> Q(df = 47) = 107.1061, p-val < .0001 #>  #> Model Results: #>  #> estimate      se    zval    pval   ci.lb   ci.ub     ​  #>   0.2219  0.0460  4.8209  <.0001  0.1317  0.3122  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### fit the same model as a location-scale model res <- rma(yi, vi, scale = ~ 1, data=dat) res #>  #> Location-Scale Model (k = 48; tau^2 estimator: REML) #>  #> Test for Heterogeneity: #> Q(df = 47) = 107.1061, p-val < .0001 #>  #> Model Results (Location): #>  #> estimate      se    zval    pval   ci.lb   ci.ub     ​  #>   0.2219  0.0460  4.8210  <.0001  0.1317  0.3122  ***  #>  #> Model Results (Scale): #>  #> estimate      se     zval    pval    ci.lb    ci.ub     ​  #>  -2.9970  0.4603  -6.5107  <.0001  -3.8992  -2.0948  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### check that we obtain the same estimate for tau^2 predict(res, newscale=1, transf=exp) #>  #>    pred  ci.lb  ci.ub  #>  0.0499 0.0203 0.1231  #>   ### add the total sample size (per 100) as a location and scale predictor dat$ni100 <- dat$ni/100 res <- rma(yi, vi, mods = ~ ni100, scale = ~ ni100, data=dat) res #>  #> Location-Scale Model (k = 48; tau^2 estimator: REML) #>  #> Test for Residual Heterogeneity: #> QE(df = 46) = 95.1352, p-val < .0001 #>  #> Test of Location Coefficients (coefficient 2): #> QM(df = 1) = 7.8268, p-val = 0.0051 #>  #> Model Results (Location): #>  #>          estimate      se     zval    pval    ci.lb    ci.ub     ​  #> intrcpt    0.3017  0.0661   4.5629  <.0001   0.1721   0.4313  ***  #> ni100     -0.0553  0.0198  -2.7976  0.0051  -0.0940  -0.0165   **  #>  #> Test of Scale Coefficients (coefficient 2): #> QS(df = 1) = 3.1850, p-val = 0.0743 #>  #> Model Results (Scale): #>  #>          estimate      se     zval    pval    ci.lb    ci.ub    ​  #> intrcpt   -1.9209  0.6690  -2.8713  0.0041  -3.2321  -0.6097  **  #> ni100     -0.9174  0.5141  -1.7847  0.0743  -1.9250   0.0901   .  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### variables in the location and scale parts can differ res <- rma(yi, vi, mods = ~ ni100 + meta, scale = ~ ni100 + imag, data=dat) #> Warning: Studies with NAs omitted from model fitting. res #>  #> Location-Scale Model (k = 46; tau^2 estimator: REML) #>  #> Test for Residual Heterogeneity: #> QE(df = 43) = 82.2711, p-val = 0.0003 #>  #> Test of Location Coefficients (coefficients 2:3): #> QM(df = 2) = 12.4826, p-val = 0.0019 #>  #> Model Results (Location): #>  #>          estimate      se     zval    pval    ci.lb    ci.ub     ​  #> intrcpt    0.2303  0.0655   3.5166  0.0004   0.1019   0.3586  ***  #> ni100     -0.0565  0.0188  -3.0113  0.0026  -0.0933  -0.0197   **  #> meta       0.1469  0.0690   2.1305  0.0331   0.0118   0.2820    *  #>  #> Test of Scale Coefficients (coefficients 2:3): #> QS(df = 2) = 5.0289, p-val = 0.0809 #>  #> Model Results (Scale): #>  #>          estimate      se     zval    pval    ci.lb    ci.ub    ​  #> intrcpt   -2.3456  0.8354  -2.8079  0.0050  -3.9829  -0.7084  **  #> ni100     -0.9995  0.6087  -1.6421  0.1006  -2.1925   0.1935      #> imag       2.1258  1.1857   1.7929  0.0730  -0.1981   4.4497   .  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>"},{"path":"/reference/robust.html","id":null,"dir":"Reference","previous_headings":"","what":"Cluster-Robust Tests and Confidence Intervals for 'rma' Objects — robust","title":"Cluster-Robust Tests and Confidence Intervals for 'rma' Objects — robust","text":"function provides cluster-robust tests confidence intervals model coefficients objects class \"rma\".","code":""},{"path":"/reference/robust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cluster-Robust Tests and Confidence Intervals for 'rma' Objects — robust","text":"","code":"robust(x, cluster, ...)  # S3 method for rma.uni robust(x, cluster, adjust=TRUE, clubSandwich=FALSE, digits, ...) # S3 method for rma.mv robust(x, cluster, adjust=TRUE, clubSandwich=FALSE, digits, ...)"},{"path":"/reference/robust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cluster-Robust Tests and Confidence Intervals for 'rma' Objects — robust","text":"x object class \"rma.uni\" \"rma.mv\". cluster vector specify clustering variable use constructing sandwich estimator variance-covariance matrix. adjust logical specify whether small-sample correction applied variance-covariance matrix. clubSandwich logical specify whether clubSandwich package used obtain cluster-robust tests confidence intervals. digits optional integer specify number decimal places printed results rounded. unspecified, default take value object. ... arguments.","code":""},{"path":"/reference/robust.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cluster-Robust Tests and Confidence Intervals for 'rma' Objects — robust","text":"function constructs cluster-robust estimate variance-covariance matrix model coefficients based sandwich-type estimator computes tests confidence intervals model coefficients. default, tests individual coefficients confidence intervals based t-distribution \\(n-p\\) degrees freedom, omnibus test statistic uses F-distribution \\(m\\) \\(n-p\\) degrees freedom, \\(n\\) number clusters, \\(p\\) denotes total number model coefficients (including intercept present), \\(m\\) denotes number coefficients tested omnibus test. sometimes called ‘residual’ method approximating (denominator) degrees freedom. adjust=TRUE (default), cluster-robust estimate variance-covariance matrix multiplied factor \\(n/(n-p)\\), serves small-sample adjustment tends improve performance method number clusters small. sometimes called ‘CR1’ adjustment/estimator (contrast ‘CR0’ adjust=FALSE). even better small-sample adjustment, one can set clubSandwich=TRUE case clubSandwich package used obtain cluster-robust tests confidence intervals. variance-covariance matrix model coefficients estimated using ‘bias-reduced linearization’ adjustment proposed Bell McCaffrey (2002) developed Tipton (2015) Pustejovsky Tipton (2018). sometimes called ‘CR2’ adjustment/estimator. degrees freedom t-tests estimated using Satterthwaite approximation. F-tests based approximate Hotelling's T-squared reference distribution, denominator degrees freedom estimated using method Zhang (2012, 2013), described Tipton Pustejovky (2015).","code":""},{"path":"/reference/robust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cluster-Robust Tests and Confidence Intervals for 'rma' Objects — robust","text":"object class \"robust.rma\". object list containing following components: beta estimated coefficients model. se robust standard errors coefficients. zval test statistics coefficients. pval corresponding p-values. ci.lb lower bound confidence intervals coefficients. ci.ub upper bound confidence intervals coefficients. vb robust variance-covariance matrix estimated coefficients. QM test statistic omnibus test moderators. QMp corresponding p-value. ... additional elements/values. results formatted printed print.rma.uni print.rma.mv functions (depending type model).","code":""},{"path":"/reference/robust.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Cluster-Robust Tests and Confidence Intervals for 'rma' Objects — robust","text":"variable specified via cluster assumed length data originally passed rma.uni rma.mv functions. subsetting removal studies missing values applied model fitting also automatically applied variable specified via cluster argument. idea robust (sandwich-type) estimator models unspecified heteroscedasticity can traced back Eicker (1967), Huber (1967), White (1980, 1984). Hence, method general often referred Eicker-Huber-White method. small-sample improvements method described MacKinnon White (1985). extension cluster-robust estimator can found Froot (1989) Williams (2000), also related GEE approach Liang Zeger (1986). Cameron Miller (2015) provide extensive overview cluster-robust methods. Sidik Jonkman (2005, 2006) introduced robust methods meta-analytic context standard random/mixed-effects models. use cluster-robust methods multivariate/multilevel meta-analytic models introduced Hedges, Tipton, Johnson (2010).","code":""},{"path":"/reference/robust.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cluster-Robust Tests and Confidence Intervals for 'rma' Objects — robust","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/robust.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cluster-Robust Tests and Confidence Intervals for 'rma' Objects — robust","text":"Bell, R. M., & McCaffry, D. F. (2002). Bias reduction standard errors linear regression multi-stage samples. Survey Methodology, 28(2), 169--181. https://www150.statcan.gc.ca/n1/en/catalogue/12-001-X20020029058 Cameron, . C., & Miller, D. L. (2015). practitioner's guide cluster-robust inference. Journal Human Resources, 50(2), 317--372. https://doi.org/10.3368/jhr.50.2.317 Eicker, F. (1967). Limit theorems regressions unequal dependent errors. L. M. LeCam & J. Neyman (Eds.), Proceedings Fifth Berkeley Symposium Mathematical Statistics Probability (pp. 59--82). Berkeley: University California Press. Froot, K. . (1989). Consistent covariance matrix estimation cross-sectional dependence heteroskedasticity financial data. Journal Financial Quantitative Analysis, 24(3), 333--355. https://doi.org/10.2307/2330815 Hedges, L. V., Tipton, E., & Johnson, M. C. (2010). Robust variance estimation meta-regression dependent effect size estimates. Research Synthesis Methods, 1(1), 39--65. https://doi.org/10.1002/jrsm.5 Huber, P. (1967). behavior maximum-likelihood estimates nonstandard conditions. L. M. LeCam & J. Neyman (Eds.), Proceedings Fifth Berkeley Symposium Mathematical Statistics Probability (pp. 221--233). University California Press. Liang, K. Y., & Zeger, S. L. (1986). Longitudinal data analysis using generalized linear models. Biometrika, 73(1), 13--22. https://doi.org/10.1093/biomet/73.1.13 MacKinnon, J. G., & White, H. (1985). heteroskedasticity-consistent covariance matrix estimators improved finite sample properties. Journal Econometrics, 29(3), 305--325. https://doi.org/10.1016/0304-4076(85)90158-7 Tipton, E. (2015). Small sample adjustments robust variance estimation meta-regression. Psychological Methods, 20(3), 375--393. https://doi.org/10.1037/met0000011 Tipton, E., & Pustejovsky, J. E. (2015). Small-sample adjustments tests moderators model fit using robust variance estimation meta-regression. Journal Educational Behavioral Statistics, 40(6), 604--634. https://doi.org/10.3102/1076998615606099 Sidik, K., & Jonkman, J. N. (2005). note variance estimation random effects meta-regression. Journal Biopharmaceutical Statistics, 15(5), 823--838. https://doi.org/10.1081/BIP-200067915 Sidik, K., & Jonkman, J. N. (2006). Robust variance estimation random effects meta-analysis. Computational Statistics & Data Analysis, 50(12), 3681--3701. https://doi.org/10.1016/j.csda.2005.07.019 White, H. (1980). heteroskedasticity-consistent covariance matrix estimator direct test heteroskedasticity. Econometrica, 48(4), 817--838. https://doi.org/10.2307/1912934 White, H. (1984). Asymptotic theory econometricians. Orlando, FL: Academic Press. Williams, R. L. (2000). note robust variance estimation cluster-correlated data. Biometrics, 56(2), 645--646. https://doi.org/10.1111/j.0006-341x.2000.00645.x Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03 Zhang, J.-T. (2012). approximate Hotelling T2-test heteroscedastic one-way MANOVA. Open Journal Statistics, 2(1), 1--11. https://doi.org/10.4236/ojs.2012.21001 Zhang, J.-T. (2013). Tests linear hypotheses ANOVA heteroscedasticity. International Journal Advanced Statistics Probability, 1, 9--24. https://doi.org/10.14419/ijasp.v1i2.908","code":""},{"path":[]},{"path":"/reference/robust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cluster-Robust Tests and Confidence Intervals for 'rma' Objects — robust","text":"","code":"############################################################################  ### copy data from Bangert-Drowns et al. (2004) into 'dat' dat <- dat.bangertdrowns2004  ### fit random-effects model res <- rma(yi, vi, data=dat) res #>  #> Random-Effects Model (k = 48; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.0499 (SE = 0.0197) #> tau (square root of estimated tau^2 value):      0.2235 #> I^2 (total heterogeneity / total variability):   58.37% #> H^2 (total variability / sampling variability):  2.40 #>  #> Test for Heterogeneity: #> Q(df = 47) = 107.1061, p-val < .0001 #>  #> Model Results: #>  #> estimate      se    zval    pval   ci.lb   ci.ub     ​  #>   0.2219  0.0460  4.8209  <.0001  0.1317  0.3122  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### obtain results based on the sandwich method robust(res, cluster=dat$id) #>  #> Random-Effects Model (k = 48; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.0499 (SE = 0.0197) #> tau (square root of estimated tau^2 value):      0.2235 #> I^2 (total heterogeneity / total variability):   58.37% #> H^2 (total variability / sampling variability):  2.40 #>  #> Test for Heterogeneity: #> Q(df = 47) = 107.1061, p-val < .0001 #>  #> Number of estimates:   48 #> Number of clusters:    48 #> Estimates per cluster: 1 #>  #> Model Results: #>  #> estimate     se¹   tval¹  df¹   pval¹  ci.lb¹  ci.ub¹     ​  #>   0.2219  0.0460  4.8283   47  <.0001  0.1295  0.3144  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> 1) results based on cluster-robust inference (var-cov estimator: CR1, #>    approx. t-test and confidence interval, dfs = residual method) #>   ### use methods from clubSandwich package robust(res, cluster=dat$id, clubSandwich=TRUE) #>  #> Random-Effects Model (k = 48; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.0499 (SE = 0.0197) #> tau (square root of estimated tau^2 value):      0.2235 #> I^2 (total heterogeneity / total variability):   58.37% #> H^2 (total variability / sampling variability):  2.40 #>  #> Test for Heterogeneity: #> Q(df = 47) = 107.1061, p-val < .0001 #>  #> Number of estimates:   48 #> Number of clusters:    48 #> Estimates per cluster: 1 #>  #> Model Results: #>  #> estimate     se¹   tval¹    df¹   pval¹  ci.lb¹  ci.ub¹     ​  #>   0.2219  0.0460  4.8280  41.04  <.0001  0.1291  0.3148  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> 1) results based on cluster-robust inference (var-cov estimator: CR2, #>    approx. t-test and confidence interval, dfs = Satterthwaite method) #>   ### fit meta-regression model res <- rma(yi, vi, mods = ~ length, data=dat) #> Warning: Studies with NAs omitted from model fitting. res #>  #> Mixed-Effects Model (k = 46; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.0441 (SE = 0.0188) #> tau (square root of estimated tau^2 value):             0.2100 #> I^2 (residual heterogeneity / unaccounted variability): 55.26% #> H^2 (unaccounted variability / sampling variability):   2.24 #> R^2 (amount of heterogeneity accounted for):            5.08% #>  #> Test for Residual Heterogeneity: #> QE(df = 44) = 96.2810, p-val < .0001 #>  #> Test of Moderators (coefficient 2): #> QM(df = 1) = 4.2266, p-val = 0.0398 #>  #> Model Results: #>  #>          estimate      se    zval    pval    ci.lb   ci.ub   ​  #> intrcpt    0.0692  0.0825  0.8384  0.4018  -0.0925  0.2309     #> length     0.0149  0.0073  2.0559  0.0398   0.0007  0.0292  *  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### obtain results based on the sandwich method robust(res, cluster=dat$id) #>  #> Mixed-Effects Model (k = 46; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.0441 (SE = 0.0188) #> tau (square root of estimated tau^2 value):             0.2100 #> I^2 (residual heterogeneity / unaccounted variability): 55.26% #> H^2 (unaccounted variability / sampling variability):   2.24 #> R^2 (amount of heterogeneity accounted for):            5.08% #>  #> Test for Residual Heterogeneity: #> QE(df = 44) = 96.2810, p-val < .0001 #>  #> Number of estimates:   46 #> Number of clusters:    46 #> Estimates per cluster: 1 #>  #> Test of Moderators (coefficient 2):¹ #> F(df1 = 1, df2 = 44) = 6.4843, p-val = 0.0145 #>  #> Model Results: #>  #>          estimate     se¹   tval¹  df¹   pval¹   ci.lb¹  ci.ub¹   ​  #> intrcpt    0.0692  0.0651  1.0628   44  0.2937  -0.0620  0.2004     #> length     0.0149  0.0059  2.5464   44  0.0145   0.0031  0.0268  *  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> 1) results based on cluster-robust inference (var-cov estimator: CR1, #>    approx. t/F-tests and confidence intervals, dfs = residual method) #>   ### use methods from clubSandwich package robust(res, cluster=dat$id, clubSandwich=TRUE) #>  #> Mixed-Effects Model (k = 46; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.0441 (SE = 0.0188) #> tau (square root of estimated tau^2 value):             0.2100 #> I^2 (residual heterogeneity / unaccounted variability): 55.26% #> H^2 (unaccounted variability / sampling variability):   2.24 #> R^2 (amount of heterogeneity accounted for):            5.08% #>  #> Test for Residual Heterogeneity: #> QE(df = 44) = 96.2810, p-val < .0001 #>  #> Number of estimates:   46 #> Number of clusters:    46 #> Estimates per cluster: 1 #>  #> Test of Moderators (coefficient 2):¹ #> F(df1 = 1, df2 = 19.16) = 6.3961, p-val = 0.0204 #>  #> Model Results: #>  #>          estimate     se¹   tval¹    df¹   pval¹   ci.lb¹  ci.ub¹   ​  #> intrcpt    0.0692  0.0655  1.0560  16.51  0.3062  -0.0694  0.2077     #> length     0.0149  0.0059  2.5290  19.16  0.0204   0.0026  0.0273  *  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> 1) results based on cluster-robust inference (var-cov estimator: CR2, #>    approx. t/F-tests and confidence intervals, dfs = Satterthwaite method) #>   ############################################################################  ### copy data from Konstantopoulos (2011) into 'dat' dat <- dat.konstantopoulos2011  ### fit multilevel random-effects model res <- rma.mv(yi, vi, random = ~ 1 | district/school, data=dat) res #>  #> Multivariate Meta-Analysis Model (k = 56; method: REML) #>  #> Variance Components: #>  #>             estim    sqrt  nlvls  fixed           factor  #> sigma^2.1  0.0651  0.2551     11     no         district  #> sigma^2.2  0.0327  0.1809     56     no  district/school  #>  #> Test for Heterogeneity: #> Q(df = 55) = 578.8640, p-val < .0001 #>  #> Model Results: #>  #> estimate      se    zval    pval   ci.lb   ci.ub   ​  #>   0.1847  0.0846  2.1845  0.0289  0.0190  0.3504  *  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### obtain results based on the sandwich method robust(res, cluster=dat$district) #>  #> Multivariate Meta-Analysis Model (k = 56; method: REML) #>  #> Variance Components: #>  #>             estim    sqrt  nlvls  fixed           factor  #> sigma^2.1  0.0651  0.2551     11     no         district  #> sigma^2.2  0.0327  0.1809     56     no  district/school  #>  #> Test for Heterogeneity: #> Q(df = 55) = 578.8640, p-val < .0001 #>  #> Number of estimates:   56 #> Number of clusters:    11 #> Estimates per cluster: 3-11 (mean: 5.09, median: 4) #>  #> Model Results: #>  #> estimate     se¹   tval¹  df¹   pval¹   ci.lb¹  ci.ub¹   ​  #>   0.1847  0.0845  2.1859   10  0.0537  -0.0036  0.3730  .  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> 1) results based on cluster-robust inference (var-cov estimator: CR1, #>    approx. t-test and confidence interval, dfs = residual method) #>   ### use methods from clubSandwich package robust(res, cluster=dat$district, clubSandwich=TRUE) #>  #> Multivariate Meta-Analysis Model (k = 56; method: REML) #>  #> Variance Components: #>  #>             estim    sqrt  nlvls  fixed           factor  #> sigma^2.1  0.0651  0.2551     11     no         district  #> sigma^2.2  0.0327  0.1809     56     no  district/school  #>  #> Test for Heterogeneity: #> Q(df = 55) = 578.8640, p-val < .0001 #>  #> Number of estimates:   56 #> Number of clusters:    11 #> Estimates per cluster: 3-11 (mean: 5.09, median: 4) #>  #> Model Results: #>  #> estimate     se¹   tval¹   df¹   pval¹   ci.lb¹  ci.ub¹   ​  #>   0.1847  0.0845  2.1870  9.86  0.0540  -0.0038  0.3733  .  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> 1) results based on cluster-robust inference (var-cov estimator: CR2, #>    approx. t-test and confidence interval, dfs = Satterthwaite method) #>   ############################################################################  ### copy data from Berkey et al. (1998) into 'dat' dat <- dat.berkey1998  ### variables v1i and v2i correspond to the 2x2 var-cov matrices of the studies; ### so use these variables to construct the V matrix (note: since v1i and v2i are ### var-cov matrices and not correlation matrices, set vi=1 for all rows) V <- vcalc(vi=1, cluster=author, rvars=c(v1i, v2i), data=dat)  ### fit multivariate model res <- rma.mv(yi, V, mods = ~ outcome - 1, random = ~ outcome | trial, struct=\"UN\", data=dat) res #>  #> Multivariate Meta-Analysis Model (k = 10; method: REML) #>  #> Variance Components: #>  #> outer factor: trial   (nlvls = 5) #> inner factor: outcome (nlvls = 2) #>  #>             estim    sqrt  k.lvl  fixed  level  #> tau^2.1    0.0327  0.1807      5     no     AL  #> tau^2.2    0.0117  0.1083      5     no     PD  #>  #>     rho.AL  rho.PD    AL  PD  #> AL       1             -   5  #> PD  0.6088       1    no   -  #>  #> Test for Residual Heterogeneity: #> QE(df = 8) = 128.2267, p-val < .0001 #>  #> Test of Moderators (coefficients 1:2): #> QM(df = 2) = 108.8607, p-val < .0001 #>  #> Model Results: #>  #>            estimate      se     zval    pval    ci.lb    ci.ub     ​  #> outcomeAL   -0.3392  0.0879  -3.8589  0.0001  -0.5115  -0.1669  ***  #> outcomePD    0.3534  0.0588   6.0057  <.0001   0.2381   0.4688  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### obtain results based on sandwich method robust(res, cluster=dat$trial) #>  #> Multivariate Meta-Analysis Model (k = 10; method: REML) #>  #> Variance Components: #>  #> outer factor: trial   (nlvls = 5) #> inner factor: outcome (nlvls = 2) #>  #>             estim    sqrt  k.lvl  fixed  level  #> tau^2.1    0.0327  0.1807      5     no     AL  #> tau^2.2    0.0117  0.1083      5     no     PD  #>  #>     rho.AL  rho.PD    AL  PD  #> AL       1             -   5  #> PD  0.6088       1    no   -  #>  #> Test for Residual Heterogeneity: #> QE(df = 8) = 128.2267, p-val < .0001 #>  #> Number of estimates:   10 #> Number of clusters:    5 #> Estimates per cluster: 2 #>  #> Test of Moderators (coefficients 1:2):¹ #> F(df1 = 2, df2 = 3) = 41.6137, p-val = 0.0065 #>  #> Model Results: #>  #>            estimate     se¹    tval¹  df¹   pval¹   ci.lb¹   ci.ub¹   ​  #> outcomeAL   -0.3392  0.1010  -3.3597    3  0.0437  -0.6605  -0.0179  *  #> outcomePD    0.3534  0.0675   5.2338    3  0.0136   0.1385   0.5683  *  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> 1) results based on cluster-robust inference (var-cov estimator: CR1, #>    approx. t/F-tests and confidence intervals, dfs = residual method) #>   ### use methods from clubSandwich package robust(res, cluster=dat$trial, clubSandwich=TRUE) #>  #> Multivariate Meta-Analysis Model (k = 10; method: REML) #>  #> Variance Components: #>  #> outer factor: trial   (nlvls = 5) #> inner factor: outcome (nlvls = 2) #>  #>             estim    sqrt  k.lvl  fixed  level  #> tau^2.1    0.0327  0.1807      5     no     AL  #> tau^2.2    0.0117  0.1083      5     no     PD  #>  #>     rho.AL  rho.PD    AL  PD  #> AL       1             -   5  #> PD  0.6088       1    no   -  #>  #> Test for Residual Heterogeneity: #> QE(df = 8) = 128.2267, p-val < .0001 #>  #> Number of estimates:   10 #> Number of clusters:    5 #> Estimates per cluster: 2 #>  #> Test of Moderators (coefficients 1:2):¹ #> F(df1 = 2, df2 = 2.76) = 40.7910, p-val = 0.0089 #>  #> Model Results: #>  #>            estimate     se¹    tval¹   df¹   pval¹   ci.lb¹   ci.ub¹    ​  #> outcomeAL   -0.3392  0.0892  -3.8031  3.81  0.0208  -0.5919  -0.0866   *  #> outcomePD    0.3534  0.0582   6.0776  3.79  0.0044   0.1884   0.5185  **  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> 1) results based on cluster-robust inference (var-cov estimator: CR2, #>    approx. t/F-tests and confidence intervals, dfs = Satterthwaite method) #>   ############################################################################"},{"path":"/reference/selmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Selection Models — selmodel","title":"Selection Models — selmodel","text":"Function fit selection models.","code":""},{"path":"/reference/selmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Selection Models — selmodel","text":"","code":"selmodel(x, ...)  # S3 method for rma.uni selmodel(x, type, alternative=\"greater\", prec,          delta, steps, verbose=FALSE, digits, control, ...)"},{"path":"/reference/selmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Selection Models — selmodel","text":"x object class \"rma.uni\". type character string specify type selection model. Possible options \"beta\", \"halfnorm\", \"negexp\", \"logistic\", \"power\", \"negexppow\", \"stepfun\". Can abbreviated. See ‘Details’. alternative character string specify sidedness hypothesis testing observed outcomes. Possible options \"greater\" (default), \"less\", \"two.sided\". Can abbreviated. prec optional character string specify measure precision (relevant selection models can incorporate selection function). Possible options \"sei\", \"vi\", \"ninv\", \"sqrtninv\". See ‘Details’. delta optional numeric vector (length number selection model parameters) fix corresponding \\(\\delta\\) value(s). specific \\(\\delta\\) value can fixed setting corresponding element argument desired value. specific \\(\\delta\\) value estimated corresponding element set equal NA. See ‘Details’. steps numeric vector one values 0 1 can must specified certain selection functions. See ‘Details’. verbose logical specify whether output generated progress model fitting (default FALSE). Can also integer. Values > 1 generate verbose output. See ‘Note’. digits optional integer specify number decimal places printed results rounded. unspecified, default take value object. control optional list control values estimation algorithm. unspecified, default values defined inside function. See ‘Note’. ... arguments.","code":""},{"path":"/reference/selmodel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Selection Models — selmodel","text":"Selection models general class models attempt model process studies included meta-analysis may influenced form publication bias. particular selection model adequate approximation underlying selection process, model provides estimates parameters interest (e.g., average true outcome amount heterogeneity true outcomes) ‘corrected’ selection process (.e., estimates parameters population studies selection taken place). present function fits variety selection models. , one pass object fitted rma.uni function first argument. model fitted form original model combined specific selection model chosen (see possible options). example, original model random-effects model, random-effects selection model fitted. Similarly, original model included moderators, also included selection model. Model fitting done via maximum likelihood (ML) estimation fixed- random-effects parameters (e.g., \\(\\mu\\) \\(\\tau^2\\) random-effects model) selection model parameters. Argument type determines specific type selection model fitted. selection models can fitted based idea selection may haven taken place based p-values studies. particular, let \\(y_i\\) \\(v_i\\) denote observed outcome corresponding sampling variance \\(\\textrm{th}\\) study. \\(z_i = y_i / \\sqrt{v_i}\\) (Wald-type) test statistic testing null hypothesis \\(\\mbox{H}_0{:}\\; \\theta_i = 0\\) \\(p_i = 1 - \\Phi(z_i)\\) (alternative=\"greater\"), \\(p_i = \\Phi(z_i)\\) (alternative=\"less\"), \\(p_i = 2(1 - \\Phi(|z_i|))\\) (alternative=\"two.sided\") corresponding (one- two-sided) p-value, \\(\\Phi()\\) denotes cumulative distribution function standard normal distribution. Finally, let \\(w(p_i)\\) denote function specifies relative likelihood selection given p-value study. \\(w(p_i) > w(p_{'})\\) \\(p_i < p_{'}\\) (.e., \\(w(p_i)\\) larger smaller p-values), alternative=\"greater\" implies selection favor increasingly significant positive outcomes, alternative=\"less\" implies selection favor increasingly significant negative outcomes, alternative=\"two.sided\" implies selection favor increasingly significant outcomes regardless direction.","code":""},{"path":"/reference/selmodel.html","id":"beta-selection-model","dir":"Reference","previous_headings":"","what":"Beta Selection Model","title":"Selection Models — selmodel","text":"type=\"beta\", function can used fit ‘beta selection model’ Citkowicz Vevea (2017). model, selection function given \\[w(p_i) = p_i^{\\delta_1 - 1} \\times (1 - p_i)^{\\delta_2 - 1}\\] \\(\\delta_1 > 0\\) \\(\\delta_2 > 0\\). null hypothesis \\(\\mbox{H}_0{:}\\; \\delta_1 = \\delta_2 = 1\\) represents case selection (least depending p-values). figure illustrates examples relative likelihood selection can depend p-value various combinations \\(\\delta_1\\) \\(\\delta_2\\). Note model allows non-monotonic selection function.","code":""},{"path":"/reference/selmodel.html","id":"half-normal-negative-exponential-logistic-and-power-selection-models","dir":"Reference","previous_headings":"","what":"Half-Normal, Negative-Exponential, Logistic, and Power Selection Models","title":"Selection Models — selmodel","text":"Preston et al. (2004) suggested first three following selection functions:  power selection model added similar properties models suggested Preston et al. (2004). models, assume \\(\\delta \\ge 0\\), functions imply monotonically decreasing relationship p-value selection probability. functions, \\(\\mbox{H}_0{:}\\; \\delta = 0\\) implies selection. figure shows relative likelihood selection function p-value \\(\\delta = 0\\) various selection functions \\(\\delta = 6\\).  , functions extended allow possibility \\(w(p_i) = 1\\) p-values certain significance threshold denoted \\(\\alpha\\) (e.g., model case relative likelihood selection equally high significant studies decreases monotonically p-values significance threshold). fit selection model, one specify \\(\\alpha\\) value (\\(0 < \\alpha < 1\\)) via steps argument. must least one observed p-value chosen threshold fit models. figure shows examples relative likelihood selection steps=.05.  Preston et al. (2004) also suggested selection functions relatively likelihood selection depends p-value, also precision (e.g., standard error) estimate (two studies similar p-values, may plausible assume larger / precise study higher probability selection). selection functions plus corresponding power functions given :  \\(\\mathrm{prec}_i = \\sqrt{v_i}\\) (.e., standard error \\(\\textrm{th}\\) study) according Preston et al. (2004). , idea generalized allow user specify specific measure precision use (via prec argument). Possible options : prec=\"sei\" standard errors, prec=\"vi\" sampling variances, prec=\"ninv\" inverse sample sizes, prec=\"sqrtninv\" inverse square root sample sizes. Using function sample sizes measure precision possible information sample sizes actually stored within object passed selmodel function. See ‘Note’. Note \\(\\mathrm{prec}_i\\) really measure imprecision (higher values corresponding lower precision). Also, regardless specific measure chosen, values actually rescaled \\(\\mathrm{prec}_i = \\mathrm{prec}_i / \\max(\\mathrm{prec}_i)\\) inside function, \\(\\mathrm{prec}_i = 1\\) least precise study \\(\\mathrm{prec}_i < 1\\) remaining studies (rescaling actually change fit model, helps improve stability model fitting algorithm). figure shows examples relative likelihood selection using selection functions two different precision values.  One can also use steps argument described combination selection functions (studies p-values chosen threshold \\(w(p_i) = 1\\) regardless exact p-value precision).","code":""},{"path":"/reference/selmodel.html","id":"negative-exponential-power-selection-model","dir":"Reference","previous_headings":"","what":"Negative Exponential Power Selection Model","title":"Selection Models — selmodel","text":"extension half-normal negative-exponential models, one can also choose type=\"negexppow\" ‘negative exponential power selection model’. selection function given \\[w(p_i) = \\exp(-\\delta_1 \\times p_i^{1/\\delta_2})\\] \\(\\delta_1 \\ge 0\\) \\(\\delta_2 \\ge 0\\) (see Begg & Mazumdar, 1994, although different parameterization used, increasing \\(\\delta_2\\) leads severe selection). figure shows examples selection function holding \\(\\delta_1\\) constant increasing \\(\\delta_2\\).  model affords greater flexibility shape selection function, requires estimation additional power parameter (half-normal negative-exponential models therefore special cases fixing \\(\\delta_2\\) 0.5 1, respectively). \\(\\mbox{H}_0{:}\\; \\delta_1 = 0\\) implies selection, \\(\\mbox{H}_0{:}\\; \\delta_2 = 0\\). One can use steps argument specify single significance threshold, \\(\\alpha\\), \\(w(p_i) = 1\\) p-values threshold otherwise \\(w(p_i)\\) follows selection function given . One can also use prec argument specify measure precision combination model, leads selection function \\[w(p_i) = \\exp(-\\delta_1 \\times \\mathrm{prec}_i \\times p_i^{1/\\delta_2})\\] hence logical extension negative exponential power selection model also incorporates measure precision selection process.","code":""},{"path":"/reference/selmodel.html","id":"step-function-selection-models","dir":"Reference","previous_headings":"","what":"Step Function Selection Models","title":"Selection Models — selmodel","text":"type=\"stepfun\", function can used fit ‘step function models’ described Iyengar Greenhouse (1988), Hedges (1992), Vevea Hedges (1995), Vevea Woods (2005). models, one must specify one multiple values via steps argument, define intervals relative likelihood selection constant. Let \\[\\alpha_1 < \\alpha_2 < \\ldots < \\alpha_c\\] denote cutpoints sorted increasing order, constraint \\(\\alpha_c = 1\\) (highest value specified via steps 1, function automatically add cutpoint), define \\(\\alpha_0 = 0\\). selection function given \\(w(p_i) = \\delta_j\\) \\(\\alpha_{j-1} < p_i \\le \\alpha_j\\). make model identifiable, set \\(\\delta_1 = 1\\). \\(\\delta_j\\) values therefore denote likelihood selection various intervals relative interval p-values 0 \\(\\alpha_1\\). Hence, null hypothesis \\(\\mbox{H}_0{:}\\; \\delta_j = 1\\) \\(j = 1, \\ldots, c\\) implies selection. example, steps=c(.05, .10, .50, 1), \\(\\delta_2\\) likelihood selection p-values .05 .10, \\(\\delta_3\\) likelihood selection p-values .10 .50, \\(\\delta_4\\) likelihood selection p-values .50 1 relative likelihood selection p-values 0 .05. figure shows corresponding selection function arbitrarily chosen \\(\\delta_j\\) values.  must least one observed p-value within interval fit model. case, error issued (setting verbose=TRUE provides information number p-values falling interval). specifying single cutpoint context random-effects model, model sometimes called ‘three-parameter selection model’ (3PSM), corresponding parameters \\(\\mu\\), \\(\\tau^2\\), \\(\\delta_2\\) (e.g., Carter et al., 2019; McShane et al., 2016; Pustejovsky & Rodgers, 2019). idea context equal-effects model also described Iyengar Greenhouse (1988). Note alternative=\"greater\" alternative=\"less\" (.e., assume relative likelihood selection related p-values studies, also directionality outcomes), usually make sense divide conventional levels significance (e.g., .05) 2 passing values steps argument. example, think studies selected positive outcomes significant two-tailed \\(\\alpha = .05\\), use alternative=\"greater\" combination steps=c(.025, 1). One challenges fitting model many cutpoints large number parameters need estimated (especially problematic number studies small). alternative approach suggested Vevea Woods (2005) fix \\(\\delta_j\\) values priori chosen values instead estimating . One can conduct sensitivity analysis examining results (e.g., estimates \\(\\mu\\) \\(\\tau^2\\) random-effects model) variety different sets \\(\\delta_j\\) values (reflecting less severe forms selection). can done specifying \\(\\delta_j\\) values via delta argument. Table 1 Vevea Woods (2005) provides illustrative examples moderate severe selection functions one- two-tailed selection. code creates data frame contains functions.  figure shows corresponding selection functions.  four functions “merely examples regarded canonical” (Vevea & Woods, 2005).","code":"tab <- data.frame(   steps = c(0.005, 0.01, 0.05, 0.10, 0.25, 0.35, 0.50, 0.65, 0.75, 0.90, 0.95, 0.99, 0.995, 1),   delta.mod.1 = c(1, 0.99, 0.95, 0.80, 0.75, 0.65, 0.60, 0.55, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50),   delta.sev.1 = c(1, 0.99, 0.90, 0.75, 0.60, 0.50, 0.40, 0.35, 0.30, 0.25, 0.10, 0.10, 0.10, 0.10),   delta.mod.2 = c(1, 0.99, 0.95, 0.90, 0.80, 0.75, 0.60, 0.60, 0.75, 0.80, 0.90, 0.95, 0.99, 1.00),   delta.sev.2 = c(1, 0.99, 0.90, 0.75, 0.60, 0.50, 0.25, 0.25, 0.50, 0.60, 0.75, 0.90, 0.99, 1.00))"},{"path":"/reference/selmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Selection Models — selmodel","text":"object class c(\"rma.uni\",\"rma\"). object list containing components regular c(\"rma.uni\",\"rma\") object, parameter estimates based selection model. importantly, following elements modified based selection model: beta estimated coefficients model. se standard errors coefficients. zval test statistics coefficients. pval corresponding p-values. ci.lb lower bound confidence intervals coefficients. ci.ub upper bound confidence intervals coefficients. vb variance-covariance matrix estimated coefficients. tau2 estimated amount (residual) heterogeneity. Always 0 method=\"EE\". se.tau2 standard error estimated amount (residual) heterogeneity. addition, object contains following additional elements: delta estimated selection model parameter(s). se.delta corresponding standard error(s). zval.delta corresponding test statistic(s). pval.delta corresponding p-value(s). ci.lb.delta lower bound confidence intervals parameter(s). ci.ub.delta upper bound confidence intervals parameter(s). LRT test statistic likelihood ratio test selection model parameter(s). LRTdf degrees freedom likelihood ratio test. LRTp p-value likelihood ratio test. LRT.tau2 test statistic likelihood ratio test testing \\(\\mbox{H}_0{:}\\; \\tau^2 = 0\\) (NA fitting equal-effects model). LRTp.tau2 p-value likelihood ratio test. ... additional elements/values.","code":""},{"path":"/reference/selmodel.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Selection Models — selmodel","text":"results fitted model formatted printed print function. estimated selection function can drawn plot. profile function can used obtain plot log-likelihood function \\(\\tau^2\\) /selection model parameter(s) model. Corresponding confidence intervals can obtained confint function.","code":""},{"path":"/reference/selmodel.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Selection Models — selmodel","text":"Model fitting done via numerical optimization model parameters. default, optim used optimization. One can also chose different optimizer via control argument (e.g., control=list(optimizer=\"nlminb\")). using optim, one can set particular method via optmethod argument (e.g., control=list(optimizer=\"optim\", optmethod=\"BFGS\"), default). Besides optim nlminb, one can also choose one optimizers minqa package (.e., uobyqa, newuoa, bobyqa), one (derivative-free) algorithms nloptr package, Newton-type algorithm implemented nlm, various algorithms implemented dfoptim package (hjk Hooke-Jeeves, nmk Nelder-Mead, mads Mesh Adaptive Direct Searches (MADS) algorithm), quasi-Newton type optimizers ucminf lbfgsb3c subspace-searching simplex algorithm subplex packages name, Barzilai-Borwein gradient decent method implemented BBoptim, parallelized version L-BFGS-B algorithm implemented optimParallel package name. optimizer name must given character string (.e., quotes). Additional control parameters can specified via control argument (e.g., control=list(maxit=1000, reltol=1e-8)). nloptr, default use BOBYQA implementation package relative convergence criterion 1e-8 function value (.e., log-likelihood), can changed via algorithm ftop_rel arguments (e.g., control=list(optimizer=\"nloptr\", algorithm=\"NLOPT_LN_SBPLX\", ftol_rel=1e-6)). optimParallel, control argument ncpus can used specify number cores use parallelization (e.g., control=list(optimizer=\"optimParallel\", ncpus=2)). parallel::detectCores(), one can check number available cores local machine. selection models (except type=\"stepfun\") require repeated evaluations integral, done via adaptive quadrature implemented integrate function. One can adjust arguments integrate function via control element intCtrl, list named arguments (e.g., control = list(intCtrl = list(rel.tol=1e-4, subdivisions=100))). starting values fixed effects, \\(\\tau^2\\) value (relevant random/mixed-effects models), \\(\\delta\\) parameter(s) chosen automatically function, one can also set starting values manually via control argument specifying vector appropriate length beta.init, single value tau2.init, vector appropriate length delta.init. default, \\(\\delta\\) parameter(s) constrained certain range, improves stability optimization algorithm. models, maximum set 100 minimum 0 (except type=\"beta\", minimum parameters 1e-05). defaults can changed via control argument specifying vector appropriate length delta.min /delta.max. difficulty fitting beta selection model (.e., type=\"beta\") behavior \\(w(p_i)\\) \\(p_i = 0\\) \\(p_i = 1\\). \\(\\delta_1 < 1\\) \\(\\delta_2 < 1\\), leads selection weights equal infinity, causes problems computing likelihood function. Following Citkowicz Vevea (2017), problem can avoided censoring p-values close 0 1. specific censoring point can set via pval.min element control argument. default selection model control=list(pval.min=1e-5). similar issues arises power selection model (.e., type=\"power\") \\(p_i = 1\\). , pval.min=1e-5 used circumvent issue. selection models, default pval.min=0. variance-covariance matrix corresponding estimates fixed effects, \\(\\tau^2\\) value (relevant random/mixed-effects models), \\(\\delta\\) parameter(s) obtained inverting Hessian, numerically approximated using hessian function numDeriv package. may fail, leading NA values standard errors hence test statistics, p-values, confidence interval bounds. One can set control argument hessianCtrl list named arguments passed method.args argument hessian function (default control=list(hessianCtrl=list(r=6))). Information progress optimization algorithm can obtained setting verbose=TRUE (work using parallelization). option useful determine model fitting progressing. One can also set verbose integer (verbose=2 yields even information verbose=3 also show progress visually drawing selection function optimization proceeds). selection functions prec argument relevant, using (function ) sample sizes measure precision (.e., prec=\"ninv\" prec=\"sqrtninv\") possible information sample sizes actually stored within object passed selmodel function. automatically case observed effect sizes outcomes computed escalc function observed effect sizes outcomes computed within model fitting function. hand, case rma.uni used together yi vi arguments yi vi values computed escalc. case, still possible pass information sample sizes rma.uni function (e.g., use rma.uni(yi, vi, ni=ni, data=dat), data frame dat includes variable called ni sample sizes). Finally, automatic rescaling chosen precision measure can switched setting scaleprec=FALSE.","code":""},{"path":"/reference/selmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Selection Models — selmodel","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/selmodel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Selection Models — selmodel","text":"Begg, C. B., & Mazumdar, M. (1994). Operating characteristics rank correlation test publication bias. Biometrics, 50(4), 1088--1101. https://doi.org/10.2307/2533446 Carter, E. C., Schönbrodt, F. D., Gervais, W. M., & Hilgard, J. (2019). Correcting bias psychology: comparison meta-analytic methods. Advances Methods Practices Psychological Science, 2(2), 115--144. https://doi.org/10.1177/2515245919847196 Citkowicz, M., & Vevea, J. L. (2017). parsimonious weight function modeling publication bias. Psychological Methods, 22(1), 28--41. https://doi.org/10.1037/met0000119 Hedges, L. V. (1992). Modeling publication selection effects meta-analysis. Statistical Science, 7(2), 246--255. https://doi.org/10.1214/ss/1177011364 Iyengar, S., & Greenhouse, J. B. (1988). Selection models file drawer problem. Statistical Science, 3(1), 109--117. https://doi.org/10.1214/ss/1177013012 McShane, B. B., Bockenholt, U., & Hansen, K. T. (2016). Adjusting publication bias meta-analysis: evaluation selection methods cautionary notes. Perspectives Psychological Science, 11(5), 730--749. https://doi.org/10.1177/1745691616662243 Preston, C., Ashby, D., & Smyth, R. (2004). Adjusting publication bias: Modelling selection process. Journal Evaluation Clinical Practice, 10(2), 313--322. https://doi.org/10.1111/j.1365-2753.2003.00457.x Pustejovsky, J. E., & Rodgers, M. . (2019). Testing funnel plot asymmetry standardized mean differences. Research Synthesis Methods, 10(1), 57--71. https://doi.org/10.1002/jrsm.1332 Vevea, J. L., & Hedges, L. V. (1995). general linear model estimating effect size presence publication bias. Psychometrika, 60(3), 419--435. https://doi.org/10.1007/BF02294384 Vevea, J. L., & Woods, C. M. (2005). Publication bias research synthesis: Sensitivity analysis using priori weight functions. Psychological Methods, 10(4), 428--443. https://doi.org/10.1037/1082-989X.10.4.428","code":""},{"path":[]},{"path":"/reference/selmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Selection Models — selmodel","text":"","code":"############################################################################  ### example from Citkowicz and Vevea (2017) for beta selection model  # copy data into 'dat' and examine data dat <- dat.baskerville2012 dat #>              author year score design alloconc blind itt fumonths retention country outcomes duration #> 1     Kottke et al. 1992     6    cct        0     1   1       19      83.0      US        2       18 #> 2    McBride et al. 2000     6    rct        0     0   0       18     100.0      US        4       12 #> 3     Stange et al. 2000     6    rct        0     0   0       24        NA      US       35       12 #> 4       Lobo et al. 2004     6    rct        1     0   0       21      57.0      NL       16       21 #> 5  Roetzhiem et al. 2005     6   crct        0     1   0       24     100.0      US        3       24 #> 6       Hogg et al. 2008     6    cct        0     0   1        6      87.0     Can       26       12 #> 7       Aspy et al. 2008     6    cct        0     1   0       18      89.0      US        4       18 #> 8       Jaen et al. 2010     6    rct        0     1   0       26      86.0      US       11       26 #> 9   Cockburn et al. 1992     7    rct        0     0   0        3      79.0     Aus        2        2 #> 10    Modell et al. 1998     7    rct        0     0   0       12     100.0      UK        1       12 #> 11    Engels et al. 2006     7    rct        1     0   1       12      92.0      NL        7        5 #> 12      Aspy et al. 2008     7    rct        0     1   0        9     100.0      US        1        9 #> 13  Deitrich et al. 1992    18    rct        0     1   0       12      96.0      NL       16       21 #> 14      Lobo et al. 2002     8    rct        1     0   1       21     100.0      US       10        3 #> 15     Bryce et al. 1995     9    rct        1     1   1       12      93.3      US        4       12 #> 16 Kinsinger et al. 1998     9    rct        1     1   0       18      94.0      US        5       12 #> 17   Solberg et al. 1998     9    rct        1     0   1       22     100.0      US       10       22 #> 18   Lemelin et al. 2001     9    rct        1     1   0       18      98.0     Can       13       18 #> 19  Frijling et al. 2002     9   crct        1     1   1       21      95.0      NL        7       21 #> 20  Frijling et al. 2003     9   crct        1     1   1       21      95.0      NL       12       21 #> 21  Margolis et al. 2004    10    rct        1     1   1       30     100.0      US        4       24 #> 22      Mold et al. 2008    10    rct        1     1   1        6     100.0      US        6        6 #> 23      Hogg et al. 2008    12    rct        1     1   1       13     100.0     Can       53       12 #>    pperf meetings hours tailor  smd   se #> 1    5.5     30.0  1.00      1 1.01 0.52 #> 2     NA      5.0  1.00      1 0.82 0.46 #> 3   20.0      4.0  1.50      1 0.59 0.23 #> 4    5.0     15.0  1.00      1 0.44 0.18 #> 5    4.0      4.0  1.00      0 0.84 0.29 #> 6   11.0     12.0  1.50      1 0.73 0.29 #> 7    3.0      3.0  6.00      1 1.12 0.36 #> 8    6.0      4.5  6.00      1 0.04 0.37 #> 9   40.0      2.0  0.25      0 0.24 0.15 #> 10  13.0      3.0  1.00      0 0.32 0.40 #> 11    NA      5.0  1.00      1 1.04 0.32 #> 12   6.0     18.0  6.00      1 1.31 0.57 #> 13  20.0     15.0  1.00      1 0.59 0.29 #> 14   8.0      3.0  1.00      1 0.66 0.19 #> 15  12.0      1.0 15.00      0 0.62 0.31 #> 16  13.0     10.0  0.75      1 0.47 0.27 #> 17  11.0      4.0  3.00      1 1.08 0.32 #> 18   8.0     33.0  1.75      1 0.98 0.32 #> 19  20.0     15.0  1.00      0 0.26 0.18 #> 20  20.0     15.0  1.00      1 0.39 0.18 #> 21  11.0      9.0  1.00      1 0.60 0.31 #> 22   8.0     18.0  4.00      1 0.94 0.53 #> 23  14.0      9.0  0.75      1 0.11 0.27  # fit random-effects model res <- rma(smd, se^2, data=dat, method=\"ML\", digits=3) res #>  #> Random-Effects Model (k = 23; tau^2 estimator: ML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.016 (SE = 0.024) #> tau (square root of estimated tau^2 value):      0.127 #> I^2 (total heterogeneity / total variability):   18.64% #> H^2 (total variability / sampling variability):  1.23 #>  #> Test for Heterogeneity: #> Q(df = 22) = 27.552, p-val = 0.191 #>  #> Model Results: #>  #> estimate     se   zval   pval  ci.lb  ci.ub     ​  #>    0.555  0.063  8.775  <.001  0.431  0.679  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   # funnel plot funnel(res, ylim=c(0,0.6), xlab=\"Standardized Mean Difference\")   # fit beta selection model # \\dontrun{ sel <- selmodel(res, type=\"beta\") sel #>  #> Random-Effects Model (k = 23; tau^2 estimator: ML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.000 (SE = 0.001) #> tau (square root of estimated tau^2 value):      0.002 #>  #> Test for Heterogeneity: #> LRT(df = 1) = 0.009, p-val = 0.925 #>  #> Model Results: #>  #> estimate     se   zval   pval   ci.lb  ci.ub   ​  #>    0.115  0.166  0.689  0.491  -0.212  0.441     #>  #> Test for Selection Model Parameters: #> LRT(df = 2) = 7.847, p-val = 0.020 #>  #> Selection Model Results: #>  #>          estimate     se    zval   pval  ci.lb  ci.ub   ​  #> delta.1     0.473  0.235  -2.240  0.025  0.012  0.934  *  #> delta.2     4.461  2.185   1.584  0.113  0.180  8.743     #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   # plot selection function plot(sel, ylim=c(0,40))# }   # fit mixed-effects meta-regression model with 'blind' dummy variable as moderator res <- rma(smd, se^2, data=dat, mods = ~ blind, method=\"ML\", digits=3) res #>  #> Mixed-Effects Model (k = 23; tau^2 estimator: ML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.016 (SE = 0.024) #> tau (square root of estimated tau^2 value):             0.128 #> I^2 (residual heterogeneity / unaccounted variability): 18.26% #> H^2 (unaccounted variability / sampling variability):   1.22 #> R^2 (amount of heterogeneity accounted for):            0.00% #>  #> Test for Residual Heterogeneity: #> QE(df = 21) = 27.503, p-val = 0.155 #>  #> Test of Moderators (coefficient 2): #> QM(df = 1) = 0.069, p-val = 0.792 #>  #> Model Results: #>  #>          estimate     se    zval   pval   ci.lb  ci.ub     ​  #> intrcpt     0.573  0.093   6.192  <.001   0.392  0.754  ***  #> blind      -0.033  0.127  -0.263  0.792  -0.282  0.215       #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   # predicted average effect for studies that do not and that do use blinding predict(res, newmods=c(0,1)) #>  #>    pred    se ci.lb ci.ub pi.lb pi.ub  #> 1 0.573 0.093 0.392 0.754 0.264 0.882  #> 2 0.540 0.087 0.370 0.710 0.237 0.842  #>   # fit beta selection model # \\dontrun{ sel <- selmodel(res, type=\"beta\") sel #>  #> Mixed-Effects Model (k = 23; tau^2 estimator: ML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.000 (SE = 0.000) #> tau (square root of estimated tau^2 value):             0.001 #>  #> Test for Residual Heterogeneity: #> LRT(df = 1) = 0.000, p-val = 1.000 #>  #> Test of Moderators (coefficient 2): #> QM(df = 1) = 1.201, p-val = 0.273 #>  #> Model Results: #>  #>          estimate     se    zval   pval   ci.lb  ci.ub   ​  #> intrcpt     0.134  0.171   0.787  0.432  -0.200  0.469     #> blind      -0.136  0.124  -1.096  0.273  -0.380  0.108     #>  #> Test for Selection Model Parameters: #> LRT(df = 2) = 9.044, p-val = 0.011 #>  #> Selection Model Results: #>  #>          estimate     se    zval   pval  ci.lb  ci.ub   ​  #> delta.1     0.420  0.239  -2.425  0.015  0.000  0.889  *  #> delta.2     5.096  2.411   1.699  0.089  0.371  9.821  .  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  predict(sel, newmods=c(0,1))# } #>  #>     pred    se  ci.lb ci.ub  pi.lb pi.ub  #> 1  0.134 0.171 -0.200 0.469 -0.200 0.469  #> 2 -0.002 0.199 -0.392 0.388 -0.392 0.388  #>   ############################################################################  ### example from Preston et al. (2004)  # copy data into 'dat' and examine data dat <- dat.hahn2001 dat #>               study ai n1i ci n2i #> 1  Banhladesh 1995a  4  19  5  19 #> 2  Banhladesh 1996a  0  18  0  18 #> 3       CHOICE 2001 34 341 50 334 #> 4     Colombia 2000  7  71 16  69 #> 5       Egypt 1886a  6  45  5  44 #> 6       Egypt 1996b  1  94  8  96 #> 7       India 1984a  0  22  0  22 #> 8       India 2000b 11  88 12  82 #> 9      Mexico 1990a  2  82  7  84 #> 10      Panama 1982  0  33  0  30 #> 11         USA 1982  0  15  1  20 #> 12         WHO 1995 33 221 43 218  ### meta-analysis of (log) odds rations using the Mantel-Haenszel method res <- rma.mh(measure=\"OR\", ai=ai, n1i=n1i, ci=ci, n2i=n2i, data=dat, digits=2, slab=study) #> Warning: Some yi/vi values are NA. res #>  #> Equal-Effects Model (k = 12) #>  #> I^2 (total heterogeneity / total variability):  0.00% #> H^2 (total variability / sampling variability): 0.82 #>  #> Test for Heterogeneity:  #> Q(df = 8) = 6.53, p-val = 0.59 #>  #> Model Results (log scale): #>  #> estimate    se   zval  pval  ci.lb  ci.ub  #>    -0.49  0.14  -3.51  <.01  -0.77  -0.22  #>  #> Model Results (OR scale): #>  #> estimate  ci.lb  ci.ub  #>     0.61   0.46   0.80  #>  #> Cochran-Mantel-Haenszel Test:    CMH = 12.00, df = 1, p-val < 0.01 #> Tarone's Test for Heterogeneity: X^2 =  7.58, df = 8, p-val = 0.48 #>   # calculate log odds ratios and corresponding sampling variances dat <- escalc(measure=\"OR\", ai=ai, n1i=n1i, ci=ci, n2i=n2i, data=dat, drop00=TRUE) dat #>  #>               study ai n1i ci n2i      yi     vi  #> 1  Banhladesh 1995a  4  19  5  19 -0.2921 0.5881  #> 2  Banhladesh 1996a  0  18  0  18      NA     NA  #> 3       CHOICE 2001 34 341 50 334 -0.4635 0.0562  #> 4     Colombia 2000  7  71 16  69 -1.0153 0.2399  #> 5       Egypt 1886a  6  45  5  44  0.1823 0.4179  #> 6       Egypt 1996b  1  94  8  96 -2.1347 1.1471  #> 7       India 1984a  0  22  0  22      NA     NA  #> 8       India 2000b 11  88 12  82 -0.1823 0.2015  #> 9      Mexico 1990a  2  82  7  84 -1.2910 0.6683  #> 10      Panama 1982  0  33  0  30      NA     NA  #> 11         USA 1982  0  15  1  20 -0.8690 2.7825  #> 12         WHO 1995 33 221 43 218 -0.3363 0.0646  #>   # fit equal-effects model res <- rma(yi, vi, data=dat, method=\"EE\") #> Warning: Studies with NAs omitted from model fitting.  # predicted odds ratio (with 95% CI) predict(res, transf=exp, digits=2) #>  #>  pred ci.lb ci.ub  #>  0.63  0.48  0.83  #>   # funnel plot funnel(res, atransf=exp, at=log(c(0.01,0.1,1,10,100)), ylim=c(0,2))   # fit half-normal, negative-exponential, logistic, and power selection models # \\dontrun{ sel1 <- selmodel(res, type=\"halfnorm\", alternative=\"less\") sel2 <- selmodel(res, type=\"negexp\",   alternative=\"less\") sel3 <- selmodel(res, type=\"logistic\", alternative=\"less\") sel4 <- selmodel(res, type=\"power\",    alternative=\"less\")  # plot selection functions plot(sel1) plot(sel2, add=TRUE, col=\"blue\") plot(sel3, add=TRUE, col=\"red\") plot(sel4, add=TRUE, col=\"green\")   # show estimates of delta (and corresponding SEs) tab <- data.frame(delta = c(sel1$delta, sel2$delta, sel3$delta, sel4$delta),                   se    = c(sel1$se.delta, sel2$se.delta, sel3$se.delta, sel4$se.delta)) rownames(tab) <- c(\"Half-normal\", \"Negative-exponential\", \"Logistic\", \"Power\") round(tab, 2) #>                      delta   se #> Half-normal           3.16 2.99 #> Negative-exponential  2.66 2.35 #> Logistic              3.34 2.39 #> Power                 1.46 1.39  # predicted odds ratios (with 95% CI) predict(res,  transf=exp, digits=2) #>  #>  pred ci.lb ci.ub  #>  0.63  0.48  0.83  #>  predict(sel1, transf=exp, digits=2) #>  #>  pred ci.lb ci.ub  #>  0.71  0.49  1.04  #>  predict(sel2, transf=exp, digits=2) #>  #>  pred ci.lb ci.ub  #>  0.76  0.48  1.20  #>  predict(sel3, transf=exp, digits=2) #>  #>  pred ci.lb ci.ub  #>  0.74  0.49  1.13  #>  predict(sel4, transf=exp, digits=2)# } #>  #>  pred ci.lb ci.ub  #>  0.74  0.49  1.12  #>   # fit selection models including standard error as precision measure (note: using # scaleprec=FALSE here since Preston et al. (2004) did not use the rescaling) # \\dontrun{ sel1 <- selmodel(res, type=\"halfnorm\", prec=\"sei\", alternative=\"less\", scaleprec=FALSE) sel2 <- selmodel(res, type=\"negexp\",   prec=\"sei\", alternative=\"less\", scaleprec=FALSE) sel3 <- selmodel(res, type=\"logistic\", prec=\"sei\", alternative=\"less\", scaleprec=FALSE) sel4 <- selmodel(res, type=\"power\",    prec=\"sei\", alternative=\"less\", scaleprec=FALSE)  # show estimates of delta (and corresponding SEs) tab <- data.frame(delta = c(sel1$delta, sel2$delta, sel3$delta, sel4$delta),                   se    = c(sel1$se.delta, sel2$se.delta, sel3$se.delta, sel4$se.delta)) rownames(tab) <- c(\"Half-normal\", \"Negative-exponential\", \"Logistic\", \"Power\") round(tab, 2) #>                      delta   se #> Half-normal           3.51 3.39 #> Negative-exponential  2.28 2.13 #> Logistic              3.02 2.32 #> Power                 1.44 1.38  # predicted odds ratio (with 95% CI) predict(res,  transf=exp, digits=2) #>  #>  pred ci.lb ci.ub  #>  0.63  0.48  0.83  #>  predict(sel1, transf=exp, digits=2) #>  #>  pred ci.lb ci.ub  #>  0.68  0.49  0.95  #>  predict(sel2, transf=exp, digits=2) #>  #>  pred ci.lb ci.ub  #>  0.69  0.50  0.95  #>  predict(sel3, transf=exp, digits=2) #>  #>  pred ci.lb ci.ub  #>  0.68  0.50  0.93  #>  predict(sel4, transf=exp, digits=2)# } #>  #>  pred ci.lb ci.ub  #>  0.69  0.50  0.96  #>   ############################################################################  ### meta-analysis on the effect of environmental tobacco smoke on lung cancer risk  # copy data into 'dat' and examine data dat <- dat.hackshaw1998 dat #>  #>    study       author year   country       design cases   or or.lb or.ub      yi     vi  #> 1      1    Garfinkel 1981       USA       cohort   153 1.18  0.90  1.54  0.1655 0.0188  #> 2      2     Hirayama 1984     Japan       cohort   200 1.45  1.02  2.08  0.3716 0.0330  #> 3      3       Butler 1988       USA       cohort     8 2.02  0.48  8.56  0.7031 0.5402  #> 4      4     Cardenas 1997       USA       cohort   150 1.20  0.80  1.60  0.1823 0.0313  #> 5      5         Chan 1982 Hong Kong case-control    84 0.75  0.43  1.30 -0.2877 0.0797  #> 6      6       Correa 1983       USA case-control    22 2.07  0.81  5.25  0.7275 0.2273  #> 7      7 Trichopolous 1983    Greece case-control    62 2.13  1.19  3.83  0.7561 0.0889  #> 8      8      Buffler 1984       USA case-control    41 0.80  0.34  1.90 -0.2231 0.1927  #> 9      9        Kabat 1984       USA case-control    24 0.79  0.25  2.45 -0.2357 0.3390  #> 10    10          Lam 1985 Hong Kong case-control    60 2.01  1.09  3.72  0.6981 0.0981  #> 11    11    Garfinkel 1985       USA case-control   134 1.23  0.81  1.87  0.2070 0.0456  #> 12    12           Wu 1985       USA case-control    29 1.20  0.50  3.30  0.1823 0.2317  #> 13    13        Akiba 1986     Japan case-control    94 1.52  0.87  2.63  0.4187 0.0796  #> 14    14          Lee 1986        UK case-control    32 1.03  0.41  2.55  0.0296 0.2174  #> 15    15          Koo 1987 Hong Kong case-control    86 1.55  0.90  2.67  0.4383 0.0770  #> 16    16    Pershagen 1987    Sweden case-control    70 1.03  0.61  1.74  0.0296 0.0715  #> 17    17       Humble 1987       USA case-control    20 2.34  0.81  6.75  0.8502 0.2926  #> 18    18          Lam 1987 Hong Kong case-control   199 1.65  1.16  2.35  0.5008 0.0324  #> 19    19          Gao 1987     China case-control   246 1.19  0.82  1.73  0.1740 0.0363  #> 20    20     Brownson 1987       USA case-control    19 1.52  0.39  5.96  0.4187 0.4839  #> 21    21         Geng 1988     China case-control    54 2.16  1.08  4.29  0.7701 0.1238  #> 22    22      Shimizu 1988     Japan case-control    90 1.08  0.64  1.82  0.0770 0.0711  #> 23    23        Inoue 1988     Japan case-control    22 2.55  0.74  8.78  0.9361 0.3982  #> 24    24    Kalandidi 1990    Greece case-control    90 1.62  0.90  2.91  0.4824 0.0896  #> 25    25        Sobue 1990     Japan case-control   144 1.06  0.74  1.52  0.0583 0.0337  #> 26    26  Wu-Williams 1990     China case-control   417 0.79  0.62  1.02 -0.2357 0.0161  #> 27    27          Liu 1991     China case-control    54 0.74  0.32  1.69 -0.3011 0.1802  #> 28    28       Jockel 1991   Germany case-control    23 2.27  0.75  6.82  0.8198 0.3171  #> 29    29     Brownson 1992       USA case-control   431 0.97  0.78  1.21 -0.0305 0.0125  #> 30    30    Stockwell 1992       USA case-control   210 1.60  0.80  3.00  0.4700 0.1137  #> 31    31           Du 1993     China case-control    75 1.19  0.66  2.13  0.1740 0.0893  #> 32    32          Liu 1993     China case-control    38 1.66  0.73  3.78  0.5068 0.1760  #> 33    33      Fontham 1994       USA case-control   651 1.26  1.04  1.54  0.2311 0.0100  #> 34    34        Kabat 1995       USA case-control    67 1.10  0.62  1.96  0.0953 0.0862  #> 35    35      Zaridze 1995    Russia case-control   162 1.66  1.12  2.45  0.5068 0.0399  #> 36    36          Sun 1996     China case-control   230 1.16  0.80  1.69  0.1484 0.0364  #> 37    37         Wang 1996     China case-control   135 1.11  0.67  1.84  0.1044 0.0664  #>   # fit random-effects model res <- rma(yi, vi, data=dat, method=\"ML\") res #>  #> Random-Effects Model (k = 37; tau^2 estimator: ML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.0204 (SE = 0.0165) #> tau (square root of estimated tau^2 value):      0.1427 #> I^2 (total heterogeneity / total variability):   27.62% #> H^2 (total variability / sampling variability):  1.38 #>  #> Test for Heterogeneity: #> Q(df = 36) = 47.4979, p-val = 0.0952 #>  #> Model Results: #>  #> estimate      se    zval    pval   ci.lb   ci.ub     ​  #>   0.2171  0.0486  4.4712  <.0001  0.1219  0.3123  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   # funnel plot funnel(res, atransf=exp, at=log(c(0.25,0.5,1,2,4,8)), ylim=c(0,0.8))   # step function selection model # \\dontrun{ sel <- selmodel(res, type=\"stepfun\", alternative=\"greater\", steps=c(.025,.10,.50,1)) sel #>  #> Random-Effects Model (k = 37; tau^2 estimator: ML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.0096 (SE = 0.0128) #> tau (square root of estimated tau^2 value):      0.0981 #>  #> Test for Heterogeneity: #> LRT(df = 1) = 1.1374, p-val = 0.2862 #>  #> Model Results: #>  #> estimate      se    zval    pval    ci.lb   ci.ub   ​  #>   0.0020  0.0889  0.0225  0.9821  -0.1723  0.1763     #>  #> Test for Selection Model Parameters: #> LRT(df = 3) = 6.4020, p-val = 0.0936 #>  #> Selection Model Results: #>  #>                      k  estimate      se      zval    pval   ci.lb   ci.ub     ​  #> 0     < p <= 0.025   7    1.0000     ---       ---     ---     ---     ---       #> 0.025 < p <= 0.1     8    0.4946  0.3152   -1.6032  0.1089  0.0000  1.1125       #> 0.1   < p <= 0.5    16    0.2136  0.1687   -4.6613  <.0001  0.0000  0.5443  ***  #> 0.5   < p <= 1       6    0.0618  0.0689  -13.6177  <.0001  0.0000  0.1969  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   # plot selection function plot(sel)# }   ############################################################################  ### validity of student ratings example from Vevea & Woods (2005)  # copy data into 'dat' and examine data dat <- dat.cohen1981 dat[c(1,4,5)] #>                     study  ni    ri #> 1      Bolton et al. 1979  10  0.68 #> 2             Bryson 1974  20  0.56 #> 3             Centra 1977  13  0.23 #> 4             Centra 1977  22  0.64 #> 5     Crooks & Smock 1974  28  0.49 #> 6   Doyle & Crichton 1978  12 -0.04 #> 7    Doyle & Whitely 1974  12  0.49 #> 8            Elliott 1950  36  0.33 #> 9    Ellis & Rickard 1977  19  0.58 #> 10       Frey et al. 1975  12  0.18 #> 11  Greenwood et al. 1976  36 -0.11 #> 12           Hoffman 1978  75  0.27 #> 13  McKeachie et al. 1971  33  0.26 #> 14      Morsh et al. 1956 121  0.40 #> 15    Remmers et al. 1949  37  0.49 #> 16 Sullivan & Skanes 1974  14  0.51 #> 17 Sullivan & Skanes 1974  40  0.40 #> 18 Sullivan & Skanes 1974  16  0.34 #> 19 Sullivan & Skanes 1974  14  0.42 #> 20            Wherry 1952  20  0.16  # calculate r-to-z transformed correlations and corresponding sampling variances dat <- escalc(measure=\"ZCOR\", ri=ri, ni=ni, data=dat[c(1,4,5)]) dat #>  #>                     study  ni    ri      yi     vi  #> 1      Bolton et al. 1979  10  0.68  0.8291 0.1429  #> 2             Bryson 1974  20  0.56  0.6328 0.0588  #> 3             Centra 1977  13  0.23  0.2342 0.1000  #> 4             Centra 1977  22  0.64  0.7582 0.0526  #> 5     Crooks & Smock 1974  28  0.49  0.5361 0.0400  #> 6   Doyle & Crichton 1978  12 -0.04 -0.0400 0.1111  #> 7    Doyle & Whitely 1974  12  0.49  0.5361 0.1111  #> 8            Elliott 1950  36  0.33  0.3428 0.0303  #> 9    Ellis & Rickard 1977  19  0.58  0.6625 0.0625  #> 10       Frey et al. 1975  12  0.18  0.1820 0.1111  #> 11  Greenwood et al. 1976  36 -0.11 -0.1104 0.0303  #> 12           Hoffman 1978  75  0.27  0.2769 0.0139  #> 13  McKeachie et al. 1971  33  0.26  0.2661 0.0333  #> 14      Morsh et al. 1956 121  0.40  0.4236 0.0085  #> 15    Remmers et al. 1949  37  0.49  0.5361 0.0294  #> 16 Sullivan & Skanes 1974  14  0.51  0.5627 0.0909  #> 17 Sullivan & Skanes 1974  40  0.40  0.4236 0.0270  #> 18 Sullivan & Skanes 1974  16  0.34  0.3541 0.0769  #> 19 Sullivan & Skanes 1974  14  0.42  0.4477 0.0909  #> 20            Wherry 1952  20  0.16  0.1614 0.0588  #>   # fit random-effects model res <- rma(yi, vi, data=dat, method=\"ML\", digits=3) res #>  #> Random-Effects Model (k = 20; tau^2 estimator: ML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.001 (SE = 0.009) #> tau (square root of estimated tau^2 value):      0.034 #> I^2 (total heterogeneity / total variability):   2.86% #> H^2 (total variability / sampling variability):  1.03 #>  #> Test for Heterogeneity: #> Q(df = 19) = 20.974, p-val = 0.338 #>  #> Model Results: #>  #> estimate     se   zval   pval  ci.lb  ci.ub     ​  #>    0.380  0.045  8.505  <.001  0.292  0.468  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   # predicted average correlation (with 95% CI) predict(res, transf=transf.ztor) #>  #>   pred ci.lb ci.ub pi.lb pi.ub  #>  0.363 0.284 0.436 0.263 0.455  #>   # funnel plot funnel(res, ylim=c(0,0.4))   # selection functions from Vevea & Woods (2005) tab <- data.frame(    steps = c(0.005, 0.01, 0.05, 0.10, 0.25, 0.35, 0.50, 0.65, 0.75, 0.90, 0.95, 0.99, 0.995, 1),    delta.mod.1 = c(1, 0.99, 0.95, 0.80, 0.75, 0.65, 0.60, 0.55, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50),    delta.sev.1 = c(1, 0.99, 0.90, 0.75, 0.60, 0.50, 0.40, 0.35, 0.30, 0.25, 0.10, 0.10, 0.10, 0.10),    delta.mod.2 = c(1, 0.99, 0.95, 0.90, 0.80, 0.75, 0.60, 0.60, 0.75, 0.80, 0.90, 0.95, 0.99, 1.00),    delta.sev.2 = c(1, 0.99, 0.90, 0.75, 0.60, 0.50, 0.25, 0.25, 0.50, 0.60, 0.75, 0.90, 0.99, 1.00))  # apply step function model with a priori chosen selection weights # \\dontrun{ sel <- lapply(tab[-1], function(delta) selmodel(res, type=\"stepfun\", steps=tab$steps, delta=delta))  # estimates (transformed correlation) and tau^2 values sav <- data.frame(estimate = round(c(res$beta, sapply(sel, function(x) x$beta)), 2),                   varcomp  = round(c(res$tau2, sapply(sel, function(x) x$tau2)), 3)) sav# } #>             estimate varcomp #>                 0.38   0.001 #> delta.mod.1     0.35   0.005 #> delta.sev.1     0.32   0.010 #> delta.mod.2     0.36   0.003 #> delta.sev.2     0.33   0.006  ############################################################################"},{"path":"/reference/simulate.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate Method for 'rma' Objects — simulate.rma","title":"Simulate Method for 'rma' Objects — simulate.rma","text":"function simulates effect sizes outcomes based \"rma\" model object.","code":""},{"path":"/reference/simulate.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate Method for 'rma' Objects — simulate.rma","text":"","code":"# S3 method for rma simulate(object, nsim = 1, seed = NULL, olim, ...)"},{"path":"/reference/simulate.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate Method for 'rma' Objects — simulate.rma","text":"object object class \"rma\". nsim number response vectors simulate (defaults 1). seed object specify random number generator initialized (‘seeded’). Either NULL integer used call set.seed simulating response vectors. set, value saved \"seed\" attribute returned value. default, NULL change random generator state, return .Random.seed \"seed\" attribute; see ‘Value’. olim optional argument specify observation/outcome limits simulated values. unspecified, limits used. ... arguments.","code":""},{"path":"/reference/simulate.rma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate Method for 'rma' Objects — simulate.rma","text":"model specified via object must model fitted either rma.uni rma.mv function.","code":""},{"path":"/reference/simulate.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate Method for 'rma' Objects — simulate.rma","text":"data frame nsim columns simulated effect sizes outcomes.    data frame comes attribute \"seed\". argument seed NULL, attribute value .Random.seed simulation started; otherwise value seed argument \"kind\" attribute value .list(RNGkind()).","code":""},{"path":"/reference/simulate.rma.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Simulate Method for 'rma' Objects — simulate.rma","text":"outcome measure used analysis bounded (e.g., correlations bounded -1 +1, proportions bounded 0 1), one can use olim argument enforce observation/outcome limits simulating values (simulated values exceed bounds ).","code":""},{"path":"/reference/simulate.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Simulate Method for 'rma' Objects — simulate.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/simulate.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulate Method for 'rma' Objects — simulate.rma","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/simulate.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate Method for 'rma' Objects — simulate.rma","text":"","code":"### copy BCG vaccine data into 'dat' dat <- dat.bcg  ### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat) dat #>  #>    trial               author year tpos  tneg cpos  cneg ablat      alloc      yi     vi  #> 1      1              Aronson 1948    4   119   11   128    44     random -0.8893 0.3256  #> 2      2     Ferguson & Simes 1949    6   300   29   274    55     random -1.5854 0.1946  #> 3      3      Rosenthal et al 1960    3   228   11   209    42     random -1.3481 0.4154  #> 4      4    Hart & Sutherland 1977   62 13536  248 12619    52     random -1.4416 0.0200  #> 5      5 Frimodt-Moller et al 1973   33  5036   47  5761    13  alternate -0.2175 0.0512  #> 6      6      Stein & Aronson 1953  180  1361  372  1079    44  alternate -0.7861 0.0069  #> 7      7     Vandiviere et al 1973    8  2537   10   619    19     random -1.6209 0.2230  #> 8      8           TPT Madras 1980  505 87886  499 87892    13     random  0.0120 0.0040  #> 9      9     Coetzee & Berjak 1968   29  7470   45  7232    27     random -0.4694 0.0564  #> 10    10      Rosenthal et al 1961   17  1699   65  1600    42 systematic -1.3713 0.0730  #> 11    11       Comstock et al 1974  186 50448  141 27197    18 systematic -0.3394 0.0124  #> 12    12   Comstock & Webster 1969    5  2493    3  2338    33 systematic  0.4459 0.5325  #> 13    13       Comstock et al 1976   27 16886   29 17825    33 systematic -0.0173 0.0714  #>   ### fit random-effects model res <- rma(yi, vi, data=dat) res #>  #> Random-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.3132 (SE = 0.1664) #> tau (square root of estimated tau^2 value):      0.5597 #> I^2 (total heterogeneity / total variability):   92.22% #> H^2 (total variability / sampling variability):  12.86 #>  #> Test for Heterogeneity: #> Q(df = 12) = 152.2330, p-val < .0001 #>  #> Model Results: #>  #> estimate      se     zval    pval    ci.lb    ci.ub     ​  #>  -0.7145  0.1798  -3.9744  <.0001  -1.0669  -0.3622  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### simulate 5 sets of new outcomes based on the fitted model newdat <- simulate(res, nsim=5, seed=1234) newdat #>         sim_1       sim_2       sim_3      sim_4      sim_5 #> 1  -1.6793004 -0.66301253 -0.25514894 -1.0869090 -1.6008315 #> 2  -0.5168313 -0.03077959 -1.44400787  0.3184048 -1.4378126 #> 3   0.2111329 -0.80867065 -0.72745421 -1.6267122 -0.8530777 #> 4  -2.0686591 -1.00952843 -1.25483770 -1.2083181 -0.3894909 #> 5  -0.4554698 -1.26462088 -0.04907549 -0.8839444  0.2802548 #> 6  -0.4281973 -1.18821837 -0.98363103 -1.2771469 -1.1521089 #> 7  -1.1354134  1.05457927 -1.23405397 -1.4237736  0.4614723 #> 8  -1.0224006 -0.63901259 -0.99684563 -1.3381844 -1.3666211 #> 9  -1.0577254 -1.01287484 -1.70503931 -1.4757537 -0.3153193 #> 10 -1.2676951 -0.98833493 -1.44021323 -1.0400940  0.8696776 #> 11 -0.9868483 -0.45226195 -1.95859894 -0.9980659 -0.7343688 #> 12 -1.6326947 -1.35250955 -1.94777167 -2.3754422 -1.3303583 #> 13 -1.1959650 -1.61270897 -0.89705339 -1.0755358 -0.7192488"},{"path":"/reference/tes.html","id":null,"dir":"Reference","previous_headings":"","what":"Test of Excess Significance — tes","title":"Test of Excess Significance — tes","text":"Function conduct test excess significance.","code":""},{"path":"/reference/tes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test of Excess Significance — tes","text":"","code":"tes(x, vi, sei, subset, data, H0=0, alternative=\"two.sided\", alpha=.05, theta, tau2,     test, tes.alternative=\"greater\", progbar=TRUE, tes.alpha=.10, digits, ...)  # S3 method for tes print(x, digits=x$digits, ...)"},{"path":"/reference/tes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test of Excess Significance — tes","text":"arguments pertain data input: x vector observed effect sizes outcomes object class \"rma\". vi vector corresponding sampling variances (ignored x object class \"rma\"). sei vector corresponding standard errors (note: one two, vi sei, needs specified). subset optional (logical numeric) vector specify subset studies included (ignored x object class \"rma\"). data optional data frame containing variables given arguments . arguments pertain tests observed effect sizes outcomes: H0 numeric value specify value effect size outcome null hypothesis (default 0). alternative character string specify sidedness hypothesis testing observed effect sizes outcomes. Possible options \"two.sided\" (default), \"greater\", \"less\". Can abbreviated. alpha alpha level testing observed effect sizes outcomes (default .05). arguments pertain power tests: theta optional numeric value specify value true effect size outcome alternative hypothesis. unspecified, estimated based data value taken \"rma\" object. tau2 optional numeric value specify amount heterogeneity true effect sizes outcomes. unspecified, true effect sizes outcomes assumed homogeneous value taken \"rma\" object. arguments pertain test excess significance: test optional character string specify type test use conducting test excess significance. Possible options \"chi2\", \"binom\", \"exact\". Can abbreviated. unspecified, function chooses type test based data. tes.alternative character string specify sidedness hypothesis test excess significance. Possible options \"greater\" (default), \"two.sided\", \"less\". Can abbreviated. progbar logical specify whether progress bar shown (default TRUE). relevant conducting exact test. tes.alpha alpha level test excess significance (default .10). relevant finding ‘limit estimate’. Miscellaneous arguments: digits optional integer specify number decimal places printed results rounded. ... arguments.","code":""},{"path":"/reference/tes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test of Excess Significance — tes","text":"function carries test excess significance described Ioannidis Trikalinos (2007). test can used examine whether observed number significant findings greater number significant findings expected given power tests. overabundance significant tests may suggest collection studies representative studies conducted particular topic. One can either pass vector observed effect sizes outcomes (via x) corresponding sampling variances via vi (standard errors via sei) function object class \"rma\". observed effect sizes outcomes tested significance based standard Wald-type test, , comparing \\[z_i = \\frac{y_i - \\mbox{H}_0}{\\sqrt{v_i}}\\] appropriate critical value(s) standard normal distribution (e.g., \\(\\pm 1.96\\) alternative=\"two.sided\" alpha=.05, defaults). Let \\(O\\) denote observed number significant tests. Given particular value true effect outcome denoted \\(\\theta\\) (, unspecified, determined computing inverse-variance weighted average observed effect sizes outcomes value taken model object), let \\(1-\\beta_i\\) denote power \\(\\textrm{th}\\) test (\\(\\beta_i\\) denotes Type II error probability). \\(\\tau^2 > 0\\), let \\(1-\\beta_i\\) denote expected power (computed based integrating power normal distribution mean \\(\\theta\\) variance \\(\\tau^2\\)). Let \\(E = \\sum_{=1}^k (1-\\beta_i)\\) denote expected number significant tests. test excess significance tests \\(O\\) significantly greater (tes.alternative=\"greater\") \\(E\\). can done using Pearson's chi-squared test (test=\"chi2\"), binomial test (test=\"binomial\"), exact test (test=\"exact\"). latter described Francis (2013). argument test unspecified, default exact test number elements sum needs computed less equal 10^6 chi-square test otherwise. One can also iteratively find value \\(\\theta\\) p-value test excess significance equal tes.alpha (.10 default). resulting value called ‘limit estimate’ denoted \\(\\theta_{lim}\\) Ioannidis Trikalinos (2007). Note limit estimate computable p-value larger tes.alpha even \\(\\theta = \\mbox{H}_0\\).","code":""},{"path":"/reference/tes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test of Excess Significance — tes","text":"object class \"tes\". object list containing following components: k number studies included analysis. O observed number significant tests. E expected number significant tests. OEratio ratio O E. test type test conducted. pval p-value test excess significance. power (estimated) power tests. sig logical vector indicating tests significant. theta value \\(\\theta\\) used computing power tests. theta.lim ‘limit estimate’ (.e., \\(\\theta_{lim}\\)). ... additional elements/values. results formatted printed print function.","code":""},{"path":"/reference/tes.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Test of Excess Significance — tes","text":"tes.alternative=\"greater\" (default), function tests \\(O\\) significantly greater \\(E\\) hence indeed test excess significance. tes.alternative=\"two.sided\", function tests \\(O\\) differs significantly \\(E\\) either direction hence apt describe test ()consistency (\\(O\\) \\(E\\)). Finally, one can also set tes.alternative=\"less\", case function tests \\(O\\) significantly lower \\(E\\), considered test excess non-significance. tes.alternative=\"two.sided\", one can actually compute two limit estimates. function attempts compute . function computes significance power studies based Wald-type tests regardless effect size outcome measure used input. works adequate approximation long within-study sample sizes small. Note test test publication bias test whether set studies includes unusual number significant findings given power studies. general usefulness test usefulness particular circumstances (e.g., substantial heterogeneity true effect sizes outcomes) subject considerable debate. See Francis (2013) commentaries article issue journal.","code":""},{"path":"/reference/tes.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Test of Excess Significance — tes","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/tes.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Test of Excess Significance — tes","text":"Francis, G. (2013). Replication, statistical consistency, publication bias. Journal Mathematical Psychology, 57(5), 153--169. https://doi.org/10.1016/j.jmp.2013.02.003 Ioannidis, J. P. ., & Trikalinos, T. . (2007). exploratory test excess significant findings. Clinical Trials, 4(3), 245--253. https://doi.org/10.1177/1740774507079441 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/tes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test of Excess Significance — tes","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=x.a, n1i=n.a, ci=x.p, n2i=n.p, data=dat.dorn2007)  ### conduct test of excess significance (using test=\"chi2\" to speed things up) tes(yi, vi, data=dat, test=\"chi2\") #>  #> Test of Excess Significance #>  #> Observed Number of Significant Findings: 10 (out of 19) #> Expected Number of Significant Findings: 4.9233 #> Observed Number / Expected Number:       2.0311 #>  #> Estimated Power of Tests (based on theta = 0.3123) #>  #>    min      q1  median      q3     max  #> 0.0894  0.1270  0.2118  0.3537  0.5397  #>  #> Test of Excess Significance: p = 0.0039 (X^2 = 7.0656, df = 1) #> Limit Estimate (theta_lim):  0.4062 (where p = 0.1) #>   ### same as fitting an EE model and then passing the object to the function res <- rma(yi, vi, data=dat, method=\"EE\") tes(res, test=\"chi2\") #>  #> Test of Excess Significance #>  #> Observed Number of Significant Findings: 10 (out of 19) #> Expected Number of Significant Findings: 4.9233 #> Observed Number / Expected Number:       2.0311 #>  #> Estimated Power of Tests (based on theta = 0.3123) #>  #>    min      q1  median      q3     max  #> 0.0894  0.1270  0.2118  0.3537  0.5397  #>  #> Test of Excess Significance: p = 0.0039 (X^2 = 7.0656, df = 1) #> Limit Estimate (theta_lim):  0.4062 (where p = 0.1) #>   ### illustrate limit estimate (value of theta where p-value of test is equal to tes.alpha) thetas <- seq(0,1,length=101) pvals <- sapply(thetas, function(theta) tes(yi, vi, data=dat, test=\"chi2\", theta=theta)$pval) plot(thetas, pvals, type=\"o\", pch=19, ylim=c(0,1)) sav <- tes(yi, vi, data=dat, test=\"chi2\") abline(h=sav$tes.alpha, lty=\"dotted\") abline(v=sav$theta.lim, lty=\"dotted\")   ### examine significance of test as a function of alpha (to examine 'significance chasing') alphas <- seq(.01,.99,length=101) pvals <- sapply(alphas, function(alpha) tes(yi, vi, data=dat, test=\"chi2\", alpha=alpha)$pval) plot(alphas, pvals, type=\"o\", pch=19, ylim=c(0,1)) abline(v=.05, lty=\"dotted\") abline(h=.10, lty=\"dotted\")"},{"path":"/reference/to.long.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Data from Vector to Long Format — to.long","title":"Convert Data from Vector to Long Format — to.long","text":"function converts summary data vector format corresponding long format.","code":""},{"path":"/reference/to.long.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Data from Vector to Long Format — to.long","text":"","code":"to.long(measure, ai, bi, ci, di, n1i, n2i, x1i, x2i, t1i, t2i,         m1i, m2i, sd1i, sd2i, xi, mi, ri, ti, sdi, ni, data, slab, subset,         add=1/2, to=\"none\", drop00=FALSE, vlong=FALSE, append=TRUE, var.names)"},{"path":"/reference/to.long.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Data from Vector to Long Format — to.long","text":"measure character string specify effect size outcome measure corresponding summary data supplied. See ‘Details’ documentation escalc function possible options. ai vector specify \\(2 \\times 2\\) table frequencies (upper left cell). bi vector specify \\(2 \\times 2\\) table frequencies (upper right cell). ci vector specify \\(2 \\times 2\\) table frequencies (lower left cell). di vector specify \\(2 \\times 2\\) table frequencies (lower right cell). n1i vector specify group sizes row totals (first group/row). n2i vector specify group sizes row totals (second group/row). x1i vector specify number events (first group). x2i vector specify number events (second group). t1i vector specify total person-times (first group). t2i vector specify total person-times (second group). m1i vector specify means (first group time point). m2i vector specify means (second group time point). sd1i vector specify standard deviations (first group time point). sd2i vector specify standard deviations (second group time point). xi vector specify frequencies event interest. mi vector specify frequencies complement event interest group means. ri vector specify raw correlation coefficients. ti vector specify total person-times. sdi vector specify standard deviations. ni vector specify sample/group sizes. data optional data frame containing variables given arguments . slab optional vector labels studies. subset optional (logical numeric) vector specify subset studies included data frame returned function. add see documentation escalc function. see documentation escalc function. drop00 see documentation escalc function. vlong optional logical whether long format used (relevant \\(2 \\times 2\\) \\(1 \\times 2\\) table data). append logical specify whether data frame specified via data argument (one specified) returned together long format data (default TRUE). var.names optional vector variable names (length depends data type). unspecified, function sets appropriate variable names default.","code":""},{"path":"/reference/to.long.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert Data from Vector to Long Format — to.long","text":"escalc function describes wide variety effect size outcome measures can computed meta-analysis. summary data used compute measures typically contained vectors, element corresponding study. .long function takes information constructs long format dataset data. example, various fields (health medical sciences), response variable measured often dichotomous (binary), data study comparing two different groups can expressed terms \\(2 \\times 2\\) table, : ai, bi, ci, di denote cell frequencies (.e., number people falling particular category) n1i n2i row totals (.e., group sizes). cell frequencies \\(k\\) \\(2 \\times 2\\) tables can specified via ai, bi, ci, di arguments (alternatively, via ai, ci, n1i, n2i arguments). function creates corresponding long format dataset. measure argument set equal one outcome measures can computed based type data, \"RR\", \"\", \"RD\" (relevant specific measure chosen, long corresponds specified summary data). See documentation escalc function details types data formats available. long format data type consists two rows per study, factor indicating study (default name study), dummy variable indicating group (default name group, coded 1 2), two variables indicating number individuals experiencing outcome 1 outcome 2 (default names out1 out2). Alternatively, vlong=TRUE, long format consists four rows per study, factor indicating study (default name study), dummy variable indicating group (default name group, coded 1 2), dummy variable indicating outcome (default name outcome, coded 1 2), variable indicating frequency respective outcome (default name freq). default variable names can changed via var.names argument (must appropriate length, depending data type). examples illustrate use function.","code":""},{"path":"/reference/to.long.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Data from Vector to Long Format — to.long","text":"data frame either \\(k\\), \\(2 \\times k\\), \\(4 \\times k\\) rows appropriate number columns (depending data type) data long format. append=TRUE data frame specified via data argument, data long format appended original data frame (rows repeated appropriate number times).","code":""},{"path":"/reference/to.long.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert Data from Vector to Long Format — to.long","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/to.long.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Convert Data from Vector to Long Format — to.long","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/to.long.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Data from Vector to Long Format — to.long","text":"","code":"### convert data to long format dat <- to.long(measure=\"OR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg) dat #>    trial               author year tpos  tneg cpos  cneg ablat      alloc study group out1  out2 #> 1      1              Aronson 1948    4   119   11   128    44     random     1     1    4   119 #> 2      1              Aronson 1948    4   119   11   128    44     random     1     2   11   128 #> 3      2     Ferguson & Simes 1949    6   300   29   274    55     random     2     1    6   300 #> 4      2     Ferguson & Simes 1949    6   300   29   274    55     random     2     2   29   274 #> 5      3      Rosenthal et al 1960    3   228   11   209    42     random     3     1    3   228 #> 6      3      Rosenthal et al 1960    3   228   11   209    42     random     3     2   11   209 #> 7      4    Hart & Sutherland 1977   62 13536  248 12619    52     random     4     1   62 13536 #> 8      4    Hart & Sutherland 1977   62 13536  248 12619    52     random     4     2  248 12619 #> 9      5 Frimodt-Moller et al 1973   33  5036   47  5761    13  alternate     5     1   33  5036 #> 10     5 Frimodt-Moller et al 1973   33  5036   47  5761    13  alternate     5     2   47  5761 #> 11     6      Stein & Aronson 1953  180  1361  372  1079    44  alternate     6     1  180  1361 #> 12     6      Stein & Aronson 1953  180  1361  372  1079    44  alternate     6     2  372  1079 #> 13     7     Vandiviere et al 1973    8  2537   10   619    19     random     7     1    8  2537 #> 14     7     Vandiviere et al 1973    8  2537   10   619    19     random     7     2   10   619 #> 15     8           TPT Madras 1980  505 87886  499 87892    13     random     8     1  505 87886 #> 16     8           TPT Madras 1980  505 87886  499 87892    13     random     8     2  499 87892 #> 17     9     Coetzee & Berjak 1968   29  7470   45  7232    27     random     9     1   29  7470 #> 18     9     Coetzee & Berjak 1968   29  7470   45  7232    27     random     9     2   45  7232 #> 19    10      Rosenthal et al 1961   17  1699   65  1600    42 systematic    10     1   17  1699 #> 20    10      Rosenthal et al 1961   17  1699   65  1600    42 systematic    10     2   65  1600 #> 21    11       Comstock et al 1974  186 50448  141 27197    18 systematic    11     1  186 50448 #> 22    11       Comstock et al 1974  186 50448  141 27197    18 systematic    11     2  141 27197 #> 23    12   Comstock & Webster 1969    5  2493    3  2338    33 systematic    12     1    5  2493 #> 24    12   Comstock & Webster 1969    5  2493    3  2338    33 systematic    12     2    3  2338 #> 25    13       Comstock et al 1976   27 16886   29 17825    33 systematic    13     1   27 16886 #> 26    13       Comstock et al 1976   27 16886   29 17825    33 systematic    13     2   29 17825  ### extra long format dat <- to.long(measure=\"OR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg, vlong=TRUE) dat #>    trial               author year tpos  tneg cpos  cneg ablat      alloc study group outcome  freq #> 1      1              Aronson 1948    4   119   11   128    44     random     1     1       1     4 #> 2      1              Aronson 1948    4   119   11   128    44     random     1     1       2   119 #> 3      1              Aronson 1948    4   119   11   128    44     random     1     2       1    11 #> 4      1              Aronson 1948    4   119   11   128    44     random     1     2       2   128 #> 5      2     Ferguson & Simes 1949    6   300   29   274    55     random     2     1       1     6 #> 6      2     Ferguson & Simes 1949    6   300   29   274    55     random     2     1       2   300 #> 7      2     Ferguson & Simes 1949    6   300   29   274    55     random     2     2       1    29 #> 8      2     Ferguson & Simes 1949    6   300   29   274    55     random     2     2       2   274 #> 9      3      Rosenthal et al 1960    3   228   11   209    42     random     3     1       1     3 #> 10     3      Rosenthal et al 1960    3   228   11   209    42     random     3     1       2   228 #> 11     3      Rosenthal et al 1960    3   228   11   209    42     random     3     2       1    11 #> 12     3      Rosenthal et al 1960    3   228   11   209    42     random     3     2       2   209 #> 13     4    Hart & Sutherland 1977   62 13536  248 12619    52     random     4     1       1    62 #> 14     4    Hart & Sutherland 1977   62 13536  248 12619    52     random     4     1       2 13536 #> 15     4    Hart & Sutherland 1977   62 13536  248 12619    52     random     4     2       1   248 #> 16     4    Hart & Sutherland 1977   62 13536  248 12619    52     random     4     2       2 12619 #> 17     5 Frimodt-Moller et al 1973   33  5036   47  5761    13  alternate     5     1       1    33 #> 18     5 Frimodt-Moller et al 1973   33  5036   47  5761    13  alternate     5     1       2  5036 #> 19     5 Frimodt-Moller et al 1973   33  5036   47  5761    13  alternate     5     2       1    47 #> 20     5 Frimodt-Moller et al 1973   33  5036   47  5761    13  alternate     5     2       2  5761 #> 21     6      Stein & Aronson 1953  180  1361  372  1079    44  alternate     6     1       1   180 #> 22     6      Stein & Aronson 1953  180  1361  372  1079    44  alternate     6     1       2  1361 #> 23     6      Stein & Aronson 1953  180  1361  372  1079    44  alternate     6     2       1   372 #> 24     6      Stein & Aronson 1953  180  1361  372  1079    44  alternate     6     2       2  1079 #> 25     7     Vandiviere et al 1973    8  2537   10   619    19     random     7     1       1     8 #> 26     7     Vandiviere et al 1973    8  2537   10   619    19     random     7     1       2  2537 #> 27     7     Vandiviere et al 1973    8  2537   10   619    19     random     7     2       1    10 #> 28     7     Vandiviere et al 1973    8  2537   10   619    19     random     7     2       2   619 #> 29     8           TPT Madras 1980  505 87886  499 87892    13     random     8     1       1   505 #> 30     8           TPT Madras 1980  505 87886  499 87892    13     random     8     1       2 87886 #> 31     8           TPT Madras 1980  505 87886  499 87892    13     random     8     2       1   499 #> 32     8           TPT Madras 1980  505 87886  499 87892    13     random     8     2       2 87892 #> 33     9     Coetzee & Berjak 1968   29  7470   45  7232    27     random     9     1       1    29 #> 34     9     Coetzee & Berjak 1968   29  7470   45  7232    27     random     9     1       2  7470 #> 35     9     Coetzee & Berjak 1968   29  7470   45  7232    27     random     9     2       1    45 #> 36     9     Coetzee & Berjak 1968   29  7470   45  7232    27     random     9     2       2  7232 #> 37    10      Rosenthal et al 1961   17  1699   65  1600    42 systematic    10     1       1    17 #> 38    10      Rosenthal et al 1961   17  1699   65  1600    42 systematic    10     1       2  1699 #> 39    10      Rosenthal et al 1961   17  1699   65  1600    42 systematic    10     2       1    65 #> 40    10      Rosenthal et al 1961   17  1699   65  1600    42 systematic    10     2       2  1600 #> 41    11       Comstock et al 1974  186 50448  141 27197    18 systematic    11     1       1   186 #> 42    11       Comstock et al 1974  186 50448  141 27197    18 systematic    11     1       2 50448 #> 43    11       Comstock et al 1974  186 50448  141 27197    18 systematic    11     2       1   141 #> 44    11       Comstock et al 1974  186 50448  141 27197    18 systematic    11     2       2 27197 #> 45    12   Comstock & Webster 1969    5  2493    3  2338    33 systematic    12     1       1     5 #> 46    12   Comstock & Webster 1969    5  2493    3  2338    33 systematic    12     1       2  2493 #> 47    12   Comstock & Webster 1969    5  2493    3  2338    33 systematic    12     2       1     3 #> 48    12   Comstock & Webster 1969    5  2493    3  2338    33 systematic    12     2       2  2338 #> 49    13       Comstock et al 1976   27 16886   29 17825    33 systematic    13     1       1    27 #> 50    13       Comstock et al 1976   27 16886   29 17825    33 systematic    13     1       2 16886 #> 51    13       Comstock et al 1976   27 16886   29 17825    33 systematic    13     2       1    29 #> 52    13       Comstock et al 1976   27 16886   29 17825    33 systematic    13     2       2 17825  ### convert data to long format dat <- to.long(measure=\"IRR\", x1i=x1i, x2i=x2i, t1i=t1i, t2i=t2i,                data=dat.hart1999, var.names=c(\"id\", \"group\", \"events\", \"ptime\")) dat #>    trial  study year x1i n1i t1i x2i n2i t2i compgrp  prevtype   trinr id group events ptime #> 1      1 AFASAK 1989   9 335 413  19 336 398 placebo   primary 2.8-4.2  1     1      9   413 #> 2      1 AFASAK 1989   9 335 413  19 336 398 placebo   primary 2.8-4.2  1     2     19   398 #> 3      2   SPAF 1991   8 210 263  19 211 245 placebo   primary 2.0-4.5  2     1      8   263 #> 4      2   SPAF 1991   8 210 263  19 211 245 placebo   primary 2.0-4.5  2     2     19   245 #> 5      3 BAATAF 1990   3 212 487  13 208 435 control   primary 1.5-2.7  3     1      3   487 #> 6      3 BAATAF 1990   3 212 487  13 208 435 control   primary 1.5-2.7  3     2     13   435 #> 7      4   CAFA 1991   6 187 237   9 191 241 placebo   primary 2.0-3.0  4     1      6   237 #> 8      4   CAFA 1991   6 187 237   9 191 241 placebo   primary 2.0-3.0  4     2      9   241 #> 9      5 SPINAF 1992   7 281 489  23 290 483 placebo   primary 1.4-2.8  5     1      7   489 #> 10     5 SPINAF 1992   7 281 489  23 290 483 placebo   primary 1.4-2.8  5     2     23   483 #> 11     6   EAFT 1993  20 225 507  50 214 405 placebo secondary 2.5-4.0  6     1     20   507 #> 12     6   EAFT 1993  20 225 507  50 214 405 placebo secondary 2.5-4.0  6     2     50   405  ### convert data to long format dat <- to.long(measure=\"MD\", m1i=m1i, sd1i=sd1i, n1i=n1i,                m2i=m2i, sd2i=sd2i, n2i=n2i, data=dat.normand1999,                var.names=c(\"id\", \"group\", \"mean\", \"sd\", \"n\")) dat #>    study             source n1i m1i sd1i n2i m2i sd2i id group mean sd   n #> 1      1          Edinburgh 155  55   47 156  75   64  1     1   55 47 155 #> 2      1          Edinburgh 155  55   47 156  75   64  1     2   75 64 156 #> 3      2     Orpington-Mild  31  27    7  32  29    4  2     1   27  7  31 #> 4      2     Orpington-Mild  31  27    7  32  29    4  2     2   29  4  32 #> 5      3 Orpington-Moderate  75  64   17  71 119   29  3     1   64 17  75 #> 6      3 Orpington-Moderate  75  64   17  71 119   29  3     2  119 29  71 #> 7      4   Orpington-Severe  18  66   20  18 137   48  4     1   66 20  18 #> 8      4   Orpington-Severe  18  66   20  18 137   48  4     2  137 48  18 #> 9      5      Montreal-Home   8  14    8  13  18   11  5     1   14  8   8 #> 10     5      Montreal-Home   8  14    8  13  18   11  5     2   18 11  13 #> 11     6  Montreal-Transfer  57  19    7  52  18    4  6     1   19  7  57 #> 12     6  Montreal-Transfer  57  19    7  52  18    4  6     2   18  4  52 #> 13     7          Newcastle  34  52   45  33  41   34  7     1   52 45  34 #> 14     7          Newcastle  34  52   45  33  41   34  7     2   41 34  33 #> 15     8               Umea 110  21   16 183  31   27  8     1   21 16 110 #> 16     8               Umea 110  21   16 183  31   27  8     2   31 27 183 #> 17     9            Uppsala  60  30   27  52  23   20  9     1   30 27  60 #> 18     9            Uppsala  60  30   27  52  23   20  9     2   23 20  52"},{"path":"/reference/to.table.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Data from Vector to Table Format — to.table","title":"Convert Data from Vector to Table Format — to.table","text":"function converts summary data vector format corresponding table format.","code":""},{"path":"/reference/to.table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Data from Vector to Table Format — to.table","text":"","code":"to.table(measure, ai, bi, ci, di, n1i, n2i, x1i, x2i, t1i, t2i,          m1i, m2i, sd1i, sd2i, xi, mi, ri, ti, sdi, ni, data, slab, subset,          add=1/2, to=\"none\", drop00=FALSE, rows, cols)"},{"path":"/reference/to.table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Data from Vector to Table Format — to.table","text":"measure character string specify effect size outcome measure corresponding summary data supplied. See ‘Details’ documentation escalc function possible options. ai vector specify \\(2 \\times 2\\) table frequencies (upper left cell). bi vector specify \\(2 \\times 2\\) table frequencies (upper right cell). ci vector specify \\(2 \\times 2\\) table frequencies (lower left cell). di vector specify \\(2 \\times 2\\) table frequencies (lower right cell). n1i vector specify group sizes row totals (first group/row). n2i vector specify group sizes row totals (second group/row). x1i vector specify number events (first group). x2i vector specify number events (second group). t1i vector specify total person-times (first group). t2i vector specify total person-times (second group). m1i vector specify means (first group time point). m2i vector specify means (second group time point). sd1i vector specify standard deviations (first group time point). sd2i vector specify standard deviations (second group time point). xi vector specify frequencies event interest. mi vector specify frequencies complement event interest group means. ri vector specify raw correlation coefficients. ti vector specify total person-times. sdi vector specify standard deviations. ni vector specify sample/group sizes. data optional data frame containing variables given arguments . slab optional vector labels studies. subset optional (logical numeric) vector specify subset studies included array returned function. add see documentation escalc function. see documentation escalc function. drop00 see documentation escalc function. rows optional vector row/group names. cols optional vector column/outcome names.","code":""},{"path":"/reference/to.table.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert Data from Vector to Table Format — to.table","text":"escalc function describes wide variety effect size outcome measures can computed meta-analysis. summary data used compute measures typically contained vectors, element corresponding study. .table function takes information constructs array \\(k\\) tables data. example, various fields (health medical sciences), response variable measured often dichotomous (binary), data study comparing two different groups can expressed terms \\(2 \\times 2\\) table, : ai, bi, ci, di denote cell frequencies (.e., number people falling particular category) n1i n2i row totals (.e., group sizes). cell frequencies \\(k\\) \\(2 \\times 2\\) tables can specified via ai, bi, ci, di arguments (alternatively, via ai, ci, n1i, n2i arguments). function creates corresponding \\(2 \\times 2 \\times k\\) array tables. measure argument set equal one outcome measures can computed based type data, \"RR\", \"\", \"RD\" (relevant specific measure chosen, long corresponds specified summary data). See documentation escalc function details types data formats available. examples illustrate use function.","code":""},{"path":"/reference/to.table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Data from Vector to Table Format — to.table","text":"array \\(k\\) elements consisting either 1 2 rows appropriate number columns.","code":""},{"path":"/reference/to.table.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert Data from Vector to Table Format — to.table","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/to.table.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Convert Data from Vector to Table Format — to.table","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/to.table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Data from Vector to Table Format — to.table","text":"","code":"### create tables dat <- to.table(measure=\"OR\", ai=tpos, bi=tneg, ci=cpos, di=cneg,                 data=dat.bcg, slab=paste(author, year, sep=\", \"),                 rows=c(\"Vaccinated\", \"Not Vaccinated\"), cols=c(\"TB+\", \"TB-\")) dat #> , , Aronson, 1948 #>  #>                TB+ TB- #> Vaccinated       4 119 #> Not Vaccinated  11 128 #>  #> , , Ferguson & Simes, 1949 #>  #>                TB+ TB- #> Vaccinated       6 300 #> Not Vaccinated  29 274 #>  #> , , Rosenthal et al, 1960 #>  #>                TB+ TB- #> Vaccinated       3 228 #> Not Vaccinated  11 209 #>  #> , , Hart & Sutherland, 1977 #>  #>                TB+   TB- #> Vaccinated      62 13536 #> Not Vaccinated 248 12619 #>  #> , , Frimodt-Moller et al, 1973 #>  #>                TB+  TB- #> Vaccinated      33 5036 #> Not Vaccinated  47 5761 #>  #> , , Stein & Aronson, 1953 #>  #>                TB+  TB- #> Vaccinated     180 1361 #> Not Vaccinated 372 1079 #>  #> , , Vandiviere et al, 1973 #>  #>                TB+  TB- #> Vaccinated       8 2537 #> Not Vaccinated  10  619 #>  #> , , TPT Madras, 1980 #>  #>                TB+   TB- #> Vaccinated     505 87886 #> Not Vaccinated 499 87892 #>  #> , , Coetzee & Berjak, 1968 #>  #>                TB+  TB- #> Vaccinated      29 7470 #> Not Vaccinated  45 7232 #>  #> , , Rosenthal et al, 1961 #>  #>                TB+  TB- #> Vaccinated      17 1699 #> Not Vaccinated  65 1600 #>  #> , , Comstock et al, 1974 #>  #>                TB+   TB- #> Vaccinated     186 50448 #> Not Vaccinated 141 27197 #>  #> , , Comstock & Webster, 1969 #>  #>                TB+  TB- #> Vaccinated       5 2493 #> Not Vaccinated   3 2338 #>  #> , , Comstock et al, 1976 #>  #>                TB+   TB- #> Vaccinated      27 16886 #> Not Vaccinated  29 17825 #>   ### create tables dat <- to.table(measure=\"IRR\", x1i=x1i, x2i=x2i, t1i=t1i, t2i=t2i,                 data=dat.hart1999, slab=paste(study, year, sep=\", \"),                 rows=c(\"Warfarin Group\", \"Placebo/Control Group\")) dat #> , , AFASAK, 1989 #>  #>                       Events Person-Time #> Warfarin Group             9         413 #> Placebo/Control Group     19         398 #>  #> , , SPAF, 1991 #>  #>                       Events Person-Time #> Warfarin Group             8         263 #> Placebo/Control Group     19         245 #>  #> , , BAATAF, 1990 #>  #>                       Events Person-Time #> Warfarin Group             3         487 #> Placebo/Control Group     13         435 #>  #> , , CAFA, 1991 #>  #>                       Events Person-Time #> Warfarin Group             6         237 #> Placebo/Control Group      9         241 #>  #> , , SPINAF, 1992 #>  #>                       Events Person-Time #> Warfarin Group             7         489 #> Placebo/Control Group     23         483 #>  #> , , EAFT, 1993 #>  #>                       Events Person-Time #> Warfarin Group            20         507 #> Placebo/Control Group     50         405 #>   ### create tables dat <- to.table(measure=\"MD\", m1i=m1i, sd1i=sd1i, n1i=n1i,                 m2i=m2i, sd2i=sd2i, n2i=n2i, data=dat.normand1999,                 slab=source, rows=c(\"Specialized Care\", \"Routine Care\")) dat #> , , Edinburgh #>  #>                  Mean SD   n #> Specialized Care   55 47 155 #> Routine Care       75 64 156 #>  #> , , Orpington-Mild #>  #>                  Mean SD  n #> Specialized Care   27  7 31 #> Routine Care       29  4 32 #>  #> , , Orpington-Moderate #>  #>                  Mean SD  n #> Specialized Care   64 17 75 #> Routine Care      119 29 71 #>  #> , , Orpington-Severe #>  #>                  Mean SD  n #> Specialized Care   66 20 18 #> Routine Care      137 48 18 #>  #> , , Montreal-Home #>  #>                  Mean SD  n #> Specialized Care   14  8  8 #> Routine Care       18 11 13 #>  #> , , Montreal-Transfer #>  #>                  Mean SD  n #> Specialized Care   19  7 57 #> Routine Care       18  4 52 #>  #> , , Newcastle #>  #>                  Mean SD  n #> Specialized Care   52 45 34 #> Routine Care       41 34 33 #>  #> , , Umea #>  #>                  Mean SD   n #> Specialized Care   21 16 110 #> Routine Care       31 27 183 #>  #> , , Uppsala #>  #>                  Mean SD  n #> Specialized Care   30 27 60 #> Routine Care       23 20 52 #>"},{"path":"/reference/to.wide.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Data from a Long to a Wide Format — to.wide","title":"Convert Data from a Long to a Wide Format — to.wide","text":"function converts data given long format wide format.","code":""},{"path":"/reference/to.wide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Data from a Long to a Wide Format — to.wide","text":"","code":"to.wide(data, study, grp, ref, grpvars, postfix=c(\".1\",\".2\"),         addid=TRUE, addcomp=TRUE, adddesign=TRUE, minlen=2,         var.names=c(\"id\",\"comp\",\"design\"))"},{"path":"/reference/to.wide.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Data from a Long to a Wide Format — to.wide","text":"data data frame long format. study either name (given character string) position (given single number) study variable data frame. grp either name (given character string) position (given single number) group variable data frame. ref optional character string specify reference group (must one groups group variable). given, frequently occurring group used reference group. grpvars either names (given character vector) positions (given numeric vector) group-level variables. postfix character string length 2 giving affix placed names group-level variables first second group. addid logical specify whether row id variable added data frame (default TRUE). addcomp logical specify whether comparison id variable added data frame (default TRUE). adddesign logical specify whether design id variable added data frame (default TRUE). minlen integer specify minimum length shortened group names comparison design id variables (default 2). var.names character string three elements specify name id, comparison, design variables (defaults \"id\", \"comp\", \"design\", respectively).","code":""},{"path":"/reference/to.wide.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert Data from a Long to a Wide Format — to.wide","text":"meta-analytic dataset may structured ‘long’ format, row dataset corresponds particular study group (e.g., treatment arm). Using function, dataset can restructured ‘wide’ format, group within study contrasted particular reference group. study group arguments used specify study group variables dataset (either character strings numbers indicating column positions variables dataset). Optional argument ref used specify reference group (must one groups group variable). Argument grpvars used specify (either character vector giving column positions) variables dataset correspond group-level outcomes (remaining variables treated study-level outcomes). dataset restructured two-group study yield single row restructured dataset, contrasting first group second/reference group. studies two groups (often called ‘multiarm’ ‘multitreatment’ studies medical literature), reference group repeated many times needed (three-group study yield two rows restructured dataset, contrasting two groups common reference group). study include reference group, another group study used reference group. group chosen based factor levels grp variable (.e., last level occurs study becomes reference group). distinguish names group-level outcome variables two first second group restructured dataset, strings given postfix argument placed respective variable names. requested, row id, comparison id, design id variables added restructured dataset. row id simply unique number row dataset. comparison id variable indicates two groups compared ). design id variable indicates groups included particular study. group names shortened comparison design variables (least minlen; actual length might longer ensure uniqueness group names). examples illustrate use function.","code":""},{"path":"/reference/to.wide.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Data from a Long to a Wide Format — to.wide","text":"data frame rows contrasting groups reference group appropriate number columns (depending number group-level outcome variables).","code":""},{"path":"/reference/to.wide.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert Data from a Long to a Wide Format — to.wide","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/to.wide.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Convert Data from a Long to a Wide Format — to.wide","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/to.wide.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Data from a Long to a Wide Format — to.wide","text":"","code":"### data in long format dat <- dat.senn2013 dat <- dat[c(1,4,3,2,5,6)] dat #>                    study comment     treatment  ni    mi   sdi #> 1       De Fronzo (1995)  change     metformin 213 -1.70 1.459 #> 2       De Fronzo (1995)  change       placebo 209  0.20 1.446 #> 3           Lewin (2007)  change     metformin 431 -0.74 1.106 #> 4           Lewin (2007)  change       placebo 144  0.08 1.004 #> 5          Willms (1999)  change     metformin  29 -2.50 0.862 #> 6          Willms (1999)  change      acarbose  31 -2.30 1.782 #> 7          Willms (1999)  change       placebo  29 -1.30 1.831 #> 8        Davidson (2007)  change rosiglitazone 117 -1.20 1.097 #> 9        Davidson (2007)  change       placebo 116  0.14 1.093 #> 10  Wolffenbuttel (1999)  change rosiglitazone 183 -0.90 1.100 #> 11  Wolffenbuttel (1999)  change       placebo 192  0.20 1.110 #> 12         Kipnes (2001)  change  pioglitazone 182 -1.20 1.369 #> 13         Kipnes (2001)  change       placebo 181  0.10 1.024 #> 14        Kerenyi (2004)  change rosiglitazone 160 -0.91 0.990 #> 15        Kerenyi (2004)  change       placebo 154 -0.14 0.920 #> 16       Hanefeld (2004)     raw  pioglitazone 319  7.61 1.072 #> 17       Hanefeld (2004)     raw     metformin 320  7.45 1.073 #> 18         Derosa (2004)     raw  pioglitazone  45  6.80 0.800 #> 19         Derosa (2004)     raw rosiglitazone  42  6.70 0.900 #> 20          Baksi (2004)  change rosiglitazone 218 -1.20 1.112 #> 21          Baksi (2004)  change       placebo 233  0.10 1.036 #> 22     Rosenstock (2008)  change rosiglitazone  59 -1.17 1.229 #> 23     Rosenstock (2008)  change       placebo  57 -0.08 1.208 #> 24            Zhu (2003)  change rosiglitazone 210 -1.90 1.470 #> 25            Zhu (2003)  change       placebo 105 -0.40 1.300 #> 26           Yang (2003)  change rosiglitazone 102 -1.09 1.650 #> 27           Yang (2003)  change     metformin  96 -0.95 1.500 #> 28 Vongthavaravat (2002)  change rosiglitazone 164 -1.10 1.559 #> 29 Vongthavaravat (2002)  change  sulfonylurea 170  0.10 0.992 #> 30          Oyama (2008)  change      acarbose  41 -0.70 0.800 #> 31          Oyama (2008)  change  sulfonylurea  43 -0.30 0.600 #> 32          Costa (1997)  change      acarbose  36 -1.10 0.360 #> 33          Costa (1997)  change       placebo  29 -0.30 0.700 #> 34      Hermansen (2007)  change   sitagliptin 106 -0.30 0.940 #> 35      Hermansen (2007)  change       placebo 106  0.27 0.940 #> 36         Garber (2008)  change  vildagliptin 132 -0.63 1.034 #> 37         Garber (2008)  change       placebo 144  0.07 1.080 #> 38           Alex (1998)  change     metformin 291  0.13 1.428 #> 39           Alex (1998)  change  sulfonylurea 300  0.50 1.450 #> 40       Johnston (1994)  change      miglitol  68 -0.41 1.072 #> 41       Johnston (1994)  change       placebo  63  0.33 1.032 #> 42      Johnston (1998a)  change      miglitol  91 -0.43 0.954 #> 43      Johnston (1998a)  change       placebo  43  0.98 1.311 #> 44            Kim (2007)  change rosiglitazone  57 -1.10 1.341 #> 45            Kim (2007)  change     metformin  56 -1.10 1.139 #> 46      Johnston (1998b)  change      miglitol  49 -0.12 1.400 #> 47      Johnston (1998b)  change       placebo  34  0.56 1.166 #> 48 Gonzalez-Ortiz (2004)  change     metformin  34 -1.30 1.861 #> 49 Gonzalez-Ortiz (2004)  change       placebo  37 -0.90 1.803 #> 50         Stucci (1996)     raw    benfluorex  28  8.03 1.290 #> 51         Stucci (1996)     raw       placebo  30  8.26 1.350 #> 52         Moulin (2006)  change    benfluorex 161 -0.82 1.028 #> 53         Moulin (2006)  change       placebo 156  0.19 1.374  ### restructure to wide format dat <- to.wide(dat, study=\"study\", grp=\"treatment\", ref=\"placebo\", grpvars=4:6) dat #>                    study comment   treatment.1 ni.1  mi.1 sdi.1   treatment.2 ni.2  mi.2 sdi.2 id #> 1            Alex (1998)  change     metformin  291  0.13 1.428  sulfonylurea  300  0.50 1.450  1 #> 2           Baksi (2004)  change rosiglitazone  218 -1.20 1.112       placebo  233  0.10 1.036  2 #> 3           Costa (1997)  change      acarbose   36 -1.10 0.360       placebo   29 -0.30 0.700  3 #> 4        Davidson (2007)  change rosiglitazone  117 -1.20 1.097       placebo  116  0.14 1.093  4 #> 5       De Fronzo (1995)  change     metformin  213 -1.70 1.459       placebo  209  0.20 1.446  5 #> 6          Derosa (2004)     raw  pioglitazone   45  6.80 0.800 rosiglitazone   42  6.70 0.900  6 #> 7          Garber (2008)  change  vildagliptin  132 -0.63 1.034       placebo  144  0.07 1.080  7 #> 8  Gonzalez-Ortiz (2004)  change     metformin   34 -1.30 1.861       placebo   37 -0.90 1.803  8 #> 9        Hanefeld (2004)     raw     metformin  320  7.45 1.073  pioglitazone  319  7.61 1.072  9 #> 10      Hermansen (2007)  change   sitagliptin  106 -0.30 0.940       placebo  106  0.27 0.940 10 #> 11       Johnston (1994)  change      miglitol   68 -0.41 1.072       placebo   63  0.33 1.032 11 #> 12      Johnston (1998a)  change      miglitol   91 -0.43 0.954       placebo   43  0.98 1.311 12 #> 13      Johnston (1998b)  change      miglitol   49 -0.12 1.400       placebo   34  0.56 1.166 13 #> 14        Kerenyi (2004)  change rosiglitazone  160 -0.91 0.990       placebo  154 -0.14 0.920 14 #> 15            Kim (2007)  change     metformin   56 -1.10 1.139 rosiglitazone   57 -1.10 1.341 15 #> 16         Kipnes (2001)  change  pioglitazone  182 -1.20 1.369       placebo  181  0.10 1.024 16 #> 17          Lewin (2007)  change     metformin  431 -0.74 1.106       placebo  144  0.08 1.004 17 #> 18         Moulin (2006)  change    benfluorex  161 -0.82 1.028       placebo  156  0.19 1.374 18 #> 19          Oyama (2008)  change      acarbose   41 -0.70 0.800  sulfonylurea   43 -0.30 0.600 19 #> 20     Rosenstock (2008)  change rosiglitazone   59 -1.17 1.229       placebo   57 -0.08 1.208 20 #> 21         Stucci (1996)     raw    benfluorex   28  8.03 1.290       placebo   30  8.26 1.350 21 #> 22 Vongthavaravat (2002)  change rosiglitazone  164 -1.10 1.559  sulfonylurea  170  0.10 0.992 22 #> 23         Willms (1999)  change      acarbose   31 -2.30 1.782       placebo   29 -1.30 1.831 23 #> 24         Willms (1999)  change     metformin   29 -2.50 0.862       placebo   29 -1.30 1.831 24 #> 25  Wolffenbuttel (1999)  change rosiglitazone  183 -0.90 1.100       placebo  192  0.20 1.110 25 #> 26           Yang (2003)  change     metformin   96 -0.95 1.500 rosiglitazone  102 -1.09 1.650 26 #> 27            Zhu (2003)  change rosiglitazone  210 -1.90 1.470       placebo  105 -0.40 1.300 27 #>     comp   design #> 1  me-su    me-su #> 2  ro-pl    ro-pl #> 3  ac-pl    ac-pl #> 4  ro-pl    ro-pl #> 5  me-pl    me-pl #> 6  pi-ro    pi-ro #> 7  vi-pl    vi-pl #> 8  me-pl    me-pl #> 9  me-pi    me-pi #> 10 si-pl    si-pl #> 11 mi-pl    mi-pl #> 12 mi-pl    mi-pl #> 13 mi-pl    mi-pl #> 14 ro-pl    ro-pl #> 15 me-ro    me-ro #> 16 pi-pl    pi-pl #> 17 me-pl    me-pl #> 18 be-pl    be-pl #> 19 ac-su    ac-su #> 20 ro-pl    ro-pl #> 21 be-pl    be-pl #> 22 ro-su    ro-su #> 23 ac-pl ac-me-pl #> 24 me-pl ac-me-pl #> 25 ro-pl    ro-pl #> 26 me-ro    me-ro #> 27 ro-pl    ro-pl  ### data in long format dat <- dat.hasselblad1998 dat #>    id study            authors year            trt  xi   ni #> 1   1     1        Reid et al. 1974     no_contact  75  731 #> 2   2     1        Reid et al. 1974 ind_counseling 363  714 #> 3   3     2    Cottraux et al. 1983     no_contact   9  140 #> 4   4     2    Cottraux et al. 1983 ind_counseling  23  140 #> 5   5     2    Cottraux et al. 1983 grp_counseling  10  138 #> 6   6     3       Slama et al. 1990     no_contact   2  106 #> 7   7     3       Slama et al. 1990 ind_counseling   9  205 #> 8   8     4    Jamrozik et al. 1984     no_contact  58  549 #> 9   9     4    Jamrozik et al. 1984 ind_counseling 237 1561 #> 10 10     5      Rabkin et al. 1984     no_contact   0   33 #> 11 11     5      Rabkin et al. 1984 ind_counseling   9   48 #> 12 12     6   Decker and Evans 1989      self_help  20   49 #> 13 13     6   Decker and Evans 1989 ind_counseling  16   43 #> 14 14     7    Richmond et al. 1986     no_contact   3  100 #> 15 15     7    Richmond et al. 1986 ind_counseling  31   98 #> 16 16     8              Leung 1991     no_contact   1   31 #> 17 17     8              Leung 1991 ind_counseling  26   95 #> 18 18     9  Mothersill et al. 1988      self_help  11   78 #> 19 19     9  Mothersill et al. 1988 ind_counseling  12   85 #> 20 20     9  Mothersill et al. 1988 grp_counseling  29  170 #> 21 21    10    Langford et al. 1983     no_contact   6   39 #> 22 22    10    Langford et al. 1983 ind_counseling  17   77 #> 23 23    11       Gritz et al. 1992     no_contact  79  702 #> 24 24    11       Gritz et al. 1992      self_help  77  694 #> 25 25    12    Campbell et al. 1986     no_contact  18  671 #> 26 26    12    Campbell et al. 1986      self_help  21  535 #> 27 27    13     Sanders et al. 1989     no_contact  64  642 #> 28 28    13     Sanders et al. 1989 ind_counseling 107  761 #> 29 29    14    Hilleman et al. 1993 ind_counseling  12   76 #> 30 30    14    Hilleman et al. 1993 grp_counseling  20   74 #> 31 31    15     Gillams et al. 1984 ind_counseling   9   55 #> 32 32    15     Gillams et al. 1984 grp_counseling   3   26 #> 33 33    16 Mogielnicki et al. 1986      self_help   7   66 #> 34 34    16 Mogielnicki et al. 1986 grp_counseling  32  127 #> 35 35    17        Page et al. 1986     no_contact   5   62 #> 36 36    17        Page et al. 1986 ind_counseling   8   90 #> 37 37    18    Vetter and Ford 1990     no_contact  20  234 #> 38 38    18    Vetter and Ford 1990 ind_counseling  34  237 #> 39 39    19  Williams and Hall 1988     no_contact   0   20 #> 40 40    19  Williams and Hall 1988 grp_counseling   9   20 #> 41 41    20    Pallonen et al. 1994     no_contact   8  116 #> 42 42    20    Pallonen et al. 1994      self_help  19  149 #> 43 43    21     Russell et al. 1983     no_contact  95 1107 #> 44 44    21     Russell et al. 1983 ind_counseling 143 1031 #> 45 45    22 Stewart and Rosser 1982     no_contact  15  187 #> 46 46    22 Stewart and Rosser 1982 ind_counseling  36  504 #> 47 47    23     Russell et al. 1979     no_contact  78  584 #> 48 48    23     Russell et al. 1979 ind_counseling  73  675 #> 49 49    24    Kendrick et al. 1995     no_contact  69 1177 #> 50 50    24    Kendrick et al. 1995 ind_counseling  54  888  ### restructure to wide format dat <- to.wide(dat, study=\"study\", grp=\"trt\", ref=\"no_contact\", grpvars=6:7) dat #>    id study            authors year          trt.1 xi.1 ni.1          trt.2 xi.2 ni.2  comp   design #> 1   1     1        Reid et al. 1974 ind_counseling  363  714     no_contact   75  731 in-no    in-no #> 2   2     2    Cottraux et al. 1983 grp_counseling   10  138     no_contact    9  140 gr-no gr-in-no #> 3   3     2    Cottraux et al. 1983 ind_counseling   23  140     no_contact    9  140 in-no gr-in-no #> 4   4     3       Slama et al. 1990 ind_counseling    9  205     no_contact    2  106 in-no    in-no #> 5   5     4    Jamrozik et al. 1984 ind_counseling  237 1561     no_contact   58  549 in-no    in-no #> 6   6     5      Rabkin et al. 1984 ind_counseling    9   48     no_contact    0   33 in-no    in-no #> 7   7     6   Decker and Evans 1989 ind_counseling   16   43      self_help   20   49 in-se    in-se #> 8   8     7    Richmond et al. 1986 ind_counseling   31   98     no_contact    3  100 in-no    in-no #> 9   9     8              Leung 1991 ind_counseling   26   95     no_contact    1   31 in-no    in-no #> 10 10     9  Mothersill et al. 1988 grp_counseling   29  170      self_help   11   78 gr-se gr-in-se #> 11 11     9  Mothersill et al. 1988 ind_counseling   12   85      self_help   11   78 in-se gr-in-se #> 12 12    10    Langford et al. 1983 ind_counseling   17   77     no_contact    6   39 in-no    in-no #> 13 13    11       Gritz et al. 1992      self_help   77  694     no_contact   79  702 se-no    se-no #> 14 14    12    Campbell et al. 1986      self_help   21  535     no_contact   18  671 se-no    se-no #> 15 15    13     Sanders et al. 1989 ind_counseling  107  761     no_contact   64  642 in-no    in-no #> 16 16    14    Hilleman et al. 1993 grp_counseling   20   74 ind_counseling   12   76 gr-in    gr-in #> 17 17    15     Gillams et al. 1984 grp_counseling    3   26 ind_counseling    9   55 gr-in    gr-in #> 18 18    16 Mogielnicki et al. 1986 grp_counseling   32  127      self_help    7   66 gr-se    gr-se #> 19 19    17        Page et al. 1986 ind_counseling    8   90     no_contact    5   62 in-no    in-no #> 20 20    18    Vetter and Ford 1990 ind_counseling   34  237     no_contact   20  234 in-no    in-no #> 21 21    19  Williams and Hall 1988 grp_counseling    9   20     no_contact    0   20 gr-no    gr-no #> 22 22    20    Pallonen et al. 1994      self_help   19  149     no_contact    8  116 se-no    se-no #> 23 23    21     Russell et al. 1983 ind_counseling  143 1031     no_contact   95 1107 in-no    in-no #> 24 24    22 Stewart and Rosser 1982 ind_counseling   36  504     no_contact   15  187 in-no    in-no #> 25 25    23     Russell et al. 1979 ind_counseling   73  675     no_contact   78  584 in-no    in-no #> 26 26    24    Kendrick et al. 1995 ind_counseling   54  888     no_contact   69 1177 in-no    in-no"},{"path":"/reference/transf.html","id":null,"dir":"Reference","previous_headings":"","what":"Transformation Functions — transf","title":"Transformation Functions — transf","text":"set transformation functions useful meta-analyses.","code":""},{"path":"/reference/transf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transformation Functions — transf","text":"","code":"transf.rtoz(xi, ...) transf.ztor(xi, ...) transf.logit(xi, ...) transf.ilogit(xi, ...) transf.arcsin(xi, ...) transf.iarcsin(xi, ...) transf.pft(xi, ni, ...) transf.ipft(xi, ni, ...) transf.ipft.hm(xi, targs, ...) transf.isqrt(xi, ...) transf.irft(xi, ti, ...) transf.iirft(xi, ti, ...) transf.ahw(xi, ...) transf.iahw(xi, ...) transf.abt(xi, ...) transf.iabt(xi, ...) transf.ztor.int(xi, targs, ...) transf.exp.int(xi, targs, ...) transf.ilogit.int(xi, targs, ...) transf.dtou1(xi, ...) transf.dtou2(xi, ...) transf.dtou3(xi, ...) transf.dtorpb(xi, n1i, n2i, ...) transf.dtobesd(xi, ...) transf.dtomd(xi, targs, ...) transf.logortord(xi, pc, ...) transf.logortorr(xi, pc, ...)"},{"path":"/reference/transf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transformation Functions — transf","text":"xi vector values transformed. ni vector sample sizes. n1i vector sample sizes first group. n2i vector sample sizes second group. ti vector person-times risk. pc control group risk (either single value vector). targs list additional arguments transformation function. See ‘Details’. ... arguments.","code":""},{"path":"/reference/transf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Transformation Functions — transf","text":"following transformation functions currently implemented: transf.rtoz: Fisher's r--z transformation correlations. transf.ztor: inverse Fisher's r--z transformation. transf.logit: logit (log odds) transformation proportions. transf.ilogit: inverse logit transformation. transf.arcsin: arcsine square root transformation proportions. transf.iarcsin: inverse arcsine transformation. transf.pft: Freeman-Tukey (double arcsine) transformation proportions. See Freeman & Tukey (1950). xi argument used specify proportions ni argument corresponding sample sizes. transf.ipft: inverse Freeman-Tukey (double arcsine) transformation proportions. See Miller (1978). transf.ipft.hm: inverse Freeman-Tukey (double arcsine) transformation proportions using harmonic mean sample sizes back-transformation. See Miller (1978). sample sizes specified via targs argument (list element called ni). transf.isqrt: inverse square root transformation (.e., function square number). transf.irft: Freeman-Tukey transformation incidence rates. See Freeman & Tukey (1950). xi argument used specify incidence rates ti argument corresponding person-times risk. transf.iirft: inverse Freeman-Tukey transformation incidence rates. transf.ahw: transformation coefficient alpha suggested Hakstian & Whalen (1976). transf.iahw: inverse transformation coefficient alpha suggested Hakstian & Whalen (1976). transf.abt: transformation coefficient alpha suggested Bonett (2002). transf.iabt: inverse transformation coefficient alpha suggested Bonett (2002). transf.ztor.int: integral transformation method z--r transformation. transf.exp.int: integral transformation method exponential transformation. transf.ilogit.int: integral transformation method inverse logit transformation. transf.dtou1: transformation standardized mean differences Cohen's U1 values (Cohen, 1988). transf.dtou2: transformation standardized mean differences Cohen's U2 values (Cohen, 1988). transf.dtou3: transformation standardized mean differences Cohen's U3 values (Cohen, 1988). transf.dtocles: transformation standardized mean differences common language effect size values (McGraw & Wong, 1992). transf.dtorpb: transformation standardized mean differences point-biserial correlations. n1i n2i specified, function assumes n1i=n2i uses approximate formula. n1i n2i specified, exact transformation formula used. transf.dtobesd: transformation standardized mean differences binomial effect size display values (Rosenthal & Rubin, 1982). Note function provides proportion first group scoring median (proportion second group scoring median simply one minus proportion first group scoring median). transf.dtomd: transformation standardized mean differences mean differences given known standard deviation, must specified via targs argument. transf.logortord: transformation log odds ratios risk differences, assuming particular value control group risk (needs specified via pc argument). transf.logortorr: transformation log odds ratios risk ratios, assuming particular value control group risk (needs specified via pc argument).","code":""},{"path":"/reference/transf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transformation Functions — transf","text":"vector transformed values.","code":""},{"path":"/reference/transf.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Transformation Functions — transf","text":"integral transformation method transformation function \\(h(z)\\) integrates \\(h(z) f(z)\\) \\(z\\) using limits targs$lower targs$upper, \\(f(z)\\) density normal distribution mean equal xi variance equal targs$tau2. example provided .","code":""},{"path":"/reference/transf.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Transformation Functions — transf","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/transf.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Transformation Functions — transf","text":"Bonett, D. G. (2002). Sample size requirements testing estimating coefficient alpha. Journal Educational Behavioral Statistics, 27(4), 335--340. https://doi.org/10.3102/10769986027004335 Cohen, J. (1988). Statistical power analysis behavioral sciences (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum Associates. Fisher, R. . (1921). “probable error” coefficient correlation deduced small sample. Metron, 1, 1--32. http://hdl.handle.net/2440/15169 Freeman, M. F., & Tukey, J. W. (1950). Transformations related angular square root. Annals Mathematical Statistics, 21(4), 607--611. https://doi.org/10.1214/aoms/1177729756 Hakstian, . R., & Whalen, T. E. (1976). k-sample significance test independent alpha coefficients. Psychometrika, 41(2), 219--231. https://doi.org/10.1007/BF02291840 McGraw, K. O., & Wong, S. P. (1992). common language effect size statistic. Psychological Bulletin, 111(2), 361--365. https://doi.org/10.1037/0033-2909.111.2.361 Miller, J. J. (1978). inverse Freeman-Tukey double arcsine transformation. American Statistician, 32(4), 138. https://doi.org/10.1080/00031305.1978.10479283 Rosenthal, R., & Rubin, D. B. (1982). simple, general purpose display magnitude experimental effect. Journal Educational Psychology, 74(2), 166--169. https://doi.org/10.1037/0022-0663.74.2.166 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":"/reference/transf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transformation Functions — transf","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit random-effects model res <- rma(yi, vi, data=dat)  ### average risk ratio with 95% CI (but technically, this provides an ### estimate of the median risk ratio, not the mean risk ratio!) predict(res, transf=exp) #>  #>    pred  ci.lb  ci.ub  pi.lb  pi.ub  #>  0.4894 0.3441 0.6962 0.1546 1.5490  #>   ### average risk ratio with 95% CI using the integral transformation predict(res, transf=transf.exp.int, targs=list(tau2=res$tau2, lower=-4, upper=4)) #>  #>    pred  ci.lb  ci.ub  pi.lb  pi.ub  #>  0.5724 0.4024 0.8142 0.1809 1.8117  #>"},{"path":"/reference/trimfill.html","id":null,"dir":"Reference","previous_headings":"","what":"Trim and Fill Analysis for 'rma.uni' Objects — trimfill","title":"Trim and Fill Analysis for 'rma.uni' Objects — trimfill","text":"Carry trim fill analysis objects class \"rma.uni\".","code":""},{"path":"/reference/trimfill.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trim and Fill Analysis for 'rma.uni' Objects — trimfill","text":"","code":"trimfill(x, ...)  # S3 method for rma.uni trimfill(x, side, estimator=\"L0\", maxiter=100, verbose=FALSE, ilim, ...)"},{"path":"/reference/trimfill.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trim and Fill Analysis for 'rma.uni' Objects — trimfill","text":"x object class \"rma.uni\". side optional character string (either \"left\" \"right\") specify side funnel plot missing studies imputed. left unspecified, side chosen within function depending results Egger's regression test (see regtest details test). estimator character string (either \"L0\", \"R0\", \"Q0\") specify estimator use estimating number missing studies (default \"L0\"). maxiter integer specify maximum number iterations use trim fill method (default 100). verbose logical specify whether output generated progress iterative algorithm used part trim fill method (default FALSE). ilim limits imputed values. unspecified, limits used. ... arguments.","code":""},{"path":"/reference/trimfill.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Trim and Fill Analysis for 'rma.uni' Objects — trimfill","text":"trim fill method nonparametric (rank-based) data augmentation technique proposed Duval Tweedie (2000a, 2000b; see also Duval, 2005). method can used estimate number studies missing meta-analysis due suppression extreme results one side funnel plot. method augments observed data funnel plot symmetric recomputes summary estimate based complete data. trim fill method can used context equal- random-effects model (.e., models without moderators). method regarded way yielding ‘valid’ estimate overall effect outcome, way examining sensitivity results one particular selection mechanism (.e., one particular form publication bias).","code":""},{"path":"/reference/trimfill.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trim and Fill Analysis for 'rma.uni' Objects — trimfill","text":"object class c(\"rma.uni.trimfill\",\"rma.uni\",\"rma\"). object list containing components objects created rma.uni, except data augmented trim fill method. following components also added: k0 estimated number missing studies. side either \"left\" \"right\", indicating side funnel plot missing studies () imputed. se.k0 standard error k0. p.k0 p-value test \\(\\mbox{H}_0\\): missing studies chosen side (estimator=\"R0\"; NA otherwise). yi observed effect sizes outcomes plus augmented values (). vi corresponding sampling variances fill logical vector indicating values yi observed (FALSE) augmented (TRUE) data. results fitted model data augmentation printed print function. Calling funnel object provides funnel plot observed augmented data.","code":""},{"path":"/reference/trimfill.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Trim and Fill Analysis for 'rma.uni' Objects — trimfill","text":"Three different estimators number missing studies proposed Duval Tweedie (2000a, 2000b). Based articles Duval (2005), \"R0\" \"L0\" recommended. advantage estimator \"R0\" provides test null hypothesis number missing studies (chosen side) zero. outcome measure used analysis bounded (e.g., correlations bounded -1 +1, proportions bounded 0 1), one can use ilim argument enforce limits imputing values (imputed values exceed bounds ). model used trim fill procedure used original model object. Hence, equal-effects model passed function, equal-effects model also used trim fill procedure results provided also based equal-effects model. ‘equal-equal’ approach. Similarly, random-effects model passed function, model used part trim fill procedure final analysis. ‘random-random’ approach. However, one can also easily fit different model final analysis used trim fill procedure. See ‘Examples’ illustration ‘equal-random’ approach.","code":""},{"path":"/reference/trimfill.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Trim and Fill Analysis for 'rma.uni' Objects — trimfill","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/trimfill.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Trim and Fill Analysis for 'rma.uni' Objects — trimfill","text":"Duval, S. J., & Tweedie, R. L. (2000a). Trim fill: simple funnel-plot-based method testing adjusting publication bias meta-analysis. Biometrics, 56(2), 455--463. https://doi.org/10.1111/j.0006-341x.2000.00455.x Duval, S. J., & Tweedie, R. L. (2000b). nonparametric \"trim fill\" method accounting publication bias meta-analysis. Journal American Statistical Association, 95(449), 89--98. https://doi.org/10.1080/01621459.2000.10473905 Duval, S. J. (2005). trim fill method. H. R. Rothstein, . J. Sutton, & M. Borenstein (Eds.) Publication bias meta-analysis: Prevention, assessment, adjustments (pp. 127--144). Chichester, England: Wiley. Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/trimfill.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Trim and Fill Analysis for 'rma.uni' Objects — trimfill","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### meta-analysis of the log risk ratios using an equal-effects model res <- rma(yi, vi, data=dat, method=\"EE\") res.tf <- trimfill(res) res.tf #>  #> Estimated number of missing studies on the right side: 4 (SE = 2.3853) #>  #> Equal-Effects Model (k = 17) #>  #> I^2 (total heterogeneity / total variability):   93.91% #> H^2 (total variability / sampling variability):  16.42 #>  #> Test for Heterogeneity: #> Q(df = 16) = 262.7316, p-val < .0001 #>  #> Model Results: #>  #> estimate      se     zval    pval    ci.lb    ci.ub     ​  #>  -0.2910  0.0383  -7.6057  <.0001  -0.3660  -0.2160  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  funnel(res.tf, legend=TRUE, cex=1.2)   ### estimator \"R0\" also provides test res.tf <- trimfill(res, estimator=\"R0\") res.tf #>  #> Estimated number of missing studies on the right side: 4 (SE = 3.1623) #> Test of H0: no missing studies on the right side:      p-val = 0.0312 #>  #> Equal-Effects Model (k = 17) #>  #> I^2 (total heterogeneity / total variability):   93.91% #> H^2 (total variability / sampling variability):  16.42 #>  #> Test for Heterogeneity: #> Q(df = 16) = 262.7316, p-val < .0001 #>  #> Model Results: #>  #> estimate      se     zval    pval    ci.lb    ci.ub     ​  #>  -0.2910  0.0383  -7.6057  <.0001  -0.3660  -0.2160  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### meta-analysis of the log risk ratios using a random-effects model res <- rma(yi, vi, data=dat) res.tf <- trimfill(res) res.tf #>  #> Estimated number of missing studies on the right side: 1 (SE = 2.4528) #>  #> Random-Effects Model (k = 14; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.3313 (SE = 0.1701) #> tau (square root of estimated tau^2 value):      0.5756 #> I^2 (total heterogeneity / total variability):   92.14% #> H^2 (total variability / sampling variability):  12.72 #>  #> Test for Heterogeneity: #> Q(df = 13) = 154.6750, p-val < .0001 #>  #> Model Results: #>  #> estimate      se     zval    pval    ci.lb    ci.ub     ​  #>  -0.6571  0.1785  -3.6805  0.0002  -1.0070  -0.3072  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  funnel(res.tf, legend=TRUE, cex=1.2)   ### the examples above are equal-equal and random-random approaches  ### illustration of an equal-random approach res <- rma(yi, vi, data=dat, method=\"EE\") res.tf <- trimfill(res) filled <- data.frame(yi = res.tf$yi, vi = res.tf$vi, fill = res.tf$fill) filled #>             yi          vi  fill #> 1  -0.88931133 0.325584765 FALSE #> 2  -1.58538866 0.194581121 FALSE #> 3  -1.34807315 0.415367965 FALSE #> 4  -1.44155119 0.020010032 FALSE #> 5  -0.21754732 0.051210172 FALSE #> 6  -0.78611559 0.006905618 FALSE #> 7  -1.62089822 0.223017248 FALSE #> 8   0.01195233 0.003961579 FALSE #> 9  -0.46941765 0.056434210 FALSE #> 10 -1.37134480 0.073024794 FALSE #> 11 -0.33935883 0.012412214 FALSE #> 12  0.44591340 0.532505845 FALSE #> 13 -0.01731395 0.071404660 FALSE #> 14  0.78929282 0.073024794  TRUE #> 15  0.85949921 0.020010032  TRUE #> 16  1.00333667 0.194581121  TRUE #> 17  1.03884624 0.223017248  TRUE rma(yi, vi, data=filled) #>  #> Random-Effects Model (k = 17; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.7164 (SE = 0.2944) #> tau (square root of estimated tau^2 value):      0.8464 #> I^2 (total heterogeneity / total variability):   96.03% #> H^2 (total variability / sampling variability):  25.19 #>  #> Test for Heterogeneity: #> Q(df = 16) = 262.7316, p-val < .0001 #>  #> Model Results: #>  #> estimate      se     zval    pval    ci.lb   ci.ub   ​  #>  -0.3422  0.2223  -1.5392  0.1237  -0.7780  0.0936     #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>"},{"path":"/reference/update.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Model Updating for 'rma' Objects — update.rma","title":"Model Updating for 'rma' Objects — update.rma","text":"function can used update (default) re-fit \"rma\" models. extracting call stored object, updating call (default) evaluating call.","code":""},{"path":"/reference/update.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model Updating for 'rma' Objects — update.rma","text":"","code":"# S3 method for rma update(object, formula., ..., evaluate = TRUE)"},{"path":"/reference/update.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model Updating for 'rma' Objects — update.rma","text":"object object class \"rma\". formula. changes formula. See ‘Details’. ... additional arguments call, arguments changed values. evaluate logical specify whether evaluate new call just return call.","code":""},{"path":"/reference/update.rma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model Updating for 'rma' Objects — update.rma","text":"objects class \"rma.uni\", \"rma.glmm\", \"rma.mv\", formula. argument can used update set moderators included model (see ‘Examples’).","code":""},{"path":"/reference/update.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model Updating for 'rma' Objects — update.rma","text":"evaluate=TRUE fitted object, otherwise updated call.","code":""},{"path":"/reference/update.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Model Updating for 'rma' Objects — update.rma","text":"present function based update.default, changes made Wolfgang Viechtbauer (wvb@metafor-project.org) formula updating works (somewhat non-standard) interface rma.uni, rma.glmm, rma.mv functions.","code":""},{"path":"/reference/update.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Model Updating for 'rma' Objects — update.rma","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/update.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model Updating for 'rma' Objects — update.rma","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit random-effects model (method=\"REML\" is default) res <- rma(yi, vi, data=dat, digits=3) res #>  #> Random-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of total heterogeneity): 0.313 (SE = 0.166) #> tau (square root of estimated tau^2 value):      0.560 #> I^2 (total heterogeneity / total variability):   92.22% #> H^2 (total variability / sampling variability):  12.86 #>  #> Test for Heterogeneity: #> Q(df = 12) = 152.233, p-val < .001 #>  #> Model Results: #>  #> estimate     se    zval   pval   ci.lb   ci.ub     ​  #>   -0.715  0.180  -3.974  <.001  -1.067  -0.362  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### fit mixed-effects model with two moderators (absolute latitude and publication year) res <- update(res, ~ ablat + year) res #>  #> Mixed-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.111 (SE = 0.084) #> tau (square root of estimated tau^2 value):             0.333 #> I^2 (residual heterogeneity / unaccounted variability): 71.98% #> H^2 (unaccounted variability / sampling variability):   3.57 #> R^2 (amount of heterogeneity accounted for):            64.63% #>  #> Test for Residual Heterogeneity: #> QE(df = 10) = 28.325, p-val = 0.002 #>  #> Test of Moderators (coefficients 2:3): #> QM(df = 2) = 12.204, p-val = 0.002 #>  #> Model Results: #>  #>          estimate      se    zval   pval    ci.lb   ci.ub    ​  #> intrcpt    -3.546  29.096  -0.122  0.903  -60.572  53.481      #> ablat      -0.028   0.010  -2.737  0.006   -0.048  -0.008  **  #> year        0.002   0.015   0.130  0.897   -0.027   0.031      #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### remove 'year' moderator res <- update(res, ~ . - year) res #>  #> Mixed-Effects Model (k = 13; tau^2 estimator: REML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.076 (SE = 0.059) #> tau (square root of estimated tau^2 value):             0.276 #> I^2 (residual heterogeneity / unaccounted variability): 68.39% #> H^2 (unaccounted variability / sampling variability):   3.16 #> R^2 (amount of heterogeneity accounted for):            75.62% #>  #> Test for Residual Heterogeneity: #> QE(df = 11) = 30.733, p-val = 0.001 #>  #> Test of Moderators (coefficient 2): #> QM(df = 1) = 16.357, p-val < .001 #>  #> Model Results: #>  #>          estimate     se    zval   pval   ci.lb   ci.ub     ​  #> intrcpt     0.251  0.249   1.009  0.313  -0.237   0.740       #> ablat      -0.029  0.007  -4.044  <.001  -0.043  -0.015  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### fit model with ML estimation update(res, method=\"ML\") #>  #> Mixed-Effects Model (k = 13; tau^2 estimator: ML) #>  #> tau^2 (estimated amount of residual heterogeneity):     0.034 (SE = 0.028) #> tau (square root of estimated tau^2 value):             0.185 #> I^2 (residual heterogeneity / unaccounted variability): 49.33% #> H^2 (unaccounted variability / sampling variability):   1.97 #> R^2 (amount of heterogeneity accounted for):            87.73% #>  #> Test for Residual Heterogeneity: #> QE(df = 11) = 30.733, p-val = 0.001 #>  #> Test of Moderators (coefficient 2): #> QM(df = 1) = 28.911, p-val < .001 #>  #> Model Results: #>  #>          estimate     se    zval   pval   ci.lb   ci.ub     ​  #> intrcpt     0.282  0.187   1.507  0.132  -0.085   0.649       #> ablat      -0.030  0.005  -5.377  <.001  -0.040  -0.019  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### example with rma.glmm() res <- rma.glmm(measure=\"OR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg, digits=3) res <- update(res, mods = ~ ablat) res #>  #> Mixed-Effects Model (k = 13; tau^2 estimator: ML) #> Model Type: Unconditional Model with Fixed Study Effects #>  #> tau^2 (estimated amount of residual heterogeneity):     0 #> tau (square root of estimated tau^2 value):             0 #> I^2 (residual heterogeneity / unaccounted variability): 0.000% #> H^2 (unaccounted variability / sampling variability):   1.000 #>  #> Tests for Residual Heterogeneity: #> Wld(df = 11) = 25.095, p-val = 0.009 #> LRT(df = 11) = 25.014, p-val = 0.009 #>  #> Test of Moderators (coefficient 2): #> QM(df = 1) = 143.181, p-val < .001 #>  #> Model Results: #>  #>          estimate     se     zval   pval   ci.lb   ci.ub     ​  #> intrcpt     0.399  0.082    4.851  <.001   0.238   0.560  ***  #> ablat      -0.033  0.003  -11.966  <.001  -0.039  -0.028  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>   ### fit conditional model with approximate likelihood update(res, model=\"CM.AL\") #>  #> Mixed-Effects Model (k = 13; tau^2 estimator: ML) #> Model Type: Conditional Model with Approximate Likelihood #>  #> tau^2 (estimated amount of residual heterogeneity):     0.032 #> tau (square root of estimated tau^2 value):             0.179 #> I^2 (residual heterogeneity / unaccounted variability): 45.973% #> H^2 (unaccounted variability / sampling variability):   1.851 #>  #> Tests for Residual Heterogeneity: #> Wld(df = 11) = 29.895, p-val = 0.002 #> LRT(df = 11) = 30.013, p-val = 0.002 #>  #> Test of Moderators (coefficient 2): #> QM(df = 1) = 31.169, p-val < .001 #>  #> Model Results: #>  #>          estimate     se    zval   pval   ci.lb   ci.ub     ​  #> intrcpt     0.293  0.187   1.568  0.117  -0.073   0.659       #> ablat      -0.030  0.005  -5.583  <.001  -0.040  -0.019  ***  #>  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>"},{"path":"/reference/vcalc.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct or Approximate the Variance-Covariance Matrix of Dependent Effect Sizes or Outcomes — vcalc","title":"Construct or Approximate the Variance-Covariance Matrix of Dependent Effect Sizes or Outcomes — vcalc","text":"function can used construct approximate variance-covariance matrix dependent effect sizes outcomes, precisely, sampling errors (.e., V matrix rma.mv).","code":""},{"path":"/reference/vcalc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct or Approximate the Variance-Covariance Matrix of Dependent Effect Sizes or Outcomes — vcalc","text":"","code":"vcalc(vi, cluster, subgroup, obs, type, time1, time2, grp1, grp2, w1, w2,       data, rho, phi, rvars, checkpd=TRUE, nearpd=FALSE, ...)"},{"path":"/reference/vcalc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct or Approximate the Variance-Covariance Matrix of Dependent Effect Sizes or Outcomes — vcalc","text":"vi numeric vector specify sampling variances observed effect sizes outcomes. cluster vector specify clustering variable (e.g., study). subgroup optional vector specify different (independent) subgroups within clusters. obs optional vector distinguish different observed effect sizes outcomes corresponding construct response/dependent variable. type optional vector distinguish different types constructs response/dependent variables underlying observed effect sizes outcomes. time1 optional numeric vector specify time points observed effect sizes outcomes obtained (first condition observed effect sizes outcomes represent contrasts two conditions). time2 optional numeric vector specify time points observed effect sizes outcomes obtained second condition (relevant observed effect sizes outcomes represent contrasts two conditions). grp1 optional vector specify group first condition observed effect sizes outcomes represent contrasts two conditions. grp2 optional vector specify group second condition observed effect sizes outcomes represent contrasts two conditions. w1 optional numeric vector specify size group (generally, inverse-sampling variance weight) first condition observed effect sizes outcomes represent contrasts two conditions. w2 optional numeric vector specify size group (generally, inverse-sampling variance weight) second condition observed effect sizes outcomes represent contrasts two conditions. data optional data frame containing variables given arguments . rho argument specify correlation(s) observed effect sizes outcomes measured concurrently. See ‘Details’. phi argument specify autocorrelation observed effect sizes outcomes measured different time points. See ‘Details’. rvars optional argument specifying variables correspond correlation matrices studies (specified, arguments except cluster subgroup ignored). See ‘Details’. checkpd logical specify whether check variance-covariance matrices within clusters positive definite (default TRUE). See ‘Note’. nearpd logical specify whether nearPD function Matrix package used variance-covariance matrices positive definite. See ‘Note’. ... arguments.","code":""},{"path":"/reference/vcalc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Construct or Approximate the Variance-Covariance Matrix of Dependent Effect Sizes or Outcomes — vcalc","text":"Standard meta-analytic models (can fitted rma.uni function) assume observed effect sizes outcomes (precisely, sampling errors) independent. assumption typically violated whenever multiple observed effect sizes outcomes computed based sample subjects (whatever study units ) least partial overlap subjects contribute information computation multiple effect sizes outcomes. present function can used construct approximate variance-covariance matrix sampling errors dependent effect sizes outcomes wide variety circumstances (variance-covariance matrix -called V matrix may needed input multilevel/multivariate meta-analytic models can fitted rma.mv function). Argument cluster used specify clustering variable. Rows value variable allowed dependent, rows different values assumed independent. Typically, cluster study identifier. Within cluster, may different subgroups overlap subjects across subgroups. Argument subgroup can used distinguish subgroups. Rows value variable within cluster allowed dependent, rows different values assumed independent even come cluster. Therefore, hereon, ‘cluster’ really refers combination cluster subgroup. Multiple effect sizes outcomes belonging cluster may dependent due variety reasons: construct interest (e.g., severity depression) may measured using different scales instruments within study (e.g., using Beck Depression Inventory (BDI) Hamilton Depression Rating Scale (HDRS)) based multiple effect sizes can computed group subjects (e.g., contrasting treatment versus control group respect scale). case, multiple effect sizes different ‘observations’ effect respect type construct. Argument obs used distinguish different effect sizes corresponding construct. obs specified, argument rho must also specified indicate degree correlation among sampling errors different effect sizes. Since correlation typically known, correlation among various scales (rough ‘guestimate’ thereof) can used proxy (.e., (typical) correlation BDI HDRS measurements). One can also specify entire correlation matrix via rho indicate, possible pair obs values, corresponding correlation. row/column names matrix must correspond unique values obs variable. Multiple types constructs (generally, types response/dependent variables) may measured group subjects (e.g., severity depression measured Beck Depression Inventory (BDI) severity anxiety measured State-Trait Anxiety Inventory (STAI)). interest meta-analysis, effect sizes can computed respect ‘type’ construct. Argument type used distinguish effect sizes corresponding different types constructs. type specified, argument rho must also specified indicate degree correlation among sampling errors effect sizes belonging different types. , correlation among various scales typically used proxy (.e., (typical) correlation BDI STAI measurements). One can also specify entire correlation matrix via rho indicate, possible pair type values, corresponding correlation. row/column names matrix must correspond unique values type variable. multiple types constructs, multiple scales instruments may also used (least studies) measure construct hence may multiple effect sizes ‘observations’ type construct. Arguments type obs used together indicate various construct types observations thereof. case, argument rho must vector two values, first specify within-construct correlation second specify -construct correlation. One can also specify list two elements rho, first element either scalar entire correlation matrix within-construct correlation(s) second element scalar entire correlation matrix -construct correlation(s). , matrices specified must row/column names corresponding unique values obs /type variables. construct scale may assessed/used multiple times, allowing computation multiple effect sizes group subjects different time points (e.g., right end treatment, short-term follow-, long-term follow-). Argument time1 used specify time points observed effect sizes obtained. Argument phi must also specified indicate autocorrelation among sampling errors two effect sizes differ one unit time1 variable. , autocorrelation measurements can used proxy. multiple constructs /multiple scales also assessed various time points, arguments type /obs (together argument rho) used needed differentiate effect sizes corresponding different constructs /scales. Many effect size outcome measures (e.g., raw standardized mean differences, log-transformed ratios means, log risk/odds ratios risk differences) reflect difference two conditions (.e., contrast). Within study, may two conditions, allowing computation multiple contrasts (e.g., treatment versus control condition treatment B versus control condition) hence corresponding effect sizes. reuse information ‘shared’ condition (example, control condition) induces correlation among effect sizes. account , arguments grp1 grp2 specified indicate (within cluster) two groups compared computation effect size (e.g., example , coding grp1=c(1,2) grp2=c(3,3); whether numbers strings used identifiers irrelevant). degree correlation two contrast-type effect sizes induced use shared condition function size groups involved computation two effect sizes (, generally, inverse-sampling variance weights condition-specific outcomes). default, group sizes (weights) assumed identical across conditions, implies correlation 0.5. group sizes (weights) known, can specified via arguments w1 w2. fact, contrast-type effect size can based - within-subjects design. least one contrast-type effect sizes based within-subjects design, time1 time2 used combination grp1 grp2 indicate effect size group(s) time point(s) involved. example, grp1=c(1,2) grp2=c(3,3) combination time1=c(1,1) time2=c(1,1) imply -subjects design involving three groups two effect size computed contrasting groups 1 2 versus group 3 single time point. hand, grp1=c(1,1) grp2=c(1,1) combination time1=c(2,1) time2=c(3,1) imply within-subjects design two effect size computed contrasting time points 2 3 versus time point 1 single group. Argument phi used indicate autocorrelation measurements within groups (.e., within-subjects design , autocorrelation time points 2 1 equivalently, time points 3 2). arguments can specified together account fairly wide variety dependency types.","code":""},{"path":"/reference/vcalc.html","id":"using-the-rvars-argument","dir":"Reference","previous_headings":"","what":"Using the rvars Argument","title":"Construct or Approximate the Variance-Covariance Matrix of Dependent Effect Sizes or Outcomes — vcalc","text":"function also provides alternative approach constructing variance-covariance matrix using rvars argument. , one must specify names variables dataset correspond correlation matrices studies (variables specified vector; e.g., c(var1, var2, var3)). particular, let \\(k_i\\) denote number rows corresponding \\(\\textrm{th}\\) cluster. values first \\(k_i\\) variables rvars used construct correlation matrix , together sampling variances (specified via vi), variance-covariance matrix. Say three studies, first two correlated estimates, second single estimate, third four correlated estimates. data structure look like : rvars = c(r1, r2, r3, r4). rvars variables consecutive set data frame (), one can use shorthand notation rvars = c(r1:r4), r1 denotes first r4 last variable set. Note lower triangular part submatrices defined rvars variables used. must many variables specified via rvars number rows largest cluster (smaller clusters, non-relevant variables can just set NA; see ).","code":"study  yi  vi  r1  r2  r3  r4 =============================     1   .   .   1  NA  NA  NA     1   .   .  .6   1  NA  NA -----------------------------     2   .   .   1  NA  NA  NA -----------------------------     3   .   .   1  NA  NA  NA     3   .   .  .8   1  NA  NA     3   .   .  .5  .5   1  NA     3   .   .  .5  .5  .8   1 ============================="},{"path":"/reference/vcalc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct or Approximate the Variance-Covariance Matrix of Dependent Effect Sizes or Outcomes — vcalc","text":"\\(k \\times k\\) variance-covariance matrix, \\(k\\) denotes length vi variable (.e., number rows dataset).","code":""},{"path":"/reference/vcalc.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Construct or Approximate the Variance-Covariance Matrix of Dependent Effect Sizes or Outcomes — vcalc","text":"Depending data structure, specified variables, specified values rho /phi, possible constructed variance-covariance matrix positive definite within one clusters (checked checkpd=TRUE, default). non-positive definite submatrices found, reasons carefully checked since might indicate misapplication function /specification implausible values rho /phi. setting nearpd=TRUE, nearPD function Matrix package used variance-covariance submatrices positive definite. used cautiously understanding matrices positive definite.","code":""},{"path":"/reference/vcalc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Construct or Approximate the Variance-Covariance Matrix of Dependent Effect Sizes or Outcomes — vcalc","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/vcalc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Construct or Approximate the Variance-Covariance Matrix of Dependent Effect Sizes or Outcomes — vcalc","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/vcalc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct or Approximate the Variance-Covariance Matrix of Dependent Effect Sizes or Outcomes — vcalc","text":"","code":"############################################################################  ### see help(dat.assink2016) for further details on this dataset  dat <- dat.assink2016 head(dat, 9) #>   study esid id      yi     vi pubstatus year deltype #> 1     1    1  1  0.9066 0.0740         1  4.5 general #> 2     1    2  2  0.4295 0.0398         1  4.5 general #> 3     1    3  3  0.2679 0.0481         1  4.5 general #> 4     1    4  4  0.2078 0.0239         1  4.5 general #> 5     1    5  5  0.0526 0.0331         1  4.5 general #> 6     1    6  6 -0.0507 0.0886         1  4.5 general #> 7     2    1  7  0.5117 0.0115         1  1.5 general #> 8     2    2  8  0.4738 0.0076         1  1.5 general #> 9     2    3  9  0.3544 0.0065         1  1.5 general  ### assume that the effect sizes within studies are correlated with rho=0.6 V <- vcalc(vi, cluster=study, obs=esid, data=dat, rho=0.6)  ### show part of V matrix for studies 1 and 2 round(V[dat$study %in% c(1,2), dat$study %in% c(1,2)], 4) #>         [,1]   [,2]   [,3]   [,4]   [,5]   [,6]   [,7]   [,8]   [,9] #>  [1,] 0.0740 0.0326 0.0358 0.0252 0.0297 0.0486 0.0000 0.0000 0.0000 #>  [2,] 0.0326 0.0398 0.0263 0.0185 0.0218 0.0356 0.0000 0.0000 0.0000 #>  [3,] 0.0358 0.0263 0.0481 0.0203 0.0239 0.0392 0.0000 0.0000 0.0000 #>  [4,] 0.0252 0.0185 0.0203 0.0239 0.0169 0.0276 0.0000 0.0000 0.0000 #>  [5,] 0.0297 0.0218 0.0239 0.0169 0.0331 0.0325 0.0000 0.0000 0.0000 #>  [6,] 0.0486 0.0356 0.0392 0.0276 0.0325 0.0886 0.0000 0.0000 0.0000 #>  [7,] 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0115 0.0056 0.0052 #>  [8,] 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0056 0.0076 0.0042 #>  [9,] 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0052 0.0042 0.0065  ### or show as list of matrices lapply(blsplit(V, dat$study)[1:2], round, 4) #> $`1` #>        [,1]   [,2]   [,3]   [,4]   [,5]   [,6] #> [1,] 0.0740 0.0326 0.0358 0.0252 0.0297 0.0486 #> [2,] 0.0326 0.0398 0.0263 0.0185 0.0218 0.0356 #> [3,] 0.0358 0.0263 0.0481 0.0203 0.0239 0.0392 #> [4,] 0.0252 0.0185 0.0203 0.0239 0.0169 0.0276 #> [5,] 0.0297 0.0218 0.0239 0.0169 0.0331 0.0325 #> [6,] 0.0486 0.0356 0.0392 0.0276 0.0325 0.0886 #>  #> $`2` #>        [,1]   [,2]   [,3] #> [1,] 0.0115 0.0056 0.0052 #> [2,] 0.0056 0.0076 0.0042 #> [3,] 0.0052 0.0042 0.0065 #>   ### use a correlation of 0.7 for effect sizes corresponding to the same type of ### delinquent behavior and a correlation of 0.5 for effect sizes corresponding ### to different types of delinquent behavior V <- vcalc(vi, cluster=study, type=deltype, obs=esid, data=dat, rho=c(0.7, 0.5)) lapply(blsplit(V, dat$study)[16], round, 3) #> $`16` #>        [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10] [,11] [,12] [,13] [,14] [,15] [,16] #>  [1,] 0.091 0.045 0.027 0.044 0.030 0.039 0.076 0.028 0.034 0.030 0.039 0.043 0.039 0.067 0.028 0.032 #>  [2,] 0.045 0.087 0.027 0.061 0.030 0.039 0.053 0.027 0.047 0.041 0.053 0.059 0.053 0.046 0.038 0.043 #>  [3,] 0.027 0.027 0.033 0.027 0.025 0.033 0.033 0.023 0.021 0.018 0.023 0.026 0.023 0.029 0.017 0.019 #>  [4,] 0.044 0.061 0.027 0.086 0.029 0.038 0.053 0.027 0.047 0.041 0.053 0.058 0.053 0.046 0.038 0.043 #>  [5,] 0.030 0.030 0.025 0.029 0.040 0.037 0.036 0.026 0.023 0.020 0.026 0.028 0.026 0.031 0.018 0.021 #>  [6,] 0.039 0.039 0.033 0.038 0.037 0.068 0.047 0.033 0.030 0.026 0.034 0.037 0.034 0.041 0.024 0.027 #>  [7,] 0.076 0.053 0.033 0.053 0.036 0.047 0.129 0.033 0.041 0.035 0.046 0.051 0.046 0.079 0.033 0.037 #>  [8,] 0.028 0.027 0.023 0.027 0.026 0.033 0.033 0.033 0.021 0.018 0.023 0.026 0.024 0.029 0.017 0.019 #>  [9,] 0.034 0.047 0.021 0.047 0.023 0.030 0.041 0.021 0.052 0.031 0.041 0.045 0.041 0.036 0.029 0.033 #> [10,] 0.030 0.041 0.018 0.041 0.020 0.026 0.035 0.018 0.031 0.039 0.036 0.039 0.036 0.031 0.025 0.029 #> [11,] 0.039 0.053 0.023 0.053 0.026 0.034 0.046 0.023 0.041 0.036 0.066 0.051 0.047 0.040 0.033 0.038 #> [12,] 0.043 0.059 0.026 0.058 0.028 0.037 0.051 0.026 0.045 0.039 0.051 0.081 0.051 0.045 0.037 0.042 #> [13,] 0.039 0.053 0.023 0.053 0.026 0.034 0.046 0.024 0.041 0.036 0.047 0.051 0.067 0.041 0.033 0.038 #> [14,] 0.067 0.046 0.029 0.046 0.031 0.041 0.079 0.029 0.036 0.031 0.040 0.045 0.041 0.099 0.029 0.033 #> [15,] 0.028 0.038 0.017 0.038 0.018 0.024 0.033 0.017 0.029 0.025 0.033 0.037 0.033 0.029 0.034 0.027 #> [16,] 0.032 0.043 0.019 0.043 0.021 0.027 0.037 0.019 0.033 0.029 0.038 0.042 0.038 0.033 0.027 0.044 #>   ### examine the correlation matrix for study 16 lapply(blsplit(V, dat$study)[16], cov2cor) #> $`16` #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] [,15] [,16] #>  [1,]  1.0  0.5  0.5  0.5  0.5  0.5  0.7  0.5  0.5   0.5   0.5   0.5   0.5   0.7   0.5   0.5 #>  [2,]  0.5  1.0  0.5  0.7  0.5  0.5  0.5  0.5  0.7   0.7   0.7   0.7   0.7   0.5   0.7   0.7 #>  [3,]  0.5  0.5  1.0  0.5  0.7  0.7  0.5  0.7  0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5 #>  [4,]  0.5  0.7  0.5  1.0  0.5  0.5  0.5  0.5  0.7   0.7   0.7   0.7   0.7   0.5   0.7   0.7 #>  [5,]  0.5  0.5  0.7  0.5  1.0  0.7  0.5  0.7  0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5 #>  [6,]  0.5  0.5  0.7  0.5  0.7  1.0  0.5  0.7  0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5 #>  [7,]  0.7  0.5  0.5  0.5  0.5  0.5  1.0  0.5  0.5   0.5   0.5   0.5   0.5   0.7   0.5   0.5 #>  [8,]  0.5  0.5  0.7  0.5  0.7  0.7  0.5  1.0  0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5 #>  [9,]  0.5  0.7  0.5  0.7  0.5  0.5  0.5  0.5  1.0   0.7   0.7   0.7   0.7   0.5   0.7   0.7 #> [10,]  0.5  0.7  0.5  0.7  0.5  0.5  0.5  0.5  0.7   1.0   0.7   0.7   0.7   0.5   0.7   0.7 #> [11,]  0.5  0.7  0.5  0.7  0.5  0.5  0.5  0.5  0.7   0.7   1.0   0.7   0.7   0.5   0.7   0.7 #> [12,]  0.5  0.7  0.5  0.7  0.5  0.5  0.5  0.5  0.7   0.7   0.7   1.0   0.7   0.5   0.7   0.7 #> [13,]  0.5  0.7  0.5  0.7  0.5  0.5  0.5  0.5  0.7   0.7   0.7   0.7   1.0   0.5   0.7   0.7 #> [14,]  0.7  0.5  0.5  0.5  0.5  0.5  0.7  0.5  0.5   0.5   0.5   0.5   0.5   1.0   0.5   0.5 #> [15,]  0.5  0.7  0.5  0.7  0.5  0.5  0.5  0.5  0.7   0.7   0.7   0.7   0.7   0.5   1.0   0.7 #> [16,]  0.5  0.7  0.5  0.7  0.5  0.5  0.5  0.5  0.7   0.7   0.7   0.7   0.7   0.5   0.7   1.0 #>   ############################################################################  ### see help(dat.ishak2007) for further details on this dataset  dat <- dat.ishak2007 head(dat, 5) #>  #>               study   y1i  v1i   y2i   v2i   y3i v3i  y4i  v4i mdur mbase  #> 1    Alegret (2001) -33.4 14.3    NA    NA    NA  NA <NA> <NA> 16.1  53.6  #> 2 Barichella (2003) -20.0  7.3    NA    NA -30.0 5.7 <NA> <NA> 13.5  45.3  #> 3     Berney (2002) -21.1  7.3    NA    NA    NA  NA <NA> <NA> 13.6  45.6  #> 4   Burchiel (1999) -20.0  8.0 -20.0   8.0 -18.0 5.0 <NA> <NA> 13.6  48.0  #> 5       Chen (2003)    NA   NA -32.9 125.0    NA  NA <NA> <NA> 12.1  65.7  #>   ### create long format dataset dat <- reshape(dat, direction=\"long\", idvar=\"study\", v.names=c(\"yi\",\"vi\"),                varying=list(c(2,4,6,8), c(3,5,7,9))) dat <- dat[order(dat$study, dat$time),]  ### remove missing measurement occasions from dat dat <- dat[!is.na(dat$yi),] rownames(dat) <- NULL  ### show the data for the first 5 studies head(dat, 8) #>  #>               study mdur mbase time    yi    vi  #> 1    Alegret (2001) 16.1  53.6    1 -33.4  14.3  #> 2 Barichella (2003) 13.5  45.3    1 -20.0   7.3  #> 3 Barichella (2003) 13.5  45.3    3 -30.0   5.7  #> 4     Berney (2002) 13.6  45.6    1 -21.1   7.3  #> 5   Burchiel (1999) 13.6  48.0    1 -20.0   8.0  #> 6   Burchiel (1999) 13.6  48.0    2 -20.0   8.0  #> 7   Burchiel (1999) 13.6  48.0    3 -18.0   5.0  #> 8       Chen (2003) 12.1  65.7    2 -32.9 125.0  #>   ### construct the full (block diagonal) V matrix with an AR(1) structure ### assuming an autocorrelation of 0.97 as estimated by Ishak et al. (2007) V <- vcalc(vi, cluster=study, time1=time, phi=0.97, data=dat) V[1:8, 1:8] #>      [,1]     [,2]     [,3] [,4]     [,5]     [,6]     [,7] [,8] #> [1,] 14.3 0.000000 0.000000  0.0 0.000000 0.000000 0.000000    0 #> [2,]  0.0 7.300000 6.069352  0.0 0.000000 0.000000 0.000000    0 #> [3,]  0.0 6.069352 5.700000  0.0 0.000000 0.000000 0.000000    0 #> [4,]  0.0 0.000000 0.000000  7.3 0.000000 0.000000 0.000000    0 #> [5,]  0.0 0.000000 0.000000  0.0 8.000000 7.760000 5.950774    0 #> [6,]  0.0 0.000000 0.000000  0.0 7.760000 8.000000 6.134819    0 #> [7,]  0.0 0.000000 0.000000  0.0 5.950774 6.134819 5.000000    0 #> [8,]  0.0 0.000000 0.000000  0.0 0.000000 0.000000 0.000000  125 cov2cor(V[1:8, 1:8]) #>      [,1]   [,2]   [,3] [,4]   [,5] [,6]   [,7] [,8] #> [1,]    1 0.0000 0.0000    0 0.0000 0.00 0.0000    0 #> [2,]    0 1.0000 0.9409    0 0.0000 0.00 0.0000    0 #> [3,]    0 0.9409 1.0000    0 0.0000 0.00 0.0000    0 #> [4,]    0 0.0000 0.0000    1 0.0000 0.00 0.0000    0 #> [5,]    0 0.0000 0.0000    0 1.0000 0.97 0.9409    0 #> [6,]    0 0.0000 0.0000    0 0.9700 1.00 0.9700    0 #> [7,]    0 0.0000 0.0000    0 0.9409 0.97 1.0000    0 #> [8,]    0 0.0000 0.0000    0 0.0000 0.00 0.0000    1  ### or show as a list of matrices blsplit(V, dat$study)[1:5] #> $`Alegret (2001)` #>      [,1] #> [1,] 14.3 #>  #> $`Barichella (2003)` #>          [,1]     [,2] #> [1,] 7.300000 6.069352 #> [2,] 6.069352 5.700000 #>  #> $`Berney (2002)` #>      [,1] #> [1,]  7.3 #>  #> $`Burchiel (1999)` #>          [,1]     [,2]     [,3] #> [1,] 8.000000 7.760000 5.950774 #> [2,] 7.760000 8.000000 6.134819 #> [3,] 5.950774 6.134819 5.000000 #>  #> $`Chen (2003)` #>      [,1] #> [1,]  125 #>  lapply(blsplit(V, dat$study)[1:5], cov2cor) #> $`Alegret (2001)` #>      [,1] #> [1,]    1 #>  #> $`Barichella (2003)` #>        [,1]   [,2] #> [1,] 1.0000 0.9409 #> [2,] 0.9409 1.0000 #>  #> $`Berney (2002)` #>      [,1] #> [1,]    1 #>  #> $`Burchiel (1999)` #>        [,1] [,2]   [,3] #> [1,] 1.0000 0.97 0.9409 #> [2,] 0.9700 1.00 0.9700 #> [3,] 0.9409 0.97 1.0000 #>  #> $`Chen (2003)` #>      [,1] #> [1,]    1 #>   ############################################################################  ### see help(dat.kalaian1996) for further details on this dataset  dat <- dat.kalaian1996 head(dat, 12) #>    id                 study year n1i n2i outcome    yi     vi  hrs ets homework type #> 1   1 Alderman & Powers (A) 1980  28  22  verbal  0.22 0.0817  7.0   1        1    1 #> 2   2 Alderman & Powers (B) 1980  39  40  verbal  0.09 0.0507 10.0   1        1    1 #> 3   3 Alderman & Powers (C) 1980  22  17  verbal  0.14 0.1045 10.5   1        1    1 #> 4   4 Alderman & Powers (D) 1980  48  43  verbal  0.14 0.0442 10.0   1        1    1 #> 5   5 Alderman & Powers (E) 1980  25  74  verbal -0.01 0.0535  6.0   1        1    1 #> 6   6 Alderman & Powers (F) 1980  37  35  verbal  0.14 0.0557  5.0   1        1    1 #> 7   7 Alderman & Powers (G) 1980  24  70  verbal  0.18 0.0561 11.0   1        1    1 #> 8   8 Alderman & Powers (H) 1980  16  19  verbal  0.01 0.1151 45.0   1        1    1 #> 9   9      Evans & Pike (A) 1973 145 129  verbal  0.13 0.0147 21.0   1        1    1 #> 10 10      Evans & Pike (A) 1973 145 129    math  0.12 0.0147 21.0   1        1    1 #> 11 11      Evans & Pike (B) 1973  72 129  verbal  0.25 0.0218 21.0   1        1    1 #> 12 12      Evans & Pike (B) 1973  72 129    math  0.06 0.0216 21.0   1        1    1  ### construct the variance-covariance matrix assuming rho = 0.66 for effect sizes ### corresponding to the 'verbal' and 'math' outcome types V <- vcalc(vi, cluster=dat$study, type=outcome, data=dat, rho=0.66) round(V[1:12,1:12], 4) #>         [,1]   [,2]   [,3]   [,4]   [,5]   [,6]   [,7]   [,8]   [,9]  [,10]  [,11]  [,12] #>  [1,] 0.0817 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [2,] 0.0000 0.0507 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [3,] 0.0000 0.0000 0.1045 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [4,] 0.0000 0.0000 0.0000 0.0442 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [5,] 0.0000 0.0000 0.0000 0.0000 0.0535 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [6,] 0.0000 0.0000 0.0000 0.0000 0.0000 0.0557 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [7,] 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0561 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [8,] 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.1151 0.0000 0.0000 0.0000 0.0000 #>  [9,] 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0147 0.0097 0.0000 0.0000 #> [10,] 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0097 0.0147 0.0000 0.0000 #> [11,] 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0218 0.0143 #> [12,] 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0143 0.0216  ############################################################################  ### see help(dat.berkey1998) for further details on this dataset  dat <- dat.berkey1998  ### variables v1i and v2i correspond to the 2x2 var-cov matrices of the studies; ### so use these variables to construct the V matrix (note: since v1i and v2i are ### var-cov matrices and not correlation matrices, set vi=1 for all rows) V <- vcalc(vi=1, cluster=author, rvars=c(v1i, v2i), data=dat) V #>         [,1]   [,2]   [,3]  [,4]   [,5]   [,6]   [,7]   [,8]   [,9]  [,10] #>  [1,] 0.0075 0.0030 0.0000 0e+00 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [2,] 0.0030 0.0077 0.0000 0e+00 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [3,] 0.0000 0.0000 0.0057 9e-04 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [4,] 0.0000 0.0000 0.0009 8e-04 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [5,] 0.0000 0.0000 0.0000 0e+00 0.0021 0.0007 0.0000 0.0000 0.0000 0.0000 #>  [6,] 0.0000 0.0000 0.0000 0e+00 0.0007 0.0014 0.0000 0.0000 0.0000 0.0000 #>  [7,] 0.0000 0.0000 0.0000 0e+00 0.0000 0.0000 0.0029 0.0009 0.0000 0.0000 #>  [8,] 0.0000 0.0000 0.0000 0e+00 0.0000 0.0000 0.0009 0.0015 0.0000 0.0000 #>  [9,] 0.0000 0.0000 0.0000 0e+00 0.0000 0.0000 0.0000 0.0000 0.0148 0.0072 #> [10,] 0.0000 0.0000 0.0000 0e+00 0.0000 0.0000 0.0000 0.0000 0.0072 0.0304 round(cov2cor(V), 2) #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] #>  [1,] 1.00 0.39 0.00 0.00 0.00 0.00 0.00 0.00 0.00  0.00 #>  [2,] 0.39 1.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  0.00 #>  [3,] 0.00 0.00 1.00 0.42 0.00 0.00 0.00 0.00 0.00  0.00 #>  [4,] 0.00 0.00 0.42 1.00 0.00 0.00 0.00 0.00 0.00  0.00 #>  [5,] 0.00 0.00 0.00 0.00 1.00 0.41 0.00 0.00 0.00  0.00 #>  [6,] 0.00 0.00 0.00 0.00 0.41 1.00 0.00 0.00 0.00  0.00 #>  [7,] 0.00 0.00 0.00 0.00 0.00 0.00 1.00 0.43 0.00  0.00 #>  [8,] 0.00 0.00 0.00 0.00 0.00 0.00 0.43 1.00 0.00  0.00 #>  [9,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 1.00  0.34 #> [10,] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.34  1.00  ### or show as a list of matrices lapply(blsplit(V, dat$author), function(x) round(cov2cor(x), 2)) #> $`Pihlstrom et al.` #>      [,1] [,2] #> [1,] 1.00 0.39 #> [2,] 0.39 1.00 #>  #> $`Lindhe et al.` #>      [,1] [,2] #> [1,] 1.00 0.42 #> [2,] 0.42 1.00 #>  #> $`Knowles et al.` #>      [,1] [,2] #> [1,] 1.00 0.41 #> [2,] 0.41 1.00 #>  #> $`Ramfjord et al.` #>      [,1] [,2] #> [1,] 1.00 0.43 #> [2,] 0.43 1.00 #>  #> $`Becker et al.` #>      [,1] [,2] #> [1,] 1.00 0.34 #> [2,] 0.34 1.00 #>   ### construct the variance-covariance matrix assuming rho = 0.4 for effect sizes ### corresponding to the 'PD' and 'AL' outcome types V <- vcalc(vi=vi, cluster=trial, type=outcome, data=dat, rho=0.4) round(V,4) #>         [,1]   [,2]   [,3]  [,4]   [,5]   [,6]   [,7]   [,8]   [,9]  [,10] #>  [1,] 0.0075 0.0030 0.0000 0e+00 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [2,] 0.0030 0.0077 0.0000 0e+00 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [3,] 0.0000 0.0000 0.0057 9e-04 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [4,] 0.0000 0.0000 0.0009 8e-04 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #>  [5,] 0.0000 0.0000 0.0000 0e+00 0.0021 0.0007 0.0000 0.0000 0.0000 0.0000 #>  [6,] 0.0000 0.0000 0.0000 0e+00 0.0007 0.0014 0.0000 0.0000 0.0000 0.0000 #>  [7,] 0.0000 0.0000 0.0000 0e+00 0.0000 0.0000 0.0029 0.0008 0.0000 0.0000 #>  [8,] 0.0000 0.0000 0.0000 0e+00 0.0000 0.0000 0.0008 0.0015 0.0000 0.0000 #>  [9,] 0.0000 0.0000 0.0000 0e+00 0.0000 0.0000 0.0000 0.0000 0.0148 0.0085 #> [10,] 0.0000 0.0000 0.0000 0e+00 0.0000 0.0000 0.0000 0.0000 0.0085 0.0304 cov2cor(V) #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] #>  [1,]  1.0  0.4  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0 #>  [2,]  0.4  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0 #>  [3,]  0.0  0.0  1.0  0.4  0.0  0.0  0.0  0.0  0.0   0.0 #>  [4,]  0.0  0.0  0.4  1.0  0.0  0.0  0.0  0.0  0.0   0.0 #>  [5,]  0.0  0.0  0.0  0.0  1.0  0.4  0.0  0.0  0.0   0.0 #>  [6,]  0.0  0.0  0.0  0.0  0.4  1.0  0.0  0.0  0.0   0.0 #>  [7,]  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.4  0.0   0.0 #>  [8,]  0.0  0.0  0.0  0.0  0.0  0.0  0.4  1.0  0.0   0.0 #>  [9,]  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   0.4 #> [10,]  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.4   1.0  ############################################################################  ### see help(dat.knapp2017) for further details on this dataset  dat <- dat.knapp2017 dat[-c(1:2)] #>    study            task difficulty group1 group2 comp    yi    vi n_sz n_hc yi_iq vi_iq #> 1      1    SOC (CANTAB)       3.83     SZ     HC    1  0.62 0.075   24   33  0.72 0.076 #> 2      2    SOC (CANTAB)       3.83    SZ1     HC    1  0.46 0.047   44   44    NA    NA #> 3      2    SOC (CANTAB)       3.83    SZ2     HC    2  0.73 0.052   38   44    NA    NA #> 4      3    SOC (CANTAB)       3.83    SZ1     HC    1  1.18 0.062   39   37    NA    NA #> 5      3    SOC (CANTAB)       3.83    SZ2     HC    2  1.09 0.073   27   37    NA    NA #> 6      3    SOC (CANTAB)       3.83    SZ3     HC    3  0.91 0.102   15   37    NA    NA #> 7      3    SOC (CANTAB)       3.83    SZ4     HC    4  0.91 0.084   20   37    NA    NA #> 8      4             TOH         NA     SZ     HC    1  0.57 0.074   28   28    NA    NA #> 9      5             TOL         NA     SZ     HC    1  0.40 0.180   13   10    NA    NA #> 10     6    SOC (CANTAB)       2.00     SZ     HC    1  0.43 0.170   12   12  0.12 0.167 #> 11     6    SOC (CANTAB)       3.00     SZ     HC    2  1.37 0.206   12   12  0.12 0.167 #> 12     6    SOC (CANTAB)       4.00     SZ     HC    3  0.23 0.168   12   12  0.12 0.167 #> 13     6    SOC (CANTAB)       5.00     SZ     HC    4  0.97 0.186   12   12  0.12 0.167 #> 14     6 SOC (one-touch)       2.00     SZ     HC    5  0.56 0.173   12   12  0.12 0.167 #> 15     6 SOC (one-touch)       3.00     SZ     HC    6  0.79 0.180   12   12  0.12 0.167 #> 16     6 SOC (one-touch)       4.00     SZ     HC    7  1.19 0.196   12   12  0.12 0.167 #> 17     6 SOC (one-touch)       5.00     SZ     HC    8  0.92 0.184   12   12  0.12 0.167 #> 18     7             SOC       3.50     SZ     HC    1  0.20 0.096   22   20  0.62 0.100 #> 19     8             TOH         NA     SZ     HC    1  1.42 0.180   13   15    NA    NA #> 20     9             TOL       4.00    SZ1     HC    1  0.35 0.074   27   28  1.21 0.086 #> 21     9             TOL       4.00    SZ2     HC    2  0.88 0.078   28   28  1.26 0.086 #> 22    10    SOC (CANTAB)       3.83     SZ     HC    1  1.08 0.079   26   33  0.76 0.074 #> 23    11    SOC (CANTAB)       3.83     SZ     HC    1  0.94 0.111   20   20  0.42 0.102 #> 24    12    SOC (CANTAB)       2.00     SZ     HC    1  0.44 0.020  135   81  0.49 0.020 #> 25    12    SOC (CANTAB)       3.00     SZ     HC    2  0.63 0.021  135   81  0.49 0.020 #> 26    12    SOC (CANTAB)       4.00     SZ     HC    3  0.38 0.020  135   81  0.49 0.020 #> 27    12    SOC (CANTAB)       5.00     SZ     HC    4  0.93 0.022  135   81  0.49 0.020 #> 28    13             TOL         NA     SZ     HC    1  0.33 0.102   24   17    NA    NA #> 29    14             TOL       2.00     SZ     HC    1  0.00 0.073   32   24    NA    NA #> 30    14             TOL       3.00     SZ     HC    2 -0.06 0.073   32   24    NA    NA #> 31    14             TOL       4.00     SZ     HC    3  0.73 0.078   32   24    NA    NA #> 32    14             TOL       5.00     SZ     HC    4  0.48 0.075   32   24    NA    NA #> 33    15             TOL       2.00     SZ     HC    1  0.43 0.092   25   20    NA    NA #> 34    15             TOL       3.00     SZ     HC    2  0.72 0.096   25   20    NA    NA #> 35    15             TOL       4.00     SZ     HC    3  0.80 0.097   25   20    NA    NA #> 36    15             TOL       5.00     SZ     HC    4  1.30 0.109   25   20    NA    NA #> 37    16             TOL       4.67     SZ     HC    1  1.84 0.190   15   15    NA    NA #> 38    17             TOL       3.50     SZ     HC    1  2.58 0.216   17   17  0.58 0.123 #> 39    18             TOL       3.00     SZ     HC    1  0.25 0.071   30   27  0.18 0.071 #> 40    18             TOL       4.00     SZ     HC    2  0.86 0.077   30   27  0.18 0.071 #> 41    18             TOL       5.00     SZ     HC    3  0.68 0.074   30   27  0.18 0.071 #> 42    19    SOC (CANTAB)       2.00     SZ     HC    1  0.21 0.060   36   31  0.48 0.062 #> 43    19    SOC (CANTAB)       3.00     SZ     HC    2  0.65 0.063   36   31  0.48 0.062 #> 44    19    SOC (CANTAB)       4.00     SZ     HC    3  0.30 0.061   36   31  0.48 0.062 #> 45    19    SOC (CANTAB)       5.00     SZ     HC    4  0.45 0.062   36   31  0.48 0.062 #> 46    20          BACS-J         NA    SZ1     HC    1  1.03 0.054   20  340    NA    NA #> 47    20          BACS-J         NA    SZ2     HC    2  0.92 0.104   10  340    NA    NA #> 48    21    SOC (CANTAB)       3.83     SZ     HC    1  1.12 0.108   28   17    NA    NA #> 49    22             TOL       2.00     SZ     HC    1  0.52 0.052   40   40    NA    NA #> 50    22             TOL       3.00     SZ     HC    2  0.50 0.052   40   40    NA    NA #> 51    22             TOL       4.00     SZ     HC    3  0.49 0.051   40   40    NA    NA #> 52    23             SOC       3.83     SZ     HC    1  0.30 0.042   48   48    NA    NA #> 53    24      TOL-Drexel       5.50    SZ1    HC1    1  0.36 0.022   86   97  0.47 0.023 #> 54    24      TOL-Drexel       5.50    SZ2    HC2    2  0.41 0.030   75   62  0.10 0.030 #> 55    25             SOC       3.83     SZ     HC    1  0.79 0.086   25   25    NA    NA #> 56    26             SOC       2.00     SZ     HC    1  0.23 0.031   77   55    NA    NA #> 57    26             SOC       3.00     SZ     HC    2  0.58 0.032   77   55    NA    NA #> 58    26             SOC       4.00     SZ     HC    3  0.57 0.032   77   55    NA    NA #> 59    26             SOC       5.00     SZ     HC    4  0.79 0.034   77   55    NA    NA #> 60    27      TOL-Drexel       5.50     SZ     HC    1  0.70 0.071   30   30    NA    NA #> 61    28             SOC       3.83     SZ     HC    1  1.16 0.136   20   15  0.23 0.117 #> 62    29          BACS-J         NA    SZ1    HC1    1  1.29 0.039   56   68  0.37 0.033 #> 63    29          BACS-J         NA    SZ2    HC2    2  0.63 0.039   47   62  0.43 0.038 #> 64    29          BACS-J         NA    SZ3    HC3    3  0.31 0.121   15   19  1.00 0.134 #> 65    30             TOL       3.83     SZ     HC    1  0.11 0.070   30   27    NA    NA #> 66    31 TOL (four-disk)       5.60     SZ     HC    1  0.87 0.036   60   60    NA    NA  ### create variable that indicates the task and difficulty combination as increasing integers dat$task.diff <- unlist(lapply(split(dat, dat$study), function(x) {    task.int <- as.integer(factor(x$task))    diff.int <- as.integer(factor(x$difficulty))    diff.int[is.na(diff.int)] <- 1    paste0(task.int, \".\", diff.int)}))  ### construct correlation matrix for two tasks with four different difficulties where the ### correlation is 0.4 for different difficulties of the same task, 0.7 for the same ### difficulty of different tasks, and 0.28 for different difficulties of different tasks R <- matrix(0.4, nrow=8, ncol=8) R[5:8,1:4] <- R[1:4,5:8] <- 0.28 diag(R[1:4,5:8]) <- 0.7 diag(R[5:8,1:4]) <- 0.7 diag(R) <- 1 rownames(R) <- colnames(R) <- paste0(rep(1:2, each=4), \".\", 1:4) R #>      1.1  1.2  1.3  1.4  2.1  2.2  2.3  2.4 #> 1.1 1.00 0.40 0.40 0.40 0.70 0.28 0.28 0.28 #> 1.2 0.40 1.00 0.40 0.40 0.28 0.70 0.28 0.28 #> 1.3 0.40 0.40 1.00 0.40 0.28 0.28 0.70 0.28 #> 1.4 0.40 0.40 0.40 1.00 0.28 0.28 0.28 0.70 #> 2.1 0.70 0.28 0.28 0.28 1.00 0.40 0.40 0.40 #> 2.2 0.28 0.70 0.28 0.28 0.40 1.00 0.40 0.40 #> 2.3 0.28 0.28 0.70 0.28 0.40 0.40 1.00 0.40 #> 2.4 0.28 0.28 0.28 0.70 0.40 0.40 0.40 1.00  ### construct an approximate V matrix accounting for the use of shared groups and ### for correlations among tasks/difficulties as specified in the R matrix above V <- vcalc(vi, cluster=study, grp1=group1, grp2=group2, w1=n_sz, w2=n_hc,            obs=task.diff, rho=R, data=dat) Vs <- blsplit(V, dat$study) cov2cor(Vs[[3]])  # study with multiple SZ groups and a single HC group #>           [,1]      [,2]      [,3]      [,4] #> [1,] 1.0000000 0.4652832 0.3847419 0.4243294 #> [2,] 0.4652832 1.0000000 0.3488477 0.3847419 #> [3,] 0.3847419 0.3488477 1.0000000 0.3181424 #> [4,] 0.4243294 0.3847419 0.3181424 1.0000000 cov2cor(Vs[[6]])  # study with two task types and multiple difficulties #>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] #> [1,] 1.00 0.40 0.40 0.40 0.70 0.28 0.28 0.28 #> [2,] 0.40 1.00 0.40 0.40 0.28 0.70 0.28 0.28 #> [3,] 0.40 0.40 1.00 0.40 0.28 0.28 0.70 0.28 #> [4,] 0.40 0.40 0.40 1.00 0.28 0.28 0.28 0.70 #> [5,] 0.70 0.28 0.28 0.28 1.00 0.40 0.40 0.40 #> [6,] 0.28 0.70 0.28 0.28 0.40 1.00 0.40 0.40 #> [7,] 0.28 0.28 0.70 0.28 0.40 0.40 1.00 0.40 #> [8,] 0.28 0.28 0.28 0.70 0.40 0.40 0.40 1.00 cov2cor(Vs[[12]]) # study with multiple difficulties for the same task #>      [,1] [,2] [,3] [,4] #> [1,]  1.0  0.4  0.4  0.4 #> [2,]  0.4  1.0  0.4  0.4 #> [3,]  0.4  0.4  1.0  0.4 #> [4,]  0.4  0.4  0.4  1.0 cov2cor(Vs[[24]]) # study with separate rows for males and females #>      [,1] [,2] #> [1,]    1    0 #> [2,]    0    1 cov2cor(Vs[[29]]) # study with separate rows for three genotypes #>      [,1] [,2] [,3] #> [1,]    1    0    0 #> [2,]    0    1    0 #> [3,]    0    0    1  ############################################################################"},{"path":"/reference/vcov.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Various Types of Variance-Covariance Matrices from 'rma' Objects — vcov.rma","title":"Extract Various Types of Variance-Covariance Matrices from 'rma' Objects — vcov.rma","text":"function extracts various types variance-covariance matrices objects class \"rma\". default, variance-covariance matrix parameter estimates (fixed effects) returned.","code":""},{"path":"/reference/vcov.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Various Types of Variance-Covariance Matrices from 'rma' Objects — vcov.rma","text":"","code":"# S3 method for rma vcov(object, type=\"fixed\", ...)"},{"path":"/reference/vcov.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Various Types of Variance-Covariance Matrices from 'rma' Objects — vcov.rma","text":"object object class \"rma\". type character string specify type variance-covariance matrix return: type=\"fixed\" returns variance-covariance matrix fixed effects (default), type=\"obs\" returns marginal variance-covariance matrix observed effect sizes outcomes, type=\"fitted\" returns variance-covariance matrix fitted values, type=\"resid\" returns variance-covariance matrix residuals. ... arguments.","code":""},{"path":"/reference/vcov.rma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Various Types of Variance-Covariance Matrices from 'rma' Objects — vcov.rma","text":"Note type=\"obs\" currently works object class \"rma.uni\" \"rma.mv\". objects class \"rma.uni\", marginal variance-covariance matrix observed effect sizes outcomes just diagonal matrix \\(\\hat{\\tau}^2 + v_i\\) along diagonal, \\(\\hat{\\tau}^2\\) estimated amount (residual) heterogeneity (set 0 equal-effects models) \\(v_i\\) sampling variance \\(\\textrm{th}\\) study. objects class \"rma.mv\", structure can complex depends random effects included model.","code":""},{"path":"/reference/vcov.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Various Types of Variance-Covariance Matrices from 'rma' Objects — vcov.rma","text":"matrix corresponding requested variance-covariance matrix.","code":""},{"path":"/reference/vcov.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract Various Types of Variance-Covariance Matrices from 'rma' Objects — vcov.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/vcov.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract Various Types of Variance-Covariance Matrices from 'rma' Objects — vcov.rma","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/vcov.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Various Types of Variance-Covariance Matrices from 'rma' Objects — vcov.rma","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit mixed-effects model with absolute latitude and publication year as moderators res <- rma(yi, vi, mods = ~ ablat + year, data=dat)  ### var-cov matrix of the fixed effects (i.e., the model coefficients) vcov(res) #>             intrcpt         ablat          year #> intrcpt 846.5702228 -0.1783751581 -0.4272176864 #> ablat    -0.1783752  0.0001047356  0.0000889397 #> year     -0.4272177  0.0000889397  0.0002156144  ### marginal var-cov matrix of the observed log risk ratios round(vcov(res, type=\"obs\"), 3) #>        1     2     3     4     5     6     7     8     9    10    11    12    13 #> 1  0.436 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 #> 2  0.000 0.305 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 #> 3  0.000 0.000 0.526 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 #> 4  0.000 0.000 0.000 0.131 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 #> 5  0.000 0.000 0.000 0.000 0.162 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 #> 6  0.000 0.000 0.000 0.000 0.000 0.118 0.000 0.000 0.000 0.000 0.000 0.000 0.000 #> 7  0.000 0.000 0.000 0.000 0.000 0.000 0.334 0.000 0.000 0.000 0.000 0.000 0.000 #> 8  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.115 0.000 0.000 0.000 0.000 0.000 #> 9  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.167 0.000 0.000 0.000 0.000 #> 10 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.184 0.000 0.000 0.000 #> 11 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.123 0.000 0.000 #> 12 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.643 0.000 #> 13 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.182  ### var-cov matrix of the fitted values round(vcov(res, type=\"fitted\"), 3) #>         1      2      3      4      5      6      7      8     9     10     11    12     13 #> 1   0.075  0.066  0.037 -0.024  0.009  0.059  0.006 -0.014 0.018  0.034  0.003 0.012 -0.011 #> 2   0.066  0.072  0.040  0.011 -0.009  0.056 -0.004 -0.023 0.012  0.038 -0.007 0.014  0.000 #> 3   0.037  0.040  0.026  0.014  0.004  0.032  0.006 -0.002 0.013  0.025  0.005 0.015  0.008 #> 4  -0.024  0.011  0.014  0.106 -0.022 -0.006 -0.005  0.003 0.000  0.018 -0.004 0.021  0.047 #> 5   0.009 -0.009  0.004 -0.022  0.040  0.006  0.031  0.036 0.022  0.004  0.032 0.012  0.008 #> 6   0.059  0.056  0.032 -0.006  0.006  0.048  0.005 -0.010 0.016  0.030  0.003 0.013 -0.002 #> 7   0.006 -0.004  0.006 -0.005  0.031  0.005  0.026  0.030 0.019  0.006  0.026 0.013  0.012 #> 8  -0.014 -0.023 -0.002  0.003  0.036 -0.010  0.030  0.042 0.019 -0.001  0.032 0.014  0.020 #> 9   0.018  0.012  0.013  0.000  0.022  0.016  0.019  0.019 0.017  0.013  0.019 0.014  0.010 #> 10  0.034  0.038  0.025  0.018  0.004  0.030  0.006 -0.001 0.013  0.024  0.005 0.015  0.010 #> 11  0.003 -0.007  0.005 -0.004  0.032  0.003  0.026  0.032 0.019  0.005  0.027 0.013  0.013 #> 12  0.012  0.014  0.015  0.021  0.012  0.013  0.013  0.014 0.014  0.015  0.013 0.015  0.017 #> 13 -0.011  0.000  0.008  0.047  0.008 -0.002  0.012  0.020 0.010  0.010  0.013 0.017  0.029  ### var-cov matrix of the residuals round(vcov(res, type=\"resid\"), 3) #>         1      2      3      4      5      6      7      8      9     10     11     12     13 #> 1   0.361 -0.066 -0.037  0.024 -0.009 -0.059 -0.006  0.014 -0.018 -0.034 -0.003 -0.012  0.011 #> 2  -0.066  0.233 -0.040 -0.011  0.009 -0.056  0.004  0.023 -0.012 -0.038  0.007 -0.014  0.000 #> 3  -0.037 -0.040  0.501 -0.014 -0.004 -0.032 -0.006  0.002 -0.013 -0.025 -0.005 -0.015 -0.008 #> 4   0.024 -0.011 -0.014  0.025  0.022  0.006  0.005 -0.003  0.000 -0.018  0.004 -0.021 -0.047 #> 5  -0.009  0.009 -0.004  0.022  0.122 -0.006 -0.031 -0.036 -0.022 -0.004 -0.032 -0.012 -0.008 #> 6  -0.059 -0.056 -0.032  0.006 -0.006  0.070 -0.005  0.010 -0.016 -0.030 -0.003 -0.013  0.002 #> 7  -0.006  0.004 -0.006  0.005 -0.031 -0.005  0.308 -0.030 -0.019 -0.006 -0.026 -0.013 -0.012 #> 8   0.014  0.023  0.002 -0.003 -0.036  0.010 -0.030  0.073 -0.019  0.001 -0.032 -0.014 -0.020 #> 9  -0.018 -0.012 -0.013  0.000 -0.022 -0.016 -0.019 -0.019  0.150 -0.013 -0.019 -0.014 -0.010 #> 10 -0.034 -0.038 -0.025 -0.018 -0.004 -0.030 -0.006  0.001 -0.013  0.160 -0.005 -0.015 -0.010 #> 11 -0.003  0.007 -0.005  0.004 -0.032 -0.003 -0.026 -0.032 -0.019 -0.005  0.096 -0.013 -0.013 #> 12 -0.012 -0.014 -0.015 -0.021 -0.012 -0.013 -0.013 -0.014 -0.014 -0.015 -0.013  0.628 -0.017 #> 13  0.011  0.000 -0.008 -0.047 -0.008  0.002 -0.012 -0.020 -0.010 -0.010 -0.013 -0.017  0.153"},{"path":"/reference/vec2mat.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a Vector into a Square Matrix — vec2mat","title":"Convert a Vector into a Square Matrix — vec2mat","text":"Function convert vector square matrix filling lower triangular part matrix.","code":""},{"path":"/reference/vec2mat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a Vector into a Square Matrix — vec2mat","text":"","code":"vec2mat(x, diag=FALSE, corr=!diag, dimnames)"},{"path":"/reference/vec2mat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a Vector into a Square Matrix — vec2mat","text":"x vector correct length. diag logical specify whether vector also contains diagonal values lower triangular part matrix (default FALSE). corr logical specify whether diagonal matrix replaced 1's (default diag=FALSE). dimnames optional vector correct length dimension names matrix.","code":""},{"path":"/reference/vec2mat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert a Vector into a Square Matrix — vec2mat","text":"values x filled lower triangular part square matrix appropriate dimensions (determined based length x). diag=TRUE, x assumed also contain diagonal values lower triangular part matrix. corr=TRUE, diagonal matrix replaced 1's.","code":""},{"path":"/reference/vec2mat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a Vector into a Square Matrix — vec2mat","text":"matrix.","code":""},{"path":"/reference/vec2mat.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert a Vector into a Square Matrix — vec2mat","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/vec2mat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a Vector into a Square Matrix — vec2mat","text":"","code":"vec2mat(1:6, corr=FALSE) #>      [,1] [,2] [,3] [,4] #> [1,]   NA    1    2    3 #> [2,]    1   NA    4    5 #> [3,]    2    4   NA    6 #> [4,]    3    5    6   NA vec2mat(seq(0.2, 0.7, by=0.1), corr=TRUE) #>      [,1] [,2] [,3] [,4] #> [1,]  1.0  0.2  0.3  0.4 #> [2,]  0.2  1.0  0.5  0.6 #> [3,]  0.3  0.5  1.0  0.7 #> [4,]  0.4  0.6  0.7  1.0 vec2mat(1:10, diag=TRUE) #>      [,1] [,2] [,3] [,4] #> [1,]    1    2    3    4 #> [2,]    2    5    6    7 #> [3,]    3    6    8    9 #> [4,]    4    7    9   10 vec2mat(1:6, corr=FALSE, dimnames=c(\"A\",\"B\",\"C\",\"D\")) #>    A  B  C  D #> A NA  1  2  3 #> B  1 NA  4  5 #> C  2  4 NA  6 #> D  3  5  6 NA"},{"path":"/reference/vif.html","id":null,"dir":"Reference","previous_headings":"","what":"Variance Inflation Factors for 'rma' Objects — vif","title":"Variance Inflation Factors for 'rma' Objects — vif","text":"Compute variance inflation factors (VIFs) objects class \"rma\".","code":""},{"path":"/reference/vif.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variance Inflation Factors for 'rma' Objects — vif","text":"","code":"vif(x, ...)  # S3 method for rma vif(x, btt, intercept=FALSE, table=FALSE, digits, ...)  # S3 method for vif.rma print(x, digits=x$digits, ...)"},{"path":"/reference/vif.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variance Inflation Factors for 'rma' Objects — vif","text":"x object class \"rma\" (vif) \"vif.rma\" (print). btt optional vector indices specify set coefficients generalized variance inflation factor (GVIF) computed. Can also string grep . See ‘Details’. intercept logical specify whether include intercept (model includes one) computation VIFs (default FALSE). See ‘Note’. table logical specify whether VIFs added model coefficient table (default FALSE). digits optional integer specify number decimal places printed results rounded. unspecified, default take value object. ... arguments.","code":""},{"path":"/reference/vif.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Variance Inflation Factors for 'rma' Objects — vif","text":"function computes variance inflation factors (VIFs) meta-regression models. Hence, model specified via argument x must include moderator variables (one useful, VIF model single moderator variable always equal 1). Let \\(b_j\\) denote estimate \\(j\\textrm{th}\\) model coefficient particular meta-regression model \\(\\mbox{Var}[b_j]\\) variance (.e., corresponding diagonal element matrix obtained vcov function). Moreover, let \\(b'_j\\) denote estimate model coefficient moderator variables model included model \\(\\mbox{Var}[b'_j]\\) corresponding variance. VIF model coefficient given \\[\\mbox{VIF}[b_j] = \\frac{\\mbox{Var}[b_j]}{\\mbox{Var}[b'_j]},\\] indicates inflation variance estimated model coefficient due potential collinearity \\(j\\textrm{th}\\) moderator variable moderator variables model. Taking square root VIF gives corresponding standard error inflation factor (SIF). btt specified, VIF computed individual model coefficient. However, model includes factors (coded terms multiple dummy variables) sets moderator variables belong together (e.g., polynomials cubic splines), one may want examine much variance coefficients set jointly impacted collinearity moderator variables model. , can compute generalized variance inflation factor (GVIF) (Fox & Monette, 1992) setting btt argument equal indices coefficients GVIF computed. square root GVIF indicates inflation confidence ellipse/(hyper)ellipsoid set coefficients corresponding set due collinearity. However, make value directly comparable SIFs (based single coefficients) set includes different number coefficients, function computes generalized standard error inflation factor (GSIF) raising GVIF power \\(1/(2m)\\) (\\(m\\) denotes number coefficients set).","code":""},{"path":"/reference/vif.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Variance Inflation Factors for 'rma' Objects — vif","text":"btt specified, either vector (table=FALSE) VIFs data frame (table=TRUE) following elements: estimate estimated model coefficients. se corresponding standard errors. zval corresponding test statistics. pval corresponding p-values. ci.lb corresponding lower bound confidence intervals. ci.ub corresponding upper bound confidence intervals. vif corresponding variance inflation factors. sif corresponding standard error inflation factors. btt specified, list elements gvif gsif GVIF GSIF values set coefficients specified.","code":""},{"path":"/reference/vif.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Variance Inflation Factors for 'rma' Objects — vif","text":"values (G)VIFs invariant scaling predictor variables model includes intercept removed inverting correlation matrix model coefficients compute (G)VIFs. default behavior. See ‘Examples’.","code":""},{"path":"/reference/vif.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Variance Inflation Factors for 'rma' Objects — vif","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/vif.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Variance Inflation Factors for 'rma' Objects — vif","text":"Belsley, D. ., Kuh, E., & Welsch, R. E. (1980). Regression diagnostics. New York: Wiley. Fox, J., & Monette, G. (1992). Generalized collinearity diagnostics. Journal American Statistical Association, 87(417), 178-183. https://doi.org/10.2307/2290467 Stewart, G. W. (1987). Collinearity least squares regression. Statistical Science, 2(1), 68-84. https://doi.org/10.1214/ss/1177013439 Wax, Y. (1992). Collinearity diagnosis relative risk regression-analysis: application assessment diet cancer relationship epidemiologic studies. Statistics Medicine, 11(10), 1273--1287. https://doi.org/10.1002/sim.4780111003 Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/vif.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Variance Inflation Factors for 'rma' Objects — vif","text":"","code":"### copy data from Bangert-Drowns et al. (2004) into 'dat' dat <- dat.bangertdrowns2004  ### fit mixed-effects meta-regression model res <- rma(yi, vi, mods = ~ length + wic + feedback + info + pers + imag + meta, data=dat) #> Warning: Studies with NAs omitted from model fitting.  ### get variance inflation factors vif(res) #>  #>   length      wic feedback     info     pers     imag     meta  #>   1.5371   1.3860   1.6490   1.8340   5.6780   1.1554   4.5333  #>   ### show that VIFs are not influenced by scaling of the predictors u <- scale # to standardize the predictors res <- rma(yi, vi, mods = ~ u(length) + u(wic) + u(feedback) + u(info) +                             u(pers) + u(imag) + u(meta), data=dat) #> Warning: Studies with NAs omitted from model fitting. vif(res) #>  #>   u(length)      u(wic) u(feedback)     u(info)     u(pers)     u(imag)     u(meta)  #>      1.5371      1.3860      1.6490      1.8340      5.6780      1.1554      4.5333  #>   ### get full table vif(res, table=TRUE) #>  #>              estimate      se     zval    pval    ci.lb   ci.ub     vif     sif  #> intrcpt        0.1825  0.0406   4.4898  <.0001   0.1028  0.2621      NA      NA  #> u(length)      0.0458  0.0496   0.9240  0.3555  -0.0514  0.1431  1.5371  1.2398  #> u(wic)        -0.0210  0.0487  -0.4308  0.6666  -0.1164  0.0744  1.3860  1.1773  #> u(feedback)    0.0329  0.0524   0.6265  0.5310  -0.0699  0.1357  1.6490  1.2842  #> u(info)       -0.0460  0.0418  -1.1006  0.2711  -0.1280  0.0360  1.8340  1.3542  #> u(pers)       -0.0573  0.0956  -0.5992  0.5490  -0.2446  0.1301  5.6780  2.3829  #> u(imag)        0.1004  0.0452   2.2233  0.0262   0.0119  0.1890  1.1554  1.0749  #> u(meta)        0.0981  0.0850   1.1537  0.2486  -0.0685  0.2647  4.5333  2.1291  #>   ### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit meta-regression model where one predictor (alloc) is a three-level factor res <- rma(yi, vi, mods = ~ ablat + alloc, data=dat)  ### get variance inflation factors for all individual coefficients vif(res, table=TRUE) #>  #>                  estimate      se     zval    pval    ci.lb    ci.ub     vif     sif  #> intrcpt            0.2932  0.4050   0.7239  0.4691  -0.5006   1.0870      NA      NA  #> ablat             -0.0273  0.0092  -2.9650  0.0030  -0.0453  -0.0092  1.0151  1.0075  #> allocrandom       -0.2675  0.3504  -0.7633  0.4453  -0.9543   0.4193  1.7224  1.3124  #> allocsystematic    0.0585  0.3795   0.1540  0.8776  -0.6854   0.8023  1.7111  1.3081  #>   ### generalized variance inflation factor for the 'alloc' factor vif(res, btt=3:4) #>  #> Collinearity Diagnostics (coefficients 3:4): #> GVIF = 1.0151, GSIF = 1.0038 #>   ### can also specify a string to grep for vif(res, btt=\"alloc\") #>  #> Collinearity Diagnostics (coefficients 3:4): #> GVIF = 1.0151, GSIF = 1.0038 #>"},{"path":"/reference/weights.rma.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Weights for 'rma' Objects — weights.rma","title":"Compute Weights for 'rma' Objects — weights.rma","text":"function computes weights given observed effect sizes outcomes model fitting objects class \"rma.uni\", \"rma.mh\", \"rma.peto\", \"rma.mv\".","code":""},{"path":"/reference/weights.rma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Weights for 'rma' Objects — weights.rma","text":"","code":"# S3 method for rma.uni weights(object, type=\"diagonal\", ...) # S3 method for rma.mh weights(object, type=\"diagonal\", ...) # S3 method for rma.peto weights(object, type=\"diagonal\", ...) # S3 method for rma.glmm weights(object, ...) # S3 method for rma.mv weights(object, type=\"diagonal\", ...)"},{"path":"/reference/weights.rma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Weights for 'rma' Objects — weights.rma","text":"object object class \"rma.uni\", \"rma.mh\", \"rma.peto\", \"rma.mv\". method yet implemented objects class \"rma.glmm\". type character string specify whether return diagonal weight matrix (\"diagonal\") entire weight matrix (\"matrix\"). \"rma.mv\", can also \"rowsum\" ‘row-sum weights’ (intercept-models). ... arguments.","code":""},{"path":"/reference/weights.rma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Weights for 'rma' Objects — weights.rma","text":"Either vector diagonal elements weight matrix entire weight matrix. diagonal elements returned, given % (add 100%).    entire weight matrix requested, always diagonal matrix objects class \"rma.uni\", \"rma.mh\", \"rma.peto\".    \"rma.mv\", structure weight matrix depends model fitted (.e., random effects included variance-covariance matrix sampling errors) often complex just diagonal.    \"rma.mv\" intercept-models, one can also take sum rows weight matrix, actually weights assigned observed effect sizes outcomes estimating model intercept. weights can obtained type=\"rowsum\" (type=\"diagonal\", also given %).","code":""},{"path":"/reference/weights.rma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute Weights for 'rma' Objects — weights.rma","text":"Wolfgang Viechtbauer wvb@metafor-project.org https://www.metafor-project.org","code":""},{"path":"/reference/weights.rma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute Weights for 'rma' Objects — weights.rma","text":"Viechtbauer, W. (2010). Conducting meta-analyses R metafor package. Journal Statistical Software, 36(3), 1--48. https://doi.org/10.18637/jss.v036.i03","code":""},{"path":[]},{"path":"/reference/weights.rma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Weights for 'rma' Objects — weights.rma","text":"","code":"### calculate log risk ratios and corresponding sampling variances dat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)  ### fit mixed-effects model with absolute latitude and publication year as moderators res <- rma(yi, vi, mods = ~ ablat + year, data=dat)  ### extract the model fitting weights (in %) weights(res) #>         1         2         3         4         5         6         7         8         9        10  #>  3.366420  4.810621  2.791974 11.231203  9.068114 12.481731  4.400814 12.801967  8.784824  7.991920  #>        11        12        13  #> 11.923841  2.283581  8.062988   ### extract the weight matrix round(weights(res, type=\"matrix\"), 4) #>         1      2      3      4      5      6      7      8      9     10     11     12     13 #> 1  2.2916 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #> 2  0.0000 3.2747 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #> 3  0.0000 0.0000 1.9006 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #> 4  0.0000 0.0000 0.0000 7.6454 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #> 5  0.0000 0.0000 0.0000 0.0000 6.1729 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #> 6  0.0000 0.0000 0.0000 0.0000 0.0000 8.4967 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #> 7  0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 2.9958 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #> 8  0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 8.7147 0.0000 0.0000 0.0000 0.0000 0.0000 #> 9  0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 5.9801 0.0000 0.0000 0.0000 0.0000 #> 10 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 5.4403 0.0000 0.0000 0.0000 #> 11 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 8.1169 0.0000 0.0000 #> 12 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 1.5545 0.0000 #> 13 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 5.4887"},{"path":"/news/index.html","id":"metafor-31-36-2021-11-30","dir":"Changelog","previous_headings":"","what":"metafor 3.1-36 (2021-11-30)","title":"metafor 3.1-36 (2021-11-30)","text":"added misc-models misc-options help pages simplified regtest(), ranktest(), tes() single functions instead using generics methods; way, data argument added added vcalc() blsplit() functions robust() gains clubSandwich argument; set TRUE, methods clubSandwich package (https://cran.r-project.org/package=clubSandwich) used obtain cluster-robust results results robust() longer printed print.robust.rma() print methods print.rma.uni() print.rma.mv() anova() now gives warning running LRTs based ML/REML estimation setting dfs=\"contain\" rma.mv() automatically sets test=\"t\" elements rho phi rma.mv() now based lower triangular part respective correlation matrix (instead upper triangular part) consistency functions; note principle backwards incompatible change, although concern special circumstances rma.mv() gains cvvc argument (calculating var-cov matrix variance/correlation/covariance components) added measure \"MPORM\" escalc() computing marginal log odds ratios based marginal 2x2 tables directly (requires specification correlation coefficients paired tables calculation sampling variances via ri argument) aggregate.escalc() gains checkpd argument struct=\"CS+CAR\" rma.glmm() now entire array optimizers available model=\"CM.EL\" measure=\"\"; switched default optim() method BFGS nlminb() consistency rma.mv(), rma.uni(), selmodel.rma.uni() rma.glmm() gains coding cor arguments hence flexibility group variable coded random effects structure whether random study effects allowed correlated random group effects rma.uni() now also provides R^2 fixed-effects models matreg() can now also analyze covariance matrix corresponding V matrix renamed argument nearPD nearpd matreg() (nearPD continues work) plot.profile.rma() gains refline argument addpoly.default() addpoly.rma() gain lty argument fixed level argument addpoly.rma() affect CI width points.regplot() function now also redraws labels (begin ) added lbfgsb3c, subplex, BBoptim possible optimizer rma.mv(), rma.glmm(), rma.uni(), selmodel.rma.uni() datasets moved metadat package (https://cran.r-project.org/package=metadat) improved documentation bit","code":""},{"path":"/news/index.html","id":"metafor-30-2-2021-06-09","dir":"Changelog","previous_headings":"","what":"metafor 3.0-2 (2021-06-09)","title":"metafor 3.0-2 (2021-06-09)","text":"CRAN release: 2021-06-09 metafor package now makes use mathjaxr package nicely render equations shown HTML help pages rma() can now also fit location-scale models added selmodel() fitting wide variety selection models (added corresponding plot.rma.uni.selmodel() function drawing estimated selection function) rma.mv() gains dfs argument now provides often better way calculating (denominator) degrees freedom approximate t- F-tests dfs=\"contain\" added tes() function test excess significance added regplot() function drawing scatter plots / bubble plots based meta-regression models added rcalc() calculating variance-covariance matrix correlation coefficients matreg() fitting regression models based correlation/covariance matrices added convenience functions dfround() vec2mat() added aggregate.escalc() function aggregate multiple effect sizes outcomes within studies/clusters regtest() now shows ‘limit estimate’ (average) true effect using sei, vi, ninv, sqrtninv predictors (model contain moderators) vif() gains btt argument can now also compute generalized variance inflation factors; proper print.vif.rma() function also added anova.rma() argument L renamed X (former still works, longer documented) argument order cumul() now just variable, order variable, used ordering studies must length original dataset used model fitting similarly, vector arguments various plotting functions forest.rma() must now length original dataset used model fitting (subsetting removal NAs automatically applied) various leave1out() cumul() functions now provide ^2 H^2 also fixed-effects models; accordingly, plot.cumul.rma() now also works models fixed level getting passed various cumul() functions plot.cumul.rma() argument addgrid renamed grid (former still works, longer documented) forest.default(), forest.rma(), labbe() gain plim argument now provide flexibility terms scaling points forest.rma() gains colout argument (adjust color observed effect sizes outcomes) various forest() functions, right header now suppressed annotate=FALSE header=TRUE funnel.default() funnel.rma() gain label offset arguments funnel.default() funnel.rma() gain lty argument; reference line now drawn default dotted line (like line pseudo confidence region) forest funnel arguments reporter.rma.uni() can now also logicals suppress drawing plots added weighted argument fsn() (Orwin’s method) added transformation functions bldiag() now properly handles ?x0 0x? matrices p-values still given 2 digits even digits=1 summary.escalc() also provides p-values (Wald-type tests); using transf argument, sampling variances, standard errors, test statistics, p-values longer shown rma.uni() longer constrains fixed tau^2 value 0 k=1 slight speedup functions repeatedly fit rma.uni() models skipping computation pseudo R^2 statistic started using pbapply package showing progress bars, also using parallel processing avoid potential confusion, references ‘credibility intervals’ removed documentation; intervals now exclusively referred ‘prediction intervals’; output, bounds therefore indicated now pi.lb pi.ub (instead cr.lb cr.ub); corresponding argument names changed addpoly.default(); argument addcred changed addpred addpoly.rma() forest.rma(); however, code using old arguments names continue work one can now use weights(...,  type=\"rowsum\") intercept-rma.mv models (obtain ‘row-sum weights’) simulate.rma() gains olim argument; renamed clim argument summary.escalc() various forest() functions olim consistency (old clim argument continue work) show nicer network graphs dat.hasselblad1998 dat.senn2013 help files added 24 datasets (dat.anand1999, dat.assink2016, dat.baskerville2012, dat.bornmann2007, dat.cannon2006, dat.cohen1981, dat.craft2003, dat.crede2010, dat.dagostino1998, dat.damico2009, dat.dorn2007, dat.hahn2001, dat.kalaian1996, dat.kearon1998, dat.knapp2017, dat.landenberger2005, dat.lau1992, dat.lim2014, dat.lopez2019, dat.maire2019,, dat.moura2021 dat.obrien2003, dat.vanhowe1999, dat.viechtbauer2021) package now runs version check startup interactive sessions; setting environment variable METAFOR_VERSION_CHECK FALSE disables refactored various functions (cleaner/simpler code) improved documentation bit","code":""},{"path":"/news/index.html","id":"metafor-24-0-2020-03-19","dir":"Changelog","previous_headings":"","what":"metafor 2.4-0 (2020-03-19)","title":"metafor 2.4-0 (2020-03-19)","text":"CRAN release: 2020-03-19 version jump 2.4-0 CRAN release (now , even minor numbers CRAN releases, odd numbers development versions) various forest() functions gain header argument escalc() gains include argument setting verbose=3 model fitting functions sets options(warn=1) forest.rma() forest.default() now throw informative errors misusing order subset arguments fixed failing tests due stringsAsFactors=FALSE change upcoming version R print.infl.rma.uni() gains infonly argument, show influential studies removed MASS Suggests (longer needed) argument btt can now also take string grep added optimParallel possible optimizer rma.mv() added (now undocumented) option fit models rma.glmm() via GLMMadaptive package (instead lme4); try , use: control=list(package=\"GLMMadaptive\") started use numbering scheme devel version (number dash indicates devel version) added contrmat() function (creating matrix indicates groups compared row dataset) added .wide() function (restructuring long format datasets wide format needed contrast-based analyses) ^2 H^2 also shown output fixed-effects models argument grid baujat() can now also color name added (now undocumented) time argument functions computationally expensive added (now undocumented) textpos argument various forest functions added new dataset (dat.graves2010) added tests","code":""},{"path":"/news/index.html","id":"metafor-21-0-2019-05-13","dir":"Changelog","previous_headings":"","what":"metafor 2.1-0 (2019-05-13)","title":"metafor 2.1-0 (2019-05-13)","text":"CRAN release: 2019-05-14 added formula() method objects class rma llplot() now also allows measure=\"GEN\"; also, documentation y-axis label corrected indicate function plots likelihoods (log likelihoods) confint.rma.mv() now returns object class list.confint.rma obtaining CIs variance correlation components model; added corresponding print.list.confint.rma() function moved tol argument permutest() control renamed comptol added PMM GENQM estimators rma.uni() added vif() function get variance inflation factors added .glmulti object making interaction glmulti easier added reporter() reporter.rma.uni() dynamically generating analysis reports objects class rma.uni output now styled/colored crayon package loaded (works ‘proper’ terminal color support; also works RStudio) overhauled plot.gosh.rma(); specified, now shows two distributions, one values outlier included one values outlier excluded; dropped hcol argument added border argument refactored influence.rma.uni() consistent internally functions; print.infl.rma.uni() plot.infl.rma.uni() adjusted accordingly; functions cooks.distance.rma.uni(), dfbetas.rma.uni(), rstudent.rma.uni() now call influence.rma.uni() computations rstudent.rma.uni() now computes SE deleted residuals way yield identical results mean shift outlier model even model fitted test=\"knha\" rstandard.rma.uni() gains type argument, can now also compute conditional residuals (still computes marginal residuals default) cooks.distance.rma.mv() gains cluster argument, Cook’s distances can computed groups estimates cooks.distance.rma.mv() gains parallel, ncpus, cl arguments can now make use parallel processing cooks.distance.rma.mv() faster using estimates full model starting values fitting models ith study/cluster deleted dataset cooks.distance.rma.mv() gains reestimate argument; set FALSE, variance/correlation components reestimated rstandard.rma.mv() gains cluster argument computing cluster-level multivariate standardized residuals added rstudent.rma.mv() dfbetas.rma.mv() smarter matching elements newmods (using named vector) predict() also works models interactions (thanks Nicole Erler pointing problem) rma.uni() rma.mv() longer issue (obvious) warnings user constrains vi V 0 (.e., vi=0 V=0, respectively) rma.mv() intelligent filtering based NAs V matrix rma.mv() now ensures strict symmetry (var-cov correlation) matrices specified via R argument fixed rma.mv() checks R argument run intended; also fixed issue multiple formulas slashes specified via random (thanks Andrew Loignon pointing problem) suppressed showing calls warnings/errors rma.mv() rma.mv() now allows continuous-time autoregressive random effects structure (struct=\"CAR\") various spatial correlation structures (struct=\"SPEXP\", \"SPGAU\", \"SPLIN\", \"SPRAT\", \"SPSPH\") rma.mv() now allows struct=\"GEN\" models correlated random effects number predictors, including continuous ones (.e., allows ‘random slopes’) various forest() functions, options(na.action=\"na.pass\") options(na.action=\"na.exclude\") annotation contains NA, now shown blank (instead NA [NA, NA]) various forest() addpoly() functions gain fonts argument various forest() functions gain top argument various forest() functions now show correct point sizes weights studies exactly forest.cumul.rma() gains col argument funnel.default() funnel.rma() can now take vectors input col bg arguments (also pch); functions also gain legend argument addpoly() functions can now also show prediction interval bounds removed ‘formula interface’ escalc(); actually adds kind extra functionality, just makes escalc() confusing use escalc() can now compute coefficient variation ratio variability ratio pre-post matched designs (\"CVRC\", \"VRC\") escalc() bit housekeeping added (currently undocumented) arguments onlyo1, addyi, addvi escalc() allow flexibility computing certain bias corrections computing sampling variances measures make use add arguments escalc() now sets add=0 measures use bias correction makes little sense; applies following measures: \"\", \"PHI\", \"RTET\", \"IRSD\", \"PAS\", \"PFT\", \"IRS\", \"IRFT\"; one can still force use bias correction explicitly setting add argument non-zero value added clim argument summary.escalc() added ilim argument trimfill() labbe() gains lty argument labbe() now (invisibly) returns data frame coordinates points drawn (may useful manual labeling points plot) added print method profile.rma objects profile.rma.mv() now check whether profiled log-likelihood values larger log-likelihood fitted model (using numerical tolerance given lltol) issues warning profile.rma.uni(), profile.rma.mv(), plot.profile.rma() gain cline argument; plot.profile.rma() gains xlim, ylab, main arguments fixed issue robust.rma.mv() model fitted sparse=TRUE (thanks Roger Martineau noting problem) various method functions (fitted(), resid(), predict(), etc.) behave consistent manner model omitted studies missings predict.rma() gains vcov argument; set TRUE, variance-covariance matrix predicted values also returned vcov.rma() can now also return variance-covariance matrix fitted values (type=\"fitted\") residuals (type=\"resid\") added $<- .matrix() methods list.rma objects fixed error simulate.rma() generate many samples rma.mv models added undocumented argument time model fitting functions; set TRUE, model fitting time printed added tests (also parallel operations); also, tests updated use proper tolerances instead rounding reorganized documentation bit","code":""},{"path":"/news/index.html","id":"metafor-20-0-2017-06-22","dir":"Changelog","previous_headings":"","what":"metafor 2.0-0 (2017-06-22)","title":"metafor 2.0-0 (2017-06-22)","text":"CRAN release: 2017-06-22 added simulate() method rma objects; added MASS Suggests (since simulating rma.mv objects requires mvrnorm() MASS) cooks.distance.rma.mv() now works properly even missing values data residuals() gains type argument can compute Pearson residuals newmods argument predict() can now named vector matrix/data frame column names get properly matched variables model added ranef.rma.mv() extracting BLUPs random effects rma.mv models functions repeatedly refit models now option show progress bar added ranktest.default(), user can now pass outcomes corresponding sampling variances directly function added regtest.default(), user can now pass outcomes corresponding sampling variances directly function funnel.default() gains subset argument funnel.default() funnel.rma() gain col bg arguments plot.profile.rma() gains ylab argument consistent handling robust.rma objects added print method rma.gosh objects (log) relative risk now called (log) risk ratio help files, plots, code, comments escalc() can now compute outcome measures based paired binary data (\"MPRR\", \"MPOR\", \"MPRD\", \"MPORC\", \"MPPETO\") escalc() can now compute (semi-)partial correlation coefficients (\"PCOR\", \"ZPCOR\", \"SPCOR\") escalc() can now compute measures variability single groups (\"CVLN\", \"SDLN\") difference variability two groups (\"CVR\", \"VR\"); also log transformed mean (\"MNLN\") added consistency escalc() can now compute sampling variance measure=\"PHI\" studies using stratified sampling (vtpye=\"ST\") [ method escalc objects now properly handles ni slab attributes better job cleaning superfluous variable name information added rbind() method escalc objects added .data.frame() method list.rma objects added new dataset (dat.pagliaro1992) another illustration network meta-analysis added new dataset (dat.laopaiboon2015) effectiveness azithromycin treating lower respiratory tract infections rma.uni() rma.mv() now check ratio largest smallest sampling variance large; results may stable (large ratios typically indicate wrongly coded data) model fitting functions now check extra/superfluous arguments specified via ... issues warning instead defining generic ranef(), import ranef() nlme improved output formatting added tests (disabled tests CRAN avoid issues R compiled --disable-long-double) general code cleanup renamed diagram_metafor.pdf vignette just diagram.pdf minor updates documentation","code":""},{"path":"/news/index.html","id":"metafor-19-9-2016-09-25","dir":"Changelog","previous_headings":"","what":"metafor 1.9-9 (2016-09-25)","title":"metafor 1.9-9 (2016-09-25)","text":"CRAN release: 2016-09-25 started use git version control system, GitHub host repository (https://github.com/wviechtb/metafor) development version package, Travis CI continuous integration service (https://travis-ci.org/wviechtb/metafor), Codecov automated code coverage reporting (https://app.codecov.io/gh/wviechtb/metafor) argument knha rma.uni() argument tdist rma.glmm() rma.mv() now superseded argument test three functions; backwards compatibility, knha tdist arguments still work, longer documented rma(yi, vi, weights=1, test=\"knha\") now yields results rma(yi, vi, weighted=FALSE, test=\"knha\") (use Knapp Hartung method context unweighted analysis remains experimental feature) one can now pass escalc object directly rma.uni(), tries automatically determine yi vi variables data frame (thanks Christian Roever suggestion) escalc() can now also used convert regular data frame escalc object measure=\"UCOR\", exact bias-correction now used (instead approximation); vtype=\"UB\", exact equation now used compute unbiased estimate variance bias-corrected correlation coefficient; hence gsl now suggested package (needed compute hypergeometric function) loaded required cooks.distance() now also works rma.mv objects; since model fitting can take time, option show progress bar added fixed issue robust.rma.mv() throwing errors model fitted sparse=TRUE fixed error robust.rma.mv() model fitted user-defined weights (user-defined weight matrix) added ranef() extracting BLUPs random effects (rma.uni objects moment) reverted back pre-1.1-0 way computing p-values individual coefficients permutest.rma.uni(), , p-value computed mean(abs(z_perm) >= abs(z_obs) - tol) (tol numerical tolerance) permutest.rma.uni() gains permci argument, can used obtain permutation-based CIs model coefficients (note computationally demanding may take long time complete) rma.glmm() continues work even saturated model fitted (although tests heterogeneity available ) rma.glmm() now allows control arguments used method.args (via control=list(hessianCtrl=list(...))) passed hessian() (numDeriv package) using model=\"CM.EL\" measure=\"\" rma.glmm(), default method.args value r passed hessian() increased 16 (slows things bit, appears improve accuracy numerical approximation Hessian, especially tau^2 close 0) various forest() addpoly() functions now new argument called width, provides manual control width annotation columns; useful creating complex forest plots monospaced font want ensure annotations properly lined decimal point annotations created various forest() addpoly() functions now bit compact default flexible efac argument various forest() functions trailing zeros axis labels now dropped forest funnel plots default; trailing zeros can retained specifying numeric (integer) value digits argument added funnel.default(), directly takes input vector observed effect sizes outcomes corresponding sampling variances, standard errors, /sample sizes added plot.profile.rma(), plot method objects returned profile.rma.uni() profile.rma.mv() functions simplified baujat.rma.uni(), baujat.rma.mh(), baujat.rma.peto() baujat.rma(), now handles objects class rma.uni, rma.mh, rma.peto baujat.rma() gains argument symbol control plotting symbol labbe() gains grid argument logical placement labels qqnorm.rma.uni(), qqnorm.rma.mh(), qqnorm.rma.peto() functions (control thereof) qqnorm.rma.uni() gains lty argument added gosh.rma() plot.gosh.rma() creating GOSH (.e., graphical display study heterogeneity) plots based Olkin et al. (2012) (rare) case observed outcomes exactly equal , test=\"knha\" (.e., knha=TRUE) rma() now leads appropriate results updated datasets containing precomputed effect size estimates observed outcomes already declared escalc objects added new datasets (dat.egger2001 dat.li2007) effectiveness intravenous magnesium acute myocardial infarction methods package now Depends (addition Matrix), rma.mv(..., sparse=TRUE) always works, even Rscript general code cleanup added tests (used consistent naming scheme tests)","code":""},{"path":"/news/index.html","id":"metafor-19-8-2015-09-28","dir":"Changelog","previous_headings":"","what":"metafor 1.9-8 (2015-09-28)","title":"metafor 1.9-8 (2015-09-28)","text":"CRAN release: 2015-09-28 due stringent package testing, increasingly difficult ensure package passes checks older versions R; now , package therefore require, checked , current (development) version R added graphics, grDevices, methods Imports (due recent change CRAN checks packages) struct argument rma.mv() now also allows \"ID\" \"DIAG\", identical \"CS\" \"HCS\" structures, correlation parameter fixed 0 added robust() (cluster) robust tests confidence intervals rma.uni rma.mv models (uses robust sandwich-type estimator variance-covariance matrix fixed effects along lines Eicker-Huber-White method) confint() now works models fitted rma.mv() function; variance correlation parameters, function provides profile likelihood confidence intervals; output generated confint() function adjusted general make formatting consistent across different model types objects class rma.mv, profile() now provides profile plots (non-fixed) variance correlation components model component specified user (via sigma2, tau2, rho, gamma2, phi arguments) measure=\"MD\" measure=\"ROM\", one can now choose vtype=\"LS\" (default) vtype=\"HO\"; former computes sampling variances without assuming homoscedasticity, latter assumes homoscedasticity multiple model objects can now passed fitstats(), AIC(), BIC() functions check duplicates slab argument now done subsetting done (suggested Michael Dewey) rma.glmm() now works using add=0, case observed outcomes (e.g., log odds log odds ratios) may NA using rma.glmm() model=\"CM.EL\", saturated model (used compute Wald-type likelihood ratio tests presence (residual) heterogeneity) often fails converge; function now continues run (instead stopping error) simply omits test results output using rma.glmm() model=\"CM.EL\" inversion Hessian fails via Choleski factorization, function now makes another attempt via QR decomposition (even works, warning issued) rma.glmm(), BIC AICc values switched around; corrected use suppressWarnings() made functions repeatedly need fit model, cumul(), influence(), profile(); way, one get inundated warning(s) (overdue) updates documentation","code":""},{"path":"/news/index.html","id":"metafor-19-7-2015-05-22","dir":"Changelog","previous_headings":"","what":"metafor 1.9-7 (2015-05-22)","title":"metafor 1.9-7 (2015-05-22)","text":"CRAN release: 2015-05-22 default optimizer rma.mv() changed nlminb() (instead optim() \"Nelder-Mead\"); extensive testing indicated nlminb() (also optim() \"BFGS\") typically quicker robust; note principle non-backwards compatible change, really necessary one; can always revert old behavior control=list(optimizer=\"optim\", optmethod=\"Nelder-Mead\") tests updated accordance recommended syntax testthat package; example, expect_equivalent(x,y) used instead test_that(x, is_equivalent_to(y)) changed is_identical_to() comparisons expect_equivalent() ones (failed Sparc Solaris)","code":""},{"path":"/news/index.html","id":"metafor-19-6-2015-05-07","dir":"Changelog","previous_headings":"","what":"metafor 1.9-6 (2015-05-07)","title":"metafor 1.9-6 (2015-05-07)","text":"CRAN release: 2015-05-07 funnel() now works rma.glmm objects (note self: quit breaking things work!) rma.glmm() now issue warning (error) Hessian saturated model inverted (needed compute Wald-type test heterogeneity, test statistic simply set NA) rma.mv() now allows two terms form ~ inner | outer; variance components corresponding structure called gamma2 correlations called phi; functions work objects class rma.mv updated accordingly rma.mv() now provides (even) optimizer choices: nlm() stats package, hjk() nmk() dfoptim package, ucminf() ucminf package; choose desired optimizer via control argument (e.g., control=list(optimizer=\"nlm\")) profile.rma.uni() profile.rma.mv() now can parallel processing (especially relevant rma.mv objects, profiling crucial model fitting can slow) various confint() functions now transf argument (apply kind transformation model coefficients confidence interval bounds); coefficients bounds objects class rma.mh rma.peto longer automatically transformed various forest() functions longer enforce actual x-axis limits (alim) encompass observed outcomes plotted; also, outcomes actual x-axis limits longer shown various forest() functions now provide control horizontal lines (top/bottom) automatically added plot via lty argument (also allows removing ); also, vertical reference line now placed behind points/CIs forest.default() now argument col can used specify color(s) used drawing study labels, points, CIs, annotations efac argument forest.rma() now also allows two values, first arrows CI limits, second summary estimates corrected axis labels various plots measure=\"PLO\" axes labbe() plots now \"(Group 1)\" \"(Group 2)\" added default anova.rma() gains argument L specifying linear combinations coefficients model tested zero case removal row data lead one inestimable model coefficients, baujat(), cooks.distance(), dfbetas(), influence(), rstudent() fail rma.uni objects; cases now handled properly models moderators, predict() function now shows study labels specified user (newmods used) one fixed effect (model coefficient) model, print.infl.rma.uni() function now shows DFBETAS values case diagnostics single table (easier inspection); one fixed effect, separate table still used DFBETAS values (one column coefficient) added measure=\"SMCRH\" escalc() function standardized mean change using raw score standardization heteroscedastic population variances two measurement occasions added measure=\"ROMC\" escalc() function (log transformed) ratio means (response ratio) means reflect two measurement occasions (e.g., single group people) hence correlated added function computing/estimating tetrachoric correlation coefficient (measure=\"RTET\"); package therefore longer suggests polycor now suggest mvtnorm (loaded needed) element fill returned trimfill.rma.uni() now logical vector (instead 0/1 dummy variable) print.list.rma() now also returns printed results invisibly data frame added new dataset (dat.senn2013) another illustration network meta-analysis metafor now depends least version 3.1.0 R","code":""},{"path":"/news/index.html","id":"metafor-19-5-2014-11-24","dir":"Changelog","previous_headings":"","what":"metafor 1.9-5 (2014-11-24)","title":"metafor 1.9-5 (2014-11-24)","text":"CRAN release: 2014-11-24 moved stats Matrix packages Depends Imports; result, add utils Imports; moved Formula package Depends Suggests added update.rma() function (updating/refitting model); model objects also now store keep call vcov() function now also extracts marginal variance-covariance matrix observed effect sizes outcomes fitted model (class rma.uni rma.mv) rma.mv() now makes use Cholesky decomposition random = ~ inner | outer formula struct=\"UN\"; numerically stable old approach avoided non-positive definite solutions forcing log-likelihood -Inf cases; old behavior can restored control = list(cholesky=FALSE) rma.mv() now requires inner variable ~ inner | outer formula factor character variable (except struct \"AR\" \"HAR\"); use ~ factor(inner) | outer case isn’t anova.rma.uni() function changed anova.rma() works now rma.uni rma.mv objects profile.rma.mv() function now omits number variance correlation component plot title x-axis label model includes one respective parameters profile() functions now pass ... argument also title() function used create figure titles (esp. relevant using cex.main argument) drop00 argument rma.mh() rma.peto() functions now also accepts vector two logicals, first applies calculating observed outcomes, second applying Mantel-Haenszel Peto’s method weights.rma.uni() now shows correct weights weighted=FALSE argument showweight renamed showweights forest.default() forest.rma() functions (consistent naming various weights() functions) added model.matrix.rma() function (extract model matrix objects class rma) funnel() radial() now (invisibly) return data frames coordinates points drawn (may useful manual labeling points plots) permutest.rma.uni() function now uses numerical tolerance making comparisons (>= <=) observed test statistic test statistic permuted data; using random permutations, function now ensures first permutation correspond original data corrected missing/redundant row/column labels output require() calls replaced requireNamespace() avoid altering search path (hopefully won’t break stuff …) non-visible changes including use (non-exported) helper functions common tasks dataset dat.collins91985a updated (including reported outcomes information various trials) oh, guess ? updated documentation …","code":""},{"path":"/news/index.html","id":"metafor-19-4-2014-07-30","dir":"Changelog","previous_headings":"","what":"metafor 1.9-4 (2014-07-30)","title":"metafor 1.9-4 (2014-07-30)","text":"CRAN release: 2014-07-30 added method=\"GENQ\" rma.uni() generalized Q-statistic estimator tau^2, allows used-defined weights (note: DL estimators just special cases method) model fitted method=\"GENQ\", confint() now use generalized Q-statistic method construct corresponding confidence interval tau^2 (thanks Dan Jackson code); iterative method used obtain CI makes use Farebrother’s algorithm implemented CompQuadForm package slight improvements rma.uni() function handles non-positive sampling variances rma.uni(), rma.mv(), rma.glmm() now try detect remove redundant predictors model fitting; therefore, exact linear relationships among predictor variables (.e., perfect multicollinearity), terms removed obtain set predictors longer perfectly multicollinear (warning issued happens); note order variables specified model formula can influence terms removed last update introduced error hat values computed model fitted rma() function using Knapp & Hartung method (.e., knha=TRUE); fixed regtest() longer works (now) rma.mv objects (wasn’t meant first place); want run something along lines, just consider adding measure precision observed outcomes (e.g., standard errors) predictor model added \"sqrtni\" \"sqrtninv\" possible options predictor argument regtest() optimizers now available rma.mv() function via nloptr package setting control = list(optimizer=\"nloptr\"); using optimizer, default use BOBYQA implementation package relative convergence criterion 1e-8 function value (see documentation change defaults) predict.rma() function now works rma.mv objects multiple tau^2 values even user specifies newmods argument tau2.levels argument (warning issued prediction intervals computed) argument var.names now works properly escalc() user made use data argument (thanks Jarrett Byrnes bringing attention) added plot() function cumulative random-effects models results obtained cumul.rma.uni() function; plot shows model estimate x-axis corresponding tau^2 estimate y-axis cumulative order results fixed omitted offset term underlying model fitted rma.glmm() function method=\"ML\", measure=\"IRR\", model=\"UM.FS\", , fitting mixed-effects Poisson regression model fixed study effects two-group event count data (thanks Peter Konings pointing error) added two new datasets (dat.bourassa1996, dat.riley2003) added function replmiss() (just useful helper function) package now uses LazyData: TRUE improvements documentation (still need mention every time?)","code":""},{"path":"/news/index.html","id":"metafor-19-3-2014-05-05","dir":"Changelog","previous_headings":"","what":"metafor 1.9-3 (2014-05-05)","title":"metafor 1.9-3 (2014-05-05)","text":"CRAN release: 2014-05-05 minor tweaks rma.uni() user transparent rma.uni() now weights argument, allowing user specify arbitrary user-defined weights; functions affected updated accordingly better handling mismatched length yi ni vectors rma.uni() rma.mv() functions subsetting now handled early possible within functions subsetting capabilities; avoids (rare) cases studies ultimately excluded subsetting still affect results general tweaks rma.mv() make bit faster argument V rma.mv() now also accepts list var-cov matrices observed effects outcomes; list elements, full (block diagonal) var-cov matrix V automatically constructed rma.mv() now new argument W allowing user specify arbitrary user-defined weights arbitrary weight matrix rma.mv() now new argument sparse; setting TRUE, function uses sparse matrix objects extent possible; can speed model fitting substantially certain models (hence, metafor package now depends Matrix package) rma.mv() now allows struct=\"AR\" struct=\"HAR\", fit models (heteroscedastic) autoregressive (AR1) structures among true effects (useful meta-analyses studies reporting outcomes multiple time points) rma.mv() now new argument Rscale can used control matrices specified via R argument scaled (see docs details) rma.mv() now checks missing values rows lower triangular part V matrix (including diagonal); way, Vi = matrix(c(.5,NA,NA,NA), nrow=2, ncol=2) var-cov matrix sampling errors particular study two outcomes, second row/column needs removed model fitting (entire study) added five new datasets (dat.begg1989, dat.ishak2007, dat.fine1993, dat.konstantopoulos2011, dat.hasselblad1998) provide illustrations use rma.mv() function (meta-analyses combining controlled uncontrolled studies, meta-analyses longitudinal studies, multilevel meta-analyses, network meta-analyses / mixed treatment comparison meta-analyses) added rstandard.rma.mv() function compute standardized residuals models fitted rma.mv() function (rstudent.rma.mv() added later point); also added hatvalues.rma.mv() computing hat values weights.rma.uni() computing weights (.e., diagonal elements weight matrix) various weights() functions now new argument type indicate whether diagonal elements weight matrix (default) entire weight matrix returned various hatvalues() functions now new argument type indicate whether diagonal elements hat matrix (default) entire hat matrix returned predict.rma() function now works properly rma.mv objects (also new argument tau2.levels specify, applicable, levels inner factor computing prediction intervals) forest.rma() function now provides bit control color summary polygon now compatible rma.mv objects; also, new argument lty, provides control line type individual CIs prediction interval addpoly.default() addpoly.rma() now border argument (consistency forest.rma() function); addpoly.rma() now yields correct CI bounds model fitted knha=TRUE forest.cumul.rma() now provides correct CI bounds models fitted Knapp & Hartung method (.e., knha=TRUE original rma() function call) various forest() functions now return information chosen values arguments xlim, alim, , ylim, rows, cex, cex.lab, cex.axis invisibly (useful tweaking default values); thanks Michael Dewey suggestion various forest() functions now new argument, clim, set limits confidence/prediction interval bounds cumul.mh() cumul.peto() now get order studies right missing values data transf argument leave1out.rma.mh(), leave1out.rma.peto(), cumul.rma.mh(), cumul.rma.peto() now used specify actual function transformation (former behavior setting argument TRUE exponentiate log RRs, log ORs, log IRRs still works back-compatibility); consistent cumul.rma.uni() leave1out.rma.uni() functions work also flexible added bldiag() function construct block diagonal matrix (list ) matrices (may needed construct V matrix using rma.mv() function); bdiag() function Matrix package thing, creates sparse matrix objects profile.rma.mv() now startmethod argument; setting \"prev\", successive model fits started parameter estimates previous model fit; may speed things bit; also, method automatically choosing xlim values changed slight improvement profile.rma.mv() function, throw error last model fit converge added new dataset (dat.linde2005) replication analyses Viechtbauer (2007) added new dataset (dat.molloy2014) illustrating meta-analysis (r--z transformed) correlation coefficients added new dataset (dat.gibson2002) illustrate combined analysis standardized mean differences probit transformed risk differences computations weights.mh() slightly changed prevent integer overflows large counts unnecessary warnings transf.ipft.hm() now suppressed (cases raised warnings already handled correctly) predict(), blup(), cumul(), leave1out(), using transf argument, standard errors (NA) longer shown output argument slab various functions now also accept non-unique study labels; make.unique() used needed make unique vignettes(\"metafor\") vignettes(\"metafor_diagram\") work (yes, know true vignettes strict sense, think show CRAN website package using minimal valid Sweave document recognized R build system makes happen) escalc() summary() method now keep better track data frame contains multiple columns outcome effect size values (corresponding sampling variances) print formatting; also simplified class structure bit (hence, print.summary.escalc() removed) summary.escalc() new argument H0 specify value outcome null hypothesis computing test statistics added measures \"OR2DN\" \"D2ORN\" escalc() transforming log odds ratios standardized mean differences vice-versa, based method Cox & Snell (1989), assumes normally distributed response variables within two groups dichotomization permutest.rma.uni() function now catches error number permutations requested large (R even create objects store results ) produces proper error message funnel.rma() function now allows yaxis argument set \"wi\" actual weights (%) placed y-axis (useful arbitrary user-defined specified) rma.glmm(), control argument optCtrl now used passing control arguments optimizers (hence, control arguments nlminbCtrl minqaCtrl now defunct) rma.glmm() throw error anymore including single moderator/predictor model predict.rma() now returns object class list.rma (therefore, function print.predict.rma() removed) rma.list objects, added [, head(), tail() methods automated testing using testthat package (still many tests add, finally made start ) encoding changed UTF-8 (use ‘foreign characters’ docs make HTML help files look bit nicer) guess ? improvements documentation! (also combined help files reduce size manual bit; yes, ’s still way big)","code":""},{"path":"/news/index.html","id":"metafor-19-2-2013-10-07","dir":"Changelog","previous_headings":"","what":"metafor 1.9-2 (2013-10-07)","title":"metafor 1.9-2 (2013-10-07)","text":"CRAN release: 2013-10-07 added function rma.mv() fit multivariate/multilevel meta-analytic models via appropriate linear (mixed-effects) models; function allows modeling non-independent sampling errors /true effects can used network meta-analyses, meta-analyses accounting phylogenetic relatedness, complicated meta-analytic data structures added AICc information criteria computed various model fitting functions value tau^2 fixed user via corresponding argument rma.uni(), tau^2 longer counted additional parameter computation information criteria (.e., AIC, BIC, AICc) rma.uni(), rma.glmm(), rma.mv() now use stringent check whether model matrix full rank added profile() method functions objects class rma.uni rma.mv (can used obtain plot profiled log-likelihood function specific variance component correlation parameter model) predict.rma() function now intercept argument allows user decide whether intercept term included calculating predicted values (rare changed default) rma.uni(), rma.glmm(), rma.mv(), control argument can now also accept integer value; values > 1 generate verbose output progress inside function rma.glmm() updated work lme4 1.0.x fitting various models; result, model=\"UM.RS\" can use nAGQ=1 moment (hopefully change future) control argument rma.glmm() can now used pass desired control arguments various functions optimizers used model fitting (admittedly use lists within argument bit unwieldy, much flexible) rma.mh() rma.peto() also now verbose argument (really needed, added sake consistency across functions) fixed (silly) error prevent rma.glmm() running measures \"IRR\", \"PLO\", \"IRLN\" missing values data (lesson: add missing values datasets unit tests!) bit code reorganization (user transparent) vignettes (\"metafor\" \"metafor_diagram\") now just ‘files’ doc directory (true vignettes begin ) improvements documentation (always)","code":""},{"path":"/news/index.html","id":"metafor-19-1-2013-07-20","dir":"Changelog","previous_headings":"","what":"metafor 1.9-1 (2013-07-20)","title":"metafor 1.9-1 (2013-07-20)","text":"CRAN release: 2013-07-20 rma.mh() now also implements Mantel-Haenszel method incidence rate differences (measure=\"IRD\") analyzing incidence rate ratios (measure=\"IRR\") rma.mh() function, Mantel-Haenszel test person-time data now also provided rma.mh() new argument correct (default TRUE) indicate whether continuity correction applied computing (Cochran-)Mantel-Haenszel test statistic renamed elements CMH CMHp (Cochran-Mantel-Haenszel test statistic corresponding p-value) MH MHp added function baujat() create Baujat plots added new dataset (dat.pignon2000) illustrate use baujat() function added function .table() convert data vector format corresponding table format added function .long() convert data vector format corresponding long format rma.glmm() now even runs k=1 (yielding trivial results) models intercept moderators, rma.glmm() now internally rescales (non-dummy) variables z-scores model fitting (improves stability model fitting, especially model=\"CM.EL\"); results given back-scaling, transparent user rma.glmm(), default number quadrature points (nAGQ) now 7 (setting 100 bit overkill) error checks misspecified arguments improvements documentation","code":""},{"path":"/news/index.html","id":"metafor-19-0-2013-06-21","dir":"Changelog","previous_headings":"","what":"metafor 1.9-0 (2013-06-21)","title":"metafor 1.9-0 (2013-06-21)","text":"CRAN release: 2013-06-21 vignette renamed metafor vignette(\"metafor\") works now added diagram documentation, showing various functions metafor package (relate ); can loaded vignette(\"metafor_diagram\") anova.rma.uni() function can now also used test (sub)sets model coefficients Wald-type test single model passed function pseudo R^2 statistic now automatically calculated rma.uni() function supplied output (mixed-effects models model includes intercept, random- effects model clearly nested within mixed-effects model) component VAF now called R2 anova.rma.uni() function added function hc() carries random-effects model analysis using method Henmi Copas (2010); thanks Michael Dewey suggestion providing code added new dataset (dat.lee2004), used article Henmi Copas (2010) illustrate method fixed missing x-axis labels forest() functions rma.glmm() now computes Hessian matrices via numDeriv package model=\"CM.EL\" measure=\"\" (.e., conditional logistic model exact likelihood); numDeriv now suggested package loaded within rma.glmm() required trimfill.rma.uni() now also implements \"Q0\" estimator (although \"L0\" \"R0\" estimators generally preferred) trimfill.rma.uni() now also calculates SE estimated number missing studies , estimator \"R0\", provides formal test null hypothesis number missing studies given side zero added new dataset (dat.bangertdrowns2004) level argument various functions now either accepts value representing percentage proportion (values greater 1 assumed percentage) summary.escalc() now computes confidence intervals correctly using transf argument computation Cochran-Mantel-Haenszel statistic rma.mh() changed slightly avoid integer overflow big counts internal improvements respect object attributes getting discarded subsetting general code cleanup improvements documentation","code":""},{"path":"/news/index.html","id":"metafor-18-0-2013-04-11","dir":"Changelog","previous_headings":"","what":"metafor 1.8-0 (2013-04-11)","title":"metafor 1.8-0 (2013-04-11)","text":"CRAN release: 2013-04-11 added additional clarifications change score outcome measures (\"MC\", \"SMCC\", \"SMCR\") help file escalc() function changed code \"SMCR\" longer expects argument sd2i specified (needed anyways) (thanks Markus Kösters bringing attention) sampling variance biserial correlation coefficient (\"RBIS\") now calculated slightly accurate way llplot() now properly scales log-likelihoods argument plot.infl.rma.uni() function replaced argument plotinf can now also set FALSE suppress plotting various case diagnostics altogether labeling axes labbe() plots now correct odds ratios (transformations thereof) added two new datasets (dat.nielweise2007 dat.nielweise2008) illustrate methods/models rma.glmm() function added new dataset (dat.yusuf1985) illustrate use rma.peto() test heterogeneity now conducted rma.peto() function exactly described Yusuf et al. (1985) rma.glmm(), default number quadrature points (nAGQ) now 100 (quite bit slower, provide sufficient accuracy cases) standard errors HS DL estimators tau^2 now correctly computed tau^2 prespecified user rma() function; addition, standard error SJ estimator also now provided tau^2 prespecified rma.uni() rma.glmm() now use better method check whether model matrix full rank ^2 H^2 statistics now also calculated mixed-effects models rma.uni() rma.glmm() function; confint.rma.uni() provides corresponding confidence intervals rma.uni models various print() methods now new argument called signif.stars, defaults getOption(\"show.signif.stars\") (default TRUE) determine whether infamous ‘significance stars’ printed slight changes wording output produced print.rma.uni() print.rma.glmm() functions improvements documentation","code":""},{"path":"/news/index.html","id":"metafor-17-0-2013-02-06","dir":"Changelog","previous_headings":"","what":"metafor 1.7-0 (2013-02-06)","title":"metafor 1.7-0 (2013-02-06)","text":"CRAN release: 2013-02-06 added rma.glmm() function fitting appropriate generalized linear (mixed-effects) models analyzing odds ratios, incidence rate ratios, proportions, rates; function makes use lme4 BiasedUrn packages; now suggested packages loaded within rma.glmm() required (makes faster loading metafor package) added several method functions objects class rma.glmm (methods yet implemented; completed future) rma.uni() now allows user specify formula yi argument, instead rma(yi, vi, mods=~mod1+mod2), one can specify model rma(yi~mod1+mod2, vi) rma.uni() now weights argument specify inverse sampling variances (instead using vi sei arguments); now, argument used (future, argument may potentially used allow user define alternative weights) rma.uni() now checks whether model matrix full rank issues error accordingly (instead rather cryptic error issued ) rma.uni() now verbose argument coef.rma() now returns model coefficients (change necessary make package compatible multcomp package; see help(rma) example); use coef(summary()) obtain full table results escalc() function now extensive error checking misspecified data unusual cases append argument now TRUE default escalc() function objects generated escalc() function now class added print() summary() methods objects class escalc added [ cbind() methods objects class escalc added additional arguments escalc() function (.e., slab, subset, var.names, replace, digits) added drop00 argument escalc(), rma.uni(), rma.mh(), rma.peto() functions added \"MN\", \"MC\", \"SMCC\", \"SMCR\" measures escalc() rma.uni() functions raw mean, raw mean change, standardized mean change (change score raw score standardization) possible outcome measures \"IRFT\" measure escalc() rma.uni() functions now computed 1/2*(sqrt(xi/ti) + sqrt(xi/ti+1/ti)) consistent definition Freeman-Tukey transformation proportions added \"RTET\" measure escalc() rma.uni() functions compute tetrachoric correlation coefficient based 2x2 table data (polycor package therefore now suggested package, loaded within escalc() required) added \"RPB\" \"RBIS\" measures escalc() rma.uni() functions compute point-biserial biserial correlation coefficient based means standard deviations added \"PBIT\" \"OR2D\" measures escalc() rma.uni() functions compute standardized mean difference based 2x2 table data added \"D2OR\" measure escalc() rma.uni() functions compute log odds ratio based standardized mean difference added \"SMDH\" measure escalc() rma.uni() functions compute standardized mean difference without assuming equal population variances added \"ARAW\", \"AHW\", \"ABT\" measures escalc() rma.uni() functions raw value Cronbach’s alpha, transformation suggested Hakstian & Whalen (1976), transformation suggested Bonett (2002) meta-analysis reliability coefficients (see help(escalc) details) corrected small mistake equation used compute sampling variance phi coefficient (measure=\"PHI\") escalc() function permutest.rma.uni() function now uses algorithm find unique permutations model matrix (may much smaller total number permutations), making exact permutation test feasible larger set circumstances (thanks John Hodgson making aware issue Hans-Jörg Viechtbauer coming recursive algorithm finding unique permutations) prediction interval forest.rma() now indicated dotted (instead dashed) line; ends interval now marked vertical bars completely rewrote funnel.rma() function now supports many options values put y-axis; trimfill.rma.uni() function adapted accordingly removed ni argument regtest.rma() function; instead, sample sizes can now explicitly specified via ni argument using rma.uni() function (.e., measure=\"GEN\"); escalc() function also now adds information ni values resulting data frame (attribute yi variable), , possible, information passed regtest.rma() added switch regtest() can also provide full results fitted model (thanks Michael Dewey suggestion) weights.rma.mh() now shows weights % intended (thanks Gavin Stewart pointing error) flexible handling digits argument various forest functions forest functions now use pretty() default set x-axis tick locations (alim arguments can still used complete control) studies considered ‘influential’ now marked asterisk printing results returned influence.rma.uni() function (see documentation function details studies identified) added additional extractor functions influence measures (.e., cooks.distance(), dfbetas()); unfortunately, covratio() dffits() functions stats package generic; , avoid masking, currently extractor functions measures better handling missing values unusual situations corrected small bug fsn() allow user specify standard errors instead sampling variances (thanks Bernd Weiss pointing ) plot.infl.rma.uni() function now allows user specify plots draw (layout) adds option show study labels x-axis added proper print() method objects generated confint.rma.uni(), confint.rma.mh(), confint.rma.peto() functions transf atransf argument monotonically decreasing function, confidence prediction interval bounds reversed order; various functions now check order bounds correctly trimfill.rma.uni() now prints information number imputed studies actually printing model object qqnorm.rma.uni(), qqnorm.rma.mh(), qqnorm.rma.peto() functions now new argument called label, allows labeling points; functions also now return (invisibly) x y coordinates points drawn rma.mh() measure=\"RD\" now computes standard error estimated risk difference based Sato, Greenland, & Robins (1989), provides consistent estimate large-stratum sparse-data limiting models restricted maximum likelihood (REML) now calculated using full likelihood equation (without leaving additive constants) model deviance now calculated -2 times difference model log-likelihood log-likelihood saturated model (appropriate definition deviance just taking -2 times model log-likelihood) dat.bcg      -> dat.colditz1994 dat.warfarin -> dat.hart1999 dat.los      -> dat.normand1999 dat.co2      -> dat.curtis1998 dat.empint   -> dat.mcdaniel1994 dat.bcg kept alias dat.colditz1994, referenced name publications added new dataset (dat.pritz1997) illustrate meta-analysis proportions (raw values transformations thereof) added new dataset (dat.bonett2010) illustrate meta-analysis Cronbach’s alpha values (raw values transformations thereof) added new datasets (dat.hackshaw1998, dat.raudenbush1985) (approximate) standard error tau^2 estimate now computed shown (residual) heterogeneity estimators added nobs() df.residual() methods objects class rma metafor.news() now simply wrapper news(package=\"metafor\") package code now byte-compiled, yields modest increases execution speed general code cleanup metafor package longer depends nlme package improvements documentation","code":""},{"path":"/news/index.html","id":"metafor-16-0-2011-04-13","dir":"Changelog","previous_headings":"","what":"metafor 1.6-0 (2011-04-13)","title":"metafor 1.6-0 (2011-04-13)","text":"CRAN release: 2011-04-13 trimfill.rma.uni() now returns proper object even number missing studies estimated zero added (log transformed) ratio means possible outcome measure escalc() rma.uni() functions (measure=\"ROM\") added new dataset (dat.co2) illustrate use ratio means outcome measure additional error checking various forest functions (especially using ilab argument) labbe.rma(), solid dashed lines now drawn behind (top ) points slight change transf.ipft.hm() missing values targs$ni ignored improvements documentation","code":""},{"path":"/news/index.html","id":"metafor-15-0-2010-12-16","dir":"Changelog","previous_headings":"","what":"metafor 1.5-0 (2010-12-16)","title":"metafor 1.5-0 (2010-12-16)","text":"CRAN release: 2010-12-16 metafor package now project website : https://www.metafor-project.org/ added labbe() function create L’Abbe plots forest.default() addpoly.default() functions now allow user directly specify lower upper confidence interval bounds (can useful CI bounds calculated methods/functions) added incidence rate single group two groups (transformations thereof) possible outcome measures escalc() rma.uni() functions (measure=\"IRR\", \"IRD\", \"IRSD\", \"IR\", \"IRLN\", \"IRS\", \"IRFT\") added incidence rate ratio possible outcome measure rma.mh() function added transformation functions related incidence rates added Freeman-Tukey double arcsine transformation inverse transformation functions added additional error checking --range p-values permutest.rma.uni() function added additional checking --range values several transformation functions added confint() methods rma.mh rma.peto objects (completeness sake; print already provides CIs) added new datasets (dat.warfarin, dat.los, dat.empint) improvements documentation","code":""},{"path":"/news/index.html","id":"metafor-14-0-2010-07-30","dir":"Changelog","previous_headings":"","what":"metafor 1.4-0 (2010-07-30)","title":"metafor 1.4-0 (2010-07-30)","text":"CRAN release: 2010-07-30 paper package now published Journal Statistical Software (https://www.jstatsoft.org/v36/i03/) added citation info; see: citation(\"metafor\") metafor package now depends nlme package added extractor functions AIC, BIC, deviance updates documentation","code":""},{"path":"/news/index.html","id":"metafor-13-0-2010-06-25","dir":"Changelog","previous_headings":"","what":"metafor 1.3-0 (2010-06-25)","title":"metafor 1.3-0 (2010-06-25)","text":"CRAN release: 2010-06-25 metafor package now depends Formula package made escalc() generic implemented default formula interface added (inverse) arcsine transformation set transformation functions","code":""},{"path":"/news/index.html","id":"metafor-12-0-2010-05-18","dir":"Changelog","previous_headings":"","what":"metafor 1.2-0 (2010-05-18)","title":"metafor 1.2-0 (2010-05-18)","text":"cases k small (e.g., k equal 1 2) now handled gracefully added sanity check cases observed outcomes equal (led division zero using Knapp & Hartung method) “smarter way set number iterations permutation tests” (see notes previous version ) now actually works like supposed permutest.rma.uni() function now provides sensible results k small; documentation function also updated notes use permutation tests circumstances made general improvements various forest plot functions making flexible particular creating complex displays; importantly, added rows argument removed addrows argument additional examples added help files forest addpoly functions demonstrate create complex displays functions added showweight argument forest.default() forest.rma() functions cumul() functions showing output columns using fixed-effects models corrected weights.rma.uni() function now handles NAs appropriately weights.rma.mh() weights.rma.peto() functions added logLik.rma() function now behaves like logLik() functions (logLik.lm() logLik.lme())","code":""},{"path":"/news/index.html","id":"metafor-11-0-2010-04-28","dir":"Changelog","previous_headings":"","what":"metafor 1.1-0 (2010-04-28)","title":"metafor 1.1-0 (2010-04-28)","text":"CRAN release: 2010-04-28 cint() generic removed replaced confint() method objects class rma.uni slightly improved code set x-axis title forest() funnel() functions added coef() method permutest.rma.uni objects added append argument escalc() function implemented smarter way set number iterations permutation tests (.e., permutest.rma.uni() function now switch exact test number iterations required exact test actually smaller requested number iterations approximate test) changed way p-values individual coefficients calculated permutest.rma.uni() ‘two times one-tailed area permutation distribution’ (consistent way typically define two-tailed p-values) added retpermdist argument permutest.rma.uni() return permutation distributions test statistics slight improvements various transformation functions cope better extreme cases p-values now calculated way small p-values stored fitted model objects longer truncated 0 (printed results still truncated depending number digits specified) changed default number iterations ML, REML, EB estimators 50 100","code":""},{"path":"/news/index.html","id":"metafor-10-1-2010-02-02","dir":"Changelog","previous_headings":"","what":"metafor 1.0-1 (2010-02-02)","title":"metafor 1.0-1 (2010-02-02)","text":"CRAN release: 2010-02-02 version jump conjunction upcoming publication paper Journal Statistical Software describing metafor package instead specifying model matrix, user can now specify model formula mods argument rma() function (e.g., like lm() function) permutest() function now allows exact permutation tests (feasible k large) forest() function now uses level argument properly adjust CI level summary estimate models without moderators (.e., fixed- random-effets models) forest() function can now also show prediction interval dashed line random-effects model information measure used now passed forest() funnel() functions, try set appropriate x-axis title accordingly funnel() function now arguments (e.g., atransf, ) providing control display x-axis predict() function now print() method new argument called addx, adds values moderator variables returned object (addx=TRUE) functions now properly handle na.action \"na.pass\" (treated essentially like \"na.exclude\") added method weights() extract weights used fitting models rma.uni() small improvements documentation","code":""},{"path":"/news/index.html","id":"metafor-05-7-2009-12-06","dir":"Changelog","previous_headings":"","what":"metafor 0.5-7 (2009-12-06)","title":"metafor 0.5-7 (2009-12-06)","text":"CRAN release: 2009-12-06 added permutest() function permutation tests added metafor.news() function display NEWS file metafor package within R (based idea animate package Yihui Xie) added checks values machine precision bit code reorganization (nothing affects functions work)","code":""},{"path":"/news/index.html","id":"metafor-05-6-2009-10-19","dir":"Changelog","previous_headings":"","what":"metafor 0.5-6 (2009-10-19)","title":"metafor 0.5-6 (2009-10-19)","text":"small changes computation DFFITS DFBETAS values influence() function, statistics line definitions regular linear regression models added option plot function objects returned influence() allow plotting covariance ratios log scale (now default) slight adjustments various print() functions (catch errors certain values NA) added control option rma() adjust step length Fisher scoring algorithm constant factor (may useful algorithm converge)","code":""},{"path":"/news/index.html","id":"metafor-05-5-2009-10-08","dir":"Changelog","previous_headings":"","what":"metafor 0.5-5 (2009-10-08)","title":"metafor 0.5-5 (2009-10-08)","text":"CRAN release: 2009-10-08 added phi coefficient (measure=\"PHI\"), Yule’s Q (\"YUQ\"), Yule’s Y (\"YUY\") additional measures escalc() function 2x2 table data forest plots now order studies first study top plot last study bottom (order can still set order subset argument) added cumul() function cumulative meta-analyses (corresponding forest() method plot cumulative results) added leave1out() function leave-one-diagnostics added option qqnorm.rma.uni() user can choose whether apply Bonferroni correction bounds pseudo confidence envelope internal changes class methods names small corrections documentation","code":""},{"path":"/news/index.html","id":"metafor-05-4-2009-09-18","dir":"Changelog","previous_headings":"","what":"metafor 0.5-4 (2009-09-18)","title":"metafor 0.5-4 (2009-09-18)","text":"CRAN release: 2009-09-18 corrected trimfill() function improvements various print functions added regtest() function various regression tests funnel plot asymmetry (e.g., Egger’s regression test) made ranktest() generic added method objects class rma test can carried fitting added anova() function full vs reduced model comparisons via fit statistics likelihood ratio tests added Orwin Rosenberg approaches fsn() added H^2 measure output random-effects models escalc(), measure=\"COR\" now used (usual) raw correlation coefficient measure=\"UCOR\" bias corrected correlation coefficients small corrections documentation","code":""},{"path":"/news/index.html","id":"metafor-05-3-2009-07-31","dir":"Changelog","previous_headings":"","what":"metafor 0.5-3 (2009-07-31)","title":"metafor 0.5-3 (2009-07-31)","text":"CRAN release: 2009-07-31 small changes examples added log transformed proportion (measure=\"PLN\") another measure escalc() function; changed \"PL\" \"PLO\" logit (.e., log odds) transformation proportions","code":""},{"path":"/news/index.html","id":"metafor-05-2-2009-07-06","dir":"Changelog","previous_headings":"","what":"metafor 0.5-2 (2009-07-06)","title":"metafor 0.5-2 (2009-07-06)","text":"added option plot.infl.rma.uni() open new device plotting DFBETAS values thanks Jim Lemon, added much better method adjusting size labels, annotations, symbols forest() function number studies large","code":""},{"path":"/news/index.html","id":"metafor-05-1-2009-06-14","dir":"Changelog","previous_headings":"","what":"metafor 0.5-1 (2009-06-14)","title":"metafor 0.5-1 (2009-06-14)","text":"made small changes documentation (typos corrected, confusing points clarified)","code":""},{"path":"/news/index.html","id":"metafor-05-0-2009-06-05","dir":"Changelog","previous_headings":"","what":"metafor 0.5-0 (2009-06-05)","title":"metafor 0.5-0 (2009-06-05)","text":"CRAN release: 2009-06-05 first version released CRAN","code":""}]
